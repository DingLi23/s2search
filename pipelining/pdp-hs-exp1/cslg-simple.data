{"id": 15198, "s2_id": "7ea5d034a98776207fd6e1ae021016ea0c1dab5d", "title": "Stabilizing Equilibrium Models by Jacobian Regularization", "abstract": "Deep equilibrium networks (DEQs) are a new class of models that eschews traditional depth in favor of finding the fixed point of a single nonlinear layer. These models have been shown to achieve performance competitive with the stateof-the-art deep networks while using significantly less memory. Yet they are also slower, brittle to architectural choices, and introduce potential instability to the model. In this paper, we propose a regularization scheme for DEQ models that explicitly regularizes the Jacobian of the fixed-point update equations to stabilize the learning of equilibrium models. We show that this regularization adds only minimal computational cost, significantly stabilizes the fixed-point convergence in both forward and backward passes, and scales well to high-dimensional, realistic domains (e.g., WikiText-103 language modeling and ImageNet classification). Using this method, we demonstrate, for the first time, an implicit-depth model that runs with approximately the same speed and level of performance as popular conventional deep networks such as ResNet-101, while still maintaining the constant memory footprint and architectural simplicity of DEQs. Code is available here.", "venue": "ICML", "authors": ["Shaojie  Bai", "Vladlen  Koltun", "J. Zico Kolter"], "year": 2021, "n_citations": 2}
{"id": 15835, "s2_id": "50c6889b547cc08a203842d5cf5bcb4c58e052b5", "title": "TPsgtR: Neural-Symbolic Tensor Product Scene-Graph-Triplet Representation for Image Captioning", "abstract": "Image captioning can be improved if the structure of the graphical representations can be formulated with conceptual positional binding. In this work, we have introduced a novel technique for caption generation using the neural-symbolic encoding of the scene-graphs, derived from regional visual information of the images and we call it Tensor Product Scene-Graph-Triplet Representation (TP$_{sgt}$R). While, most of the previous works concentrated on identification of the object features in images, we introduce a neuro-symbolic embedding that can embed identified relationships among different regions of the image into concrete forms, instead of relying on the model to compose for any/all combinations. These neural symbolic representation helps in better definition of the neural symbolic space for neuro-symbolic attention and can be transformed to better captions. With this approach, we introduced two novel architectures (TP$_{sgt}$R-TDBU and TP$_{sgt}$R-sTDBU) for comparison and experiment result demonstrates that our approaches outperformed the other models, and generated captions are more comprehensive and natural.", "venue": "ArXiv", "authors": ["Chiranjib  Sur"], "year": 2019, "n_citations": 8}
{"id": 18031, "s2_id": "76b7ed94113927ae1695d4a188a66ee8ac997290", "title": "Machine Vision in the Context of Robotics: A Systematic Literature Review", "abstract": "Machine vision is critical to robotics due to a wide range of applications which rely on input from visual sensors such as autonomous mobile robots and smart production systems. To create the smart homes and systems of tomorrow, an overview about current challenges in the research field would be of use to identify further possible directions, created in a systematic and reproducible manner. In this work a systematic literature review was conducted covering research from the last 10 years. We screened 172 papers from four databases and selected 52 relevant papers. While robustness and computation time were improved greatly, occlusion and lighting variance are still the biggest problems faced. From the number of recent publications, we conclude that the observed field is of relevance and interest to the research community. Further challenges arise in many areas of the field.", "venue": "ArXiv", "authors": ["Javad  Ghofrani", "Robert  Kirschne", "Daniel  Rossburg", "Dirk  Reichelt", "Tom  Dimter"], "year": 2019, "n_citations": 0}
{"id": 18271, "s2_id": "f7dbae4a4ec9995d8dfccc725842e7080a63d835", "title": "Relevance as a Metric for Evaluating Machine Learning Algorithms", "abstract": "In machine learning, the choice of a learning algorithm that is suitable for the application domain is critical. The performance metric used to compare different algorithms must also reflect the concerns of users in the application domain under consideration. In this paper, we propose a novel probability-based performance metric called Relevance Score for evaluating supervised learning algorithms. We evaluate the proposed metric through empirical analysis on a dataset gathered from an intelligent lighting pilot installation. In comparison to the commonly used Classification Accuracy metric, the Relevance Score proves to be more appropriate for a certain class of applications.", "venue": "MLDM", "authors": ["Aravind Kota Gopalakrishna", "Tanir  Ozcelebi", "Antonio  Liotta", "Johan J. Lukkien"], "year": 2013, "n_citations": 18}
{"id": 38902, "s2_id": "5429605fa95ea4eab11e0bc28a687572e7c42abf", "title": "Learning strange attractors with reservoir systems", "abstract": "This paper shows that the celebrated Embedding Theorem of Takens is a particular case of a much more general statement according to which, randomly generated linear state-space representations of generic observations of an invertible dynamical system carry in their wake an embedding of the phase space dynamics into the chosen Euclidean state space. This embedding coincides with a natural generalized synchronization that arises in this setup and that yields a topological conjugacy between the state-space dynamics driven by the generic observations of the dynamical system and the dynamical system itself. This result provides additional tools for the representation, learning, and analysis of chaotic attractors and sheds additional light on the reservoir computing phenomenon that appears in the context of recurrent neural networks.", "venue": "ArXiv", "authors": ["Lyudmila  Grigoryeva", "Allen  Hart", "Juan-Pablo  Ortega"], "year": 2021, "n_citations": 2}
{"id": 45933, "s2_id": "6c6170ffb39cdc8cfffbeda9c7a2259eda5875f2", "title": "Tree-to-tree Neural Networks for Program Translation", "abstract": "Program translation is an important tool to migrate legacy code in one language into an ecosystem built in a different language. In this work, we are the first to employ deep neural networks toward tackling this problem. We observe that program translation is a modular procedure, in which a sub-tree of the source tree is translated into the corresponding target sub-tree at each step. To capture this intuition, we design a tree-to-tree neural network to translate a source tree into a target one. Meanwhile, we develop an attention mechanism for the tree-to-tree model, so that when the decoder expands one non-terminal in the target tree, the attention mechanism locates the corresponding sub-tree in the source tree to guide the expansion of the decoder. We evaluate the program translation capability of our tree-to-tree model against several state-of-the-art approaches. Compared against other neural translation models, we observe that our approach is consistently better than the baselines with a margin of up to 15 points. Further, our approach can improve the previous state-of-the-art program translation approaches by a margin of 20 points on the translation of real-world projects.", "venue": "NeurIPS", "authors": ["Xinyun  Chen", "Chang  Liu", "Dawn Xiaodong Song"], "year": 2018, "n_citations": 127}
{"id": 51107, "s2_id": "a370d85c593eaf86176743ad406d3f2ea54202a7", "title": "SA-GD: Improved Gradient Descent Learning Strategy with Simulated Annealing", "abstract": "Gradient descent algorithm is the most utilized method when optimizing machine learning issues. However, there exists many local minimums and saddle points in the loss function, especially for high dimensional non-convex optimization problems like deep learning. Gradient descent may make loss function trapped in these local intervals which impedes further optimization, resulting in poor generalization ability. This paper proposes the SA-GD algorithm which introduces the thought of simulated annealing algorithm to gradient descent. SA-GD method offers model the ability of mounting hills in probability, tending to enable the model to jump out of these local areas and converge to a optimal state finally. We took CNN models as an example and tested the basic CNN models on various benchmark datasets. Compared to the baseline models with traditional gradient descent algorithm, models with SA-GD algorithm possess better generalization ability without sacrificing the efficiency and stability of model convergence. In addition, SAGD can be utilized as an effective ensemble learning approach which improves the final performance significantly.", "venue": "ArXiv", "authors": ["Zhicheng  Cai"], "year": 2021, "n_citations": 0}
{"id": 52943, "s2_id": "5f82206bc41cd0c3626c97602b37312a185b992b", "title": "Risks of Using Non-verified Open Data: A case study on using Machine Learning techniques for predicting Pregnancy Outcomes in India", "abstract": "Artificial intelligence (AI) has evolved considerably in the last few years. While applications of AI is now becoming more common in fields like retail and marketing, application of AI in solving problems related to developing countries is still an emerging topic. Specially, AI applications in resource-poor settings remains relatively nascent. There is a huge scope of AI being used in such settings. For example, researchers have started exploring AI applications to reduce poverty and deliver a broad range of critical public services. However, despite many promising use cases, there are many dataset related challenges that one has to overcome in such projects. These challenges often take the form of missing data, incorrectly collected data and improperly labeled variables, among other factors. As a result, we can often end up using data that is not representative of the problem we are trying to solve. In this case study, we explore the challenges of using such an open dataset from India, to predict an important health outcome. We highlight how the use of AI without proper understanding of reporting metrics can lead to erroneous conclusions.", "venue": "ArXiv", "authors": ["Anusua  Trivedi", "Sumit  Mukherjee", "Edmund  Tse", "Anne  Ewing", "Juan Lavista Ferres"], "year": 2019, "n_citations": 3}
{"id": 59668, "s2_id": "91d523be4d85f6d700148b57c896eac3212fa8d8", "title": "The Devils in the Point Clouds: Studying the Robustness of Point Cloud Convolutions", "abstract": "Recently, there has been a significant interest in performing convolution over irregularly sampled point clouds. Since point clouds are very different from regular raster images, it is imperative to study the generalization of the convolution networks more closely, especially their robustness under variations in scale and rotations of the input data. This paper investigates different variants of PointConv, a convolution network on point clouds, to examine their robustness to input scale and rotation changes. Of the variants we explored, two are novel and generated significant improvements. The first is replacing the multilayer perceptron based weight function with much simpler third degree polynomials, together with a Sobolev norm regularization. Secondly, for 3D datasets, we derive a novel viewpoint-invariant descriptor by utilizing 3D geometric properties as the input to PointConv, in addition to the regular 3D coordinates. We have also explored choices of activation functions, neighborhood, and subsampling methods. Experiments are conducted on the 2D MNIST & CIFAR-10 datasets as well as the 3D SemanticKITTI & ScanNet datasets. Results reveal that on 2D, using third degree polynomials greatly improves PointConv\u2019s robustness to scale changes and rotations, even surpassing traditional 2D CNNs for the MNIST dataset. On 3D datasets, the novel viewpoint-invariant descriptor significantly improves the performance as well as robustness of PointConv. We achieve the state-of-the-art semantic segmentation performance on the SemanticKITTI dataset, as well as comparable performance with the current highest framework on the ScanNet dataset among point-based approaches.", "venue": "ArXiv", "authors": ["Xingyi  Li", "Wenxuan  Wu", "Xiaoli Z. Fern", "Li  Fuxin"], "year": 2021, "n_citations": 0}