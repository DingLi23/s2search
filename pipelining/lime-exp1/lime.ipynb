{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, sys, os, pandas as pd,json, os\n",
    "sys.path.insert(1, '../../')\n",
    "from getting_data import load_sample\n",
    "from s2search_score_pipelining import init_ranker\n",
    "\n",
    "f_list = np.array([\n",
    "    'title', 'abstract', 'venue', 'authors', \n",
    "    'year', \n",
    "    'n_citations'\n",
    "])\n",
    "\n",
    "exp_name = 'exp5'\n",
    "sample_name = 'cslg'\n",
    "query = 'Machine Learning'\n",
    "\n",
    "def find_paper_by_title(title, paper_data):\n",
    "    for p in paper_data:\n",
    "        if p['title'] == title:\n",
    "            return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample(exp_name, sample_name)\n",
    "paper_data = json.loads(df.to_json(orient='records'))\n",
    "\n",
    "data_in_arr = []\n",
    "\n",
    "for p in paper_data:\n",
    "    p['authors'] = str(p['authors'])\n",
    "    data_in_arr.append([p[feature_name] for feature_name in f_list])\n",
    "    \n",
    "data_in_arr = np.array(data_in_arr, dtype='object')\n",
    "\n",
    "target_value_npz_file = os.path.join('.', 'scores', f'{sample_name}_target_value.npz')\n",
    "\n",
    "if os.path.exists(target_value_npz_file):\n",
    "    target_value = np.load(target_value_npz_file)['arr_0']\n",
    "else:\n",
    "    ranker = init_ranker()\n",
    "    target_value = np.array(ranker.score(query, paper_data))\n",
    "    \n",
    "    scores_dir = os.path.join('.', 'scores')\n",
    "    if not os.path.exists(str(scores_dir)):\n",
    "        os.mkdir(str(scores_dir))\n",
    "    print(f'\\tsave PDP data to {target_value_npz_file}')\n",
    "    np.savez_compressed(target_value_npz_file, target_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "categorical_features = np.array([0,1,2,3])\n",
    "\n",
    "le= sklearn.preprocessing.LabelEncoder()\n",
    "le.fit(target_value)\n",
    "labels = le.transform(target_value)\n",
    "class_names = le.classes_\n",
    "\n",
    "categorical_names = {}\n",
    "for feature in categorical_features:\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    le.fit(data_in_arr[:, feature])\n",
    "    data_in_arr[:, feature] = le.transform(data_in_arr[:, feature])\n",
    "    categorical_names[feature] = le.classes_\n",
    "    \n",
    "data_in_arr = data_in_arr.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from joblib import dump, load\n",
    "\n",
    "encoder = ColumnTransformer([(\"enc\", sklearn.preprocessing.OneHotEncoder(), categorical_features)], remainder = 'passthrough')\n",
    "\n",
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data_in_arr, target_value, random_state=1, train_size=0.80)\n",
    "\n",
    "encoder.fit(data_in_arr)\n",
    "encoded_train = encoder.transform(train)\n",
    "\n",
    "rf_trained_model_file = os.path.join('.', 'rf.pickle')\n",
    "\n",
    "if os.path.exists(rf_trained_model_file):\n",
    "    with open(rf_trained_model_file, 'rb') as f:\n",
    "        load(f)\n",
    "else:\n",
    "    rf = sklearn.ensemble.RandomForestRegressor(n_estimators=100)\n",
    "    rf.fit(encoded_train, labels_train)\n",
    "    dump(rf, rf_trained_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 275453 features, but RandomForestRegressor is expecting 15880 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=7'>8</a>\u001b[0m explainer \u001b[39m=\u001b[39m lime\u001b[39m.\u001b[39mlime_tabular\u001b[39m.\u001b[39mLimeTabularExplainer(train ,feature_names \u001b[39m=\u001b[39m f_list,class_names\u001b[39m=\u001b[39mclass_names,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=8'>9</a>\u001b[0m                                                    categorical_features\u001b[39m=\u001b[39mcategorical_features, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=9'>10</a>\u001b[0m                                                    categorical_names\u001b[39m=\u001b[39mcategorical_names, kernel_width\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mregression\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=11'>12</a>\u001b[0m i \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=13'>14</a>\u001b[0m exp \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mexplain_instance(test[i], predict_fn, num_features\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(f_list))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=14'>15</a>\u001b[0m listed_exp \u001b[39m=\u001b[39m exp\u001b[39m.\u001b[39mas_list()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m f_ex \u001b[39min\u001b[39;00m listed_exp:\n",
      "File \u001b[0;32m~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py:355\u001b[0m, in \u001b[0;36mLimeTabularExplainer.explain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=347'>348</a>\u001b[0m     scaled_data \u001b[39m=\u001b[39m (data \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mmean_) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale_\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=348'>349</a>\u001b[0m distances \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mpairwise_distances(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=349'>350</a>\u001b[0m         scaled_data,\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=350'>351</a>\u001b[0m         scaled_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=351'>352</a>\u001b[0m         metric\u001b[39m=\u001b[39mdistance_metric\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=352'>353</a>\u001b[0m )\u001b[39m.\u001b[39mravel()\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=354'>355</a>\u001b[0m yss \u001b[39m=\u001b[39m predict_fn(inverse)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=356'>357</a>\u001b[0m \u001b[39m# for classification, the model needs to provide a list of tuples - classes\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=357'>358</a>\u001b[0m \u001b[39m# along with prediction probabilities\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=358'>359</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[1;32m/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb Cell 7'\u001b[0m in \u001b[0;36mpredict_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_fn\u001b[39m(x):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime.ipynb#ch0000006?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m rf\u001b[39m.\u001b[39;49mpredict(encoder\u001b[39m.\u001b[39;49mtransform(x))\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:971\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=968'>969</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=969'>970</a>\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=970'>971</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=972'>973</a>\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=973'>974</a>\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:579\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=575'>576</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=576'>577</a>\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=577'>578</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=578'>579</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=579'>580</a>\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/ensemble/_forest.py?line=580'>581</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=581'>582</a>\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=583'>584</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=584'>585</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=586'>587</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=396'>397</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=398'>399</a>\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=399'>400</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=400'>401</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=401'>402</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/sklearn/base.py?line=402'>403</a>\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 275453 features, but RandomForestRegressor is expecting 15880 features as input."
     ]
    }
   ],
   "source": [
    "import lime, warnings\n",
    "import lime.lime_tabular\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def predict_fn(x):\n",
    "    return rf.predict(encoder.transform(x)).astype(float)\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(train ,feature_names = f_list,class_names=class_names,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=5, mode='regression')\n",
    "\n",
    "i = np.random.randint(0, test.shape[0])\n",
    "\n",
    "exp = explainer.explain_instance(test[i], predict_fn, num_features=len(f_list))\n",
    "listed_exp = exp.as_list()\n",
    "\n",
    "for f_ex in listed_exp:\n",
    "    kv, score = f_ex\n",
    "    if str(kv).startswith('title='):\n",
    "        title = str(kv).replace('title=', '')\n",
    "\n",
    "original_paper = find_paper_by_title(title, paper_data)\n",
    "\n",
    "# ranker = init_ranker()\n",
    "# print(ranker.score(query, [original_paper]))\n",
    "\n",
    "print(listed_exp)\n",
    "print()\n",
    "print(f\"actual prediction: {labels_test[i]}\")\n",
    "exp.show_in_notebook(show_all=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cf082d97203dbc4e6105f8e92bf9fdc7b5fae703590b3e03586d98d926929c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('s2search397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
