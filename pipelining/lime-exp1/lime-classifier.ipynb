{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, sys, os, pandas as pd,json, os, warnings\n",
    "sys.path.insert(1, '../../')\n",
    "from getting_data import load_sample\n",
    "from s2search_score_pipelining import init_ranker\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "f_list = np.array([\n",
    "    'title', 'abstract', 'venue', 'authors', \n",
    "    'year', \n",
    "    'n_citations'\n",
    "])\n",
    "\n",
    "setting = 0\n",
    "\n",
    "if setting == 0:\n",
    "    exp_name = 'exp5'\n",
    "    sample_name = 'cslg'\n",
    "    pk_name = 'rf.pickle'\n",
    "if setting == 1:\n",
    "    exp_name = 'pdp-exp1'\n",
    "    sample_name = 'cslg-rand-5000'\n",
    "    pk_name = 'rf-5000.pickle'\n",
    "\n",
    "query = 'Machine Learning'\n",
    "\n",
    "def find_paper_by_title(title, paper_data):\n",
    "    for p in paper_data:\n",
    "        if p['title'] == title:\n",
    "            return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample(exp_name, sample_name)\n",
    "paper_data = json.loads(df.to_json(orient='records'))\n",
    "\n",
    "data_in_arr = []\n",
    "\n",
    "for p in paper_data:\n",
    "    p['authors'] = str(p['authors'])\n",
    "    data_in_arr.append([p[feature_name] for feature_name in f_list])\n",
    "    \n",
    "data_in_arr = np.array(data_in_arr, dtype='object')\n",
    "\n",
    "target_value_npz_file = os.path.join('.', 'scores', f'{sample_name}_target_value.npz')\n",
    "\n",
    "clazz = ['<-10', '<0', '>0']\n",
    "\n",
    "target_class_value = []\n",
    "\n",
    "if os.path.exists(target_value_npz_file):\n",
    "    target_value = np.load(target_value_npz_file)['arr_0']\n",
    "else:\n",
    "    ranker = init_ranker()\n",
    "    target_value = np.array(ranker.score(query, paper_data))\n",
    "    \n",
    "    scores_dir = os.path.join('.', 'scores')\n",
    "    if not os.path.exists(str(scores_dir)):\n",
    "        os.mkdir(str(scores_dir))\n",
    "    print(f'\\tsave PDP data to {target_value_npz_file}')\n",
    "    np.savez_compressed(target_value_npz_file, target_value)\n",
    "    \n",
    "for score in target_value:\n",
    "    if score < -10:\n",
    "        target_class_value.append(clazz[0])\n",
    "    elif score < 0:\n",
    "        target_class_value.append(clazz[1])\n",
    "    else:\n",
    "        target_class_value.append(clazz[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "categorical_features = np.array([0,1,2,3])\n",
    "\n",
    "le= sklearn.preprocessing.LabelEncoder()\n",
    "le.fit(target_value)\n",
    "labels = le.transform(target_value)\n",
    "class_names = le.classes_\n",
    "\n",
    "categorical_names = {}\n",
    "for feature in categorical_features:\n",
    "    le = sklearn.preprocessing.LabelEncoder()\n",
    "    le.fit(data_in_arr[:, feature])\n",
    "    data_in_arr[:, feature] = le.transform(data_in_arr[:, feature])\n",
    "    categorical_names[feature] = le.classes_\n",
    "    \n",
    "data_in_arr = data_in_arr.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47993329029481385"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from joblib import dump, load\n",
    "\n",
    "encoder = ColumnTransformer([(\"enc\", sklearn.preprocessing.OneHotEncoder(), categorical_features)], remainder = 'passthrough')\n",
    "\n",
    "train, test, labels_train, labels_test = sklearn.model_selection.train_test_split(data_in_arr, target_class_value, random_state=1, train_size=0.80)\n",
    "\n",
    "# encoder.fit(data_in_arr)\n",
    "# encoded_train = encoder.transform(train)\n",
    "\n",
    "rf_trained_model_file = os.path.join('.', f'classifier_{pk_name}')\n",
    "\n",
    "if os.path.exists(rf_trained_model_file):\n",
    "    with open(rf_trained_model_file, 'rb') as f:\n",
    "        rf = load(f)\n",
    "else:\n",
    "    rf = sklearn.ensemble.GradientBoostingClassifier(n_estimators=300, learning_rate=0.02)\n",
    "    rf.fit(train, labels_train)\n",
    "    # dump(rf, rf_trained_model_file)\n",
    "\n",
    "def predict_fn(x):\n",
    "    # return gbtree.predict(encoder.transform(x))\n",
    "    return rf.predict((x))\n",
    "\n",
    "sklearn.metrics.accuracy_score(labels_test, predict_fn(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "LIME does not currently support classifier models without probability scores. If this conflicts with your use case, please let us know: https://github.com/datascienceinc/lime/issues/16",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime-classifier.ipynb Cell 7'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime-classifier.ipynb#ch0000006?line=3'>4</a>\u001b[0m explainer \u001b[39m=\u001b[39m lime\u001b[39m.\u001b[39mlime_tabular\u001b[39m.\u001b[39mLimeTabularExplainer(train ,feature_names \u001b[39m=\u001b[39m f_list,class_names\u001b[39m=\u001b[39mclass_names,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime-classifier.ipynb#ch0000006?line=4'>5</a>\u001b[0m                                                    categorical_features\u001b[39m=\u001b[39mcategorical_features, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime-classifier.ipynb#ch0000006?line=5'>6</a>\u001b[0m                                                    categorical_names\u001b[39m=\u001b[39mcategorical_names, kernel_width\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime-classifier.ipynb#ch0000006?line=7'>8</a>\u001b[0m i \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime-classifier.ipynb#ch0000006?line=9'>10</a>\u001b[0m exp \u001b[39m=\u001b[39m explainer\u001b[39m.\u001b[39;49mexplain_instance(test[i], predict_fn, num_features\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(f_list), top_labels\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime-classifier.ipynb#ch0000006?line=10'>11</a>\u001b[0m listed_exp \u001b[39m=\u001b[39m exp\u001b[39m.\u001b[39mas_list()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yinnnyou/workspace/s2search/pipelining/lime-exp1/lime-classifier.ipynb#ch0000006?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m f_ex \u001b[39min\u001b[39;00m listed_exp:\n",
      "File \u001b[0;32m~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py:361\u001b[0m, in \u001b[0;36mLimeTabularExplainer.explain_instance\u001b[0;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=358'>359</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=359'>360</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(yss\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=360'>361</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLIME does not currently support \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=361'>362</a>\u001b[0m                                   \u001b[39m\"\u001b[39m\u001b[39mclassifier models without probability \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=362'>363</a>\u001b[0m                                   \u001b[39m\"\u001b[39m\u001b[39mscores. If this conflicts with your \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=363'>364</a>\u001b[0m                                   \u001b[39m\"\u001b[39m\u001b[39muse case, please let us know: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=364'>365</a>\u001b[0m                                   \u001b[39m\"\u001b[39m\u001b[39mhttps://github.com/datascienceinc/lime/issues/16\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=365'>366</a>\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(yss\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    <a href='file:///~/miniconda3/envs/s2search397/lib/python3.9/site-packages/lime/lime_tabular.py?line=366'>367</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: LIME does not currently support classifier models without probability scores. If this conflicts with your use case, please let us know: https://github.com/datascienceinc/lime/issues/16"
     ]
    }
   ],
   "source": [
    "import lime, warnings\n",
    "import lime.lime_tabular\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(train ,feature_names = f_list,class_names=class_names,\n",
    "                                                   categorical_features=categorical_features, \n",
    "                                                   categorical_names=categorical_names, kernel_width=3)\n",
    "\n",
    "i = np.random.randint(0, test.shape[0])\n",
    "\n",
    "exp = explainer.explain_instance(test[i], predict_fn, num_features=len(f_list), top_labels=1)\n",
    "listed_exp = exp.as_list()\n",
    "\n",
    "for f_ex in listed_exp:\n",
    "    kv, score = f_ex\n",
    "    if str(kv).startswith('title='):\n",
    "        title = str(kv).replace('title=', '')\n",
    "\n",
    "original_paper = find_paper_by_title(title, paper_data)\n",
    "\n",
    "# ranker = init_ranker()\n",
    "# print(ranker.score(query, [original_paper]))\n",
    "\n",
    "# print(listed_exp)\n",
    "print()\n",
    "print(f\"actual prediction: {labels_test[i]}\")\n",
    "exp.show_in_notebook(show_all=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cf082d97203dbc4e6105f8e92bf9fdc7b5fae703590b3e03586d98d926929c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('s2search397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
