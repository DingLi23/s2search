{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to not force global because 1 worker available\n",
      "get ranker in 7920 with global setting: True and gb_ranker len 1\n",
      "[Main taks:-1] compute 92938 scores with worker 7920\n",
      "[Main taks][03/24/2022, 00:09:31] 92938 scores within 35.520907 sec \n",
      "fail to not force global because 1 worker available\n",
      "get ranker in 7920 with global setting: True and gb_ranker len 1\n",
      "[Main taks:-1] compute 92938 scores with worker 7920\n",
      "[Main taks][03/24/2022, 00:10:23] 92938 scores within 46.723759 sec \n",
      "fail to not force global because 1 worker available\n",
      "get ranker in 7920 with global setting: True and gb_ranker len 1\n",
      "[Main taks:-1] compute 92938 scores with worker 7920\n",
      "[Main taks][03/24/2022, 00:10:43] 92938 scores within 15.141943 sec \n",
      "fail to not force global because 1 worker available\n",
      "get ranker in 7920 with global setting: True and gb_ranker len 1\n",
      "[Main taks:-1] compute 92938 scores with worker 7920\n",
      "[Main taks][03/24/2022, 00:11:13] 92938 scores within 25.299571 sec \n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np, sys, os, pandas as pd,json, os\n",
    "sys.path.insert(1, '../../')\n",
    "from getting_data import load_sample, feature_key_list, categorical_feature_key_list\n",
    "from s2search_score_pipelining import get_scores\n",
    "from s2search_score_pdp import save_pdp_to_npz\n",
    "\n",
    "setting = 0\n",
    "exp_name = 'exp5'\n",
    "sample_name = 'cslg'\n",
    "\n",
    "query = 'Machine Learning'\n",
    "\n",
    "categorical_name = {}\n",
    "\n",
    "def remove_duplicate(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "categorical_name_file = os.path.join('.', 'scores', f'{sample_name}_categorical_name.npz')\n",
    "\n",
    "for i in range(len(feature_key_list)):\n",
    "    feature_name = feature_key_list[i]\n",
    "    if feature_name in categorical_feature_key_list:\n",
    "        df = load_sample(exp_name, sample_name, query=query, sort=feature_name, rank_f=get_scores)\n",
    "        if feature_name == 'authors':\n",
    "            l = [json.dumps(x) for x in df[feature_name]]\n",
    "        else:\n",
    "            l = list(df[feature_name])\n",
    "        categorical_name[i] = remove_duplicate(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample(exp_name, sample_name)\n",
    "paper_data = json.loads(df.to_json(orient='records'))\n",
    "\n",
    "y_pred_file = os.path.join('.', 'scores', f'{sample_name}_y_pred.npz')\n",
    "if not os.path.exists(y_pred_file):\n",
    "    y_pred = get_scores(query, paper_data)\n",
    "    save_pdp_to_npz('.', y_pred_file, y_pred)\n",
    "else:\n",
    "    y_pred = np.load(y_pred_file)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(score):\n",
    "    if score <= -17:\n",
    "        return '(,-17]'\n",
    "    elif score <= -10:\n",
    "        return '(-17, -10]'\n",
    "    elif score <= -5:\n",
    "        return '(-10, -5]'    \n",
    "    elif score <= 0:\n",
    "        return '(-5, <0]'  \n",
    "    elif score <= 3:\n",
    "        return '(0, 3]'\n",
    "    elif score <= 5:\n",
    "        return '(3, 5]'\n",
    "    elif score <= 6:\n",
    "        return '(5, 6]'\n",
    "    elif score <= 7:\n",
    "        return '(6, 7]'\n",
    "    elif score <= 8:\n",
    "        return '(7, 8]'\n",
    "    elif score <= 9:\n",
    "        return '(8, 9]'\n",
    "    else:\n",
    "        return '(9,)'\n",
    "\n",
    "# make class_name\n",
    "class_name = ['(,-17]','(-17, -10]','(-10, -5]','(-5, <0]','(0, 3]','(3, 5]','(5, 6]','(6, 7]','(7, 8]','(8, 9]','(9,)']\n",
    "\n",
    "categorical_name_map = {}\n",
    "\n",
    "for i in range(len(feature_key_list)):\n",
    "    feature_name = feature_key_list[i]\n",
    "    if feature_name in categorical_feature_key_list:\n",
    "        categorical_name_map[i] = {}\n",
    "        values = categorical_name[i]\n",
    "        for j in range(len(values)):\n",
    "            value = values[j]\n",
    "            categorical_name_map[i][value] = j\n",
    "\n",
    "# encoding data\n",
    "for i in range(len(paper_data)):\n",
    "    paper_data[i] = [\n",
    "        categorical_name_map[0][paper_data[i]['title']], categorical_name_map[1][paper_data[i]['abstract']],\n",
    "        categorical_name_map[2][paper_data[i]['venue']], categorical_name_map[3][json.dumps(paper_data[i]['authors'])],\n",
    "        paper_data[i]['year'],\n",
    "        paper_data[i]['n_citations']\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55397, 28139, 2995, 84492, 2019, 61]\n",
      "title          Pricing options and computing implied volatili...\n",
      "abstract       This paper proposes a data-driven approach, by...\n",
      "venue                                                      Risks\n",
      "authors        [Shuaiqiang  Liu, Cornelis W. Oosterlee, Sande...\n",
      "year                                                        2019\n",
      "n_citations                                                   61\n",
      "Name: 92937, dtype: object\n",
      "{'title': 'Pricing options and computing implied volatilities using neural networks', 'abstract': 'This paper proposes a data-driven approach, by means of an Artificial Neural Network (ANN), to value financial options and to calculate implied volatilities with the aim of accelerating the corresponding numerical methods. With ANNs being universal function approximators, this method trains an optimized ANN on a data set generated by a sophisticated financial model, and runs the trained ANN as an agent of the original solver in a fast and efficient way. We test this approach on three different types of solvers, including the analytic solution for the Black-Scholes equation, the COS method for the Heston stochastic volatility model and Brent’s iterative root-finding method for the calculation of implied volatilities. The numerical results show that the ANN solver can reduce the computing time significantly.', 'venue': 'Risks', 'authors': ['Shuaiqiang  Liu', 'Cornelis W. Oosterlee', 'Sander M. Bohte'], 'year': 2019, 'n_citations': 61}\n"
     ]
    }
   ],
   "source": [
    "def decode_paper(encoded_p):\n",
    "    return dict(\n",
    "        title=categorical_name[0][encoded_p[0]],\n",
    "        abstract=categorical_name[1][encoded_p[1]],\n",
    "        venue=categorical_name[2][encoded_p[2]],\n",
    "        authors=json.loads(categorical_name[3][encoded_p[3]]),\n",
    "        year=encoded_p[4],\n",
    "        n_citations=encoded_p[5],\n",
    "    )\n",
    "\n",
    "decoded_i = 92937\n",
    "\n",
    "print(paper_data[decoded_i])\n",
    "print(df.iloc[decoded_i])\n",
    "print(decode_paper(paper_data[decoded_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor import anchor_tabular\n",
    "\n",
    "paper_data = np.array(paper_data)\n",
    "\n",
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    class_name,\n",
    "    feature_key_list,\n",
    "    paper_data,\n",
    "    categorical_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_fn(x):\n",
    "    predictions = get_scores(query, [decode_paper(p) for p in x], ptf = False)\n",
    "    encoded_pred = [class_name.index(get_class(pp)) for pp in predictions]\n",
    "    return np.array(encoded_pred)\n",
    "\n",
    "idx = 92936\n",
    "exp = explainer.explain_instance(paper_data[idx], pred_fn, threshold=0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:  (6, 7]\n",
      "-------------------\n",
      "Anchor: \n",
      "abstract = With the growing interest in machine learning community to solve real world problems, it has become crucial to uncover the hidden reasoning behind their decisions by focusing on the fairness and auditing the predictions made by these black-box models. In this paper, we propose a novel method to address two key issues: (a) Can we simultaneously learn fair disentangled representations while ensuring the utility of the learned representation for downstream tasks, and (b) Can we provide theoretical insights into when the proposed approach will be both fair and accurate. To address the former, we propose the method FRIED, Fair Representation learning using Interpolation Enabled Disentanglement. In our architecture, by imposing a critic-based adversarial framework, we enforce the interpolated points in the latent space to be more realistic. This helps in capturing the data manifold effectively and enhances utility of the learned representation for downstream prediction tasks. We address the latter question by developing theory on fairness-accuracy trade-offs using classifier-based conditional mutual information estimation. We demonstrate the effectiveness of FRIED on datasets of different modalities — tabular, text, and image datasets. We observe that the representations learned by FRIED are overall fairer in comparison to existing baselines and also accurate for downstream prediction tasks. Additionally, we evaluate FRIED on a real-world healthcare claims dataset where we conduct an expert aided model auditing study providing useful insights into opioid addiction patterns.\n",
      "AND\n",
      "title = Fair Representation Learning using Interpolation Enabled Disentanglement\n",
      "AND\n",
      "year > 2018.00\n",
      "AND\n",
      "n_citations <= 15.00\n",
      "\n",
      "Precision: 1.00\n",
      "Coverage: 0.00\n"
     ]
    }
   ],
   "source": [
    "print('Prediction: ', explainer.class_names[pred_fn([paper_data[idx]])[0]])\n",
    "print('-------------------')\n",
    "print('Anchor: \\n%s' % ('\\nAND\\n'.join(exp.names())))\n",
    "print('\\nPrecision: %.2f' % exp.precision())\n",
    "print('Coverage: %.2f' % exp.coverage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract = With the growing interest in machine learning community to solve real world problems, it has become crucial to uncover the hidden reasoning behind their decisions by focusing on the fairness and auditing the predictions made by these black-box models. In this paper, we propose a novel method to address two key issues: (a) Can we simultaneously learn fair disentangled representations while ensuring the utility of the learned representation for downstream tasks, and (b) Can we provide theoretical insights into when the proposed approach will be both fair and accurate. To address the former, we propose the method FRIED, Fair Representation learning using Interpolation Enabled Disentanglement. In our architecture, by imposing a critic-based adversarial framework, we enforce the interpolated points in the latent space to be more realistic. This helps in capturing the data manifold effectively and enhances utility of the learned representation for downstream prediction tasks. We address the latter question by developing theory on fairness-accuracy trade-offs using classifier-based conditional mutual information estimation. We demonstrate the effectiveness of FRIED on datasets of different modalities — tabular, text, and image datasets. We observe that the representations learned by FRIED are overall fairer in comparison to existing baselines and also accurate for downstream prediction tasks. Additionally, we evaluate FRIED on a real-world healthcare claims dataset where we conduct an expert aided model auditing study providing useful insights into opioid addiction patterns.\n",
      "title = Fair Representation Learning using Interpolation Enabled Disentanglement\n",
      "year > 2018.00\n",
      "n_citations <= 15.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': [0.6061285562361398],\n",
       " 'abstract': [0.21565362198168192],\n",
       " 'venue': [],\n",
       " 'authors': [],\n",
       " 'year': [],\n",
       " 'n_citations': []}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = dict(\n",
    "    title=[],\n",
    "    abstract=[],\n",
    "    venue=[],\n",
    "    authors=[],\n",
    "    year=[],\n",
    "    n_citations=[],\n",
    ")\n",
    "previous_single_precision = 0\n",
    "\n",
    "for j in range(len(exp.names())):\n",
    "    name = exp.names()[j]\n",
    "    print(name)\n",
    "    current_single_precision = exp.precision(j) - previous_single_precision\n",
    "    previous_single_precision = exp.precision(j)\n",
    "    for feature_name in metrics.keys():\n",
    "        if name.startswith(f'{feature_name} = '):\n",
    "            metrics[feature_name].append(current_single_precision)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 03/24/2022, 00:11:22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'title': 0.27368109945322894,\n",
       " 'abstract': 0.7164179104477612,\n",
       " 'venue': 0,\n",
       " 'authors': 0,\n",
       " 'year': 0,\n",
       " 'n_citations': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "utc_tz = pytz.timezone('America/Montreal')\n",
    "\n",
    "metrics = dict(\n",
    "    title=0,\n",
    "    abstract=0,\n",
    "    venue=0,\n",
    "    authors=0,\n",
    "    year=0,\n",
    "    n_citations=0,\n",
    ")\n",
    "\n",
    "for i in range(len(paper_data)):\n",
    "    print(i, datetime.datetime.now(tz=utc_tz).strftime(\"%m/%d/%Y, %H:%M:%S\"))\n",
    "    exp = explainer.explain_instance(paper_data[i], pred_fn, threshold=0.99, tau=0.5)\n",
    "\n",
    "    previous_single_precision = 0\n",
    "    for j in range(len(exp.names())):\n",
    "        name = exp.names()[j]\n",
    "        current_single_precision = exp.precision(j) - previous_single_precision\n",
    "        previous_single_precision = exp.precision(j)\n",
    "        for feature_name in metrics.keys():\n",
    "            if name.startswith(f'{feature_name} = '):\n",
    "                metrics[feature_name] += (current_single_precision)\n",
    "\n",
    "    break\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cf082d97203dbc4e6105f8e92bf9fdc7b5fae703590b3e03586d98d926929c4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('s2search397')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
