{"id": 1616, "s2_id": "1c30ed337cdcee7e0fffb4fb586a3066e7c92a8a", "title": "Neuron Interaction Based Representation Composition for Neural Machine Translation", "abstract": "Recent NLP studies reveal that substantial linguistic information can be attributed to single neurons, i.e., individual dimensions of the representation vectors. We hypothesize that modeling strong interactions among neurons helps to better capture complex information by composing the linguistic properties embedded in individual neurons. Starting from this intuition, we propose a novel approach to compose representations learned by different components in neural machine translation (e.g., multi-layer networks or multi-head attention), based on modeling strong interactions among neurons in the representation vectors. Specifically, we leverage bilinear pooling to model pairwise multiplicative interactions among individual neurons, and a low-rank approximation to make the model computationally feasible. We further propose extended bilinear pooling to incorporate first-order representations. Experiments on WMT14 English\u21d2German and English\u21d2French translation tasks show that our model consistently improves performances over the SOTA Transformer baseline. Further analyses demonstrate that our approach indeed captures more syntactic and semantic information as expected.", "venue": "AAAI", "authors": ["Jian  Li", "Xing  Wang", "Baosong  Yang", "Shuming  Shi", "Michael R. Lyu", "Zhaopeng  Tu"], "year": 2020, "n_citations": 12}
{"id": 15499, "s2_id": "b92a154661a63a7cd1cd9d3fffd8744520247d81", "title": "Towards Label Imbalance in Multi-label Classification with Many Labels", "abstract": "In multi-label classification, an instance may be associated with a set of labels simultaneously. Recently, the research on multi-label classification has largely shifted its focus to the other end of the spectrum where the number of labels is assumed to be extremely large. The existing works focus on how to design scalable algorithms that offer fast training procedures and have a small memory footprint. However they ignore and even compound another challenge - the label imbalance problem. To address this drawback, we propose a novel Representation-based Multi-label Learning with Sampling (RMLS) approach. To the best of our knowledge, we are the first to tackle the imbalance problem in multi-label classification with many labels. Our experimentations with real-world datasets demonstrate the effectiveness of the proposed approach.", "venue": "ArXiv", "authors": ["Li  Li", "Houfeng  Wang"], "year": 2016, "n_citations": 12}
{"id": 19175, "s2_id": "5b95b9b7ab2fe18406b2a6c29ef126f9b60c2b0d", "title": "Random Hinge Forest for Differentiable Learning", "abstract": "We propose random hinge forests, a simple, efficient, and novel variant of decision forests. Importantly, random hinge forests can be readily incorporated as a general component within arbitrary computation graphs that are optimized end-to-end with stochastic gradient descent or variants thereof. We derive random hinge forest and ferns, focusing on their sparse and efficient nature, their min-max margin property, strategies to initialize them for arbitrary network architectures, and the class of optimizers most suitable for optimizing random hinge forest. The performance and versatility of random hinge forests are demonstrated by experiments incorporating a variety of of small and large UCI machine learning data sets and also ones involving the MNIST, Letter, and USPS image datasets. We compare random hinge forests with random forests and the more recent backpropagating deep neural decision forests.", "venue": "ArXiv", "authors": ["Nathan  Lay", "Adam P. Harrison", "Sharon  Schreiber", "Gitesh  Dawer", "Adrian  Barbu"], "year": 2018, "n_citations": 9}
{"id": 23720, "s2_id": "0989400d1fb0cc102e2fe9603e658ed9b2dd7d2b", "title": "Indexability and Rollout Policy for Multi-State Partially Observable Restless Bandits", "abstract": "Restless multi-armed bandits with partially observable states has applications in communication systems, age of information and recommendation systems. In this paper, we study multi-state partially observable restless bandit models. We consider three different models based on information observable to decision maker\u20141) no information is observable from actions of a bandit 2) perfect information from bandit is observable only for one action on bandit, there is a fixed restart state, i.e., transition occurs from all other states to that state 3) perfect state information is available to decision maker for both actions on a bandit and there are two restart state for two actions. We develop the structural properties. We also show a threshold type policy and indexability for model 2 and 3. We present Monte Carlo (MC) rollout policy. We use it for whittle index computation in case of model 2. We obtain the concentration bound on value function in terms of horizon length and number of trajectories for MC rollout policy. We derive explicit index formula for model 3. We finally describe Monte Carlo rollout policy for model 1 when it is difficult to show indexability. We demonstrate the numerical examples using myopic policy, Monte Carlo rollout policy and Whittle index policy. We observe that Monte Carlo rollout policy is good competitive policy to myopic.", "venue": "ArXiv", "authors": ["Rahul  Meshram", "Kesav  Kaza"], "year": 2021, "n_citations": 2}
{"id": 29989, "s2_id": "fa126559be48a3ff9cf88b2d463b40928b366a78", "title": "SoK: exploring the state of the art and the future potential of artificial intelligence in digital forensic investigation", "abstract": "Multi-year digital forensic backlogs have become commonplace in law enforcement agencies throughout the globe. Digital forensic investigators are overloaded with the volume of cases requiring their expertise compounded by the volume of data to be processed. Artificial intelligence is often seen as the solution to many big data problems. This paper summarises existing artificial intelligence based tools and approaches in digital forensics. Automated evidence processing leveraging artificial intelligence based techniques shows great promise in expediting the digital forensic analysis process while increasing case processing capacities. For each application of artificial intelligence highlighted, a number of current challenges and future potential impact is discussed.", "venue": "ARES", "authors": ["Xiaoyu  Du", "Chris  Hargreaves", "John  Sheppard", "Felix  Anda", "Asanka  Sayakkara", "Nhien-An  Le-Khac", "Mark  Scanlon"], "year": 2020, "n_citations": 11}
{"id": 52073, "s2_id": "f928851c2da0ef5ea58d931520525a7760ad719a", "title": "A Graph-Constrained Changepoint Learning Approach for Automatic QRS-Complex Detection", "abstract": "This study presents a new viewpoint on ECG signal analysis by applying a graph-based changepoint detection model to locate R-peak positions. This model is based on a new graph learning algorithm to learn the constraint graph given the labeled ECG data. The proposed learning algorithm starts with a simple initial graph and iteratively edits the graph so that the final graph has the maximum accuracy in R-peak detection. We evaluate the performance of the algorithm on the MIT-BIH Arrhythmia Database. The evaluation results demonstrate that the proposed method can obtain comparable results to other state-of-the-art approaches. The proposed method achieves the overall sensitivity of Sen = 99.64%, positive predictivity of PPR = 99.71%, and detection error rate of DER = 0.19.", "venue": "2020 54th Asilomar Conference on Signals, Systems, and Computers", "authors": ["Atiyeh  Fotoohinasab", "Toby  Hocking", "Fatemeh  Afghah"], "year": 2020, "n_citations": 1}
{"id": 52732, "s2_id": "bc23dc3de275c421d91c73135974f18b5cb2ac52", "title": "Maximal adversarial perturbations for obfuscation: Hiding certain attributes while preserving rest", "abstract": "In this paper we investigate the usage of adversarial perturbations for the purpose of privacy from human perception and model (machine) based detection. We employ adversarial perturbations for obfuscating certain variables in raw data while preserving the rest. Current adversarial perturbation methods are used for data poisoning with minimal perturbations of the raw data such that the machine learning model's performance is adversely impacted while the human vision cannot perceive the difference in the poisoned dataset due to minimal nature of perturbations. We instead apply relatively maximal perturbations of raw data to conditionally damage model's classification of one attribute while preserving the model performance over another attribute. In addition, the maximal nature of perturbation helps adversely impact human perception in classifying hidden attribute apart from impacting model performance. We validate our result qualitatively by showing the obfuscated dataset and quantitatively by showing the inability of models trained on clean data to predict the hidden attribute from the perturbed dataset while being able to predict the rest of attributes.", "venue": "ArXiv", "authors": ["Indu  Ilanchezian", "Praneeth  Vepakomma", "Abhishek  Singh", "Otkrist  Gupta", "G. N. Srinivasa Prasanna", "Ramesh  Raskar"], "year": 2019, "n_citations": 0}
{"id": 64823, "s2_id": "3652bf81b1c875ac344c03afb076a73b40656895", "title": "Restricting the Flow: Information Bottlenecks for Attribution", "abstract": "Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work we adapt the information bottleneck concept for attribution. By adding noise to intermediate feature maps we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method\u2019s information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not required for the network's decision.", "venue": "ICLR", "authors": ["Karl  Schulz", "Leon  Sixt", "Federico  Tombari", "Tim  Landgraf"], "year": 2020, "n_citations": 66}
{"id": 84647, "s2_id": "23c01f2071a70856a2bb04892e75e3871ff4df62", "title": "A Collaborative Mechanism for Crowdsourcing Prediction Problems", "abstract": "Machine Learning competitions such as the Netflix Prize have proven reasonably successful as a method of \"crowdsourcing\" prediction tasks. But these competitions have a number of weaknesses, particularly in the incentive structure they create for the participants. We propose a new approach, called a Crowdsourced Learning Mechanism, in which participants collaboratively \"learn\" a hypothesis for a given prediction task. The approach draws heavily from the concept of a prediction market, where traders bet on the likelihood of a future event. In our framework, the mechanism continues to publish the current hypothesis, and participants can modify this hypothesis by wagering on an update. The critical incentive property is that a participant will profit an amount that scales according to how much her update improves performance on a released test set.", "venue": "NIPS", "authors": ["Jacob D. Abernethy", "Rafael M. Frongillo"], "year": 2011, "n_citations": 51}
{"id": 85219, "s2_id": "1cf641017c25cb0cd9a05b1307c3f74d94a8407e", "title": "MAGI-X: Manifold-Constrained Gaussian Process Inference for Unknown System Dynamics", "abstract": "Ordinary differential equations (ODEs), commonly used to characterize the dynamic systems, are difficult to propose in closed-form for many complicated scientific applications, even with the help of domain expert. We propose a fast and accurate data-driven method, MAGI-X, to learn the unknown dynamic from the observation data in a non-parametric fashion, without the need of any domain knowledge. Unlike the existing methods that mainly rely on the costly numerical integration, MAGI-X utilizes the powerful functional approximator of neural network to learn the unknown nonlinear dynamic within the MAnifold-constrained Gaussian process Inference (MAGI) framework that completely circumvents the numerical integration. Comparing against the state-of-the-art methods on three realistic examples, MAGI-X achieves competitive accuracy in both fitting and forecasting while only taking a fraction of computational time. Moreover, MAGI-X provides practical solution for the inference of partial observed systems, which no previous method is able to handle.", "venue": "ArXiv", "authors": ["Chaofan  Huang", "Simin  Ma", "Shihao  Yang"], "year": 2021, "n_citations": 0}
{"id": 102312, "s2_id": "e361c902420ee81e66e4421dad4e612611483273", "title": "Stable Policy Optimization via Off-Policy Divergence Regularization", "abstract": "Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO) are among the most successful policy gradient approaches in deep reinforcement learning (RL). While these methods achieve state-of-the-art performance across a wide range of challenging tasks, there is room for improvement in the stabilization of the policy learning and how the off-policy data are used. In this paper we revisit the theoretical foundations of these algorithms and propose a new algorithm which stabilizes the policy improvement through a proximity term that constrains the discounted state-action visitation distribution induced by consecutive policies to be close to one another. This proximity term, expressed in terms of the divergence between the visitation distributions, is learned in an off-policy and adversarial manner. We empirically show that our proposed method can have a beneficial effect on stability and improve final performance in benchmark high-dimensional control tasks.", "venue": "UAI", "authors": ["Ahmed  Touati", "Amy  Zhang", "Joelle  Pineau", "Pascal  Vincent"], "year": 2020, "n_citations": 5}
{"id": 109629, "s2_id": "44cbb1c01094e452e3fe661e1379b9cdb0e4e56a", "title": "Semi-Supervised Learning with GANs: Revisiting Manifold Regularization", "abstract": "GANS are powerful generative models that are able to model the manifold of natural images. We leverage this property to perform manifold regularization by approximating the Laplacian norm using a Monte Carlo approximation that is easily computed with the GAN. When incorporated into the feature-matching GAN of Improved GAN, we achieve state-of-the-art results for GAN-based semi-supervised learning on the CIFAR-10 dataset, with a method that is significantly easier to implement than competing methods.", "venue": "ICLR", "authors": ["Bruno  Lecouat", "Chuan Sheng Foo", "Houssam  Zenati", "Vijay Ramaseshan Chandrasekhar"], "year": 2018, "n_citations": 19}
{"id": 110717, "s2_id": "23a89c1acfca56707ebb6f160f1092f96f7b6b5d", "title": "Clustering of Bank Customers using LSTM-based encoder-decoder and Dynamic Time Warping", "abstract": "Clustering is an unsupervised data mining technique that can be employed to segment customers. The efficient clustering of customers enables banks to design and make offers based on the features of the target customers. The present study uses a real-world financial dataset (Berka, 2000) to cluster bank customers by an encoder-decoder network and the dynamic time warping (DTW) method. The customer features required for clustering are obtained in four ways: Dynamic Time Warping (DTW), Recency Frequency and Monetary (RFM), LSTM encoder-decoder network, and our proposed hybrid method. Once the LSTM model was trained by customer transaction data, a feature vector of each customer was automatically extracted by the encoder. Moreover, the distance between pairs of sequences of transaction amounts was obtained using DTW. Another vector feature was calculated for customers by RFM scoring. In the hybrid method, the feature vectors are combined from the encoder-decoder output, the DTW distance, and the demographic data (e.g., age and gender). Finally, feature vectors were introduced as input to the k-means clustering algorithm, and we compared clustering results with Silhouette and Davies\u2013Bouldin index. As a result, the clusters obtained from the hybrid approach are more accurate and meaningful than those derived from individual clustering techniques. In addition, the type of neural network layers had a substantial effect on the clusters, and high network error does not necessarily worsen clustering performance.", "venue": "ArXiv", "authors": ["Ehsan  Barkhordar", "Mohammad Hassan Shirali-Shahreza", "Hamid Reza Sadeghi"], "year": 2021, "n_citations": 0}
{"id": 137928, "s2_id": "5b7d8bee7f666326925f0933ca5a52b16ba1ff8f", "title": "Adversarial Training against Location-Optimized Adversarial Patches", "abstract": "Deep neural networks have been shown to be susceptible to adversarial examples -- small, imperceptible changes constructed to cause mis-classification in otherwise highly accurate image classifiers. As a practical alternative, recent work proposed so-called adversarial patches: clearly visible, but adversarially crafted rectangular patches in images. These patches can easily be printed and applied in the physical world. While defenses against imperceptible adversarial examples have been studied extensively, robustness against adversarial patches is poorly understood. In this work, we first devise a practical approach to obtain adversarial patches while actively optimizing their location within the image. Then, we apply adversarial training on these location-optimized adversarial patches and demonstrate significantly improved robustness on CIFAR10 and GTSRB. Additionally, in contrast to adversarial training on imperceptible adversarial examples, our adversarial patch training does not reduce accuracy.", "venue": "ECCV Workshops", "authors": ["Sukrut  Rao", "David  Stutz", "Bernt  Schiele"], "year": 2020, "n_citations": 16}
{"id": 148583, "s2_id": "aef2050fe0fa48136cff50ec38bb5af2c6992bce", "title": "Differentiable Pooling for Hierarchical Feature Learning", "abstract": "We introduce a parametric form of pooling, based on a Gaussian, which can be optimized alongside the features in a single global objective function. By contrast, existing pooling schemes are based on heuristics (e.g. local maximum) and have no clear link to the cost function of the model. Furthermore, the variables of the Gaussian explicitly store location information, distinct from the appearance captured by the features, thus providing a what/where decomposition of the input signal. Although the differentiable pooling scheme can be incorporated in a wide range of hierarchical models, we demonstrate it in the context of a Deconvolutional Network model (Zeiler et al. ICCV 2011). We also explore a number of secondary issues within this model and present detailed experiments on MNIST digits.", "venue": "ArXiv", "authors": ["Matthew D. Zeiler", "Rob  Fergus"], "year": 2012, "n_citations": 13}
{"id": 151170, "s2_id": "0fbd84db8b61ecd8daf3af0c369668c468316877", "title": "catch22: CAnonical Time-series CHaracteristics", "abstract": "Capturing the dynamical properties of time series concisely as interpretable feature vectors can enable efficient clustering and classification for time-series applications across science and industry. Selecting an appropriate feature-based representation of time series for a given application can be achieved through systematic comparison across a comprehensive time-series feature library, such as those in the hctsa toolbox. However, this approach is computationally expensive and involves evaluating many similar features, limiting the widespread adoption of feature-based representations of time series for real-world applications. In this work, we introduce a method to infer small sets of time-series features that (i) exhibit strong classification performance across a given collection of time-series problems, and (ii) are minimally redundant. Applying our method to a set of 93 time-series classification datasets (containing over 147,000 time series) and using a filtered version of the hctsa feature library (4791 features), we introduce a set of 22 CAnonical Time-series CHaracteristics, catch22, tailored to the dynamics typically encountered in time-series data-mining tasks. This dimensionality reduction, from 4791 to 22, is associated with an approximately 1000-fold reduction in computation time and near linear scaling with time-series length, despite an average reduction in classification accuracy of just 7%. catch22 captures a diverse and interpretable signature of time series in terms of their properties, including linear and non-linear autocorrelation, successive differences, value distributions and outliers, and fluctuation scaling properties. We provide an efficient implementation of catch22, accessible from many programming environments, that facilitates feature-based time-series analysis for scientific, industrial, financial and medical applications using a common language of interpretable time-series properties.", "venue": "Data Mining and Knowledge Discovery", "authors": ["Carl H. Lubba", "Sarab S. Sethi", "Philip  Knaute", "Simon R. Schultz", "Ben D. Fulcher", "Nick S. Jones"], "year": 2019, "n_citations": 46}
{"id": 153522, "s2_id": "4558b932075a862c72bb98bbce5f08590f563b14", "title": "Visual Semantic Planning Using Deep Successor Representations", "abstract": "A crucial capability of real-world intelligent agents is their ability to plan a sequence of actions to achieve their goals in the visual world. In this work, we address the problem of visual semantic planning: the task of predicting a sequence of actions from visual observations that transform a dynamic environment from an initial state to a goal state. Doing so entails knowledge about objects and their affordances, as well as actions and their preconditions and effects. We propose learning these through interacting with a visual and dynamic environment. Our proposed solution involves bootstrapping reinforcement learning with imitation learning. To ensure cross task generalization, we develop a deep predictive model based on successor representations. Our experimental results show near optimal results across a wide range of tasks in the challenging THOR environment.", "venue": "2017 IEEE International Conference on Computer Vision (ICCV)", "authors": ["Yuke  Zhu", "Daniel  Gordon", "Eric  Kolve", "Dieter  Fox", "Li  Fei-Fei", "Abhinav  Gupta", "Roozbeh  Mottaghi", "Ali  Farhadi"], "year": 2017, "n_citations": 107}
{"id": 164431, "s2_id": "835f661beb33d3df1b17f78b5b3069ce760678a4", "title": "Automatic non-invasive Cough Detection based on Accelerometer and Audio Signals", "abstract": "We present an automatic non-invasive way of detecting cough events based on both accelerometer and audio signals. The acceleration signals are captured by a smartphone firmly attached to the patient\u2019s bed, using its integrated accelerometer. The audio signals are captured simultaneously by the same smartphone using an external microphone. We have compiled a manually-annotated dataset containing such simultaneouslycaptured acceleration and audio signals for approximately 6000 cough and 68000 non-cough events from 14 adult male patients in a tuberculosis clinic. LR, SVM and MLP are evaluated as baseline classifiers and compared with deep architectures such as CNN, LSTM, and Resnet50 using a leave-oneout cross-validation scheme. We find that the studied classifiers can use either acceleration or audio signals to distinguish between coughing and other activities including sneezing, throatclearing, and movement on the bed with high accuracy. However, in all cases, the deep neural networks outperform the shallow classifiers by a clear margin and the Resnet50 offers the best performance by achieving an AUC exceeding 0.98 and 0.99 for acceleration and audio signals respectively. While audio-based classification consistently offers a better performance than acceleration-based classification, we observe that the difference is very small for the best systems. Since the acceleration signal requires less processing power, and since the need to record audio is sidestepped and thus privacy is inherently secured, and since the recording device is attached to the bed and not worn, an accelerometer-based highly accurate noninvasive cough detector may represent a more convenient and readily accepted method in long-term cough monitoring.", "venue": "ArXiv", "authors": ["Madhurananda  Pahar", "Igor  Miranda", "Andreas  Diacon", "Thomas  Niesler"], "year": 2021, "n_citations": 0}
{"id": 165003, "s2_id": "dc95f071a92afa62058fcb9d21dded9c6b381bd7", "title": "Functional Isolation Forest", "abstract": "For the purpose of monitoring the behavior of complex infrastructures (e.g. aircrafts, transport or energy networks), high-rate sensors are deployed to capture multivariate data, generally unlabeled, in quasi continuous-time to detect quickly the occurrence of anomalies that may jeopardize the smooth operation of the system of interest. The statistical analysis of such massive data of functional nature raises many challenging methodological questions. The primary goal of this paper is to extend the popular Isolation Forest (IF) approach to Anomaly Detection, originally dedicated to finite dimensional observations, to functional data. The major difficulty lies in the wide variety of topological structures that may equip a space of functions and the great variety of patterns that may characterize abnormal curves. We address the issue of (randomly) splitting the functional space in a flexible manner in order to isolate progressively any trajectory from the others, a key ingredient to the efficiency of the algorithm. Beyond a detailed description of the algorithm, computational complexity and stability issues are investigated at length. From the scoring function measuring the degree of abnormality of an observation provided by the proposed variant of the IF algorithm, a Functional Statistical Depth function is defined and discussed as well as a multivariate functional extension. Numerical experiments provide strong empirical evidence of the accuracy of the extension proposed.", "venue": "ACML", "authors": ["Guillaume  Staerman", "Pavlo  Mozharovskyi", "St\u00e9phan  Cl\u00e9men\u00e7on", "Florence  d'Alch\u00e9-Buc"], "year": 2019, "n_citations": 11}
{"id": 165757, "s2_id": "24980b747505e479c7a63fecba8ab2056ff2efe9", "title": "Understood in Translation: Transformers for Domain Understanding", "abstract": "Knowledge acquisition is the essential first step of any Knowledge Graph (KG) application. This knowledge can be extracted from a given corpus (KG generation process) or specified from an existing KG (KG specification process). Focusing on domain specific solutions, knowledge acquisition is a labor intensive task usually orchestrated and supervised by subject matter experts. Specifically, the domain of interest is usually manually defined and then the needed generation or extraction tools are utilized to produce the KG. Herein, we propose a supervised machine learning method, based on Transformers, for domain definition of a corpus. We argue why such automated definition of the domain\u2019s structure is beneficial both in terms of construction time and quality of the generated graph. The proposed method is extensively validated on three public datasets (WebNLG, NYT and DocRED) by comparing it with two reference methods based on CNNs and RNNs models. The evaluation shows the efficiency of our model in this task. Focusing on scientific document understanding, we present a new health domain dataset based on publications extracted from PubMed and we successfully utilize our method on this. Lastly, we demonstrate how this work lays the foundation for fully automated and unsupervised KG", "venue": "SDU@AAAI", "authors": ["Dimitrios  Christofidellis", "Matteo  Manica", "Leonidas  Georgopoulos", "Hans  Vandierendonck"], "year": 2021, "n_citations": 0}
{"id": 168410, "s2_id": "dd0da1cd62f3b49402e4544aa3fdbe0a362fbca0", "title": "Learning Stabilizable Dynamical Systems via Control Contraction Metrics", "abstract": "We propose a novel framework for learning stabilizable nonlinear dynamical systems for continuous control tasks in robotics. The key idea is to develop a new control-theoretic regularizer for dynamics fitting rooted in the notion of stabilizability, which guarantees that the learned system can be accompanied by a robust controller capable of stabilizing any open-loop trajectory that the system may generate. By leveraging tools from contraction theory, statistical learning, and convex optimization, we provide a general and tractable semi-supervised algorithm to learn stabilizable dynamics, which can be applied to complex underactuated systems. We validated the proposed algorithm on a simulated planar quadrotor system and observed notably improved trajectory generation and tracking performance with the control-theoretic regularized model over models learned using traditional regression techniques, especially when using a small number of demonstration examples. The results presented illustrate the need to infuse standard model-based reinforcement learning algorithms with concepts drawn from nonlinear control theory for improved reliability.", "venue": "EasyChair Preprints", "authors": ["Sumeet  Singh", "Vikas  Sindhwani", "Jean-Jacques E. Slotine", "Marco  Pavone"], "year": 2019, "n_citations": 13}
{"id": 168672, "s2_id": "321c7329344758eaa8289504a8416926c8913872", "title": "Usage-Based Vehicle Insurance: Driving Style Factors of Accident Probability and Severity", "abstract": "The paper introduces an approach to telematics devices data application in automotive insurance. We conduct a comparative analysis of different types of devices that collect information on vehicle utilization and driving style of its driver, describe advantages and disadvantages of these devices and indicate the most efficient from the insurer point of view. The possible formats of telematics data are described and methods of their processing to a format convenient for modelling are proposed. We also introduce an approach to classify the accidents strength. Using all the available information, we estimate accident probability models for different types of accidents and identify an optimal set of factors for each of the models. We assess the quality of resulting models using both in-sample and out-of-sample estimates.", "venue": "Journal of Transportation Safety & Security", "authors": ["Konstantin  Korishchenko", "Ivan  Stankevich", "Nikolay  Pilnik", "Daria  Petrova"], "year": 2021, "n_citations": 0}
{"id": 171333, "s2_id": "1e6de530a183cded2373c8f0ffc54f4a9b7bd02e", "title": "The Origins and Prevalence of Texture Bias in Convolutional Neural Networks", "abstract": "Recent work has indicated that, unlike humans, ImageNet-trained CNNs tend to classify images by texture rather than by shape. How pervasive is this bias, and where does it come from? We find that, when trained on datasets of images with conflicting shape and texture, CNNs learn to classify by shape at least as easily as by texture. What factors, then, produce the texture bias in CNNs trained on ImageNet? Different unsupervised training objectives and different architectures have small but significant and largely independent effects on the level of texture bias. However, all objectives and architectures still lead to models that make texture-based classification decisions a majority of the time, even if shape information is decodable from their hidden representations. The effect of data augmentation is much larger. By taking less aggressive random crops at training time and applying simple, naturalistic augmentation (color distortion, noise, and blur), we train models that classify ambiguous images by shape a majority of the time, and outperform baselines on out-of-distribution test sets. Our results indicate that apparent differences in the way humans and ImageNet-trained CNNs process images may arise not from differences in their internal workings, but from differences in the data that they see.", "venue": "NeurIPS", "authors": ["Katherine L. Hermann", "Ting  Chen", "Simon  Kornblith"], "year": 2020, "n_citations": 49}
{"id": 172810, "s2_id": "a81abf2175e36308c54f67dffdea7de74803a42d", "title": "Characterizing Distribution Equivalence and Structure Learning for Cyclic and Acyclic Directed Graphs", "abstract": "The main approach to defining equivalence among acyclic directed causal graphical models is based on the conditional independence relationships in the distributions that the causal models can generate, in terms of the Markov equivalence. However, it is known that when cycles are allowed in the causal structure, conditional independence may not be a suitable notion for equivalence of two structures, as it does not reflect all the information in the distribution that is useful for identification of the underlying structure. In this paper, we present a general, unified notion of equivalence for linear Gaussian causal directed graphical models, whether they are cyclic or acyclic. In our proposed definition of equivalence, two structures are equivalent if they can generate the same set of data distributions. We also propose a weaker notion of equivalence called quasi-equivalence, which we show is the extent of identifiability from observational data. We propose analytic as well as graphical methods for characterizing the equivalence of two structures. Additionally, we propose a score-based method for learning the structure from observational data, which successfully deals with both acyclic and cyclic structures.", "venue": "ICML", "authors": ["AmirEmad  Ghassami", "Alan  Yang", "Negar  Kiyavash", "Kun  Zhang"], "year": 2020, "n_citations": 4}
{"id": 173240, "s2_id": "a179f28aa0d8a380f9bbd94a0e0be835bf775f6c", "title": "Utilizing Concept Drift for Measuring the Effectiveness of Policy Interventions: The Case of the COVID-19 Pandemic", "abstract": "As a reaction to the high infectiousness and lethality of the COVID-19 virus, countries around the world have adopted drastic policy measures to contain the pandemic. However, it remains unclear which effect these measures, so-called non-pharmaceutical interventions (NPIs), have on the spread of the virus. In this article, we use machine learning and apply drift detection methods in a novel way to measure the effectiveness of policy interventions: We analyze the effect of NPIs on the development of daily case numbers of COVID-19 across 9 European countries and 28 US states. Our analysis shows that it takes more than two weeks on average until NPIs show a significant effect on the number of new cases. We then analyze how characteristics of each country or state, e.g., decisiveness regarding NPIs, climate or population density, influence the time lag until NPIs show their effectiveness. In our analysis, especially the timing of school closures reveals a significant effect on the development of the pandemic. This information is crucial for policy makers confronted with difficult decisions to trade off strict containment of the virus with NPI relief.", "venue": "ArXiv", "authors": ["Lucas  Baier", "Niklas  K\u00fchl", "Jakob  Sch\u00f6ffer", "Gerhard  Satzger"], "year": 2020, "n_citations": 2}
{"id": 174316, "s2_id": "2d9978d3d17a02d03d5fedccc388a2ba5a3a2367", "title": "GaNDLF: A Generally Nuanced Deep Learning Framework for Scalable End-to-End Clinical Workflows in Medical Imaging", "abstract": "Deep Learning (DL) has greatly highlighted the potential impact of optimized machine learning in both the scientific and clinical communities. The advent of open-source DL libraries from major industrial entities, such as TensorFlow (Google), PyTorch (Facebook), and MXNet (Apache), further contributes to DL promises on the democratization of computational analytics. However, increased technical and specialized background is required to develop DL algorithms, and the variability of implementation details hinders their reproducibility. Towards lowering the barrier and making the mechanism of DL development, training, and inference more stable, reproducible, and scalable, without requiring an extensive technical background, this manuscript proposes the Generally Nuanced Deep Learning Framework (GaNDLF). With built-in support for k-fold cross-validation, data augmentation, multiple modalities and output classes, and multi-GPU training, as well as the ability to work with both radiographic and histologic imaging, GaNDLF aims to provide an end-to-end solution for all DL-related tasks, to tackle problems in medical imaging and provide a robust application framework for deployment in clinical workflows.", "venue": "ArXiv", "authors": ["Sarthak  Pati", "Siddhesh P. Thakur", "Megh  Bhalerao", "Ujjwal  Baid", "Caleb  Grenko", "Brandon  Edwards", "Micah  Sheller", "Jose  Agraz", "Bhakti  Baheti", "Vishnu  Bashyam", "Parth  Sharma", "Babak  Haghighi", "Aimilia  Gastounioti", "Mark  Bergman", "Bjoern  Menze", "Despina  Kontos", "Christos  Davatzikos", "Spyridon  Bakas"], "year": 2021, "n_citations": 5}
{"id": 177204, "s2_id": "df703f9143e1ac5e3cd26a89e4ea8d6c398a7379", "title": "Orthogonal Deep Models as Defense Against Black-Box Attacks", "abstract": "Deep learning has demonstrated state-of-the-art performance for a variety of challenging computer vision tasks. On one hand, this has enabled deep visual models to pave the way for a plethora of critical applications like disease prognostics and smart surveillance. On the other, deep learning has also been found vulnerable to adversarial attacks, which calls for new techniques to defend deep models against these attacks. Among the attack algorithms, the black-box schemes are of serious practical concern since they only need publicly available knowledge of the targeted model. We carefully analyze the inherent weakness of deep models in black-box settings where the attacker may develop the attack using a model similar to the targeted model. Based on our analysis, we introduce a novel gradient regularization scheme that encourages the internal representation of a deep model to be orthogonal to another, even if the architectures of the two models are similar. Our unique constraint allows a model to concomitantly endeavour for higher accuracy while maintaining near orthogonal alignment of gradients with respect to a reference model. Detailed empirical study verifies that controlled misalignment of gradients under our orthogonality objective significantly boosts a model\u2019s robustness against transferable black-box adversarial attacks. In comparison to regular models, the orthogonal models are significantly more robust to a range of $l_{p}$ norm bounded perturbations. We verify the effectiveness of our technique on a variety of large-scale models.", "venue": "IEEE Access", "authors": ["Mohammad A. A. K. Jalwana", "Naveed  Akhtar", "Mohammed  Bennamoun", "Ajmal  Mian"], "year": 2020, "n_citations": 4}
{"id": 182600, "s2_id": "9e46345d413f5a1452f822a91c42b41116b17863", "title": "Classification of Perceived Human Stress using Physiological Signals", "abstract": "In this paper, we present an experimental study for the classification of perceived human stress using non-invasive physiological signals. These include electroencephalography (EEG), galvanic skin response (GSR), and photoplethysmography (PPG). We conducted experiments consisting of steps including data acquisition, feature extraction, and perceived human stress classification. The physiological data of 28 participants are acquired in an open eye condition for a duration of three minutes. Four different features are extracted in time domain from EEG, GSR and PPG signals and classification is performed using multiple classifiers including support vector machine, the Naive Bayes, and multi-layer perceptron (MLP). The best classification accuracy of 75% is achieved by using MLP classifier. Our experimental results have shown that our proposed scheme outperforms existing perceived stress classification methods, where no stress inducers are used.", "venue": "2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)", "authors": ["Aamir  Arsalan", "Muhammad  Majid", "Syed Muhammad Anwar", "Ulas  Bagci"], "year": 2019, "n_citations": 6}
{"id": 183296, "s2_id": "d02d1c71c45b94582a85410d3163c3e7dcd9ae10", "title": "Temporal Difference Updating without a Learning Rate", "abstract": "We derive an equation for temporal difference learning from statistical principles. Specifically, we start with the variational principle and then bootstrap to produce an updating rule for discounted state value estimates. The resulting equation is similar to the standard equation for temporal difference learning with eligibility traces, so called TD(\u03bb), however it lacks the parameter \u03b1 that specifies the learning rate. In the place of this free parameter there is now an equation for the learning rate that is specific to each state transition. We experimentally test this new learning rule against TD(\u03bb) and find that it offers superior performance in various settings. Finally, we make some preliminary investigations into how to extend our new temporal difference algorithm to reinforcement learning. To do this we combine our update equation with both Watkins' Q(\u03bb) and Sarsa(\u03bb) and find that it again offers superior performance without a learning rate parameter.", "venue": "NIPS", "authors": ["Marcus  Hutter", "Shane  Legg"], "year": 2007, "n_citations": 15}
{"id": 183923, "s2_id": "68ceae96c0238fd24be096c1c0a1d378c0fd1e50", "title": "Characterizing Speech Adversarial Examples Using Self-Attention U-Net Enhancement", "abstract": "Recent studies have highlighted adversarial examples as ubiquitous threats to the deep neural network (DNN) based speech recognition systems. In this work, we present a U-Net based attention model, UNetAt, to enhance adversarial speech signals. Specifically, we evaluate the model performance by interpretable speech recognition metrics and discuss the model performance by the augmented adversarial training. Our experiments show that our proposed U-NetAt improves the perceptual evaluation of speech quality (PESQ) from 1.13 to 2.78, speech transmission index (STI) from 0.65 to 0.75, shortterm objective intelligibility (STOI) from 0.83 to 0.96 on the task of speech enhancement with adversarial speech examples. We conduct experiments on the automatic speech recognition (ASR) task with adversarial audio attacks. We find that (i) temporal features learned by the attention network are capable of enhancing the robustness of DNN based ASR models; (ii) the generalization power of DNN based ASR model could be enhanced by applying adversarial training with an additive adversarial data augmentation. The ASR metric on word-error-rates (WERs) shows that there is an absolute 2.22 % decrease under gradient-based perturbation, and an absolute 2.03 % decrease, under evolutionary-optimized perturbation, which suggests that our enhancement models with adversarial training can further secure a resilient ASR system.", "venue": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Chao-Han Huck Yang", "Jun  Qi", "Pin-Yu  Chen", "Xiaoli  Ma", "Chin-Hui  Lee"], "year": 2020, "n_citations": 28}
{"id": 191728, "s2_id": "b5f4b13e674cd0ce8744f250b0d4826c6d8dc135", "title": "Controlling the False Split Rate in Tree-Based Aggregation", "abstract": "In many domains, data measurements can naturally be associated with the leaves of a tree, expressing the relationships among these measurements. For example, companies belong to industries, which in turn belong to ever coarser divisions such as sectors; microbes are commonly arranged in a taxonomic hierarchy from species to kingdoms; street blocks belong to neighborhoods, which in turn belong to larger-scale regions. The problem of tree-based aggregation that we consider in this paper asks which of these tree-defined subgroups of leaves should really be treated as a single entity and which of these entities should be distinguished from each other. We introduce the false split rate, an error measure that describes the degree to which subgroups have been split when they should not have been. We then propose a multiple hypothesis testing algorithm for tree-based aggregation, which we prove controls this error measure. We focus on two main examples of tree-based aggregation, one which involves aggregating means and the other which involves aggregating regression coefficients. We apply this methodology to aggregate stocks based on their volatility and to aggregate neighborhoods of New York City based on taxi fares.", "venue": "ArXiv", "authors": ["Simeng  Shao", "Jacob  Bien", "Adel  Javanmard"], "year": 2021, "n_citations": 0}
{"id": 196714, "s2_id": "520644e50dc5603f82b687c9578c0453244d41c1", "title": "A new space for comparing graphs", "abstract": "Finding a new mathematical representation for graphs, which allows direct comparison between different graph structures, is an open-ended research direction. Having such a representation is the first prerequisite for a variety of machine learning algorithms like classification, clustering, etc., over graph datasets. In this paper, we propose a symmetric positive semidefinite matrix with the (i, j)-th entry equal to the covariance between normalized vectors Aie and Aje (e being vector of all ones) as a representation for a graph with adjacency matrix A. We show that the proposed matrix representation encodes the spectrum of the underlying adjacency matrix and it also contains information about the counts of small sub-structures present in the graph such as triangles and small paths. In addition, we show that this matrix is a \u201cgraph invariant\u201d. All these properties make the proposed matrix a suitable object for representing graphs. The representation, being a covariance matrix in a fixed dimensional metric space, gives a mathematical embedding for graphs. This naturally leads to a measure of similarity on graph objects. We define similarity between two given graphs as a Bhattacharya similarity measure between their corresponding covariance matrix representations. As shown in our experimental study on the task of social network classification, such a similarity measure outperforms other widely used state-of-the-art methodologies. Our proposed method is also computationally efficient. The computation of both the matrix representation and the similarity value can be performed in operations linear in the number of edges. This makes our method scalable in practice. We believe our theoretical and empirical results provide evidence for studying truncated power iterations, of the adjacency matrix, to characterize social networks.", "venue": "2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2014)", "authors": ["Anshumali  Shrivastava", "Ping  Li"], "year": 2014, "n_citations": 28}
{"id": 202183, "s2_id": "724cc225a0171bcde03e06e83b64bc21d9aa5460", "title": "Combining Context-Free and Contextualized Representations for Arabic Sarcasm Detection and Sentiment Identification", "abstract": "Since their inception, transformer-based language models have led to impressive performance gains across multiple natural language processing tasks. For Arabic, the current state-of-the-art results on most datasets are achieved by the AraBERT language model. Notwithstanding these recent advancements, sarcasm and sentiment detection persist to be challenging tasks in Arabic, given the language\u2019s rich morphology, linguistic disparity and dialectal variations. This paper proffers team SPPU-AASM\u2019s submission for the WANLP ArSarcasm shared-task 2021, which centers around the sarcasm and sentiment polarity detection of Arabic tweets. The study proposes a hybrid model, combining sentence representations from AraBERT with static word vectors trained on Arabic social media corpora. The proposed system achieves a F1-sarcastic score of 0.62 and a F-PN score of 0.715 for the sarcasm and sentiment detection tasks, respectively. Simulation results show that the proposed system outperforms multiple existing approaches for both the tasks, suggesting that the amalgamation of context-free and context-dependent text representations can help capture complementary facets of word meaning in Arabic. The system ranked second and tenth in the respective sub-tasks of sarcasm detection and sentiment identification.", "venue": "WANLP", "authors": ["Amey  Hengle", "Atharva  Kshirsagar", "Shaily  Desai", "Manisha  Marathe"], "year": 2021, "n_citations": 1}
{"id": 209634, "s2_id": "abee3a81e91050b8f1a197def7aa87b42685a93c", "title": "In situ process quality monitoring and defect detection for direct metal laser melting", "abstract": "Quality control and quality assurance are challenges in Direct Metal Laser Melting (DMLM). Intermittent machine diagnostics and downstream part inspections catch problems after undue cost has been incurred processing defective parts. In this paper we demonstrate two methodologies for in-process fault detection and part quality prediction that can be readily deployed on existing commercial DMLM systems with minimal hardware modification. Novel features were derived from the time series of common photodiode sensors along with standard machine control signals. A Bayesian approach attributes measurements to one of multiple process states and a least squares regression model predicts severity of certain material defects.", "venue": "ArXiv", "authors": ["Sarah  Felix", "Saikat Ray Majumder", "H. Kirk Mathews", "Michael  Lexa", "Gabriel  Lipsa", "Xiaohu  Ping", "Subhrajit  Roychowdhury", "Thomas  Spears"], "year": 2021, "n_citations": 0}
{"id": 210309, "s2_id": "cfb4a39d8b16aa7f9421ff06f98dbb58fe02d276", "title": "Untangling Dense Knots by Learning Task-Relevant Keypoints", "abstract": "Untangling ropes, wires, and cables is a challenging task for robots due to the high-dimensional configuration space, visual homogeneity, self-occlusions, and complex dynamics. We consider dense (tight) knots that lack space between self-intersections and present an iterative approach that uses learned geometric structure in configurations. We instantiate this into an algorithm, HULK: Hierarchical Untangling from Learned Keypoints, which combines learning-based perception with a geometric planner into a policy that guides a bilateral robot to untangle knots. To evaluate the policy, we perform experiments both in a novel simulation environment modelling cables with varied knot types and textures and in a physical system using the da Vinci surgical robot. We find that HULK is able to untangle cables with dense figure-eight and overhand knots and generalize to varied textures and appearances. We compare two variants of HULK to three baselines and observe that HULK achieves 43.3% higher success rates on a physical system compared to the next best baseline. HULK successfully untangles a cable from a dense initial configuration containing up to two overhand and figure-eight knots in 97.9% of 378 simulation experiments with an average of 12.1 actions per trial. In physical experiments, HULK achieves 61.7% untangling success, averaging 8.48 actions per trial. Supplementary material, code, and videos can be found at this https URL.", "venue": "CoRL", "authors": ["Jennifer  Grannen", "Priya  Sundaresan", "Brijen  Thananjeyan", "Jeffrey  Ichnowski", "Ashwin  Balakrishna", "Minho  Hwang", "Vainavi  Viswanath", "Michael  Laskey", "Joseph E. Gonzalez", "Ken  Goldberg"], "year": 2020, "n_citations": 8}
{"id": 211057, "s2_id": "8a4f72e16205cfc81794e941a5083270678e03dd", "title": "Robust Spammer Detection by Nash Reinforcement Learning", "abstract": "Online reviews provide product evaluations for customers to make decisions. Unfortunately, the evaluations can be manipulated using fake reviews (\"spams\") by professional spammers, who have learned increasingly insidious and powerful spamming strategies by adapting to the deployed detectors. Spamming strategies are hard to capture, as they can be varying quickly along time, different across spammers and target products, and more critically, remained unknown in most cases. Furthermore, most existing detectors focus on detection accuracy, which is not well-aligned with the goal of maintaining the trustworthiness of product evaluations. To address the challenges, we formulate a minimax game where the spammers and spam detectors compete with each other on their practical goals that are not solely based on detection accuracy. Nash equilibria of the game lead to stable detectors that are agnostic to any mixed detection strategies. However, the game has no closed-form solution and is not differentiable to admit the typical gradient-based algorithms. We turn the game into two dependent Markov Decision Processes (MDPs) to allow efficient stochastic optimization based on multi-armed bandit and policy gradient. We experiment on three large review datasets using various state-of-the-art spamming and detection strategies and show that the optimization algorithm can reliably find an equilibrial detector that can robustly and effectively prevent spammers with any mixed spamming strategies from attaining their practical goal. Our code is available at https://github.com/YingtongDou/Nash-Detect.", "venue": "KDD", "authors": ["Yingtong  Dou", "Guixiang  Ma", "Philip S. Yu", "Sihong  Xie"], "year": 2020, "n_citations": 12}
{"id": 215967, "s2_id": "3332dc72fbe3907e45e8a500c6a1202ad5092c0f", "title": "Deep clustering: Discriminative embeddings for segmentation and separation", "abstract": "We address the problem of \"cocktail-party\" source separation in a deep learning framework called deep clustering. Previous deep network approaches to separation have shown promising performance in scenarios with a fixed number of sources, each belonging to a distinct signal class, such as speech and noise. However, for arbitrary source classes and number, \"class-based\" methods are not suitable. Instead, we train a deep network to assign contrastive embedding vectors to each time-frequency region of the spectrogram in order to implicitly predict the segmentation labels of the target spectrogram from the input mixtures. This yields a deep network-based analogue to spectral clustering, in that the embeddings form a low-rank pair-wise affinity matrix that approximates the ideal affinity matrix, while enabling much faster performance. At test time, the clustering step \"decodes\" the segmentation implicit in the embeddings by optimizing K-means with respect to the unknown assignments. Preliminary experiments on single-channel mixtures from multiple speakers show that a speaker-independent model trained on two-speaker mixtures can improve signal quality for mixtures of held-out speakers by an average of 6dB. More dramatically, the same model does surprisingly well with three-speaker mixtures.", "venue": "2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["John R. Hershey", "Zhuo  Chen", "Jonathan Le Roux", "Shinji  Watanabe"], "year": 2016, "n_citations": 782}
{"id": 228294, "s2_id": "642b2b2e8d686ab18a6a44c24ea9babab3f3785e", "title": "Stochastic Intervention for Causal Inference via Reinforcement Learning", "abstract": "Causal inference methods are widely applied in various decision-making domains such as precision medicine, optimal policy and economics. Central to causal inference is the treatment effect estimation of intervention strategies, such as changes in drug dosing and increases in financial aid. Existing methods are mostly restricted to the deterministic treatment and compare outcomes under different treatments. However, they are unable to address the substantial recent interest of treatment effect estimation under stochastic treatment, e.g., \u201chow all units health status change if they adopt 50% dose reduction\u201d. In other words, they lack the capability of providing fine-grained treatment effect estimation to support sound decision-making. In our study, we advance the causal inference research by proposing a new effective framework to estimate the treatment effect on stochastic intervention. Particularly, we develop a stochastic intervention effect estimator (SIE) based on nonparametric influence function, with the theoretical guarantees of robustness and fast convergence rates. Additionally, we construct a customised reinforcement learning algorithm based on the random search solver which can effectively find the optimal policy to produce the greatest expected outcomes for the decision-making process. Finally, we conduct an empirical study to justify that our framework can achieve significant performance in comparison with state-of-the-art baselines. \u2217Corresponding author Email addresses: TriDung.Duong@student.uts.edu.au (Tri Dung Duong), Qian.Li@uts.edu.au (Qian Li), Guandong.Xu@uts.edu.au (Guandong Xu) Preprint submitted to Journal of LTEX Templates May 31, 2021 ar X iv :2 10 5. 13 51 4v 1 [ cs .A I] 2 8 M ay 2 02 1", "venue": "ArXiv", "authors": ["Tri Dung Duong", "Qian  Li", "Guandong  Xu"], "year": 2021, "n_citations": 1}
{"id": 236890, "s2_id": "1dc3b66cbeb2e3f9fc5b538fe2f535d452383bd7", "title": "Occlusion-Aware Search for Object Retrieval in Clutter", "abstract": "We address the manipulation task of retrieving a target object from a cluttered shelf. When the target object is hidden, the robot must search through the clutter for retrieving it. Solving this task requires reasoning over the likely locations of the target object. It also requires physics reasoning over multi-object interactions and future occlusions. In this work, we present a data-driven hybrid planner for generating occlusion-aware actions in closed-loop. The hybrid planner explores likely locations of the occluded target object as predicted by a learned distribution from the observation stream. The search is guided by a heuristic trained with reinforcement learning to act on observations with occlusions. We evaluate our approach in different simulation and real-world settings (video available on https://youtu.be/dY7YQ3LUVQg). The results validate that our approach can search and retrieve a target object in near real time in the real world while only being trained in simulation.", "venue": "2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "authors": ["Wissam  Bejjani", "Wisdom C. Agboh", "Mehmet R. Dogar", "Matteo  Leonetti"], "year": 2021, "n_citations": 2}
{"id": 251788, "s2_id": "354ec9f2a18e3871e9df87b25de27bb4d243a6ba", "title": "Towards \"AlphaChem\": Chemical Synthesis Planning with Tree Search and Deep Neural Network Policies", "abstract": "Retrosynthesis is a technique to plan the chemical synthesis of organic molecules, for example drugs, agro- and fine chemicals. In retrosynthesis, a search tree is built by analysing molecules recursively and dissecting them into simpler molecular building blocks until one obtains a set of known building blocks. The search space is intractably large, and it is difficult to determine the value of retrosynthetic positions. Here, we propose to model retrosynthesis as a Markov Decision Process. In combination with a Deep Neural Network policy learned from essentially the complete published knowledge of chemistry, Monte Carlo Tree Search (MCTS) can be used to evaluate positions. In exploratory studies, we demonstrate that MCTS with neural network policies outperforms the traditionally used best-first search with hand-coded heuristics.", "venue": "ICLR", "authors": ["Marwin H. S. Segler", "Mike  Preuss", "Mark P. Waller"], "year": 2017, "n_citations": 24}
{"id": 253090, "s2_id": "16e66b38d8089739d3383feaee0619975759c1b5", "title": "DESlib: A Dynamic ensemble selection library in Python", "abstract": "DESlib is an open-source python library providing the implementation of several dynamic selection techniques. The library is divided into three modules: (i) \\emph{dcs}, containing the implementation of dynamic classifier selection methods (DCS); (ii) \\emph{des}, containing the implementation of dynamic ensemble selection methods (DES); (iii) \\emph{static}, with the implementation of static ensemble techniques. The library is fully documented (documentation available online on Read the Docs), has a high test coverage (this http URL) and is part of the scikit-learn-contrib supported projects. Documentation, code and examples can be found on its GitHub page: this https URL.", "venue": "J. Mach. Learn. Res.", "authors": ["Rafael M. O. Cruz", "Luiz G. Hafemann", "Robert  Sabourin", "George D. C. Cavalcanti"], "year": 2020, "n_citations": 33}
{"id": 253890, "s2_id": "d1889363bd7219105d734c434efac6b83e9bdb61", "title": "Sentiment Analysis of Yelp Reviews: A Comparison of Techniques and Models", "abstract": "We use over 350,000 Yelp reviews on 5,000 restaurants to perform an ablation study on text preprocessing techniques. We also compare the effectiveness of several machine learning and deep learning models on predicting user sentiment (negative, neutral, or positive). For machine learning models, we find that using binary bag-of-word representation, adding bi-grams, imposing minimum frequency constraints and normalizing texts have positive effects on model performance. For deep learning models, we find that using pre-trained word embeddings and capping maximum length often boost model performance. Finally, using macro F1 score as our comparison metric, we find simpler models such as Logistic Regression and Support Vector Machine to be more effective at predicting sentiments than more complex models such as Gradient Boosting, LSTM and BERT.", "venue": "ArXiv", "authors": ["Siqi  Liu"], "year": 2020, "n_citations": 3}
{"id": 264126, "s2_id": "e2a3ec751e00939bee51f0dfa3a68e367ddfb608", "title": "Automatic Generation of Machine Learning Synthetic Data Using ROS", "abstract": "Data labeling is a time intensive process. As such, many data scientists use various tools to aid in the data generation and labeling process. While these tools help automate labeling, many still require user interaction throughout the process. Additionally, most target only a few network frameworks. Any researchers exploring multiple frameworks must find additional tools or write conversion scripts. This paper presents an automated tool for generating synthetic data in arbitrary network formats. It uses Robot Operating System (ROS) and Gazebo, which are common tools in the robotics community. Through ROS paradigms, it allows extensive user customization of the simulation environment and data generation process. Additionally, a plugin-like framework allows the development of arbitrary data format writers without the need to change the main body of code. Using this tool, the authors were able to generate an arbitrarily large image dataset for three unique training formats using approximately 15 minutes of user setup time and a variable amount of hands-off run time, depending on the dataset size. The source code for this data generation tool is available at https://github.com/Navy-RISE-Lab/nn_data_collection", "venue": "HCI", "authors": ["Kyle M. Hart", "Ari B. Goodman", "Ryan P. O'Shea"], "year": 2021, "n_citations": 0}
{"id": 270678, "s2_id": "9753dd8da1f391339121199873fc621105ae24fc", "title": "Learning Networks from Random Walk-Based Node Similarities", "abstract": "Digital presence in the world of online social media entails significant privacy risks. In this work we consider a privacy threat to a social network in which an attacker has access to a subset of random walk-based node similarities, such as effective resistances (i.e., commute times) or personalized PageRank scores. Using these similarities, the attacker's goal is to infer as much information as possible about the underlying network, including any remaining unknown pairwise node similarities and edges. \nFor the effective resistance metric, we show that with just a small subset of measurements, the attacker can learn a large fraction of edges in a social network, even when the measurements are noisy. We also show that it is possible to learn a graph which accurately matches the underlying network on all other effective resistances. This second observation is interesting from a data mining perspective, since it can be expensive to accurately compute all effective resistances. As an alternative, our graphs learned from just a subset of approximate effective resistances can be used as surrogates in a wide range of applications that use effective resistances to probe graph structure, including for graph clustering, node centrality evaluation, and anomaly detection. \nWe obtain our results by formalizing the graph learning objective mathematically, using two optimization problems. One formulation is convex and can be solved provably in polynomial time. The other is not, but we solve it efficiently with projected gradient and coordinate descent. We demonstrate the effectiveness of these methods on a number of social networks obtained from Facebook. We also discuss how our methods can be generalized to other random walk-based similarities, such as personalized PageRank. Our code is available at this https URL", "venue": "ArXiv", "authors": ["Jeremy G. Hoskins", "Cameron  Musco", "Christopher  Musco", "Charalampos E. Tsourakakis"], "year": 2018, "n_citations": 4}
{"id": 278486, "s2_id": "b7f3d982d77678a074010bba7c702f14528bbe8b", "title": "There is More than Meets the Eye: Self-Supervised Multi-Object Detection and Tracking with Sound by Distilling Multimodal Knowledge", "abstract": "Attributes of sound inherent to objects can provide valuable cues to learn rich representations for object detection and tracking. Furthermore, the co-occurrence of audiovisual events in videos can be exploited to localize objects over the image field by solely monitoring the sound in the environment. Thus far, this has only been feasible in scenarios where the camera is static and for single object detection. Moreover, the robustness of these methods has been limited as they primarily rely on RGB images which are highly susceptible to illumination and weather changes. In this work, we present the novel self-supervised MM-DistillNet framework consisting of multiple teachers that leverage diverse modalities including RGB, depth and thermal images, to simultaneously exploit complementary cues and distill knowledge into a single audio student network. We propose the new MTA loss function that facilitates the distillation of information from multimodal teachers in a self-supervised manner. Additionally, we propose a novel self-supervised pretext task for the audio student that enables us to not rely on labor-intensive manual annotations. We introduce a large-scale multimodal dataset with over 113,000 time-synchronized frames of RGB, depth, thermal, and audio modalities. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods while being able to detect multiple objects using only sound during inference and even while moving.", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Francisco Rivera Valverde", "Juana Valeria Hurtado", "Abhinav  Valada"], "year": 2021, "n_citations": 4}
{"id": 282241, "s2_id": "fb44ecf9dc16c9e94d006155b491dffc12d156d5", "title": "Video-Data Pipelines for Machine Learning Applications", "abstract": "Data pipelines are an essential component for end-to-end solutions that take machine learning algorithms to production. Engineering data pipelines for video-sequences poses several challenges including isolation of key-frames from video sequences that are high quality and represent significant variations in the scene. Manual isolation of such quality key-frames can take hours of sifting through hours\u2019 worth of video data. In this work, we present a data pipeline framework that can automate this process of manual frame sifting in video sequences by controlling the fraction of frames that can be removed based on image quality and content type. Additionally, the frames that are retained can be automatically tagged per sequence, thereby simplifying the process of automated data retrieval for future ML model deployments. We analyze the performance of the proposed video-data pipeline for versioned deployment and monitoring for object detection algorithms that are trained on outdoor autonomous driving video sequences. The proposed video-data pipeline can retain anywhere between 0.1-20% of the all input frames that are representative of high image quality and high variations in content. This frame selection, automated scene tagging followed by model verification can be completed in under 30 seconds for 22 video-sequences under analysis in this work. Thus, the proposed framework can be scaled to additional video-sequence data sets for automating ML versioned deployments.", "venue": "ArXiv", "authors": ["Sohini  Roychowdhury", "James Y. Sato"], "year": 2021, "n_citations": 0}
{"id": 286519, "s2_id": "d4c773179291a5089730ce4f0940f4bcec62abee", "title": "Graph Representation Learning via Multi-task Knowledge Distillation", "abstract": "Machine learning on graph structured data has attracted much research interest due to its ubiquity in real world data. However, how to efficiently represent graph data in a general way is still an open problem. Traditional methods use handcraft graph features in a tabular form but suffer from the defects of domain expertise requirement and information loss. Graph representation learning overcomes these defects by automatically learning the continuous representations from graph structures, but they require abundant training labels, which are often hard to fulfill for graph-level prediction problems. In this work, we demonstrate that, if available, the domain expertise used for designing handcraft graph features can improve the graph-level representation learning when training labels are scarce. Specifically, we proposed a multi-task knowledge distillation method. By incorporating network-theory-based graph metrics as auxiliary tasks, we show on both synthetic and real datasets that the proposed multi-task learning method can improve the prediction performance of the original learning task, especially when the training data size is small.", "venue": "ArXiv", "authors": ["Jiaqi  Ma", "Qiaozhu  Mei"], "year": 2019, "n_citations": 9}
{"id": 288902, "s2_id": "32e207fef0798fccd63dc614740733fd0525a92d", "title": "Hierarchical Latent Semantic Mapping for automated topic generation", "abstract": "Much of information sits in an unprecedented amount of text data. Managing allocation of these large scale text data is an important problem for many areas. Topic modeling performs well in this problem. The traditional generative models (PLSA,LDA) are the state-of-the-art approaches in topic modeling and most recent research on topic generation has been focusing on improving or extending these models. However, results of traditional generative models are sensitive to the number of topics K, which must be specified manually and determines the rank of solution space for topic generation. The problem of generating topics from corpus resembles community detection in networks. Many effective algorithms can automatically detect communities from networks without a manually specified number of the communities. Inspired by these algorithms, in this paper, we propose a novel method named Hierarchical Latent Semantic Mapping (HLSM), which automatically generates topics from corpus. HLSM calculates the association between each pair of words in the latent topic space, then constructs a unipartite network of words with this association and hierarchically generates topics from this network. We apply HLSM to several document collections and the experimental comparisons against several state-of-the-art approaches demonstrate the promising performance.", "venue": "2016 17th IEEE/ACIS International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)", "authors": ["Guorui  Zhou", "Guang  Chen"], "year": 2016, "n_citations": 0}
{"id": 290210, "s2_id": "9a2ea3db0ccd9eb78e01c5d6fc8605afe95ac1c9", "title": "Deep Learning Tubes for Tube MPC", "abstract": "Learning-based control aims to construct models of a system to use for planning or trajectory optimization, e.g. in model-based reinforcement learning. In order to obtain guarantees of safety in this context, uncertainty must be accurately quantified. This uncertainty may come from errors in learning (due to a lack of data, for example), or may be inherent to the system. Propagating uncertainty forward in learned dynamics models is a difficult problem. In this work we use deep learning to obtain expressive and flexible models of how distributions of trajectories behave, which we then use for nonlinear Model Predictive Control (MPC). We introduce a deep quantile regression framework for control that enforces probabilistic quantile bounds and quantifies epistemic uncertainty. Using our method we explore three different approaches for learning tubes that contain the possible trajectories of the system, and demonstrate how to use each of them in a Tube MPC scheme. We prove these schemes are recursively feasible and satisfy constraints with a desired margin of probability. We present experiments in simulation on a nonlinear quadrotor system, demonstrating the practical efficacy of these ideas.", "venue": "Robotics: Science and Systems", "authors": ["David D. Fan", "Ali-akbar  Agha-mohammadi", "Evangelos A. Theodorou"], "year": 2020, "n_citations": 23}
{"id": 290663, "s2_id": "28dd191c48026ada9c60e18557d7ce9909427ecc", "title": "Supervising Unsupervised Learning with Evolutionary Algorithm in Deep Neural Network", "abstract": "A method to control results of gradient descent unsupervised learning in a deep neural network by using evolutionary algorithm is proposed. To process crossover of unsupervisedly trained models, the algorithm evaluates pointwise fitness of individual nodes in neural network. Labeled training data is randomly sampled and breeding process selects nodes by calculating degree of their consistency on different sets of sampled data. This method supervises unsupervised training by evolutionary process. We also introduce modified Restricted Boltzmann Machine which contains repulsive force among nodes in a neural network and it contributes to isolate network nodes each other to avoid accidental degeneration of nodes by evolutionary process. These new methods are applied to document classification problem and it results better accuracy than a traditional fully supervised classifier implemented with linear regression algorithm.", "venue": "ArXiv", "authors": ["Takeshi  Inagaki"], "year": 2018, "n_citations": 0}
{"id": 292854, "s2_id": "a6458494bedaafceff42dacf1aba2dd8eb4732a4", "title": "Variational Hyper RNN for Sequence Modeling", "abstract": "In this work, we propose a novel probabilistic sequence model that excels at capturing high variability in time series data, both across sequences and within an individual sequence. Our method uses temporal latent variables to capture information about the underlying data pattern and dynamically decodes the latent information into modifications of weights of the base decoder and recurrent model. The efficacy of the proposed method is demonstrated on a range of synthetic and real-world sequential data that exhibit large scale variations, regime shifts, and complex dynamics.", "venue": "ArXiv", "authors": ["Ruizhi  Deng", "Yanshuai  Cao", "Bo  Chang", "Leonid  Sigal", "Greg  Mori", "Marcus A. Brubaker"], "year": 2020, "n_citations": 1}
{"id": 293931, "s2_id": "71c47f601cbf10b09ddd3a79fc49720e70010885", "title": "SN-Graph: a Minimalist 3D Object Representation for Classification", "abstract": "Using deep learning techniques to process 3D objects has achieved many successes. However, few methods focus on the representation of 3D objects, which could be more effective for specific tasks than traditional representations, such as point clouds, voxels, and multi-view images. In this paper, we propose a Sphere Node Graph (SN-Graph) to represent 3D objects. Specifically, we extract a certain number of internal spheres (as nodes) from the signed distance field (SDF), and then establish connections (as edges) among the sphere nodes to construct a graph, which is seamlessly suitable for 3D analysis using graph neural network (GNN). Experiments conducted on the ModelNet40 dataset show that when there are fewer nodes in the graph or the tested objects are rotated arbitrarily, the classification accuracy of SN-Graph is significantly higher than the state-of-the-art methods.", "venue": "2021 IEEE International Conference on Multimedia and Expo (ICME)", "authors": ["Siyu  Zhang", "Hui  Cao", "Yuqi  Liu", "Shen  Cai", "Yanting  Zhang", "Yuanzhan  Li", "Xiaoyu  Chi"], "year": 2021, "n_citations": 0}
{"id": 299810, "s2_id": "eb84466e794dcaaea4de99f04704c9d5cb6e6a4d", "title": "Online Learning for Wireless Distributed Computing", "abstract": "There has been a growing interest for Wireless Distributed Computing (WDC), which leverages collaborative computing over multiple wireless devices. WDC enables complex applications that a single device cannot support individually. However, the problem of assigning tasks over multiple devices becomes challenging in the dynamic environments encountered in real-world settings, considering that the resource availability and channel conditions change over time in unpredictable ways due to mobility and other factors. In this paper, we formulate a task assignment problem as an online learning problem using an adversarial multi-armed bandit framework. We propose MABSTA, a novel online learning algorithm that learns the performance of unknown devices and channel qualities continually through exploratory probing and makes task assignment decisions by exploiting the gained knowledge. For maximal adaptability, MABSTA is designed to make no stochastic assumption about the environment. We analyze it mathematically and provide a worst-case performance guarantee for any dynamic environment. We also compare it with the optimal offline policy as well as other baselines via emulations on trace-data obtained from a wireless IoT testbed, and show that it offers competitive and robust performance in all cases. To the best of our knowledge, MABSTA is the first online algorithm in this domain of task assignment problems and provides provable performance guarantee.", "venue": "ArXiv", "authors": ["Yi-Hsuan  Kao", "Kwame-Lante  Wright", "Bhaskar  Krishnamachari", "Fan  Bai"], "year": 2016, "n_citations": 4}
{"id": 308562, "s2_id": "d1362afa5ed5d7d27d3ec140ea2c095bafd6181e", "title": "Instance-Dependent PU Learning by Bayesian Optimal Relabeling", "abstract": "When learning from positive and unlabelled data, it is a strong assumption that the positive observations are randomly sampled from the distribution of $X$ conditional on $Y = 1$, where X stands for the feature and Y the label. Most existing algorithms are optimally designed under the assumption. However, for many real-world applications, the observed positive examples are dependent on the conditional probability $P(Y = 1|X)$ and should be sampled biasedly. In this paper, we assume that a positive example with a higher $P(Y = 1|X)$ is more likely to be labelled and propose a probabilistic-gap based PU learning algorithms. Specifically, by treating the unlabelled data as noisy negative examples, we could automatically label a group positive and negative examples whose labels are identical to the ones assigned by a Bayesian optimal classifier with a consistency guarantee. The relabelled examples have a biased domain, which is remedied by the kernel mean matching technique. The proposed algorithm is model-free and thus do not have any parameters to tune. Experimental results demonstrate that our method works well on both generated and real-world datasets.", "venue": "ArXiv", "authors": ["Fengxiang  He", "Tongliang  Liu", "Geoffrey I. Webb", "Dacheng  Tao"], "year": 2018, "n_citations": 12}
{"id": 315594, "s2_id": "58dfe5664c3c970a2cd8e0504e177b99bb0adcd2", "title": "On Batch Normalisation for Approximate Bayesian Inference", "abstract": "We study batch normalisation in the context of variational inference methods in Bayesian neural networks, such as mean-field or MC Dropout. We show that batch-normalisation does not affect the optimum of the evidence lower bound (ELBO). Furthermore, we study the Monte Carlo Batch Normalisation (MCBN) algorithm, proposed as an approximate inference technique parallel to MC Dropout, and show that for larger batch sizes, MCBN fails to capture epistemic uncertainty. Finally, we provide insight into what is required to fix this failure, namely having to view the mini-batch size as a variational parameter in MCBN. We comment on the asymptotics of the ELBO with respect to this variational parameter, showing that as dataset size increases towards infinity, the batch-size must increase towards infinity as well for MCBN to be a valid approximate inference technique.", "venue": "ArXiv", "authors": ["Jishnu  Mukhoti", "Puneet K. Dokania", "Philip H.S. Torr", "Yarin  Gal"], "year": 2020, "n_citations": 0}
{"id": 328241, "s2_id": "53e6f10e70393bdbafa98238272977760196fddf", "title": "Learning Continuous Semantic Representations of Symbolic Expressions", "abstract": "Combining abstract, symbolic reasoning with continuous neural reasoning is a grand challenge of representation learning. As a step in this direction, we propose a new architecture, called neural equivalence networks, for the problem of learning continuous semantic representations of algebraic and logical expressions. These networks are trained to represent semantic equivalence, even of expressions that are syntactically very different. The challenge is that semantic representations must be computed in a syntax-directed manner, because semantics is compositional, but at the same time, small changes in syntax can lead to very large changes in semantics, which can be difficult for continuous neural architectures. We perform an exhaustive evaluation on the task of checking equivalence on a highly diverse class of symbolic algebraic and boolean expression types, showing that our model significantly outperforms existing architectures.", "venue": "ICML", "authors": ["Miltiadis  Allamanis", "Pankajan  Chanthirasegaran", "Pushmeet  Kohli", "Charles A. Sutton"], "year": 2017, "n_citations": 60}
{"id": 330824, "s2_id": "3541c8ad8345905ed259c4dbaf4e6932d6f9e2b4", "title": "Forecasting Bitcoin closing price series using linear regression and neural networks models", "abstract": "In this article we forecast daily closing price series of Bitcoin, Litecoin and Ethereum cryptocurrencies, using data on prices and volumes of prior days. Cryptocurrencies price behaviour is still largely unexplored, presenting new opportunities for researchers and economists to highlight similarities and differences with standard financial prices. We compared our results with various benchmarks: one recent work on Bitcoin prices forecasting that follows different approaches, a well-known paper that uses Intel, National Bank shares and Microsoft daily NASDAQ closing prices spanning a 3-year interval and another, more recent paper which gives quantitative results on stock market index predictions. We followed different approaches in parallel, implementing both statistical techniques and machine learning algorithms: the Simple Linear Regression (SLR) model for uni-variate series forecast using only closing prices, and the Multiple Linear Regression (MLR) model for multivariate series using both price and volume data. We used two artificial neural networks as well: Multilayer Perceptron (MLP) and Long short-term memory (LSTM). While the entire time series resulted to be indistinguishable from a random walk, the partitioning of datasets into shorter sequences, representing different price \u201cregimes\u201d, allows to obtain precise forecast as evaluated in terms of Mean Absolute Percentage Error(MAPE) and relative Root Mean Square Error (relativeRMSE). In this case the best results are obtained using more than one previous price, thus confirming the existence of time regimes different from random walks. Our models perform well also in terms of time complexity, and provide overall results better than those obtained in the benchmark studies, improving the state-of-the-art.", "venue": "PeerJ Comput. Sci.", "authors": ["Nicola  Uras", "Lodovica  Marchesi", "Michele  Marchesi", "Roberto  Tonelli"], "year": 2020, "n_citations": 9}
{"id": 332484, "s2_id": "734f8e1e5a39a08fd43b0b48c80a2dd2340ac6aa", "title": "Outside the Echo Chamber: Optimizing the Performative Risk", "abstract": "In performative prediction, predictions guide decision-making and hence can influence the distribution of future data. To date, work on performative prediction has focused on finding performatively stable models, which are the fixed points of repeated retraining. However, stable solutions can be far from optimal when evaluated in terms of the performative risk, the loss experienced by the decision maker when deploying a model. In this paper, we shift attention beyond performative stability and focus on optimizing the performative risk directly. We identify a natural set of properties of the loss function and model-induced distribution shift under which the performative risk is convex, a property which does not follow from convexity of the loss alone. Furthermore, we develop algorithms that leverage our structural assumptions to optimize the performative risk with better sample efficiency than generic methods for derivative-free convex optimization.", "venue": "ICML", "authors": ["John  Miller", "Juan C. Perdomo", "Tijana  Zrnic"], "year": 2021, "n_citations": 16}
{"id": 347191, "s2_id": "e73ca773367975189680bc208153cc5f78fc4a6f", "title": "RegNet: Multimodal sensor registration using deep neural networks", "abstract": "In this paper, we present RegNet, the first deep convolutional neural network (CNN) to infer a 6 degrees of freedom (DOF) extrinsic calibration between multimodal sensors, exemplified using a scanning LiDAR and a monocular camera. Compared to existing approaches, RegNet casts all three conventional calibration steps (feature extraction, feature matching and global regression) into a single real-time capable CNN. Our method does not require any human interaction and bridges the gap between classical offline and target-less online calibration approaches as it provides both a stable initial estimation as well as a continuous online correction of the extrinsic parameters. During training we randomly decalibrate our system in order to train RegNet to infer the correspondence between projected depth measurements and RGB image and finally regress the extrinsic calibration. Additionally, with an iterative execution of multiple CNNs, that are trained on different magnitudes of decalibration, our approach compares favorably to state-of-the-art methods in terms of a mean calibration error of 0.28\u00b0 for the rotational and 6 cm for the translation components even for large decalibrations up to 1.5 m and 20\u00b0.", "venue": "2017 IEEE Intelligent Vehicles Symposium (IV)", "authors": ["Nick  Schneider", "Florian  Piewak", "Christoph  Stiller", "Uwe  Franke"], "year": 2017, "n_citations": 56}
{"id": 349309, "s2_id": "92faea491cfb376477073aa4a070fa0973bba032", "title": "FastICARL: Fast Incremental Classifier and Representation Learning with Efficient Budget Allocation in Audio Sensing Applications", "abstract": "Various incremental learning (IL) approaches have been proposed to help deep learning models learn new tasks/classes continuously without forgetting what was learned previously (i.e., avoid catastrophic forgetting). With the growing number of deployed audio sensing applications that need to dynamically incorporate new tasks and changing input distribution from users, the ability of IL on-device becomes essential for both efficiency and user privacy. However, prior works suffer from high computational costs and storage demands which hinders the deployment of IL ondevice. In this work, to overcome these limitations, we develop an end-to-end and on-device IL framework, FastICARL, that incorporates an exemplar-based IL and quantization in the context of audio-based applications. We first employ k-nearestneighbor to reduce the latency of IL. Then, we jointly utilize a quantization technique to decrease the storage requirements of IL. We implement FastICARL on two types of mobile devices and demonstrate that FastICARL remarkably decreases the IL time up to 78-92% and the storage requirements by 2-4 times without sacrificing its performance. FastICARL enables complete on-device IL, ensuring user privacy as the user data does not need to leave the device.", "venue": "Interspeech 2021", "authors": ["Young D. Kwon", "Jagmohan  Chauhan", "Cecilia  Mascolo"], "year": 2021, "n_citations": 1}
{"id": 354659, "s2_id": "73e00b00f34d173f2b20a99e1e395fa60d0e6bef", "title": "Deep Joint Source-channel Coding for Wireless Image Transmission", "abstract": "We propose a joint source and channel coding (JSCC) technique for wireless image transmission that does not rely on explicit codes for either compression or error correction; instead, it directly maps the image pixel values to the complex-valued channel input symbols. We parameterize the encoder and decoder functions by two convolutional neural networks (CNNs), which are trained jointly, and can be considered as an autoencoder with a non-trainable layer in the middle that represents the noisy communication channel. Our results show that the proposed deep JSCC scheme outperforms digital transmission concatenating JPEG or JPEG2000 compression with a capacity achieving channel code at low signal-to-noise ratio (SNR) and channel bandwidth values in the presence of additive white Gaussian noise (AWGN). More strikingly, deep JSCC does not suffer from the ``cliff effect'', and it provides a graceful performance degradation as the channel SNR varies with respect to the SNR value assumed during training. In the case of a slow Rayleigh fading channel, deep JSCC learns noise resilient coded representations and significantly outperforms separation-based digital communication at all SNR and channel bandwidth values.", "venue": "ICASSP", "authors": ["Eirina  Bourtsoulatze", "David Burth Kurka", "Deniz  G\u00fcnd\u00fcz"], "year": 2019, "n_citations": 3}
{"id": 370998, "s2_id": "6578fe52b223f9f460d2506332adb08387113eee", "title": "GraphTER: Unsupervised Learning of Graph Transformation Equivariant Representations via Auto-Encoding Node-Wise Transformations", "abstract": "Recent advances in Graph Convolutional Neural Networks (GCNNs) have shown their efficiency for nonEuclidean data on graphs, which often require a large amount of labeled data with high cost. It it thus critical to learn graph feature representations in an unsupervised manner in practice. To this end, we propose a novel unsupervised learning of Graph Transformation Equivariant Representations (GraphTER), aiming to capture intrinsic patterns of graph structure under both global and local transformations. Specifically, we allow to sample different groups of nodes from a graph and then transform them node-wise isotropically or anisotropically. Then, we self-train a representation encoder to capture the graph structures by reconstructing these node-wise transformations from the feature representations of the original and transformed graphs. In experiments, we apply the learned GraphTER to graphs of 3D point cloud data, and results on point cloud segmentation/classification show that GraphTER significantly outperforms state-of-the-art unsupervised approaches and pushes greatly closer towards the upper bound set by the fully supervised counterparts. The code is available at: https://github.com/gyshgx868/graph-ter.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Xiang  Gao", "Wei  Hu", "Guo-Jun  Qi"], "year": 2020, "n_citations": 16}
{"id": 371627, "s2_id": "778e0961835ada4006bc08482aae84e18e1f0656", "title": "Graph Partner Neural Networks for Semi-Supervised Learning on Graphs", "abstract": "Graph Convolutional Networks (GCNs) are powerful for processing graph-structured data and have achieved state-of-the-art performance in several tasks such as node classification, link prediction, and graph classification. However, it is inevitable for deep GCNs to suffer from an over-smoothing issue that the representations of nodes will tend to be indistinguishable after repeated graph convolution operations. To address this problem, we propose the Graph Partner Neural Network (GPNN) which incorporates a de-parameterized GCN and a parameter-sharing MLP. We provide empirical and theoretical evidence to demonstrate the effectiveness of the proposed MLP partner on tackling over-smoothing while benefiting from appropriate smoothness. To further tackle over-smoothing and regulate the learning process, we introduce a welldesigned consistency contrastive loss and Kullback\u2013Leibler (KL) divergence loss. Besides, we present a graph enhancement technique to improve the overall quality of edges in graphs. While most GCNs can work with shallow architecture only, GPNN can obtain better results through increasing model depth. Experiments on various node classification tasks have demonstrated the state-of-theart performance of GPNN. Meanwhile, extensive ablation studies are conducted to investigate the contributions of each component in tackling oversmoothing and improving performance.", "venue": "ArXiv", "authors": ["Langzhang  Liang", "Cuiyun  Gao", "Shiyi  Chen", "Shishi  Duan", "Yu  pan", "Junjin  Zheng", "Lei  Wang", "Zenglin  Xu"], "year": 2021, "n_citations": 0}
{"id": 391130, "s2_id": "489664671ea8488a39c195920c92e945a0e0de60", "title": "Reinforcement Learning for Adaptive Mesh Refinement", "abstract": "Large-scale finite element simulations of complex physical systems governed by partial differential equations crucially depend on adaptive mesh refinement (AMR) to allocate computational budget to regions where higher resolution is required. Existing scalable AMR methods make heuristic refinement decisions based on instantaneous error estimation and thus do not aim for long-term optimality over an entire simulation. We propose a novel formulation of AMR as a Markov decision process and apply deep reinforcement learning (RL) to train refinement policies directly from simulation. AMR poses a new problem for RL in that both the state dimension and available action set changes at every step, which we solve by proposing new policy architectures with differing generality and inductive bias. The model sizes of these policy architectures are independent of the mesh size and hence scale to arbitrarily large and complex simulations. We demonstrate in comprehensive experiments on static function estimation and the advection of different fields that RL policies can be competitive with a widely-used error estimator and generalize to larger, more complex, and unseen test problems.", "venue": "ArXiv", "authors": ["Jiachen  Yang", "Tarik  Dzanic", "Brenden  Petersen", "Jun  Kudo", "Ketan  Mittal", "Vladimir  Tomov", "Jean-Sylvain  Camier", "Tuo  Zhao", "Hongyuan  Zha", "Tzanio  Kolev", "Robert  Anderson", "Daniel  Faissol"], "year": 2021, "n_citations": 0}
{"id": 391923, "s2_id": "c79afe37a74e4e8b921a3c4887fe721415b8bbdf", "title": "Deep Classification of Epileptic Signals", "abstract": "Electrophysiological observation plays a major role in epilepsy evaluation. However, human interpretation of brain signals is subjective and prone to misdiagnosis. Automating this process, especially seizure detection relying on scalpbased Electroencephalography (EEG) and intracranial EEG, has been the focus of research over recent decades. Nevertheless, its numerous challenges have inhibited a definitive solution. Inspired by recent advances in deep learning, here we describe a new classification approach for EEG time series based on Recurrent Neural Networks (RNNs) via the use of Long- Short Term Memory (LSTM) networks. The proposed deep network effectively learns and models discriminative temporal patterns from EEG sequential data. Especially, the features are automatically discovered from the raw EEG data without any pre-processing step, eliminating humans from laborious feature design task. Our light-weight system has a low computational complexity and reduced memory requirement for large training datasets. On a public dataset, a multi-fold cross-validation scheme of the proposed architecture exhibited an average validation accuracy of 95.54% and an average AUC of 0.9582 of the ROC curve among all sets defined in the experiment. This work reinforces the benefits of deep learning to be further attended in clinical applications and neuroscientific research.", "venue": "2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)", "authors": ["David  Ahmedt-Aristizabal", "Clinton  Fookes", "Kien  Nguyen", "Sridha  Sridharan"], "year": 2018, "n_citations": 34}
{"id": 395961, "s2_id": "ed419abafd02db767570dea2bc05e7c2336b38e1", "title": "Causal Order Identification to Address Confounding: Binary Variables", "abstract": "This paper considers an extension of the linear non-Gaussian acyclic model (LiNGAM) that determines the causal order among variables from a dataset when the variables are expressed by a set of linear equations, including noise. In particular, we assume that the variables are binary. The existing LiNGAM assumes that no confounding is present, which is restrictive in practice. Based on the concept of independent component analysis (ICA), this paper proposes an extended framework in which the mutual information among the noises is minimized. Another significant contribution is to reduce the realization to the shortest path problem, in which the distance between each pair of nodes expresses an associated mutual information value, and the path with the minimum sum (KL divergence) is sought. Although p! mutual information values should be compared, this paper dramatically reduces the computation when no confounding is present. The proposed algorithm finds the globally optimal solution, while the existing approaches locally greedily seek the order based on hypothesis testing. We use the best estimator in the sense of Bayes/MDL that correctly detects independence for mutual information estimation. Experiments using artificial and actual data show that the proposed version of LiNGAM achieves significantly better performance, particularly when confounding is present.", "venue": "Behaviormetrika", "authors": ["Joe  Suzuki", "Yusuke  Inaoka"], "year": 2021, "n_citations": 0}
{"id": 400593, "s2_id": "8d459c9c600ae97f1200bded634c390e490f9b53", "title": "Adversarial Attacks Hidden in Plain Sight", "abstract": "Convolutional neural networks have been used to achieve a string of successes during recent years, but their lack of interpretability remains a serious issue. Adversarial examples are designed to deliberately fool neural networks into making any desired incorrect classification, potentially with very high certainty. Several defensive approaches increase robustness against adversarial attacks, demanding attacks of greater magnitude, which lead to visible artifacts. By considering human visual perception, we compose a technique that allows to hide such adversarial attacks in regions of high complexity, such that they are imperceptible even to an astute observer. We carry out a user study on classifying adversarially modified images to validate the perceptual quality of our approach and find significant evidence for its concealment with regards to human visual perception.", "venue": "IDA", "authors": ["Jan Philip G\u00f6pfert", "Andr\u00e9  Artelt", "Heiko  Wersing", "Barbara  Hammer"], "year": 2020, "n_citations": 3}
{"id": 406277, "s2_id": "d2554717997551f00b5ef819d2619c288f347588", "title": "Visual Explanations for Convolutional Neural Networks via Latent Traversal of Generative Adversarial Networks", "abstract": "Lack of explainability in artificial intelligence, specifically deep neural networks, remains a bottleneck for implementing models in practice. Popular techniques such as Gradient-weighted Class Activation Mapping (Grad-CAM) provide a coarse map of salient features in an image, which rarely tells the whole story of what a convolutional neural network (CNN) learned. Using COVID-19 chest X-rays, we present a method for interpreting what a CNN has learned by utilizing Generative Adversarial Networks (GANs). Our GAN framework disentangles lung structure from COVID-19 features. Using this GAN, we can visualize the transition of a pair of COVID negative lungs in a chest radiograph to a COVID positive pair by interpolating in the latent space of the GAN, which provides fine-grained visualization of how the CNN responds to varying features within the lungs.", "venue": "ArXiv", "authors": ["Amil  Dravid", "Aggelos K. Katsaggelos"], "year": 2021, "n_citations": 0}
{"id": 414115, "s2_id": "5c89f80364548f1a954fa0952668e715a30cca6a", "title": "Log-DenseNet: How to Sparsify a DenseNet", "abstract": "Skip connections are increasingly utilized by deep neural networks to improve accuracy and cost-efficiency. In particular, the recent DenseNet is efficient in computation and parameters, and achieves state-of-the-art predictions by directly connecting each feature layer to all previous ones. However, DenseNet's extreme connectivity pattern may hinder its scalability to high depths, and in applications like fully convolutional networks, full DenseNet connections are prohibitively expensive. This work first experimentally shows that one key advantage of skip connections is to have short distances among feature layers during backpropagation. Specifically, using a fixed number of skip connections, the connection patterns with shorter backpropagation distance among layers have more accurate predictions. Following this insight, we propose a connection template, Log-DenseNet, which, in comparison to DenseNet, only slightly increases the backpropagation distances among layers from 1 to ($1 + \\log_2 L$), but uses only $L\\log_2 L$ total connections instead of $O(L^2)$. Hence, Log-DenseNets are easier than DenseNets to implement and to scale. We demonstrate the effectiveness of our design principle by showing better performance than DenseNets on tabula rasa semantic segmentation, and competitive results on visual recognition.", "venue": "ArXiv", "authors": ["Hanzhang  Hu", "Debadeepta  Dey", "Allison Del Giorno", "Martial  Hebert", "J. Andrew Bagnell"], "year": 2017, "n_citations": 19}
{"id": 419793, "s2_id": "61582ab78c8d8ee70e80e18951ebdbbc84f12f57", "title": "Image Classification via Quantum Machine Learning", "abstract": "Quantum Computing and especially Quantum Machine Learning, in a short period of time, has gained a lot of interest through research groups around the world. This can be seen in the increasing number of proposed models for pattern classification applying quantum principles to a certain degree. Despise the increasing volume of models, there is a void in testing these models on real datasets and not only on synthetic ones. The objective of this work is to classify patterns with binary attributes using a quantum classifier. Specially, we show results of a complete quantum classifier applied to image datasets. The experiments show favorable output while dealing with balanced classification problems as well as with imbalanced classes where the minority class is the most relevant. This is promising in medical areas, where usually the important class is also the minority class.", "venue": "ArXiv", "authors": ["H'ector Iv'an Garc'ia Hern'andez", "Raymundo Torres Ruiz", "Guo-Hua  Sun"], "year": 2020, "n_citations": 4}
{"id": 433544, "s2_id": "7e6f25c33323f66c60d7b1f680d34d71361d10b7", "title": "Gaussian Process Subset Scanning for Anomalous Pattern Detection in Non-iid Data", "abstract": "Identifying anomalous patterns in real-world data is essential for understanding where, when, and how systems deviate from their expected dynamics. Yet methods that separately consider the anomalousness of each individual data point have low detection power for subtle, emerging irregularities. Additionally, recent detection techniques based on subset scanning make strong independence assumptions and suffer degraded performance in correlated data. We introduce methods for identifying anomalous patterns in non-iid data by combining Gaussian processes with novel log-likelihood ratio statistic and subset scanning techniques. Our approaches are powerful, interpretable, and can integrate information across multiple data streams. We illustrate their performance on numeric simulations and three open source spatiotemporal datasets of opioid overdose deaths, 311 calls, and storm reports.", "venue": "AISTATS", "authors": ["William  Herlands", "Edward  McFowland", "Andrew Gordon Wilson", "Daniel B. Neill"], "year": 2018, "n_citations": 10}
{"id": 434352, "s2_id": "1f94cffa588ce6cefdcede99d10cf777607f8875", "title": "Composable Probabilistic Inference Networks Using MRAM-based Stochastic Neurons", "abstract": "Magnetoresistive random access memory (MRAM) technologies with thermally unstable nanomagnets are leveraged to develop an intrinsic stochastic neuron as a building block for restricted Boltzmann machines (RBMs) to form deep belief networks (DBNs). The embedded MRAM-based neuron is modeled using precise physics equations. The simulation results exhibit the desired sigmoidal relation between the input voltages and probability of the output state. A probabilistic inference network simulator (PIN-Sim) is developed to realize a circuit-level model of an RBM utilizing resistive crossbar arrays along with differential amplifiers to implement the positive and negative weight values. The PIN-Sim is composed of five main blocks to train a DBN, evaluate its accuracy, and measure its power consumption. The MNIST dataset is leveraged to investigate the energy and accuracy tradeoffs of seven distinct network topologies in SPICE using the 14nm HP-FinFET technology library with the nominal voltage of 0.8V, in which an MRAM-based neuron is used as the activation function. The software and hardware level simulations indicate that a 784\u00d7 200\u00d7 10 topology can achieve less than 5% error rates with \u223c400pJ energy consumption. The error rates can be reduced to 2.5% by using a 784\u00d7 500\u00d7 500\u00d7 500\u00d7 10 DBN at the cost of \u223c10\u00d7 higher energy consumption and significant area overhead. Finally, the effects of specific hardware-level parameters on power dissipation and accuracy tradeoffs are identified via the developed PIN-Sim framework.", "venue": "ACM J. Emerg. Technol. Comput. Syst.", "authors": ["Ramtin  Zand", "Kerem Yunus Camsari", "Supriyo  Datta", "Ronald F. DeMara"], "year": 2019, "n_citations": 21}
{"id": 436790, "s2_id": "70c28c1d065b0fb980a0cab538f1b3e273c5f77c", "title": "Convergence Rates for Empirical Estimation of Binary Classification Bounds", "abstract": "Bounding the best achievable error probability for binary classification problems is relevant to many applications including machine learning, signal processing, and information theory. Many bounds on the Bayes binary classification error rate depend on information divergences between the pair of class distributions. Recently, the Henze\u2013Penrose (HP) divergence has been proposed for bounding classification error probability. We consider the problem of empirically estimating the HP-divergence from random samples. We derive a bound on the convergence rate for the Friedman\u2013Rafsky (FR) estimator of the HP-divergence, which is related to a multivariate runs statistic for testing between two distributions. The FR estimator is derived from a multicolored Euclidean minimal spanning tree (MST) that spans the merged samples. We obtain a concentration inequality for the Friedman\u2013Rafsky estimator of the Henze\u2013Penrose divergence. We validate our results experimentally and illustrate their application to real datasets.", "venue": "Entropy", "authors": ["Salimeh Yasaei Sekeh", "Morteza  Noshad", "Kevin R. Moon", "Alfred O. Hero"], "year": 2019, "n_citations": 2}
{"id": 439524, "s2_id": "9ae09659d56ca8373f7c2079b9e2d7718c315089", "title": "Online Distributed Learning Over Networks in RKH Spaces Using Random Fourier Features", "abstract": "We present a novel diffusion scheme for online kernel-based learning over networks. So far, a major drawback of any online learning algorithm, operating in a reproducing kernel Hilbert space (RKHS), is the need for updating a growing number of parameters as time iterations evolve. Besides complexity, this leads to an increased need of communication resources in a distributed setting. In contrast, we propose to approximate the solution as a fixed-size vector (of larger dimension than the input space) using the previously introduced framework of random Fourier features. This paves the way to use standard linear combine-then-adapt techniques. To the best of our knowledge, this is the first time that a complete protocol for distributed online learning in RKHS is presented. Conditions for asymptotic convergence and boundness of the networkwise regret are also provided. The simulated tests illustrate the performance of the proposed scheme.", "venue": "IEEE Transactions on Signal Processing", "authors": ["Pantelis  Bouboulis", "Symeon  Chouvardas", "Sergios  Theodoridis"], "year": 2018, "n_citations": 38}
{"id": 444812, "s2_id": "18486ffffd6d19ac0521975ce3b5f916212a520c", "title": "Learning Robust and Multilingual Speech Representations", "abstract": "Unsupervised speech representation learning has shown remarkable success at finding representations that correlate with phonetic structures and improve downstream speech recognition performance. However, most research has been focused on evaluating the representations in terms of their ability to improve the performance of speech recognition systems on read English (e.g. Wall Street Journal and LibriSpeech). This evaluation methodology overlooks two important desiderata that speech representations should have: robustness to domain shifts and transferability to other languages. In this paper we learn representations from up to 8000 hours of diverse and noisy speech data and evaluate the representations by looking at their robustness to domain shifts and their ability to improve recognition performance in many languages. We find that our representations confer significant robustness advantages to the resulting recognition systems: we see significant improvements in out-of-domain transfer relative to baseline feature sets and the features likewise provide improvements in 25 phonetically diverse languages.", "venue": "FINDINGS", "authors": ["Kazuya  Kawakami", "Luyu  Wang", "Chris  Dyer", "Phil  Blunsom", "Aaron van den Oord"], "year": 2020, "n_citations": 43}
{"id": 446827, "s2_id": "ccea6c716c014ab3fb28d142f7e7528fb2741558", "title": "Attribution in Scale and Space", "abstract": "We study the attribution problem for deep networks applied to perception tasks. For vision tasks, attribution techniques attribute the prediction of a network to the pixels of the input image. We propose a new technique called Blur Integrated Gradients (Blur IG). This technique has several advantages over other methods. First, it can tell at what scale a network recognizes an object. It produces scores in the scale/frequency dimension, that we find captures interesting phenomena. Second, it satisfies the scale-space axioms, which imply that it employs perturbations that are free of artifact. We therefore produce explanations that are cleaner and consistent with the operation of deep networks. Third, it eliminates the need for baseline parameter for Integrated Gradients for perception tasks. This is desirable because the choice of baseline has a significant effect on the explanations. We compare the proposed technique against previous techniques and demonstrate application on three tasks: ImageNet object recognition, Diabetic Retinopathy prediction, and AudioSet audio event identification. Code and examples are at https://github.com/PAIR-code/saliency.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Shawn  Xu", "Subashini  Venugopalan", "Mukund  Sundararajan"], "year": 2020, "n_citations": 16}
{"id": 447281, "s2_id": "2eb2769dbf08c12f1edae106d3effeaf1243740b", "title": "Chi-square Tests Driven Method for Learning the Structure of Factored MDPs", "abstract": "SDYNA is a general framework designed to address large stochastic reinforcement learning problems. Unlike previous model based methods in FMDPs, it incrementally learns the structure and the parameters of a RL problem using supervised learning techniques. Then, it integrates decision-theoric planning algorithms based on FMDPs to compute its policy. SPITI is an instanciation of SDYNA that exploits ITI, an incremental decision tree algorithm, to learn the reward function and the Dynamic Bayesian Networks with local structures representing the transition function of the problem. These representations are used by an incremental version of the Structured Value Iteration algorithm. In order to learn the structure, SPITI uses Chi-Square tests to detect the independence between two probability distributions. Thus, we study the relation between the threshold used in the Chi-Square test, the size of the model built and the relative error of the value function of the induced policy with respect to the optimal value. We show that, on stochastic problems, one can tune the threshold so as to generate both a compact model and an efficient policy. Then, we show that SPITI, while keeping its model compact, uses the generalization property of its learning method to perform better than a stochastic classical tabular algorithm in large RL problem with an unknown structure. We also introduce a new measure based on Chi-Square to qualify the accuracy of the model learned by SPITI. We qualitatively show that the generalization property in SPITI within the FMDP framework may prevent an exponential growth of the time required to learn the structure of large stochastic RL problems.", "venue": "UAI", "authors": ["Thomas  Degris", "Olivier  Sigaud", "Pierre-Henri  Wuillemin"], "year": 2006, "n_citations": 17}
{"id": 458389, "s2_id": "559faf4b49ef3f317e894f7ba3947d1769bdeb8c", "title": "Recycling Randomness with Structure for Sublinear time Kernel Expansions", "abstract": "We propose a scheme for recycling Gaussian random vectors into structured matrices to approximate various kernel functions in sublinear time via random embeddings. Our framework includes the Fastfood construction of Le et al. (2013) as a special case, but also extends to Circulant, Toeplitz and Hankel matrices, and the broader family of structured matrices that are characterized by the concept of low-displacement rank. We introduce notions of coherence and graph-theoretic structural constants that control the approximation quality, and prove unbiasedness and low-variance properties of random feature maps that arise within our framework. For the case of low-displacement matrices, we show how the degree of structure and randomness can be controlled to reduce statistical variance at the cost of increased computation and storage requirements. Empirical results strongly support our theory and justify the use of a broader family of structured matrices for scaling up kernel methods using random features.", "venue": "ICML", "authors": ["Krzysztof  Choromanski", "Vikas  Sindhwani"], "year": 2016, "n_citations": 37}
{"id": 459934, "s2_id": "db6fb4f666814e893518690ee13055f234b06db4", "title": "COMET: A Recipe for Learning and Using Large Ensembles on Massive Data", "abstract": "COMET is a single-pass MapReduce algorithm for learning on large-scale data. It builds multiple random forest ensembles on distributed blocks of data and merges them into a mega-ensemble. This approach is appropriate when learning from massive-scale data that is too large to fit on a single machine. To get the best accuracy, IVoting should be used instead of bagging to generate the training subset for each decision tree in the random forest. Experiments with two large datasets (5GB and 50GB compressed) show that COMET compares favorably (in both accuracy and training time) to learning on a sub sample of data using a serial algorithm. Finally, we propose a new Gaussian approach for lazy ensemble evaluation which dynamically decides how many ensemble members to evaluate per data point, this can reduce evaluation cost by 100X or more.", "venue": "2011 IEEE 11th International Conference on Data Mining", "authors": ["Justin D. Basilico", "M. Arthur Munson", "Tamara G. Kolda", "Kevin R. Dixon", "W. Philip Kegelmeyer"], "year": 2011, "n_citations": 39}
{"id": 488876, "s2_id": "f05815eec5314b2f6d2d9f4af58531cd96a962a7", "title": "Wav2CLIP: Learning Robust Audio Representations From CLIP", "abstract": "We propose Wav2CLIP, a robust audio representation learning method by distilling from Contrastive Language-Image Pre-training (CLIP). We systematically evaluate Wav2CLIP on a variety of audio tasks including classification, retrieval, and generation, and show that Wav2CLIP can outperform several publicly available pretrained audio representation algorithms. Wav2CLIP projects audio into a shared embedding space with images and text, which enables multimodal applications such as zero-shot classification, and cross-modal retrieval. Furthermore, Wav2CLIP needs just \u223c10% of the data to achieve competitive performance on downstream tasks compared with fully supervised models, and is more efficient to pretrain than competing methods as it does not require learning a visual model in concert with an auditory model. Finally, we demonstrate image generation from Wav2CLIP as qualitative assessment of the shared embedding space. Our code and model weights are open sourced and made available for further applications.", "venue": "ArXiv", "authors": ["Ho-Hsiang  Wu", "Prem  Seetharaman", "Kundan  Kumar", "Juan Pablo Bello"], "year": 2021, "n_citations": 1}
{"id": 496705, "s2_id": "697f0e24f24b016cef9474db485fe61a667f07b8", "title": "ViSeR: Visual Self-Regularization", "abstract": "We propose using large set of unlabeled images as a source of regularization data for learning robust representation. Given a visual model trained in a supervised fashion, we augment our training samples by incorporating large number of unlabeled data and train a semi-supervised model. We demonstrate that our proposed learning approach leverages an abundance of unlabeled images and boosts the visual recognition performance which alleviates the need to rely on large labeled datasets for learning robust representation. In our approach, each labeled image propagates its label to its nearest unlabeled image instances. These retrieved unlabeled images serve as local perturbations of each labeled image to perform Visual Self-Regularization (ViSeR). Using the labeled instances and our regularizers we show that we significantly improve object categorization and localization on the MS COCO and Visual Genome datasets.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "authors": ["Hamid  Izadinia", "Pierre  Garrigues"], "year": 2020, "n_citations": 2}
{"id": 497872, "s2_id": "f9252977eb13c12b3eeade1fce08653a2367e9e5", "title": "Learning Graphical Models of Images, Videos and Their Spatial Transformations", "abstract": "Mixtures of Gaussians, factor analyzers (probabilistic PCA) and hidden Markov models are staples of static and dynamic data modeling and image and video modeling in particular. We show how topographic transformations in the input, such as translation and shearing in images, can be accounted for in these models by including a discrete transformation variable. The resulting models perform clustering, dimensionality reduction and time-series analysis in a way that is invariant to transformations in the input. Using the EM algorithm, these transformation invariant models can be fit to static data and time series. We give results on filtering microscopy images, face and facial pose clustering, handwritten digit modeling and recognition, video clustering, object tracking, and removal of distractions from video sequences.", "venue": "UAI", "authors": ["Brendan J. Frey", "Nebojsa  Jojic"], "year": 2000, "n_citations": 37}
{"id": 505437, "s2_id": "c0b5e431dea6de3a657cdd209786ec9722e32496", "title": "Anomaly Detection and Classification for Streaming Data using PDEs", "abstract": "Nondominated sorting, also called Pareto Depth Analysis (PDA), is widely used in multi-objective optimization and has recently found important applications in multi-criteria anomaly detection. Recently, a partial differential equation (PDE) continuum limit was discovered for nondominated sorting leading to a very fast approximate sorting algorithm called PDE-based ranking. We propose in this paper a fast real-time streaming version of the PDA algorithm for anomaly detection that exploits the computational advantages of PDE continuum limits. Furthermore, we derive new PDE continuum limits for sorting points within their nondominated layers and show how the new PDEs can be used to classify anomalies based on which criterion was more significantly violated. We also prove statistical convergence rates for PDE-based ranking, and present the results of numerical experiments with both synthetic and real data.", "venue": "SIAM J. Appl. Math.", "authors": ["Bilal  Abbasi", "Jeff  Calder", "Adam M. Oberman"], "year": 2018, "n_citations": 5}
{"id": 509682, "s2_id": "e5000713fa1dec7ba73162f516048b65110d96c0", "title": "Memorization Precedes Generation: Learning Unsupervised GANs with Memory Networks", "abstract": "We propose an approach to address two issues that commonly occur during training of unsupervised GANs. First, since GANs use only a continuous latent distribution to embed multiple classes or clusters of data, they often do not correctly handle the structural discontinuity between disparate classes in a latent space. Second, discriminators of GANs easily forget about past generated samples by generators, incurring instability during adversarial training. We argue that these two infamous problems of unsupervised GAN training can be largely alleviated by a learnable memory network to which both generators and discriminators can access. Generators can effectively learn representation of training samples to understand underlying cluster distributions of data, which ease the structure discontinuity problem. At the same time, discriminators can better memorize clusters of previously generated samples, which mitigate the forgetting problem. We propose a novel end-to-end GAN model named memoryGAN, which involves a memory network that is unsupervisedly trainable and integrable to many existing GAN models. With evaluations on multiple datasets such as Fashion-MNIST, CelebA, CIFAR10, and Chairs, we show that our model is probabilistically interpretable, and generates realistic image samples of high visual fidelity. The memoryGAN also achieves the state-of-the-art inception scores over unsupervised GAN models on the CIFAR10 dataset, without any optimization tricks and weaker divergences.", "venue": "ICLR", "authors": ["Youngjin  Kim", "Minjung  Kim", "Gunhee  Kim"], "year": 2018, "n_citations": 28}
{"id": 519835, "s2_id": "93ce2da29f10290c88142a9a7641afc2d7325db1", "title": "Balancing Accuracy and Latency in Multipath Neural Networks", "abstract": "The growing capacity of neural networks has strongly contributed to their success at complex machine learning tasks and the computational demand of such large models has, in turn, stimulated a significant improvement in the hardware necessary to accelerate their computations. However, models with high latency aren't suitable for limited-resource environments such as hand-held and IoT devices. Hence, many deep learning techniques aim to address this problem by developing models with reasonable accuracy without violating the limited-resource constraint. In this work, we use a one-shot neural architecture search model to implicitly evaluate the performance of an intractable number of multipath neural networks. Combining this architecture search with a pruning technique and architecture sample evaluation, we can model the relation between the accuracy and the latency of a spectrum of models with graded complexity. We show that our method can accurately model the relative performance between models with different latencies and predict the performance of unseen models with good precision across different datasets.", "venue": "ArXiv", "authors": ["Mohammed  Amer", "Tom'as  Maul", "Iman Yi Liao"], "year": 2021, "n_citations": 0}
{"id": 531909, "s2_id": "1b066dbfba1c3229b0182012427e942bad60ae98", "title": "Simulation of Turbulent Flow around a Generic High-Speed Train using Hybrid Models of RANS Numerical Method with Machine Learning", "abstract": "In the present paper, an aerodynamic investigation of a high-speed train is performed. In the first section of this article, a generic high-speed train against a turbulent flow is simulated, numerically. The Reynolds-Averaged Navier-Stokes (RANS) equations combined with the turbulence model are applied to solve incompressible turbulent flow around a high-speed train. Flow structure, velocity and pressure contours and streamlines at some typical wind directions are the most important results of this simulation. The maximum and minimum values are specified and discussed. Also, the pressure coefficient for some critical points on the train surface is evaluated. In the following, the wind direction influence the aerodynamic key parameters as drag, lift, and side forces at the mentioned wind directions are analyzed and compared. Moreover, the effects of velocity changes (50, 60, 70, 80 and 90 m/s) are estimated and compared on the above flow and aerodynamic parameters. In the second section of the paper, various data-driven methods including Gene Expression Programming (GEP), Gaussian Process Regression (GPR), and random forest (RF), are applied for predicting output parameters. So, drag, lift, and side forces and also minimum and a maximum of pressure coefficients for mentioned wind directions and velocity are predicted and compared using statistical parameters. Obtained results indicated that RF in all coefficients of wind direction and most coefficients of free stream velocity provided the most accurate predictions. As a conclusion, RF may be recommended for the prediction of aerodynamic coefficients.", "venue": "ArXiv", "authors": ["Alireza  Hajipour", "Arash Mirabdolah Lavasani", "Mohammad Eftekhari Yazdi", "Amir  Mosavi", "Shahaboddin  Shamshirband", "Kwok-Wing  Chau"], "year": 2020, "n_citations": 0}
{"id": 539961, "s2_id": "418f7df55040800ea2ba0e33edbe423e06c34b43", "title": "Frame-Capture-Based CSI Recomposition Pertaining to Firmware-Agnostic WiFi Sensing", "abstract": "With regard to the implementation of WiFi sensing agnostic according to the availability of channel state information (CSI), we investigate the possibility of estimating a CSI matrix based on its compressed version, which is known as beamforming feedback matrix (BFM). Being different from the CSI matrix that is processed and discarded in physical layer components, the BFM can be captured using a medium-access-layer framecapturing technique because this is exchanged among an access point (AP) and stations (STAs) over the air. This indicates that WiFi sensing that leverages the BFM matrix is more practical to implement using the pre-installed APs. However, the ability of BFM-based sensing has been evaluated in a few tasks, and more general insights into its performance should be provided. To fill this gap, we propose a CSI estimation method based on BFM, approximating the estimation function with a machine learning model. In addition, to improve the estimation accuracy, we leverage the inter-subcarrier dependency using the BFMs at multiple subcarriers in orthogonal frequency division multiplexing transmissions. Our simulation evaluation reveals that the estimated CSI matches the ground-truth amplitude. Moreover, compared to CSI estimation at each individual subcarrier, the effect of the BFMs at multiple subcarriers on the CSI estimation accuracy is validated.", "venue": "ArXiv", "authors": ["Ryosuke  Hanahara", "Sohei  Itahara", "Kota  Yamashita", "Yusuke  Koda", "Akihito  Taya", "Takayuki  Nishio", "Koji  Yamamoto"], "year": 2021, "n_citations": 0}
{"id": 543081, "s2_id": "5df086289ac8a4b0f50a980e8e89d03ba227a041", "title": "Supervised Classification: Quite a Brief Overview", "abstract": "Abstract The original problem of supervised classification considers the task of automatically assigning objects to their respective classes on the basis of numerical measurements derived from these objects. Classifiers are the tools that implement the actual functional mapping from these measurements\u2014also called features or inputs\u2014to the so-called class label\u2014or output. The fields of pattern recognition and machine learning study ways of constructing such classifiers. The main idea behind supervised methods is that of learning from examples: given a number of example input-output relations, to what extent can the general mapping be learned that takes any new and unseen feature vector to its correct class? This chapter provides a basic introduction to the underlying ideas of how to approach a supervised classification problem. In addition, it provides an overview of some specific classification techniques, delves into the issues of object representation and classifier evaluation, and (very) briefly covers some variations on the basic supervised classification task that may also be of interest to the practitioner.", "venue": "ArXiv", "authors": ["Marco  Loog"], "year": 2017, "n_citations": 10}
{"id": 564497, "s2_id": "58e8c7b3ae700545ac8741a0a18d1474d4a397e7", "title": "Fusion of ANN and SVM classifiers for network attack detection", "abstract": "With the progressive increase of network application and electronic devices (computer, mobile phones, android, etc), attack and intrusion detection is becoming a very challenging task in cybercrime detection area. In this context, most of existing approaches of attack detection rely mainly on a finite set of attacks. However, these solutions are vulnerable, that is, they fail in detecting some attacks when sources of informations are ambiguous or imperfect. But, few approaches started investigating toward this direction. Following this trends, this paper investigates the role of machine learning approach (ANN, SVM)in detecting TCP connection traffic as normal or suspicious one. But, using ANN and SVM is an expensive technique individually. In this paper, combining two classifiers has been proposed, where artificial neural network (ANN) classifier and support vector machine (SVM) were employed. Additionally, our proposed solution allows to visualize obtained classification results. Accuracy of the proposed solution has been compared with other classifier results. Experiments have been conducted with different network connection selected from NSL-KDD DARPA dataset. Empirical results show that combining ANN and SVM techniques for attack detection is a promising direction.", "venue": "2017 18th International Conference on Sciences and Techniques of Automatic Control and Computer Engineering (STA)", "authors": ["Takwa  Omrani", "Adel  Dallali", "Bilgacem Chibani Rhaimi", "Jaouhar  Fattahi"], "year": 2017, "n_citations": 21}
{"id": 574405, "s2_id": "964862d717c39d768df746d91d9432c031b3fefa", "title": "Bayesian Uncertainty Estimation of Learned Variational MRI Reconstruction", "abstract": "Recent deep learning approaches focus on improving quantitative scores of dedicated benchmarks, and therefore only reduce the observation-related (aleatoric) uncertainty. However, the model-immanent (epistemic) uncertainty is less frequently systematically analyzed. In this work, we introduce a Bayesian variational framework to quantify the epistemic uncertainty. To this end, we solve the linear inverse problem of undersampled MRI reconstruction in a variational setting. The associated energy functional is composed of a data fidelity term and the total deep variation (TDV) as a learned parametric regularizer. To estimate the epistemic uncertainty we draw the parameters of the TDV regularizer from a multivariate Gaussian distribution, whose mean and covariance matrix are learned in a stochastic optimal control problem. In several numerical experiments, we demonstrate that our approach yields competitive results for undersampled MRI reconstruction. Moreover, we can accurately quantify the pixelwise epistemic uncertainty, which can serve radiologists as an additional resource to visualize reconstruction reliability.", "venue": "IEEE transactions on medical imaging", "authors": ["Dominik  Narnhofer", "Alexander  Effland", "Erich  Kobler", "Kerstin  Hammernik", "Florian  Knoll", "Thomas  Pock"], "year": 2021, "n_citations": 2}
{"id": 578852, "s2_id": "d002664ad8e1090c83788a881797d683014c7d9b", "title": "Off-Dynamics Inverse Reinforcement Learning from Hetero-Domain", "abstract": "We propose an approach for inverse reinforcement learning from hetero-domain which learns a reward function in the simulator, drawing on the demonstrations from the real world. The intuition behind the method is that the reward function should not only be oriented to imitate the experts, but should encourage actions adjusted for the dynamics difference between the simulator and the real world. To achieve this, the widely used GAN-inspired IRL method is adopted, and its discriminator, recognizing policy-generating trajectories, is modified with the quantification of dynamics difference. The training process of the discriminator can yield the transferable reward function suitable for simulator dynamics, which can be guaranteed by derivation. Effectively, our method assigns higher rewards for demonstration trajectories which do not exploit discrepancies between the two domains. With extensive experiments on continuous control tasks, our method shows its effectiveness and demonstrates its scalability to highdimensional tasks.", "venue": "ArXiv", "authors": ["Yachen  Kang", "Jinxin  Liu", "Xin  Cao", "Donglin  Wang"], "year": 2021, "n_citations": 0}
{"id": 579585, "s2_id": "a783d9cd8298252d87d47f9decb17f28a4987541", "title": "Continuous Monitoring of Blood Pressure with Evidential Regression", "abstract": "Photoplethysmogram (PPG) signal-based blood pressure (BP) estimation is a promising candidate for modern BP measurements, as PPG signals can be easily obtained from wearable devices in a non-invasive manner, allowing quick BP measurement. However, the performance of existing machine learning-based BP measuring methods still fall behind some BP measurement guidelines and most of them provide only point estimates of systolic blood pressure (SBP) and diastolic blood pressure (DBP). In this paper, we present a cutting-edge method which is capable of continuously monitoring BP from the PPG signal and satisfies healthcare criteria such as the Association for the Advancement of Medical Instrumentation (AAMI) and the British Hypertension Society (BHS) standards. Furthermore, the proposed method provides the reliability of the predicted BP by estimating its uncertainty to help diagnose medical condition based on the model prediction. Experiments on the MIMIC II database verify the state-of-the-art performance of the proposed method under several metrics and its ability to accurately represent uncertainty in prediction.", "venue": "ArXiv", "authors": ["Hyeongju  Kim", "Woo Hyun Kang", "Hyeonseung  Lee", "Nam Soo Kim"], "year": 2021, "n_citations": 0}
{"id": 591327, "s2_id": "be6858f60ecf83ffaf952d24ecd522f9883c80d8", "title": "On the Complexity of Bandit and Derivative-Free Stochastic Convex Optimization", "abstract": "The problem of stochastic convex optimization with bandit feedback (in the learning community) or without knowledge of gradients (in the optimization community) has received much attention in recent years, in the form of algorithms and performance upper bounds. However, much less is known about the inherent complexity of these problems, and there are few lower bounds in the literature, especially for nonlinear functions. In this paper, we investigate the attainable error/regret in the bandit and derivative-free settings, as a function of the dimension d and the available number of queries T. We provide a precise characterization of the attainable performance for strongly-convex and smooth functions, which also imply a non-trivial lower bound for more general problems. Moreover, we prove that in both the bandit and derivative-free setting, the required number of queries must scale at least quadratically with the dimension. Finally, we show that on the natural class of quadratic functions, it is possible to obtain a \"fast\" O(1/T) error rate in terms of T, under mild assumptions, even without having access to gradients. To the best of our knowledge, this is the first such rate in a derivative-free stochastic setting, and holds despite previous results which seem to imply the contrary.", "venue": "COLT", "authors": ["Ohad  Shamir"], "year": 2013, "n_citations": 136}
{"id": 596741, "s2_id": "1ee21e79a483540e636df3317e61857bb4dd0693", "title": "Triple Memory Networks: a Brain-Inspired Method for Continual Learning", "abstract": "Continual acquisition of novel experience without interfering with previously learned knowledge, i.e., continual learning, is critical for artificial neural networks, while limited by catastrophic forgetting. A neural network adjusts its parameters when learning a new task but then fails to conduct the old tasks well. By contrast, the biological brain can effectively address catastrophic forgetting through consolidating memories as more specific or more generalized forms to complement each other, which is achieved in the interplay of the hippocampus and neocortex, mediated by the prefrontal cortex. Inspired by such a brain strategy, we propose a novel approach named triple-memory networks (TMNs) for continual learning. TMNs model the interplay of the three brain regions as a triple-network architecture of generative adversarial networks (GANs). The input information is encoded as specific representations of data distributions in a generator, or generalized knowledge of solving tasks in a discriminator and a classifier, with implementing appropriate brain-inspired algorithms to alleviate catastrophic forgetting in each module. Particularly, the generator replays generated data of the learned tasks to the discriminator and the classifier, both of which are implemented with a weight consolidation regularizer to complement the lost information in the generation process. TMNs achieve the state-of-the-art performance of generative memory replay on a variety of class-incremental learning benchmarks on MNIST, SVHN, CIFAR-10, and ImageNet-50.", "venue": "IEEE transactions on neural networks and learning systems", "authors": ["Liyuan  Wang", "Bo  Lei", "Qian  Li", "Hang  Su", "Jun  Zhu", "Yi  Zhong"], "year": 2021, "n_citations": 3}
{"id": 600930, "s2_id": "c114ce10c4a315d92c3815f54bc9893e7e6ef182", "title": "Picking Winning Tickets Before Training by Preserving Gradient Flow", "abstract": "Overparameterization has been shown to benefit both the optimization and generalization of neural networks, but large networks are resource hungry at both training and test time. Network pruning can reduce test-time resource requirements, but is typically applied to trained networks and therefore cannot avoid the expensive training process. We aim to prune networks at initialization, thereby saving resources at training time as well. Specifically, we argue that efficient training requires preserving the gradient flow through the network. This leads to a simple but effective pruning criterion we term Gradient Signal Preservation (GraSP). We empirically investigate the effectiveness of the proposed method with extensive experiments on CIFAR-10, CIFAR-100, Tiny-ImageNet and ImageNet, using VGGNet and ResNet architectures. Our method can prune 80% of the weights of a VGG-16 network on ImageNet at initialization, with only a 1.6% drop in top-1 accuracy. Moreover, our method achieves significantly better performance than the baseline at extreme sparsity levels.", "venue": "ICLR", "authors": ["Chaoqi  Wang", "Guodong  Zhang", "Roger  Grosse"], "year": 2020, "n_citations": 143}
{"id": 610967, "s2_id": "eec1c63cb23b213e976b87018d683d5937ef8b4f", "title": "Geometric Insights into the Convergence of Nonlinear TD Learning", "abstract": "While there are convergence guarantees for temporal difference (TD) learning when using linear function approximators, the situation for nonlinear models is far less understood, and divergent examples are known. Here we take a first step towards extending theoretical convergence guarantees to TD learning with nonlinear function approximation. More precisely, we consider the expected learning dynamics of the TD(0) algorithm for value estimation. As the step-size converges to zero, these dynamics are defined by a nonlinear ODE which depends on the geometry of the space of function approximators, the structure of the underlying Markov chain, and their interaction. We find a set of function approximators that includes ReLU networks and has geometry amenable to TD learning regardless of environment, so that the solution performs about as well as linear TD in the worst case. Then, we show how environments that are more reversible induce dynamics that are better for TD learning and prove global convergence to the true value function for well-conditioned function approximators. Finally, we generalize a divergent counterexample to a family of divergent problems to demonstrate how the interaction between approximator and environment can go wrong and to motivate the assumptions needed to prove convergence.", "venue": "ICLR", "authors": ["David  Brandfonbrener", "Joan  Bruna"], "year": 2020, "n_citations": 10}
{"id": 620212, "s2_id": "997eb30eb3d961ed5e44d4cad61241b3750764a2", "title": "Selfgait: A Spatiotemporal Representation Learning Method for Self-Supervised Gait Recognition", "abstract": "Gait recognition plays a vital role in human identification since gait is a unique biometric feature that can be perceived at a distance. Although existing gait recognition methods can learn gait features from gait sequences in different ways, the performance of gait recognition suffers from insufficient labeled data, especially in some practical scenarios associated with short gait sequences or various clothing styles. It is unpractical to label the numerous gait data. In this work, we propose a self-supervised gait recognition method, termed SelfGait, which takes advantage of the massive, diverse, unlabeled gait data as a pre-training process to improve the representation abilities of spatiotemporal backbones. Specifically, we employ the horizontal pyramid mapping (HPM) and micro-motion template builder (MTB) as our spatiotemporal backbones to capture the multi-scale spatiotemporal representations. Experiments on CASIA-B and OU-MVLP benchmark gait datasets demonstrate the effectiveness of the proposed SelfGait compared with four state-of-the-art gait recognition methods. The source code has been released at https://github.com/EchoItLiu/SelfGait.", "venue": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Yiqun  Liu", "Yi  Zeng", "Jian  Pu", "Hongming  Shan", "Peiyang  He", "Junping  Zhang"], "year": 2021, "n_citations": 1}
{"id": 620515, "s2_id": "e9e6e15ea13ad647bdb90a6286b5e33ce7b3068b", "title": "Deep Neural Network Based Differential Equation Solver for HIV Enzyme Kinetics", "abstract": "Purpose We seek to use neural networks (NNs) to solve a well-known system of differential equations describing the balance between T cells and HIV viral burden. Materials and Methods In this paper we employ a 3-input parallel NN to approximate solutions for the system of first order ordinary differential equations describing the above biochemical relationship. Results The numerical results obtained by the NN are very similar to a host of numerical approximations from the literature. Conclusion We have demonstrated use of NN integration of a wellknown and medically important system of first order coupled ordinary differential equations. Our trial-and-error approach counteracts the system\u2019s inherent scale imbalance. However, it highlights the need to address scale imbalance more substantively in future work. Doing so will allow more automated solutions to larger systems of equations, which could describe increasingly complex and biologically interesting systems. \u2217Equal contribution ar X iv :2 10 2. 08 47 1v 1 [ qbi o. Q M ] 1 6 Fe b 20 21", "venue": "ArXiv", "authors": ["Joseph  Stember", "Parvathy  Jayan", "Hrithwik  Shalu"], "year": 2021, "n_citations": 1}
{"id": 638932, "s2_id": "65b68a1bf7e45e95ea26f697e1443612ae62ffd3", "title": "Robust Estimators under the Imprecise Dirichlet Model", "abstract": "Walley\u2019s Imprecise Dirichlet Model (IDM) for categorical data overcomes several fundamental problems which other approaches to uncertainty suffer from. Yet, to be useful in practice, one needs efficient ways for computing the imprecise=robust sets or intervals. The main objective of this work is to derive exact, conservative, and approximate, robust and credible interval estimates under the IDM for a large class of statistical estimators, including the entropy and mutual information. Marcus Hutter 4 Robust Estimators Imprecise Dirichlet Model The Dirichlet Model \u2022 Discrete random variables: i \u2208 \u03a9 := {1, ..., d} \u2022 i.i.d. random process: outcome i \u2208 {1, ..., d} with probability \u03c0i. \u2022 Likelihood of data D with ni observations i and sample size n = n+ (x+ := \u2211 i xi) is p(D|\u03c0) = \u220f i \u03c0 ni i . \u2022 Initial uncertainty in \u03c0 is modeled by a (second order) \u201cbelief\u201d Dirichlet prior p(\u03c0) \u221d i \u03c0 \u2032 i\u22121 i . Marcus Hutter 5 Robust Estimators Imprecise Dirichlet Model The Dirichlet Model (ctd.) \u2022 Notation: Write ni = s \u00b7 ti with s := n+, hence t \u2208 \u2206 := {t \u2208 IR : ti \u2265 0\u2200i, t+ = 1} \u2022 Examples of uninformed priors: ti = 1 d\u2200i: Haldane (s = 0), Perks (s = 1), Jeffreys (s = d2 ), Bayes/Laplace/uniform (s = d). \u2022 Posterior: p(\u03c0|D) = p(\u03c0|n) \u221d i \u03c0ni+sti\u22121 i . \u2022 Expected value: Et[F ] = \u222b \u2206 F(\u03c0)p(\u03c0|n)d\u03c0 \u2022 Variance: Vart[F ] = Et[F]\u2212 Et[F ]. Marcus Hutter 6 Robust Estimators Imprecise Dirichlet Model The Imprecise Dirichlet Model \u2022 Model our ignorance by considering sets of priors p(\u03c0), often called Imprecise probabilities. \u2022 The Imprecise Dirichlet Model (IDM) [Walley:96] considers the set of all t \u2208 \u2206, i.e. {pt(\u03c0) : t \u2208 \u2206}. \u2022 IDM satisfies symmetry principle and is reparametrization invariant (RIP). \u2022 Set of priors \u21d2 set of posteriors \u21d2 set of expected vals. \u2022 For real-valued quantities like Et[F ] the sets are typically intervals (called robust): Et[F ] \u2208 [mint\u2208\u2206 Et[F ] , maxt\u2208\u2206 Et[F ]] Marcus Hutter 7 Robust Estimators Imprecise Dirichlet Model Problem Setup and Notation F (u) := Et[F ] with identification u\u00b7\u00b7\u00b7 i = ni+st \u00b7\u00b7\u00b7 i n+s . Goal: Derive expressions for upper and lower F values F := max u\u2208\u2206\u2032 F (u) and F := min u\u2208\u2206\u2032 F (u), F := [F , F ] \u2206\u2032 = {u : ui \u2265 ui , u+ = 1} with ui := ni n+s . Example: F (u) = Et[\u03c0i] = ni+sti n+s = ui \u21d2 F = [ ni n+s , ni+s n+s ] Marcus Hutter 8 Robust Estimators Imprecise Dirichlet Model Exact Robust Intervals for Concave F \u2022 Assume F : \u2206\u2032 \u2192 IR concave and F (u) = di=1 f(ui): \u2022 F attains the the global minimum F at corner u with t F i = \u03b4iiF and i F := arg maxi ni. \u2022 F attains the global maximum F at water-filling point u with ui = max{ui , \u0169}, where \u0169 = minm\u2208{1...d} s+ \u2211 k\u2264m nik m(n+s) , where ni1 \u2264 ni2 \u2264 ... \u2264 nid . Marcus Hutter 9 Robust Estimators Imprecise Dirichlet Model Approximate Robust Intervals Exact expansion of F (u) = \u2211 i f(ui) around u . Assume F : \u2206\u2032 \u2192 IR Lipschitz diff. and \u03c3 := s n+s small. \u21d2 F \u2212 F = O(\u03c3) \u21d2 approximation to F should be O(\u03c3). Notation: F v G :\u21d4 F \u2264 G and F = G + O(\u03c3) F0 + F lb R v F \u2264 F (u) \u2264 F v F0 + F R F0 = F (u), F R = \u03c3 max i f (ui ) = \u03c3f \u2032(mini ni n+s ), F lb R = \u03c3 min i f (ui + \u03c3) = \u03c3f \u2032(maxi ni+s n+s ), Marcus Hutter 10 Robust Estimators Imprecise Dirichlet Model Application: Expected Entropy H H(\u03c0) := \u2212i \u03c0i log \u03c0i \u21d2 H(u) := Et[H] = \u2211 i h(ui) with h(ui) = ui \u00b7 \u2211n+s k=(n+s)ui+1 k\u22121 (for integer s and (n+ s)ui) General expression in terms of DiGamma function \u03c8. Example (exact): For d = 2, n1 = 3, n2 = 6, s = 1 we have H = [0.5639..., 0.6256...], so H \u2212H = O( 1 10 ). Example (approximate): \u03c3 = 1 10 , [H0 + H lb R , H0 + H ub R ] = [0.5564..., 0.6404...], hence H0 + H R \u2212H = 0.0148 = O( 1 102 ), H \u2212H0 \u2212H lb R = 0.0074... = O( 1 102 ). Marcus Hutter 11 Robust Estimators Imprecise Dirichlet Model Error Propagation \u2022 F := G + H. Naive: F \u2264 G + H, but F 6v G + H. \u2022 Results: O(\u03c3) bounds (v) for F = G ? H and ? \u2208 {+,\u2212,\u00d7, /, ...}. \u2022 Every function F (w.b.c.) can be written as a sum of a concave function G and a convex function H. \u2022 For convex and concave functions, determining bounds is particularly easy (special case on previous slides). \u2022 Often F decomposes naturally into convex and concave parts as is the case for the mutual information: I(\u03c0) = H(\u03c0i+) +H(\u03c0+\uf6be)\u2212H(\u03c0i\uf6be) Marcus Hutter 12 Robust Estimators Imprecise Dirichlet Model IDM for Product Spaces \u2022 Product spaces: \u03a9 = \u03a91 \u00d7 \u03a92 = {1, ..., d1}\u00d7{1, ..., d2} \u2022 Applications: mutual inform., robust trees, Bayes nets. \u2022 Full IDM invariant under general (non-column/row cross) groupings of elements of \u03a9: t \u2208 \u2206 := {t \u2208 IRd1\u00d7d2 : tij \u2265 0\u2200ij, t++ = 1} \u2022 Smaller IDM, invariant only under groupings of whole columns and/or rows of \u03a9, makes more sense: t \u2208 \u2206d1 \u2297\u2206d2 ( \u2206. \u2022 Result: Smaller IDM leads to O(\u03c3) smaller (=better) robust sets. Marcus Hutter 13 Robust Estimators Imprecise Dirichlet Model Exact Robust Credible Sets For a probability distribution p : IR \u2192 [0, 1], a/the \u03b1-credible set is A := arg min A:p(A)\u2265\u03b1 Vol(A) For a set of probability distributions {pt(x)}, a robust \u03b1-credible set is a set A which contains x with pt-probability at least \u03b1 for all t. A minimal size robust \u03b1-credible set is A := arg min A=\u222atAt:pt(At)\u2265\u03b1\u2200t\u2208T Vol(A) 6= \u22c3", "venue": "ISIPTA", "authors": ["Marcus  Hutter"], "year": 2003, "n_citations": 15}
{"id": 639888, "s2_id": "4fdc4696ca365a0e531550de98d6f595f21247bc", "title": "Large scale Lasso with windowed active set for convolutional spike sorting", "abstract": "Spike sorting is a fundamental preprocessing step in neuroscience that is central to access simultaneous but distinct neuronal activities and therefore to better understand the animal or even human brain. But numerical complexity limits studies that require processing large scale datasets in terms of number of electrodes, neurons, spikes and length of the recorded signals. We propose in this work a novel active set algorithm aimed at solving the Lasso for a classical convolutional model. Our algorithm can be implemented efficiently on parallel architecture and has a linear complexity w.r.t. the temporal dimensionality which ensures scaling and will open the door to online spike sorting. We provide theoretical results about the complexity of the algorithm and illustrate it in numerical experiments along with results about the accuracy of the spike recovery and robustness to the regularization parameter.", "venue": "ArXiv", "authors": ["Laurent  Dragoni", "R\u00e9mi  Flamary", "Karim  Lounici", "Patricia  Reynaud-Bouret"], "year": 2019, "n_citations": 0}
{"id": 646096, "s2_id": "b759e9b6d0203f85c5537d46e2b4392e6b08b3cd", "title": "Solving Inverse Computational Imaging Problems Using Deep Pixel-Level Prior", "abstract": "Signal reconstruction is a challenging aspect of computational imaging as it often involves solving ill-posed inverse problems. Recently, deep feed-forward neural networks have led to state-of-the-art results in solving various inverse imaging problems. However, being task specific, these networks have to be learned for each inverse problem. On the other hand, a more flexible approach would be to learn a deep generative model once and then use it as a signal prior for solving various inverse problems. In this paper, we show that among the various state-of-the-art deep generative models, autoregressive models are especially suitable for our purpose for the following reasons. First, they explicitly model the pixel level dependencies and hence are capable of reconstructing low-level details, such as texture patterns and edges better. Second, they provide an explicit expression for the image prior, which can then be used for MAP-based inference along with the forward model. Third, they can model long range dependencies in images which make them ideal for handling global multiplexing as encountered in various compressive imaging systems. We demonstrate the efficacy of our proposed approach in solving three computational imaging problems: Single Pixel Camera, LiSens, and FlatCam. For both real and simulated cases, we obtain better reconstructions than the state-of-the-art methods in terms of perceptual and quantitative metrics.", "venue": "IEEE Transactions on Computational Imaging", "authors": ["Akshat  Dave", "Anil Kumar Vadathya", "Ramana  Subramanyam", "Rahul  Baburajan", "Kaushik  Mitra"], "year": 2019, "n_citations": 19}
{"id": 646325, "s2_id": "cea6505d02ec1817b8a7f956a7d4a1f37cddc8b9", "title": "Truth or Backpropaganda? An Empirical Investigation of Deep Learning Theory", "abstract": "We empirically evaluate common assumptions about neural networks that are widely held by practitioners and theorists alike. In this work, we: (1) prove the widespread existence of suboptimal local minima in the loss landscape of neural networks, and we use our theory to find examples; (2) show that small-norm parameters are not optimal for generalization; (3) demonstrate that ResNets do not conform to wide-network theories, such as the neural tangent kernel, and that the interaction between skip connections and batch normalization plays a role; (4) find that rank does not correlate with generalization or robustness in a practical setting.", "venue": "ICLR", "authors": ["Micah  Goldblum", "Jonas  Geiping", "Avi  Schwarzschild", "Michael  Moeller", "Tom  Goldstein"], "year": 2020, "n_citations": 21}
{"id": 647151, "s2_id": "fc1992b20ca130a15f60fd077e29c3b218f5e5d9", "title": "Deep multi-modal classification of intraductal papillary mucinous neoplasms (IPMN) with canonical correlation analysis", "abstract": "Pancreatic cancer has the poorest prognosis among all cancer types. Intraductal Papillary Mucinous Neoplasms (IPMNs) are radiographically identifiable precursors to pancreatic cancer; hence, early detection and precise risk assessment of IPMN are vital. In this work, we propose a Convolutional Neural Network (CNN) based computer aided diagnosis (CAD) system to perform IPMN diagnosis and risk assessment by utilizing multi-modal MRI. In our proposed approach, we use minimum and maximum intensity projections to ease the annotation variations among different slices and type of MRIs. Then, we present a CNN to obtain deep feature representation corresponding to each MRI modality (T1-weighted and T2-weighted). At the final step, we employ canonical correlation analysis (CCA) to perform a fusion operation at the feature level, leading to discriminative canonical correlation features. Extracted features are used for classification. Our results indicate significant improvements over other potential approaches to solve this important problem. The proposed approach doesn't require explicit sample balancing in cases of imbalance between positive and negative examples. To the best of our knowledge, our study is the first to automatically diagnose IPMN using multi-modal MRI.", "venue": "2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)", "authors": ["Sarfaraz  Hussein", "Pujan  Kandel", "Juan E. Corral", "Candice W. Bolan", "Michael B. Wallace", "Ulas  Bagci"], "year": 2018, "n_citations": 6}
{"id": 648918, "s2_id": "2e121ab7b5e3b4884eec0c573373271bd899ca1c", "title": "Multi-Stage Transmission Line Flow Control Using Centralized and Decentralized Reinforcement Learning Agents", "abstract": "Planning future operational scenarios of bulk power systems that meet security and economic constraints typically requires intensive labor efforts in performing massive simulations. To automate this process and relieve engineers\u2019 burden, a novel multi-stage control approach is presented in this paper to train centralized and decentralized reinforcement learning agents that can automatically adjust grid controllers for regulating transmission line flows at normal condition and under contingencies. The power grid flow control problem is formulated as Markov Decision Process (MDP). At stage one, centralized soft actor-critic (SAC) agent is trained to control generator active power outputs in a wide area to control transmission line flows against specified security limits. If line overloading issues remain unresolved, stage two is used to train decentralized SAC agent via load throw-over at local substations. The effectiveness of the proposed approach is verified on a series of actual planning cases used for operating the power grid of SGCC Zhejiang Electric Power Company.", "venue": "ArXiv", "authors": ["Xiumin  Shang", "Jinping  Yang", "Bingquan  Zhu", "Lin  Ye", "Jing  Zhang", "Jianping  Xu", "Qin  Lyu", "Ruisheng  Diao"], "year": 2021, "n_citations": 0}
{"id": 653666, "s2_id": "3d565e5c621323fec6648da118fecf370530fd7c", "title": "RKT: Relation-Aware Self-Attention for Knowledge Tracing", "abstract": "The world has transitioned into a new phase of online learning in response to the recent Covid19 pandemic. Now more than ever, it has become paramount to push the limits of online learning in every manner to keep flourishing the education system. One crucial component of online learning is Knowledge Tracing (KT). The aim of KT is to model student's knowledge level based on their answers to a sequence of exercises referred as interactions. Students acquire their skills while solving exercises and each such interaction has a distinct impact on student ability to solve a future exercise. This impact is characterized by 1) the relation between exercises involved in the interactions and 2) student forget behavior. Traditional studies on knowledge tracing do not explicitly model both the components jointly to estimate the impact of these interactions. In this paper, we propose a novel Relation-aware self-attention model for Knowledge Tracing (RKT). We introduce a relation-aware self-attention layer that incorporates the contextual information. This contextual information integrates both the exercise relation information through their textual content as well as student performance data and the forget behavior information through modeling an exponentially decaying kernel function. Extensive experiments on three real-world datasets, among which two new collections are released to the public, show that our model outperforms state-of-the-art knowledge tracing methods. Furthermore, the interpretable attention weights help visualize the relation between interactions and temporal patterns in the human learning process.", "venue": "CIKM", "authors": ["Shalini  Pandey", "Jaideep  Srivastava"], "year": 2020, "n_citations": 17}
{"id": 659719, "s2_id": "83e87cbcc00dd35e99178d1c29ed39945a46709a", "title": "Auditing: Active Learning with Outcome-Dependent Query Costs", "abstract": "We propose a learning setting in which unlabeled data is free, and the cost of a label depends on its value, which is not known in advance. We study binary classification in an extreme case, where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection, in which investigating an honest transaction should be avoided if possible. We term the setting auditing, and consider the auditing complexity of an algorithm: the number of negative labels the algorithm requires in order to learn a hypothesis with low relative error. We design auditing algorithms for simple hypothesis classes (thresholds and rectangles), and show that with these algorithms, the auditing complexity can be significantly lower than the active label complexity. We also show a general competitive approach for learning with outcome-dependent costs.", "venue": "NIPS", "authors": ["Sivan  Sabato", "Anand D. Sarwate", "Nathan  Srebro"], "year": 2013, "n_citations": 7}
{"id": 664453, "s2_id": "009ad484993d57c2454a3fabfd86072ce6a15f49", "title": "Transductive Multi-label Zero-shot Learning", "abstract": "Zero-shot learning has received increasing interest as a means to alleviate the often prohibitive expense of annotating training data for large scale recognition problems. These methods have achieved great success via learning intermediate semantic representations in the form of attributes and more recently, semantic word vectors. However, they have thus far been constrained to the single-label case, in contrast to the growing popularity and importance of more realistic multi-label data. In this paper, for the first time, we investigate and formalise a general framework for multi-label zero-shot learning, addressing the unique challenge therein: how to exploit multi-label correlation at test time with no training data for those classes? In particular, we propose (1) a multi-output deep regression model to project an image into a semantic word space, which explicitly exploits the correlations in the intermediate semantic layer of word vectors; (2) a novel zero-shot learning algorithm for multi-label data that exploits the unique compositionality property of semantic word vector representations; and (3) a transductive learning strategy to enable the regression model learned from seen classes to generalise well to unseen classes. Our zero-shot learning experiments on a number of standard multi-label datasets demonstrate that our method outperforms a variety of baselines.", "venue": "BMVC", "authors": ["Yanwei  Fu", "Yongxin  Yang", "Timothy M. Hospedales", "Tao  Xiang", "Shaogang  Gong"], "year": 2014, "n_citations": 43}
{"id": 674444, "s2_id": "83ef43b332dd99f1cc266ab1765c33a611b99bb8", "title": "Natlog: a Lightweight Logic Programming Language with a Neuro-symbolic Touch", "abstract": "We introduce Natlog, a lightweight Logic Programming language, sharing Prolog\u2019s unificationdriven execution model, but with a simplified syntax and semantics. Our proof-of-concept Natlog implementation is tightly embedded in the Python-based deep-learning ecosystem with focus on content-driven indexing of ground term datasets. As an overriding of our symbolic indexing algorithm, the same function can be delegated to a neural network, serving ground facts to Natlog\u2019s resolution engine. Our open-source implementation is available as a Python package at https: //pypi.org/project/natlog/. Keyphrases: Python-based logic programming system, embedded logic programming language, ground term fact database indexing, neuro-symbolic logic programming, logic programming language implementation.", "venue": "ICLP Technical Communications", "authors": ["Paul  Tarau"], "year": 2021, "n_citations": 0}
{"id": 684061, "s2_id": "28b9778945a5f042ea17baee5eab9517d91e23ae", "title": "Noise-robust classification with hypergraph neural network", "abstract": "This paper presents a novel version of hypergraph neural network method. This method is utilized to solve the noisy label learning problem. First, we apply the PCA dimensional reduction technique to the feature matrices of the image datasets in order to reduce the \u201cnoise\u201d and the redundant features in the feature matrices of the image datasets and to reduce the runtime constructing the hypergraph of the hypergraph neural network method. Then, the classic graph based semisupervised learning method, the classic hypergraph based semi-supervised learning method, the graph neural network, the hypergraph neural network, and our proposed hypergraph neural network are employed to solve the noisy label learning problem. The accuracies of these five methods are evaluated and compared. Experimental results show that the hypergraph neural network methods achieve the best performance when the noise level increases. Moreover, the hypergraph neural network methods are at least as good as the graph neural network.", "venue": "ArXiv", "authors": ["Nguyen Trinh Vu Dang", "Loc  Tran", "Linh  Tran"], "year": 2021, "n_citations": 1}
{"id": 690830, "s2_id": "942788c58670918a04bc00db62a9f4366b8ba870", "title": "Deep learning at the shallow end: Malware classification for non-domain experts", "abstract": "Current malware detection and classification approaches generally rely on time consuming and knowledge intensive processes to extract patterns (signatures) and behaviors from malware, which are then used for identification. Moreover, these signatures are often limited to local, contiguous sequences within the data whilst ignoring their context in relation to each other and throughout the malware file as a whole. We present a Deep Learning based malware classification approach that requires no expert domain knowledge and is based on a purely data driven approach for complex pattern and feature identification.", "venue": "Digit. Investig.", "authors": ["Quan  Le", "Ois\u00edn  Boydell", "Brian Mac Namee", "Mark  Scanlon"], "year": 2018, "n_citations": 83}
{"id": 695723, "s2_id": "3a4d427e53424cc2a4ba2d0204d9b5fddcab2ba5", "title": "Comparison of non-linear activation functions for deep neural networks on MNIST classification task", "abstract": "Activation functions play a key role in neural networks so it becomes fundamental to understand their advantages and disadvantages in order to achieve better performances. This paper will first introduce common types of non linear activation functions that are alternative to the well known sigmoid function and then evaluate their characteristics. Moreover deeper neural networks will be analysed because they positively influence the final performances compared to shallower networks. They also strictly depend on the weight initialisation hence the effect of drawing weights from Gaussian and uniform distribution will be analysed making particular attention on how the number of incoming and outgoing connection to a node influence the whole network.", "venue": "ArXiv", "authors": ["Dabal  Pedamonti"], "year": 2018, "n_citations": 118}
{"id": 696261, "s2_id": "3245b2436d9f39b9ecadd275a815d09c2e130497", "title": "Unsupervised Learning of Object Keypoints for Perception and Control", "abstract": "The study of object representations in computer vision has primarily focused on developing representations that are useful for image classification, object detection, or semantic segmentation as downstream tasks. In this work we aim to learn object representations that are useful for control and reinforcement learning (RL). To this end, we introduce Transporter, a neural network architecture for discovering concise geometric object representations in terms of keypoints or image-space coordinates. Our method learns from raw video frames in a fully unsupervised manner, by transporting learnt image features between video frames using a keypoint bottleneck. The discovered keypoints track objects and object parts across long time-horizons more accurately than recent similar methods. Furthermore, consistent long-term tracking enables two notable results in control domains -- (1) using the keypoint co-ordinates and corresponding image features as inputs enables highly sample-efficient reinforcement learning; (2) learning to explore by controlling keypoint locations drastically reduces the search space, enabling deep exploration (leading to states unreachable through random action exploration) without any extrinsic rewards.", "venue": "NeurIPS", "authors": ["Tejas  Kulkarni", "Ankush  Gupta", "Catalin  Ionescu", "Sebastian  Borgeaud", "Malcolm  Reynolds", "Andrew  Zisserman", "Volodymyr  Mnih"], "year": 2019, "n_citations": 85}
{"id": 699927, "s2_id": "0d37c762336ce69801c7fda5eb140d716ece0859", "title": "The Implicit and Explicit Regularization Effects of Dropout", "abstract": "Dropout is a widely-used regularization technique, often required to obtain state-of-the-art for a number of architectures. This work demonstrates that dropout introduces two distinct but entangled regularization effects: an explicit effect (also studied in prior work) which occurs since dropout modifies the expected training objective, and, perhaps surprisingly, an additional implicit effect from the stochasticity in the dropout training update. This implicit regularization effect is analogous to the effect of stochasticity in small mini-batch stochastic gradient descent. We disentangle these two effects through controlled experiments. We then derive analytic simplifications which characterize each effect in terms of the derivatives of the model and the loss, for deep neural networks. We demonstrate these simplified, analytic regularizers accurately capture the important aspects of dropout, showing they faithfully replace dropout in practice.", "venue": "ICML", "authors": ["Colin  Wei", "Sham  Kakade", "Tengyu  Ma"], "year": 2020, "n_citations": 36}
{"id": 701678, "s2_id": "1c2e0a4e47722c5e2e068b4c194a51d5155ca1c1", "title": "Structure-Aware Stochastic Control for Transmission Scheduling", "abstract": "In this paper, we consider the problem of real-time transmission scheduling over time-varying channels. We first formulate this transmission scheduling problem as a Markov decision process and systematically unravel the structural properties (e.g., concavity in the state-value function and monotonicity in the optimal scheduling policy) exhibited by the optimal solutions. We then propose an online learning algorithm that preserves these structural properties and achieves \u03b5-optimal solutions for an arbitrarily small \u03b5. The advantages of the proposed online method are given as follows: 1) It does not require a priori knowledge of the traffic arrival and channel statistics, and 2) it adaptively approximates the state-value functions using piecewise linear functions and has low storage and computation complexity. We also extend the proposed low-complexity online learning solution to enable prioritized data transmission. The simulation results demonstrate that the proposed method achieves significantly better utility (or delay)-energy tradeoffs compared to existing state-of-the-art online optimization methods.", "venue": "IEEE Transactions on Vehicular Technology", "authors": ["Fangwen  Fu", "Mihaela van der Schaar"], "year": 2012, "n_citations": 48}
{"id": 703227, "s2_id": "be0d94d84507c14fabea0d7eedfd30dcd6ae8b19", "title": "Towards Data-Driven Affirmative Action Policies under Uncertainty", "abstract": "In this paper, we study university admissions under a centralized system that uses grades and standardized test scores to match applicants to university programs. We consider affirmative action policies that seek to increase the number of admitted applicants from underrepresented groups. Since such a policy has to be announced before the start of the application period, there is uncertainty about the score distribution of the students applying to each program. This poses a difficult challenge for policy-makers. We explore the possibility of using a predictive model trained on historical data to help optimize the parameters of such policies.", "venue": "ArXiv", "authors": ["Corinna  Hertweck", "Carlos  Castillo", "Michael  Mathioudakis"], "year": 2020, "n_citations": 0}
{"id": 707510, "s2_id": "1a5e5f1e35fd8629c75977f48480c469137cfebe", "title": "Deep graph matching meets mixed-integer linear programming: Relax at your own risk ?", "abstract": "This preprint is under consideration at Pattern Recognition. Graph matching is an important problem that has received widespread attention, especially in the field of computer vision. Recently, state-of-the-art methods seek to incorporate graph matching with deep learning. However, there is no research to explain what role the graph matching algorithm plays in the model. Therefore, we propose an approach integrating a MILP formulation of the graph matching problem. This formulation is solved to optimal and it provides inherent baseline. Meanwhile, similar approaches are derived by releasing the optimal guarantee of the graph matching solver and by introducing a quality level. This quality level controls the quality of the solutions provided by the graph matching solver. In addition, several relaxations of the graph matching problem are put to the test. Our experimental evaluation gives several theoretical insights and guides the direction of deep graph matching methods. \u2217c.puqing@gmail.com \u2020romain.raveaux@univ-tours.fr 1 ar X iv :2 10 8. 00 39 4v 1 [ cs .C V ] 1 A ug 2 02 1", "venue": "SSRN Electronic Journal", "authors": ["Zhoubo  Xu", "Puqing  Chen", "Romain  Raveaux", "Xin  Yang", "Huadong  Liu"], "year": 2021, "n_citations": 0}
{"id": 734059, "s2_id": "e17c9894d4c965add07278f508e5a1d277df810b", "title": "Reinforcement Learning", "abstract": "Questions 1. Consider the comparison between \u03b5-greedy methods shown in Figure 2.1 in the Sutton and Barto book. Which method will perform best in the long run in terms of cumulative rewards and cumulative probability of selecting the best action? How much better will it be? 2. Show that in the case of two actions, the softmax operation using the Gibbs distribution becomes the logistic, or sigmoid, function commonly used in artificial neural networks. What effect does the temperature parameter have on the function? 3. In the incremental version of the action value estimation (exponential recency-weighted average, sec 2.6 in Sutton&Barto), if the step size parameter, \u03b1k(a), is not constant, then the estimate Qk(a) is a weighted average of previously received rewards with a weighting different from the one in sec 2.6. What is the weighting on each prior reward in the general case? 4. Consider the optimistic initial value example, fig. 2.4 in S+B. This represents averages over 2000 individual, randomly chosen 10-armed bandit tasks, so the result should be reliable. How do you explain the oscillations and spikes in the early part of the curve for the optimistic method? What makes this method perform differently on particular early plays?", "venue": "Encyclopedia of Machine Learning", "authors": ["Peter  Stone"], "year": 2010, "n_citations": 0}
{"id": 801562, "s2_id": "5aca883021ad4ec24ba92a9880ab327b6d9c58e7", "title": "Multilateration of Random Networks with Community Structure", "abstract": "The minimal number of nodes required to multilaterate a network endowed with geodesic distance (i.e., to uniquely identify all nodes based on shortest path distances to the selected nodes) is called its metric dimension. This quantity is related to a useful technique for embedding graphs in low-dimensional Euclidean spaces and representing the nodes of a graph numerically for downstream analyses such as vertex classification via machine learning. While metric dimension has been studied for many kinds of graphs, its behavior on the Stochastic Block Model (SBM) ensemble has not. The simple community structure of graphs in this ensemble make them interesting in a variety of contexts. Here we derive probabilistic bounds for the metric dimension of random graphs generated according to the SBM, and describe algorithms of varying complexity to find---with high probability---subsets of nodes for multilateration. Our methods are tested on SBM ensembles with parameters extracted from real-world networks. We show that our methods scale well with increasing network size as compared to the state-of-the-art Information Content Heuristic algorithm for metric dimension approximation.", "venue": "ArXiv", "authors": ["Richard D. Tillquist", "Manuel E. Lladser"], "year": 2019, "n_citations": 1}
{"id": 807318, "s2_id": "01bd5840e93f45692cab8f594e293015155f9963", "title": "Freshman or Fresher? Quantifying the Geographic Variation of Internet Language", "abstract": "We present a new computational technique to detect and analyze statistically significant geographic variation in language. Our meta-analysis approach captures statistical properties of word usage across geographical regions and uses statistical methods to identify significant changes specific to regions. While previous approaches have primarily focused on lexical variation between regions, our method identifies words that demonstrate semantic and syntactic variation as well. \nWe extend recently developed techniques for neural language models to learn word representations which capture differing semantics across geographical regions. In order to quantify this variation and ensure robust detection of true regional differences, we formulate a null model to determine whether observed changes are statistically significant. Our method is the first such approach to explicitly account for random variation due to chance while detecting regional variation in word meaning. \nTo validate our model, we study and analyze two different massive online data sets: millions of tweets from Twitter spanning not only four different countries but also fifty states, as well as millions of phrases contained in the Google Book Ngrams. Our analysis reveals interesting facets of language change at multiple scales of geographic resolution -- from neighboring states to distant continents. \nFinally, using our model, we propose a measure of semantic distance between languages. Our analysis of British and American English over a period of 100 years reveals that semantic variation between these dialects is shrinking.", "venue": "ArXiv", "authors": ["Vivek  Kulkarni", "Bryan  Perozzi", "Steven  Skiena"], "year": 2015, "n_citations": 16}
{"id": 809036, "s2_id": "4e1e8e2dc15469b5f5b30a9607fa4209a51b9112", "title": "Some Remarks on Replicated Simulated Annealing", "abstract": "Recently authors have introduced the idea of training discrete weights neural networks using a mix between classical simulated annealing and a replica ansatz known from the statistical physics literature. Among other points, they claim their method is able to find robust configurations. In this paper, we analyze this so-called \"replicated simulated annealing\" algorithm. In particular, we explicit criteria to guarantee its convergence, and study when it successfully samples from configurations. We also perform experiments using synthetic and real data bases.", "venue": "ArXiv", "authors": ["Vincent  Gripon", "Matthias  L\u00f6we", "Franck  Vermet"], "year": 2020, "n_citations": 1}
{"id": 809475, "s2_id": "9e380323c2a6db51450253e3ce5ed72bddbe64a0", "title": "Instance based Generalization in Reinforcement Learning", "abstract": "Agents trained via deep reinforcement learning (RL) routinely fail to generalize to unseen environments, even when these share the same underlying dynamics as the training levels. Understanding the generalization properties of RL is one of the challenges of modern machine learning. Towards this goal, we analyze policy learning in the context of Partially Observable Markov Decision Processes (POMDPs) and formalize the dynamics of training levels as instances. We prove that, independently of the exploration strategy, reusing instances introduces significant changes on the effective Markov dynamics the agent observes during training. Maximizing expected rewards impacts the learned belief state of the agent by inducing undesired instance specific speedrunning policies instead of generalizeable ones, which are suboptimal on the training set. We provide generalization bounds to the value gap in train and test environments based on the number of training instances, and use insights based on these to improve performance on unseen levels. We propose training a shared belief representation over an ensemble of specialized policies, from which we compute a consensus policy that is used for data collection, disallowing instance specific exploitation. We experimentally validate our theory, observations, and the proposed computational solution over the CoinRun benchmark.", "venue": "NeurIPS", "authors": ["Martin  Bertran", "Natalia  Martinez", "Mariano  Phielipp", "Guillermo  Sapiro"], "year": 2020, "n_citations": 3}
{"id": 809972, "s2_id": "d225d8cd872c112a9bb6b2ee20cd54c28104c6b8", "title": "Boosting Anomaly Detection Using Unsupervised Diverse Test-Time Augmentation", "abstract": "Anomaly detection is a well-known task that involves the identification of abnormal events that occur relatively infrequently. Methods for improving anomaly detection performance have been widely studied. However, no studies utilizing test-time augmentation (TTA) for anomaly detection in tabular data have been performed. TTA involves aggregating the predictions of several synthetic versions of a given test sample; TTA produces different points of view for a specific test instance and might decrease its prediction bias. We propose the Test-Time Augmentation for anomaly Detection (TTAD) technique, a TTA-based method aimed at improving anomaly detection performance. TTAD augments a test instance based on its nearest neighbors; various methods, including the k-Means centroid and SMOTE methods, are used to produce the augmentations. Our technique utilizes a Siamese network to learn an advanced distance metric when retrieving a test instance\u2019s neighbors. Our experiments show that the anomaly detector that uses our TTA technique achieved significantly higher AUC results on all datasets evaluated.", "venue": "ArXiv", "authors": ["Seffi  Cohen", "Niv  Goldshlager", "Lior  Rokach", "Bracha  Shapira"], "year": 2021, "n_citations": 0}
{"id": 810396, "s2_id": "a29b401a56e8a24ebf7de9229b169f604a6436f0", "title": "Inference, Prediction, and Entropy-Rate Estimation of Continuous-time, Discrete-event Processes", "abstract": "Author(s): Marzen, SE; Crutchfield, JP | Abstract: Inferring models, predicting the future, and estimating the entropy rate of discrete-time, discrete-event processes is well-worn ground. However, a much broader class of discrete-event processes operates in continuous-time. Here, we provide new methods for inferring, predicting, and estimating them. The methods rely on an extension of Bayesian structural inference that takes advantage of neural network's universal approximation power. Based on experiments with complex synthetic data, the methods are competitive with the state-of-the-art for prediction and entropy-rate estimation.", "venue": "ArXiv", "authors": ["Sarah E. Marzen", "James P. Crutchfield"], "year": 2020, "n_citations": 2}
{"id": 811132, "s2_id": "7d4d936df2f628550123cef40996277628468e61", "title": "Intrinsic dimension estimation of data by principal component analysis", "abstract": "Estimating intrinsic dimensionality of data is a classic problem in pattern recognition and statistics. Principal Component Analysis (PCA) is a powerful tool in discovering dimensionality of data sets with a linear structure; it, however, becomes ineffective when data have a nonlinear structure. In this paper, we propose a new PCA-based method to estimate intrinsic dimension of data with nonlinear structures. Our method works by first finding a minimal cover of the data set, then performing PCA locally on each subset in the cover and finally giving the estimation result by checking up the data variance on all small neighborhood regions. The proposed method utilizes the whole data set to estimate its intrinsic dimension and is convenient for incremental learning. In addition, our new PCA procedure can filter out noise in data and converge to a stable estimation with the neighborhood region size increasing. Experiments on synthetic and real world data sets show effectiveness of the proposed method.", "venue": "ArXiv", "authors": ["Mingyu  Fan", "Nannan  Gu", "Hong  Qiao", "Bo  Zhang"], "year": 2010, "n_citations": 18}
{"id": 813840, "s2_id": "9040593af5948e4a7d0614597ac587c2da6bb4ff", "title": "Finding Significant Fourier Coefficients: Clarifications, Simplifications, Applications and Limitations", "abstract": "Ideas from Fourier analysis have been used in cryptography for three decades. Akavia, Goldwasser and Safra unified some of these ideas to give a complete algorithm that finds significant Fourier coefficients of functions on any finite abelian group. Their algorithm stimulated a lot of interest in the cryptography community, especially in the context of \"bit security\". This paper attempts to be a friendly and comprehensive guide to the tools and results in this field. The intended readership is cryptographers who have heard about these tools and seek an understanding of their mechanics, and their usefulness and limitations. A compact overview of the algorithm is presented with emphasis on the ideas behind it. We survey some applications of this algorithm, and explain that several results should be taken in the right context. We point out that some of the most important bit security problems are still open. Our original contributions include: an approach to the subject based on modulus switching; a discussion of the limitations on the usefulness of these tools; an answer to an open question about the modular inversion hidden number problem.", "venue": "IACR Cryptol. ePrint Arch.", "authors": ["Steven D. Galbraith", "Joel  Laity", "Barak  Shani"], "year": 2016, "n_citations": 2}
{"id": 816247, "s2_id": "35009a365220fa1369b03d389bb3dd58dcc2ba5c", "title": "Achieving Privacy in the Adversarial Multi-Armed Bandit", "abstract": "In this paper, we improve the previously best known regret \nChristos Dimitrakakis \nUniversity of Lille, France Chalmers University of Technology, Sweden Harvard University, USA christos.dimitrakakis@gmail.com \nmovie recommendations can be formalized similarly (Pandey and Olston 2006). \nPrivacy can be a serious issue in the bandit setting (c.f. (Jain, Kothari, and Thakurta 2012; Thakurta and Smith 2013; Mishra and Thakurta 2015; Zhao et al. 2014)). For example, in clinical trials, we may want to detect and publish results about the best drug without leaking sensitive information, such as the patient\u2019s health condition and genome. Differen- tial privacy (Dwork 2006) formally bounds the amount of information that a third party can learn no matter their power or side information. \nDifferential privacy has been used before in the stochastic setting (Tossou and Dimitrakakis 2016; Mishra and Thakurta 2015; Jain, Kothari, and Thakurta 2012) where the authors obtain optimal algorithms up to logarithmic factors. In the adversarial setting, (Thakurta and Smith 2013) adapts an algorithm called Follow The Approximate Leader to make it private and obtain a regret bound of O(T2/3). In this work, we show that a number of simple algorithms can satisfy privacy guarantees, while achieving nearly optimal regret (up to logarithmic factors) that scales naturally with the level of privacy desired. \nOur work is also of independent interest for non-private multi-armed bandit algorithms, as there are competitive with the current state of the art against switching-cost adversaries (where we recover the optimal bound). Finally, we provide rigorous empirical results against a variety of adversaries. \nThe following section gives the main background and nota- tions. Section 3.1 describes meta-algorithms that perturb the gain sequence to achieve privacy, while Section 3.2 explains how to leverage the privacy inherent in the EXP3 algorithm by modifying the way gains are used. Section 4 compares our algorithms with EXP3 in a variety of settings. The full proofs of all our main results are in the full version. \n2 Preliminaries \n2.1 The Multi-Armed Bandit problem \nFormally, a bandit game is defined between an adversary and an agent as follows: there is a set of K arms A, and at each round t, the agent plays an arm It \u2208 A. Given the choice It, the adversary grants the agent a gain gIt,t \u2208 [0,1]. The agent only observes the gain of arm It, and not that of any other arms. The goal of this agent is to maximize its total gain \nbound to achieve e-differential privacy in oblivious adversarial \nbandits from O(T2/3/e) to O(\u221aT lnT/e). This is achieved \n by combining a Laplace Mechanism with EXP3. We show that \nthough EXP3 is already differentially private, it leaks a linear \namount of information in T . However, we can improve this \nprivacy by relying on its intrinsic exponential mechanism for \n\u221a \n selecting actions. This allows us to reach O( \na regret of O(T2/3) that holds against an adaptive adversary, an improvement from the best known of O(T3/4). This is done by using an algorithm that run EXP3 in a mini-batch loop. Finally, we run experiments that clearly demonstrate the validity of our theoretical analysis.", "venue": "AAAI", "authors": ["Aristide C. Y. Tossou", "Christos  Dimitrakakis"], "year": 2017, "n_citations": 34}
{"id": 817647, "s2_id": "dcc7d779629ad900d10a2f46d3f13e54e43fda93", "title": "AutoMOS: Learning a non-intrusive assessor of naturalness-of-speech", "abstract": "Developers of text-to-speech synthesizers (TTS) often make use of human raters to assess the quality of synthesized speech. We demonstrate that we can model human raters' mean opinion scores (MOS) of synthesized speech using a deep recurrent neural network whose inputs consist solely of a raw waveform. Our best models provide utterance-level estimates of MOS only moderately inferior to sampled human ratings, as shown by Pearson and Spearman correlations. When multiple utterances are scored and averaged, a scenario common in synthesizer quality assessment, AutoMOS achieves correlations approaching those of human raters. The AutoMOS model has a number of applications, such as the ability to explore the parameter space of a speech synthesizer without requiring a human-in-the-loop.", "venue": "ArXiv", "authors": ["Brian  Patton", "Yannis  Agiomyrgiannakis", "Michael  Terry", "Kevin W. Wilson", "Rif A. Saurous", "D.  Sculley"], "year": 2016, "n_citations": 25}
{"id": 836147, "s2_id": "96af77c627fabcec662622a634dea07d8e82d4f2", "title": "A Machine Learning-based Recommendation System for Swaptions Strategies", "abstract": "Derivative traders are usually required to scan through hundreds, even thousands of possible trades on a daily basis. Up to now, not a single solution is available to aid in their job. Hence, this work aims to develop a trading recommendation system, and apply this system to the so-called Mid-Curve Calendar Spread (MCCS), an exotic swaption-based derivatives package. In summary, our trading recommendation system follows this pipeline: (i) on a certain trade date, we compute metrics and sensitivities related to an MCCS; (ii) these metrics are feed in a model that can predict its expected return for a given holding period; and after repeating (i) and (ii) for all trades we (iii) rank the trades using some dominance criteria. To suggest that such approach is feasible, we used a list of 35 different types of MCCS; a total of 11 predictive models; and 4 benchmark models. Our results suggest that in general linear regression with lasso regularisation compared favourably to other approaches from a predictive and interpretability perspective.", "venue": "ArXiv", "authors": ["Adriano Soares Koshiyama", "Nick  Firoozye", "Philip C. Treleaven"], "year": 2018, "n_citations": 1}
{"id": 841966, "s2_id": "34f883f31a6132e44775791e0919fba9abe9efbd", "title": "Invisible Perturbations: Physical Adversarial Examples Exploiting the Rolling Shutter Effect", "abstract": "Physical adversarial examples for camera-based computer vision have so far been achieved through visible artifacts \u2014 a sticker on a Stop sign, colorful borders around eyeglasses or a 3D printed object with a colorful texture. An implicit assumption here is that the perturbations must be visible so that a camera can sense them. By contrast, we contribute a procedure to generate, for the first time, physical adversarial examples that are invisible to human eyes. Rather than modifying the victim object with visible artifacts, we modify light that illuminates the object. We demonstrate how an attacker can craft a modulated light signal that adversarially illuminates a scene and causes targeted misclassifications on a state-of-the-art ImageNet deep learning model. Concretely, we exploit the radiometric rolling shutter effect in commodity cameras to create precise striping patterns that appear on images. To human eyes, it appears like the object is illuminated, but the camera creates an image with stripes that will cause ML models to output the attacker-desired classification. We conduct a range of simulation and physical experiments with LEDs, demonstrating targeted attack rates up to 84%.", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Athena  Sayles", "Ashish  Hooda", "Mohit  Gupta", "Rahul  Chatterjee", "Earlence  Fernandes"], "year": 2021, "n_citations": 5}
{"id": 842755, "s2_id": "23cf10b58fbafa5c6ff246a929f830aa0c44d819", "title": "Unsupervised Learning of Particle Image Velocimetry", "abstract": "Particle Image Velocimetry (PIV) is a classical flow estimation problem which is widely considered and utilised, especially as a diagnostic tool in experimental fluid dynamics and the remote sensing of environmental flows. Recently, the development of deep learning based methods has inspired new approaches to tackle the PIV problem. These supervised learning based methods are driven by large volumes of data with ground truth training information. However, it is difficult to collect reliable ground truth data in large-scale, real-world scenarios. Although synthetic datasets can be used as alternatives, the gap between the training set-ups and real-world scenarios limits applicability. We present here what we believe to be the first work which takes an unsupervised learning based approach to tackle PIV problems. The proposed approach is inspired by classic optical flow methods. Instead of using ground truth data, we make use of photometric loss between two consecutive image frames, consistency loss in bidirectional flow estimates and spatial smoothness loss to construct the total unsupervised loss function. The approach shows significant potential and advantages for fluid flow estimation. Results presented here demonstrate that our method outputs competitive results compared with classical PIV methods as well as supervised learning based methods for a broad PIV dataset, and even outperforms these existing approaches in some difficult flow cases. Codes and trained models are available at this https URL.", "venue": "ISC Workshops", "authors": ["Mingrui  Zhang", "Matthew D. Piggott"], "year": 2020, "n_citations": 4}
{"id": 845142, "s2_id": "59af66507b94bf53105d4103d88ed969a391af1e", "title": "Learning stochastic decision trees", "abstract": "We give a quasipolynomial-time algorithm for learning stochastic decision trees that is optimally resilient to adversarial noise. Given an \u03b7-corrupted set of uniform random samples labeled by a size-s stochastic decision tree, our algorithm runs in time nO(log(s/\u03b5)/\u03b5 2) and returns a hypothesis with error within an additive 2\u03b7 +\u03b5 of the Bayes optimal. An additive 2\u03b7 is the information-theoretic minimum. Previously no non-trivial algorithm with a guarantee of O(\u03b7) + \u03b5 was known, even for weaker noise models. Our algorithm is furthermore proper, returning a hypothesis that is itself a decision tree; previously no such algorithm was known even in the noiseless setting. 2012 ACM Subject Classification Theory of computation \u2192 Boolean function learning", "venue": "ICALP", "authors": ["Guy  Blanc", "Jane  Lange", "Li-Yang  Tan"], "year": 2021, "n_citations": 0}
{"id": 847379, "s2_id": "ffb44f449c5efd617ba81293da0e230f4a770d65", "title": "Secure multi-party linear regression at plaintext speed", "abstract": "We detail distributed algorithms for scalable, secure multiparty linear regression and feature selection at essentially the same speed as plaintext regression. While the core geometric ideas are simple, the recognition of their broad utility when combined is novel. Our scheme opens the door to efficient and secure genome-wide association studies across multiple biobanks.", "venue": "ArXiv", "authors": ["Jonathan M. Bloom"], "year": 2019, "n_citations": 4}
{"id": 849212, "s2_id": "cd8a2bee8510e05691e8e83532739dca2229d99b", "title": "Developing a novel fair-loan-predictor through a multi-sensitive debiasing pipeline: DualFair", "abstract": "Machine learning (ML) models are increasingly used for high-stake applications that can greatly impact people\u2019s lives. Despite their use, thesemodels have the potential to be biased towards certain social groups on the basis of race, gender, or ethnicity. Many prior works have attempted to mitigate this \u201cmodel discrimination\u201d by updating the training data (pre-processing), altering the model learning process (inprocessing), or manipulating model output (post-processing). However, these works have not yet been extended to the realm of multi-sensitive parameters and sensitive options (MSPSO), where sensitive parameters are attributes that can be discriminated against (e.g race) and sensitive options are options within sensitive parameters (e.g black or white), thus giving them limited real-world usability. Prior work in fairness has also suffered from an accuracy-fairness tradeoff that prevents both the accuracy and fairness from being high. Moreover, previous literature has failed to provide holistic fairness metrics that work with MSPSO. In this paper, we solve all three of these problems by (a) creating a novel bias mitigation technique called DualFair and (b) developing a new fairness metric (i.e. AWI) that can handle MSPSO. Lastly, we test our novel mitigation method using a comprehensive U.S mortgage lending dataset and show that our classifier, or fair loan predictor, obtains better fairness and accuracy metrics than current state-of-the-art models. CCS Concepts: \u2022 Algorithmic fairness \u2192 Credit lending; \u2022 Bias-Mitigation\u2192 DualFair Pipeline.", "venue": "ArXiv", "authors": ["Arashdeep  Singh", "Jashandeep  Singh", "Ariba  Khan", "Amar  Gupta"], "year": 2021, "n_citations": 0}
{"id": 881953, "s2_id": "c29b0bc79ec0664d0f6643d9ccc98e49c1ddcebe", "title": "Autonomous Navigation in Dynamic Environments: Deep Learning-Based Approach", "abstract": "Mobile robotics is a research area that has witnessed incredible advances for the last decades. Robot navigation is an essential task for mobile robots. Many methods are proposed for allowing robots to navigate within different environments. This thesis studies different deep learningbased approaches, highlighting the advantages and disadvantages of each scheme. In fact, these approaches are promising that some of them can navigate the robot in unknown and dynamic environments. In this thesis, one of the deep learning methods based on convolutional neural network (CNN) is realized by software implementations. There are different preparation studies to complete this thesis such as introduction to Linux, robot operating system (ROS), C++, python, and GAZEBO simulator. Within this work, we modified the drone network (namely, DroNet) approach to be used in an indoor environment by using a ground robot in different cases. Indeed, the DroNet approach suffers from the absence of goal-oriented motion. Therefore, this thesis mainly focuses on tackling this problem via mapping using simultaneous localization and mapping (SLAM) and path planning techniques using Dijkstra. Afterward, the combination between the DroNet ground robot-based, mapping, and path planning leads to a goal-oriented motion, following the shortest path while avoiding the dynamic obstacle. Finally, we propose a low-cost approach, for indoor applications such as restaurants, museums, etc, on the base of using a monocular camera instead of a laser scanner.", "venue": "ArXiv", "authors": ["Omar  Mohamed", "Zeyad  Mohsen", "Mohamed  Wageeh", "Mohamed  Hegazy"], "year": 2021, "n_citations": 0}
{"id": 895650, "s2_id": "5b9f9a7aace48e8e8b2703f7d8a0739f04f5ea84", "title": "Towards Equity and Algorithmic Fairness in Student Grade Prediction", "abstract": "Equity of educational outcome and fairness of AI with respect to race have been topics of increasing importance in education. In this work, we address both with empirical evaluations of grade prediction in higher education, an important task to improve curriculum design, plan interventions for academic support, and offer course guidance to students. With fairness as the aim, we trial several strategies for both label and instance balancing to attempt to minimize differences in algorithm performance with respect to race. We find that an adversarial learning approach, combined with grade label balancing, achieved by far the fairest results. With equity of educational outcome as the aim, we trial strategies for boosting predictive performance on historically underserved groups and find success in sampling those groups in inverse proportion to their historic outcomes. With AI-infused technology supports increasingly prevalent on campuses, our methodologies fill a need for frameworks to consider performance trade-offs with respect to sensitive student attributes and allow institutions to instrument their AI resources in ways that are attentive to equity and fairness.", "venue": "AIES", "authors": ["Weijie  Jiang", "Zachary A. Pardos"], "year": 2021, "n_citations": 1}
{"id": 901817, "s2_id": "e0364be4a77dbdef1afc193e6aef7047d815f0ca", "title": "Deep learning research landscape & roadmap in a nutshell: past, present and future - Towards deep cortical learning", "abstract": "The past, present and future of deep learning is presented in this work. Given this landscape & roadmap, we predict that deep cortical learning will be the convergence of deep learning & cortical learning which builds an artificial cortical column ultimately.", "venue": "ArXiv", "authors": ["Aras R. Dargazany"], "year": 2019, "n_citations": 0}
{"id": 914915, "s2_id": "e71cd818b64ad5db39010969603a107b794fdcff", "title": "On Deep Set Learning and the Choice of Aggregations", "abstract": "Recently, it has been shown that many functions on sets can be represented by sum decompositions. These decompositons easily lend themselves to neural approximations, extending the applicability of neural nets to set-valued inputs---Deep Set learning. This work investigates a core component of Deep Set architecture: aggregation functions. We suggest and examine alternatives to commonly used aggregation functions, including learnable recurrent aggregation functions. Empirically, we show that the Deep Set networks are highly sensitive to the choice of aggregation functions: beyond improved performance, we find that learnable aggregations lower hyper-parameter sensitivity and generalize better to out-of-distribution input size.", "venue": "ICANN", "authors": ["Maximilian  S\u00f6lch", "Adnan  Akhundov", "Patrick van der Smagt", "Justin  Bayer"], "year": 2019, "n_citations": 4}
{"id": 917672, "s2_id": "02e0a9cbfc536869bb97326c38f6ba13266326e6", "title": "Model retraining and information sharing in a supply chain with long-term fluctuating demands", "abstract": "Demand forecasting based on empirical data is a viable approach for optimizing a supply chain. However, in this approach, a model constructed from past data occasionally becomes outdated due to long-term changes in the environment, in which case the model should be updated (i.e., retrained) using the latest data. In this study, we examine the effects of updating models in a supply chain using a minimal setting. We demonstrate that when each party in the supply chain has its own forecasting model, uncoordinated model retraining causes the bullwhip effect even if a very simple replenishment policy is applied. Our results also indicate that sharing the forecasting model among the parties involved significantly reduces the bullwhip effect.", "venue": "Scientific reports", "authors": ["Takahiro  Ezaki", "Naoto  Imura", "Katsuhiro  Nishinari"], "year": 2021, "n_citations": 1}
{"id": 934566, "s2_id": "e379f7c85441df5d8ddc1565cabf4b4290c22f1f", "title": "SSP: Semantic Space Projection for Knowledge Graph Embedding with Text Descriptions", "abstract": "Knowledge representation is an important, long-history topic in AI, and there have been a large amount of work for knowledge graph embedding which projects symbolic entities and relations into low-dimensional, real-valued vector space. However, most embedding methods merely concentrate on data fitting and ignore the explicit semantic expression, leading to uninterpretable representations. Thus, traditional embedding methods have limited potentials for many applications such as question answering, and entity classification. To this end, this paper proposes a semantic representation method for knowledge graph \\textbf{(KSR)}, which imposes a two-level hierarchical generative process that globally extracts many aspects and then locally assigns a specific category in each aspect for every triple. Since both aspects and categories are semantics-relevant, the collection of categories in each aspect is treated as the semantic representation of this triple. Extensive experiments justify our model outperforms other state-of-the-art baselines substantially.", "venue": "AAAI", "authors": ["Han  Xiao", "Minlie  Huang", "Lian  Meng", "Xiaoyan  Zhu"], "year": 2017, "n_citations": 133}
{"id": 938187, "s2_id": "e7374dc71b795789112fdea963aafba8233c7b2a", "title": "MLR (Memory, Learning and Recognition): A General Cognitive Model - applied to Intelligent Robots and Systems Control", "abstract": "This paper introduces a new perspective of intelligent robots and systems control. The presented and proposed cognitive model: Memory, Learning and Recognition (MLR), is an effort to bridge the gap between Robotics, AI, Cognitive Science, and Neuroscience. The currently existing gap prevents us from integrating the current advancement and achievements of these four research fields which are actively trying to define intelligence in either application-based way or in generic way. This cognitive model defines intelligence more specifically, parametrically and detailed. The proposed MLR model helps us create a general control model for robots and systems independent of their application domains and platforms since it is mainly based on the dataset provided for robots and systems controls. This paper is mainly proposing and introducing this concept and trying to prove this concept in a small scale, firstly through experimentation. The proposed concept is also applicable to other different platforms in real-time as well as in simulation.", "venue": "ArXiv", "authors": ["Aras R. Dargazany"], "year": 2019, "n_citations": 0}
{"id": 940461, "s2_id": "6b11b013364aa9429b0456ecf76911d08e06c664", "title": "Rapid Robust Principal Component Analysis: CUR Accelerated Inexact Low Rank Estimation", "abstract": "Robust principal component analysis (RPCA) is a widely used tool for dimension reduction. In this work, we propose a novel non-convex algorithm, coined Iterated Robust CUR (IRCUR), for solving RPCA problems, which dramatically improves the computational efficiency in comparison with the existing algorithms. IRCUR achieves this acceleration by employing CUR decomposition when updating the low rank component, which allows us to obtain an accurate low rank approximation via only three small submatrices. Consequently, IRCUR is able to process only the small submatrices and avoid the expensive computing on full matrix through the entire algorithm. Numerical experiments establish the computational advantage of IRCUR over the state-of-art algorithms on both synthetic and real-world datasets.", "venue": "IEEE Signal Processing Letters", "authors": ["HanQin  Cai", "Keaton  Hamm", "Longxiu  Huang", "Jiaqi  Li", "Tao  Wang"], "year": 2021, "n_citations": 8}
{"id": 941865, "s2_id": "b82af699979d56de7190a7639802089076a7cd9f", "title": "Correlated Feature Selection with Extended Exclusive Group Lasso", "abstract": "In many high dimensional classification or regression problems set in a biological context, the complete identification of the set of informative features is often as important as predictive accuracy, since this can provide mechanistic insight and conceptual understanding. Lasso and related algorithms have been widely used since their sparse solutions naturally identify a set of informative features. However, Lasso performs erratically when features are correlated. This limits the use of such algorithms in biological problems, where features such as genes often work together in pathways, leading to sets of highly correlated features. In this paper, we examine the performance of a Lasso derivative, the exclusive group Lasso, in this setting. We propose fast algorithms to solve the exclusive group Lasso, and introduce a solution to the case when the underlying group structure is unknown. The solution combines stability selection with random group allocation and introduction of artificial features. Experiments with both synthetic and real-world data highlight the advantages of this proposed methodology over Lasso in comprehensive selection of informative features.", "venue": "ArXiv", "authors": ["Yuxin  Sun", "Benny  Chain", "Samuel  Kaski", "John  Shawe-Taylor"], "year": 2020, "n_citations": 3}
{"id": 975365, "s2_id": "3fe97c4bec362afb198b9ec6262cdd6f36739f23", "title": "LUVLi Face Alignment: Estimating Landmarks\u2019 Location, Uncertainty, and Visibility Likelihood", "abstract": "Modern face alignment methods have become quite accurate at predicting the locations of facial landmarks, but they do not typically estimate the uncertainty of their predicted locations nor predict whether landmarks are visible. In this paper, we present a novel framework for jointly predicting landmark locations, associated uncertainties of these predicted locations, and landmark visibilities. We model these as mixed random variables and estimate them using a deep network trained using our proposed Location, Uncertainty, and Visibility Likelihood (LUVLi) loss. In addition, we release an entirely new labeling of a large face alignment dataset with over 19,000 face images in a full range of head poses. Each face is manually labeled with the ground-truth locations of 68 landmarks, with the additional information of whether each landmarks is visible, self-occluded (due to extreme head poses), or externally occluded. Not only does our joint estimation yield accurate estimates of the uncertainty of predicted landmark locations, but it also yields state-of-the-art estimates for the landmark locations themselves on mulitple standard face alignment datasets. Our method's estimates of the uncertainty of predicted landmark locations could be used to automatically identify input images on which face alignment fails, which can be critical for downstream tasks.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Abhinav  Kumar", "Tim K. Marks", "Wenxuan  Mou", "Ye  Wang", "Michael  Jones", "Anoop  Cherian", "Toshiaki  Koike-Akino", "Xiaoming  Liu", "Chen  Feng"], "year": 2020, "n_citations": 37}
{"id": 983761, "s2_id": "36bc38e726f5fb0878539187c5a1669f66843fc7", "title": "Comprehensive SNN Compression Using ADMM Optimization and Activity Regularization", "abstract": "As well known, the huge memory and compute costs of both artificial neural networks (ANNs) and spiking neural networks (SNNs) greatly hinder their deployment on edge devices with high efficiency. Model compression has been proposed as a promising technique to improve the running efficiency via parameter and operation reduction, whereas this technique is mainly practiced in ANNs rather than SNNs. It is interesting to answer how much an SNN model can be compressed without compromising its functionality, where two challenges should be addressed: 1) the accuracy of SNNs is usually sensitive to model compression, which requires an accurate compression methodology and 2) the computation of SNNs is event-driven rather than static, which produces an extra compression dimension on dynamic spikes. To this end, we realize a comprehensive SNN compression through three steps. First, we formulate the connection pruning and weight quantization as a constrained optimization problem. Second, we combine spatiotemporal backpropagation (STBP) and alternating direction method of multipliers (ADMMs) to solve the problem with minimum accuracy loss. Third, we further propose activity regularization to reduce the spike events for fewer active operations. These methods can be applied in either a single way for moderate compression or a joint way for aggressive compression. We define several quantitative metrics to evaluate the compression performance for SNNs. Our methodology is validated in pattern recognition tasks over MNIST, N-MNIST, CIFAR10, and CIFAR100 datasets, where extensive comparisons, analyses, and insights are provided. To the best of our knowledge, this is the first work that studies SNN compression in a comprehensive manner by exploiting all compressible components and achieves better results.", "venue": "IEEE transactions on neural networks and learning systems", "authors": ["Lei  Deng", "Yujie  Wu", "Yifan  Hu", "Ling  Liang", "Guoqi  Li", "Xing  Hu", "Yufei  Ding", "Peng  Li", "Yuan  Xie"], "year": 2021, "n_citations": 8}
{"id": 985861, "s2_id": "e5a0345c0ddf37e9e5da91153dbc09fd148a4272", "title": "LAGC: Lazily Aggregated Gradient Coding for Straggler-Tolerant and Communication-Efficient Distributed Learning", "abstract": "Gradient-based distributed learning in parameter server (PS) computing architectures is subject to random delays due to straggling worker nodes and to possible communication bottlenecks between PS and workers. Solutions have been recently proposed to separately address these impairments based on the ideas of gradient coding (GC), worker grouping, and adaptive worker selection. This article provides a unified analysis of these techniques in terms of wall-clock time, communication, and computation complexity measures. Furthermore, in order to combine the benefits of GC and grouping in terms of robustness to stragglers with the communication and computation load gains of adaptive selection, novel strategies, named lazily aggregated GC (LAGC) and grouped-LAG (G-LAG), are introduced. Analysis and results show that G-LAG provides the best wall-clock time and communication performance while maintaining a low computational cost, for two representative distributions of the computing times of the worker nodes.", "venue": "IEEE Transactions on Neural Networks and Learning Systems", "authors": ["Jingjing  Zhang", "Osvaldo  Simeone"], "year": 2021, "n_citations": 8}
{"id": 988361, "s2_id": "c5908ddac6a5c5b5a41a246d92eb807dc60012d6", "title": "Subsampling bias and the best-discrepancy systematic cross validation", "abstract": "Statistical machine learning models should be evaluated and validated before putting to work. Conventional k -fold Monte Carlo cross-validation (MCCV) procedure uses a pseudo-random sequence to partition instances into k subsets, which usually causes subsampling bias, inflates generalization errors and jeopardizes the reliability and effectiveness of cross-validation. Based on ordered systematic sampling theory in statistics and low-discrepancy sequence theory in number theory, we propose a new k -fold cross-validation procedure by replacing a pseudo-random sequence with a best-discrepancy sequence, which ensures low subsampling bias and leads to more precise expected-prediction-error (EPE) estimates. Experiments with 156 benchmark datasets and three classifiers (logistic regression, decision tree and naive bayes) show that in general, our cross-validation procedure can extrude subsampling bias in the MCCV by lowering the EPE around 7.18% and the variances around 26.73%. In comparison, the stratified MCCV can reduce the EPE and variances of the MCCV around 1.58% and 11.85%, respectively. The leave-one-out (LOO) can lower the EPE around 2.50% but its variances are much higher than the any other cross-validation (CV) procedure. The computational time of our cross-validation procedure is just 8.64% of the MCCV, 8.67% of the stratified MCCV and 16.72% of the LOO. Experiments also show that our approach is more beneficial for datasets characterized by relatively small size and large aspect ratio. This makes our approach particularly pertinent when solving bioscience classification problems. Our proposed systematic subsampling technique could be generalized to other machine learning algorithms that involve random subsampling mechanism.", "venue": "ArXiv", "authors": ["Liang  Guo", "Jianya  Liu", "Ruodan  Lu"], "year": 2019, "n_citations": 1}
{"id": 990557, "s2_id": "d0a8a79fffd35308ac4dd840fa9bcd1c5b123fc6", "title": "Temporal Collaborative Ranking Via Personalized Transformer", "abstract": "The collaborative ranking problem has been an important open research question as most recommendation problems can be naturally formulated as ranking problems. While much of collaborative ranking methodology assumes static ranking data, the importance of temporal information to improving ranking performance is increasingly apparent. Recent advances in deep learning, especially the discovery of various attention mechanisms and newer architectures in addition to widely used RNN and CNN in natural language processing, have allowed us to make better use of the temporal ordering of items that each user has engaged with. In particular, the SASRec model, inspired by the popular Transformer model in natural languages processing, has achieved state-of-art results in the temporal collaborative ranking problem and enjoyed more than 10x speed-up when compared to earlier CNN/RNN-based methods. However, SASRec is inherently an un-personalized model and does not include personalized user embeddings. To overcome this limitation, we propose a Personalized Transformer (SSE-PT) model, outperforming SASRec by almost 5% in terms of NDCG@10 on 5 real-world datasets. Furthermore, after examining some random users' engagement history and corresponding attention heat maps used during the inference stage, we find our model is not only more interpretable but also able to focus on recent engagement patterns for each user. Moreover, our SSE-PT model with a slight modification, which we call SSE-PT++, can handle extremely long sequences and outperform SASRec in ranking results with comparable training speed, striking a balance between performance and speed requirements. Code and data are open sourced at this https URL.", "venue": "ArXiv", "authors": ["Liwei  Wu", "Shuqing  Li", "Cho-Jui  Hsieh", "James  Sharpnack"], "year": 2019, "n_citations": 3}
{"id": 994665, "s2_id": "e3ea7015f69118d3ee9c2730f91dbdef1297f9de", "title": "Skillful Twelve Hour Precipitation Forecasts using Large Context Neural Networks", "abstract": "The problem of forecasting weather has been scientifically studied for centuries due to its high impact on human lives, transportation, food production and energy management, among others. Current operational forecasting models are based on physics and use supercomputers to simulate the atmosphere to make forecasts hours and days in advance. Better physics-based forecasts require improvements in the models themselves, which can be a substantial scientific challenge, as well as improvements in the underlying resolution, which can be computationally prohibitive. An emerging class of weather models based on neural networks represents a paradigm shift in weather forecasting: the models learn the required transformations from data instead of relying on hand-coded physics and are computationally efficient. For neural models, however, each additional hour of lead time poses a substantial challenge as it requires capturing ever larger spatial contexts and increases the uncertainty of the prediction [9]. In this work, we present a neural network that is capable of large-scale precipitation forecasting up to twelve hours ahead and, starting from the same atmospheric state, the model achieves greater skill than the state-of-the-art physics-based models HRRR and HREF that currently operate in the Continental United States. Interpretability analyses reinforce the observation that the model learns to emulate advanced physics principles. These results represent a substantial step towards establishing a new paradigm of efficient forecasting with neural networks.", "venue": "ArXiv", "authors": ["Lasse  Espeholt", "Shreya  Agrawal", "Casper  Sonderby", "Manoj  Kumar", "Jonathan  Heek", "Carla  Bromberg", "Cenk  Gazen", "Jason  Hickey", "Aaron  Bell", "Nal  Kalchbrenner"], "year": 2021, "n_citations": 1}
{"id": 1001679, "s2_id": "ecf00e7a9fa3193aa6f98b0f1dbd8343e29b4553", "title": "Accurate Streaming Support Vector Machines", "abstract": "A widely-used tool for binary classification is the Support Vector Machine (SVM), a supervised learning technique that finds the \"maximum margin\" linear separator between the two classes. While SVMs have been well studied in the batch (offline) setting, there is considerably less work on the streaming (online) setting, which requires only a single pass over the data using sub-linear space. Existing streaming algorithms are not yet competitive with the batch implementation. In this paper, we use the formulation of the SVM as a minimum enclosing ball (MEB) problem to provide a streaming SVM algorithm based off of the blurred ball cover originally proposed by Agarwal and Sharathkumar. Our implementation consistently outperforms existing streaming SVM approaches and provides higher accuracies than libSVM on several datasets, thus making it competitive with the standard SVM batch implementation.", "venue": "ArXiv", "authors": ["Vikram  Nathan", "Sharath  Raghvendra"], "year": 2014, "n_citations": 2}
{"id": 1008875, "s2_id": "07c3dc399583caba107616122dd1347b004fa418", "title": "Sequence Modeling using Gated Recurrent Neural Networks", "abstract": "In this paper, we have used Recurrent Neural Networks to capture and model human motion data and generate motions by prediction of the next immediate data point at each time-step. Our RNN is armed with recently proposed Gated Recurrent Units which has shown promising results in some sequence modeling problems such as Machine Translation and Speech Synthesis. We demonstrate that this model is able to capture long-term dependencies in data and generate realistic motions.", "venue": "ArXiv", "authors": ["Mohammad  Pezeshki"], "year": 2015, "n_citations": 7}
{"id": 1012010, "s2_id": "7a1856f8f26ebdf6418f56c6cbf5c05e1e363d47", "title": "Sleep apnea and respiratory anomaly detection from a wearable band and oxygen saturation", "abstract": "Sleep-related respiratory abnormalities are typically detected using polysomnography. There is a need in general medicine and critical care for a more convenient method to detect sleep apnea automatically from a simple, easy-to-wear device. The objective was to detect abnormal respiration and estimate the Apnea\u2013Hypopnea Index (AHI) automatically with a wearable respiratory device with and without SpO2 signals using a large (n\u2009=\u2009412) dataset serving as ground truth. Simultaneously recorded polysomnography (PSG) and wearable respiratory effort data were used to train and evaluate models in a cross-validation fashion. Time domain and complexity features were extracted, important features were identified, and a random forest model was employed to detect events and predict AHI. Four models were trained: one each using the respiratory features only, a feature from the SpO2 (%)-signal only, and two additional models that use the respiratory features and the SpO2 (%) feature, one allowing a time lag of 30 s between the two signals. Event-based classification resulted in areas under the receiver operating characteristic curves of 0.94, 0.86, and 0.82, and areas under the precision-recall curves of 0.48, 0.32, and 0.51 for the models using respiration and SpO2, respiration-only, and SpO2-only, respectively. Correlation between expert-labelled and predicted AHI was 0.96, 0.78, and 0.93, respectively. A wearable respiratory effort signal with or without SpO2 signal predicted AHI accurately, and best performance was achieved with using both signals.", "venue": "Sleep and Breathing", "authors": ["Wolfgang  Ganglberger", "Abigail A. Bucklin", "Ryan A. Tesh", "Madalena  Da Silva Cardoso", "Haoqi  Sun", "Michael J. Leone", "Luis  Paixao", "Ezhil  Panneerselvam", "Elissa M. Ye", "B. Taylor Thompson", "Oluwaseun  Akeju", "David  Kuller", "Robert J. Thomas", "M. Brandon Westover"], "year": 2021, "n_citations": 0}
{"id": 1013394, "s2_id": "f710fd478699af8aba28b14648923d28f0e9d31e", "title": "Breaking Type-Safety in Go: An Empirical Study on the Usage of the unsafe Package", "abstract": "A decade after its first release, the Go programming language has become a major programming language in the development landscape. While praised for its clean syntax and C-like performance, Go also contains a strong static type-system that prevents arbitrary type casting and arbitrary memory access, making the language type-safe by design. However, to give developers the possibility of implementing low-level code, Go ships with a special package called unsafe that offers developers a way around the type-safety of Go programs. The package gives greater flexibility to developers but comes at a higher risk of runtime errors, chances of non-portability, and the loss of compatibility guarantees for future versions of Go. \nIn this paper, we present the first large-scale study on the usage of the unsafe package in 2,438 popular Go projects. Our investigation shows that unsafe is used in 24% of Go projects, motivated primarily by communicating with operating systems and C code, but is also commonly used as a source of performance optimization. Developers are willing to use unsafe to break language specifications (e.g., string immutability) for better performance and 6% of analyzed projects that use unsafe perform risky pointer conversions that can lead to program crashes and unexpected behavior. Furthermore, we report a series of real issues faced by projects that use unsafe, from crashing errors and non-deterministic behavior to having their deployment restricted from certain popular environments. Our findings can be used to understand how and why developers break type-safety in Go, and help motivate further tools and language development that could make the usage of unsafe in Go even safer.", "venue": "IEEE Transactions on Software Engineering", "authors": ["Diego Elias Costa", "Suhaib  Mujahid", "Rabe  Abdalkareem", "Emad  Shihab"], "year": 2021, "n_citations": 1}
{"id": 1018690, "s2_id": "ce33455faff33dffdd6d034ff915a5fa94b702f8", "title": "The Ridgelet Prior: A Covariance Function Approach to Prior Specification for Bayesian Neural Networks", "abstract": "Bayesian neural networks attempt to combine the strong predictive performance of neural networks with formal quantification of uncertainty associated with the predictive output in the Bayesian framework. However, it remains unclear how to endow the parameters of the network with a prior distribution that is meaningful when lifted into the output space of the network. A possible solution is proposed that enables the user to posit an appropriate covariance function for the task at hand. Our approach constructs a prior distribution for the parameters of the network, called a ridgelet prior, that approximates the posited covariance structure in the output space of the network. The approach is rooted in the ridgelet transform and we establish both finite-sample-size error bounds and the consistency of the approximation of the covariance function in a limit where the number of hidden units is increased. Our experimental assessment is limited to a proof-of-concept, where we demonstrate that the ridgelet prior can out-perform an unstructured prior on regression problems for which an informative covariance function can be a priori provided.", "venue": "ArXiv", "authors": ["Takuo  Matsubara", "Chris J. Oates", "Franccois-Xavier  Briol"], "year": 2020, "n_citations": 4}
{"id": 1021101, "s2_id": "1fe1fb612c252d172723ffab029f6ab5d0bac6b2", "title": "Sparsely Activated Networks: A new method for decomposing and compressing data", "abstract": "Recent literature on unsupervised learning focused on designing structural priors with the aim of learning meaningful features, but without considering the description length of the representations. In this thesis, first we introduce the{\\phi}metric that evaluates unsupervised models based on their reconstruction accuracy and the degree of compression of their internal representations. We then present and define two activation functions (Identity, ReLU) as base of reference and three sparse activation functions (top-k absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize the previously defined metric $\\varphi$. We lastly present Sparsely Activated Networks (SANs) that consist of kernels with shared weights that, during encoding, are convolved with the input and then passed through a sparse activation function. During decoding, the same weights are convolved with the sparse activation map and subsequently the partial reconstructions from each weight are summed to reconstruct the input. We compare SANs using the five previously defined activation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST, FMNIST) and show that models that are selected using $\\varphi$ have small description representation length and consist of interpretable kernels.", "venue": "ArXiv", "authors": ["Paschalis  Bizopoulos"], "year": 2019, "n_citations": 0}
{"id": 1028731, "s2_id": "169d6428b54ae5fa69422df335f29365bf834d73", "title": "High-quality Thermal Gibbs Sampling with Quantum Annealing Hardware", "abstract": "Jon Nelson, Marc Vuffray, Andrey Y. Lokhov, Tameem Albash, 4 and Carleton Coffrin Advanced Network Science Initiative, Los Alamos National Laboratory, Los Alamos, NM, USA Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM, USA Department of Electrical and Computer Engineering, University of New Mexico, Albuquerque, NM, USA Department of Physics and Astronomy and Center for Quantum Information and Control, University of New Mexico, Albuquerque, NM, USA", "venue": "ArXiv", "authors": ["Jon  Nelson", "Marc  Vuffray", "Andrey Y. Lokhov", "Tameem  Albash", "Carleton  Coffrin"], "year": 2021, "n_citations": 1}
{"id": 1029389, "s2_id": "dde7173b4f2c5e8b33581cbea5192cd5bd0dff08", "title": "Simplex-Structured Matrix Factorization: Sparsity-based Identifiability and Provably Correct Algorithms", "abstract": "In this paper, we provide novel algorithms with identifiability guarantees for simplex-structured matrix factorization (SSMF), a generalization of nonnegative matrix factorization. Current state-of-the-art algorithms that provide identifiability results for SSMF rely on the sufficiently scattered condition (SSC) which requires the data points to be well spread within the convex hull of the basis vectors. The conditions under which our proposed algorithms recover the unique decomposition is in most cases much weaker than the SSC. We only require to have $d$ points on each facet of the convex hull of the basis vectors whose dimension is $d-1$. The key idea is based on extracting facets containing the largest number of points. We illustrate the effectiveness of our approach on synthetic data sets and hyperspectral images, showing that it outperforms state-of-the-art SSMF algorithms as it is able to handle higher noise levels, rank deficient matrices, outliers, and input data that highly violates the SSC.", "venue": "SIAM J. Math. Data Sci.", "authors": ["Maryam  Abdolali", "Nicolas  Gillis"], "year": 2021, "n_citations": 6}
{"id": 1034596, "s2_id": "c1ee1fd05d582d4091857849e566afc9c06555b8", "title": "Unsupervised Neural Mask Estimator for Generalized Eigen-Value Beamforming Based Asr", "abstract": "The state-of-art methods for acoustic beamforming in multi-channel ASR are based on a neural mask estimator that predicts the presence of speech and noise. These models are trained using a paired corpus of clean and noisy recordings (teacher model). In this paper, we attempt to move away from the requirements of having supervised clean recordings for training the mask estimator. The models based on signal enhancement and beamforming using multi-channel linear prediction serve as the required mask estimate. In this way, the model training can also be carried out on real recordings of noisy speech rather than simulated ones alone done in a typical teacher model. Several experiments performed on noisy and reverberant environments in the CHiME-3 corpus as well as the REVERB challenge corpus highlight the effectiveness of the proposed approach. The ASR results for the proposed approach provide performances that are significantly better than a teacher model trained on an out-of-domain dataset and on par with the oracle mask estimators trained on the in-domain dataset.", "venue": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Rohit  Kumar", "Anirudh  Sreeram", "Anurenjan  Purushothaman", "Sriram  Ganapathy"], "year": 2020, "n_citations": 5}
{"id": 1035863, "s2_id": "3a1e8b46fbddb1a37585ca0657af521305a2cc56", "title": "Towards Optimal Strategies for Training Self-Driving Perception Models in Simulation", "abstract": "Autonomous driving relies on a huge volume of real-world data to be labeled to high precision. Alternative solutions seek to exploit driving simulators that can generate large amounts of labeled data with a plethora of content variations. However, the domain gap between the synthetic and real data remains, raising the following important question: What are the best ways to utilize a self-driving simulator for perception tasks? In this work, we build on top of recent advances in domain-adaptation theory, and from this perspective, propose ways to minimize the reality gap. We primarily focus on the use of labels in the synthetic domain alone. Our approach introduces both a principled way to learn neural-invariant representations and a theoretically inspired view on how to sample the data from the simulator. Our method is easy to implement in practice as it is agnostic of the network architecture and the choice of the simulator. We showcase our approach on the bird\u2019s-eye-view vehicle segmentation task with multi-sensor data (cameras, lidar) using an open-source simulator (CARLA), and evaluate the entire framework on a real-world dataset (nuScenes). Last but not least, we show what types of variations (e.g. weather conditions, number of assets, map design, and color diversity) matter to perception networks when trained with driving simulators, and which ones can be compensated for with our domain adaptation technique.", "venue": "ArXiv", "authors": ["David  Acuna", "Jonah  Philion", "Sanja  Fidler"], "year": 2021, "n_citations": 0}
{"id": 1045799, "s2_id": "698966657f47b507e2099f76f522926c1ed553af", "title": "Sparse Training Theory for Scalable and Efficient Agents", "abstract": "A fundamental task for artificial intelligence is learning. Deep Neural Networks have proven to cope perfectly with all learning paradigms, i.e. supervised, unsupervised, and reinforcement learning. Nevertheless, traditional deep learning approaches make use of cloud computing facilities and do not scale well to autonomous agents with low computational resources. Even in the cloud, they suffer from computational and memory limitations, and they cannot be used to model adequately large physical worlds for agents which assume networks with billions of neurons. These issues are addressed in the last few years by the emerging topic of sparse training, which trains sparse networks from scratch. This paper discusses sparse training state-of-the-art, its challenges and limitations while introducing a couple of new theoretical research directions which has the potential of alleviating sparse training limitations to push deep learning scalability well beyond its current boundaries. Nevertheless, the theoretical advancements impact in complex multi-agents settings is discussed from a real-world perspective, using the smart grid case study.", "venue": "AAMAS", "authors": ["Decebal Constantin Mocanu", "Elena  Mocanu", "Tiago  Pinto", "Selima  Curci", "Phuong H. Nguyen", "Madeleine  Gibescu", "Damien  Ernst", "Zita A. Vale"], "year": 2021, "n_citations": 4}
{"id": 1050074, "s2_id": "e22eafc782789b973bf4613eaf6f2dd9cadeb939", "title": "Using Contextual Information as Virtual Items on Top-N Recommender Systems", "abstract": "Traditionally, recommender systems for the Web deal with applications that have two dimensions, users and items. Based on access logs that relate these dimensions, a recommendation model can be built and used to identify a set of N items that will be of interest to a certain user. In this paper we propose a method to complement the information in the access logs with contextual information without changing the recommendation algorithm. The method consists in representing context as virtual items. We empirically test this method with two top-N recommender systems, an itembased collaborative filtering technique and association rules, on three data sets. The results show that our method is able to take advantage of the context (new dimensions) when it is informative.", "venue": "ArXiv", "authors": ["Marcos Aur\u00e9lio Domingues", "Al\u00edpio M\u00e1rio Jorge", "Carlos  Soares"], "year": 2011, "n_citations": 21}
{"id": 1054204, "s2_id": "ff1ef27425a0d8c9b493808e204e89f71b8e2aff", "title": "Dynamic Boltzmann Machines for Second Order Moments and Generalized Gaussian Distributions", "abstract": "Dynamic Boltzmann Machine (DyBM) has been shown highly efficient to predict time-series data. Gaussian DyBM is a DyBM that assumes the predicted data is generated by a Gaussian distribution whose first-order moment (mean) dynamically changes over time but its second-order moment (variance) is fixed. However, in many financial applications, the assumption is quite limiting in two aspects. First, even when the data follows a Gaussian distribution, its variance may change over time. Such variance is also related to important temporal economic indicators such as the market volatility. Second, financial time-series data often requires learning datasets generated by the generalized Gaussian distribution with an additional shape parameter that is important to approximate heavy-tailed distributions. Addressing those aspects, we show how to extend DyBM that results in significant performance improvement in predicting financial time-series data.", "venue": "ArXiv", "authors": ["Raymond H. Putra", "Takayuki  Osogami", "Sakyasingha  Dasgupta"], "year": 2017, "n_citations": 0}
{"id": 1054224, "s2_id": "5a1451d5cecb85b98e139c0efba90b53a90cb568", "title": "Learning Stable Manoeuvres in Quadruped Robots from Expert Demonstrations", "abstract": "With the research into development of quadruped robots picking up pace, learning based techniques are being explored for developing locomotion controllers for such robots. A key problem is to generate leg trajectories for continuously varying target linear and angular velocities, in a stable manner. In this paper, we propose a two pronged approach to address this problem. First, multiple simpler policies are trained to generate trajectories for a discrete set of target velocities and turning radius. These policies are then augmented using a higher level neural network for handling the transition between the learned trajectories. Specifically, we develop a neural network based filter that takes in target velocity, radius and transforms them into new commands that enable smooth transitions to the new trajectory. This transformation is achieved by learning from expert demonstrations. An application of this is the transformation of a novice user\u2019s input into an expert user\u2019s input, thereby ensuring stable manoeuvres regardless of the user\u2019s experience. Training our proposed architecture requires much less expert demonstrations compared to standard neural network architectures. Finally, we demonstrate experimentally these results in the in-house quadruped Stoch 2.", "venue": "2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)", "authors": ["Sashank  Tirumala", "Sagar  Gubbi", "Kartik  Paigwar", "Aditya  Sagi", "Ashish  Joglekar", "Shalabh  Bhatnagar", "Ashitava  Ghosal", "Bharadwaj  Amrutur", "Shishir  Kolathaya"], "year": 2020, "n_citations": 2}
{"id": 1060304, "s2_id": "a37873860f279bfda39add3bc0caf69e2f9ffbff", "title": "What Objective Does Self-paced Learning Indeed Optimize?", "abstract": "Self-paced learning (SPL) is a recently raised methodology designed through simulating the learning principle of humans/animals. A variety of SPL realization schemes have been designed for different computer vision and pattern recognition tasks, and empirically substantiated to be effective in these applications. However, the investigation on its theoretical insight is still a blank. To this issue, this study attempts to provide some new theoretical understanding under the SPL scheme. Specifically, we prove that the solving strategy on SPL accords with a majorization minimization algorithm implemented on a latent objective function. Furthermore, we find that the loss function contained in this latent objective has a similar configuration with non-convex regularized penalty (NSPR) known in statistics and machine learning. Such connection inspires us discovering more intrinsic relationship between SPL regimes and NSPR forms, like SCAD, LOG and EXP. The robustness insight under SPL can then be finely explained. We also analyze the capability of SPL on its easy loss prior embedding property, and provide an insightful interpretation to the effectiveness mechanism under previous SPL variations. Besides, we design a group-partial-order loss prior, which is especially useful to weakly labeled large-scale data processing tasks. Through applying SPL with this loss prior to the FCVID dataset, which is currently one of the biggest manually annotated video dataset, our method achieves state-of-the-art performance beyond previous methods, which further helps supports the proposed theoretical arguments.", "venue": "ArXiv", "authors": ["Deyu  Meng", "Qian  Zhao"], "year": 2015, "n_citations": 66}
{"id": 1061405, "s2_id": "29e297fdf25bdf033027dcda6d4fdc9c125e3850", "title": "Triplet Entropy Loss: Improving The Generalisation of Short Speech Language Identification Systems", "abstract": "We present several methods to improve the generalisation of language identification (LID) systems to new speakers and to new domains. These methods involve Spectral augmentation, where spectrograms are masked in the frequency or time bands during training and CNN architectures that are pre-trained on the Imagenet dataset. The paper also introduces the novel Triplet Entropy Loss training method, which involves training a network simultaneously using Cross Entropy and Triplet loss. It was found that all three methods improved the generalisation of the models, though not significantly. Even though the models trained using Triplet Entropy Loss showed a better understanding of the languages and higher accuracies, it appears as though the models still memorise word patterns present in the spectrograms rather than learning the finer nuances of a language. The research shows that Triplet Entropy Loss has great potential and should be investigated further, not only in language identification tasks but any classification task.", "venue": "ArXiv", "authors": ["Ruan van der Merwe"], "year": 2020, "n_citations": 3}
{"id": 1065400, "s2_id": "bd0f3a931762406fa21c4090db82a5833bab3324", "title": "Deep Stock Predictions", "abstract": "Forecasting stock prices can be interpreted as a time series prediction problem, for which Long Short Term Memory (LSTM) neural networks are often used due to their architecture specifically built to solve such problems. In this paper, we consider the design of a trading strategy that performs portfolio optimization using the LSTM stock price prediction for four different companies. We then customize the loss function used to train the LSTM to increase the profit earned. Moreover, we propose a data driven approach for optimal selection of window length and multi-step prediction length, and consider the addition of analyst calls as technical indicators to a multi-stack Bidirectional LSTM strengthened by the addition of Attention units. We find the LSTM model with the customized loss function to have an improved performance in the training bot over a regressive baseline such as ARIMA, while the addition of analyst call does improve the performance for certain datasets.", "venue": "ArXiv", "authors": ["Akash  Doshi", "Alexander  Issa", "Puneet  Sachdeva", "Sina  Rafati", "Somnath  Rakshit"], "year": 2020, "n_citations": 1}
{"id": 1067893, "s2_id": "28abe2867cd92cd1c0af667558589204472ab777", "title": "Staging Epileptogenesis with Deep Neural Networks", "abstract": "Epilepsy is a common neurological disorder characterized by recurrent seizures accompanied by excessive synchronous brain activity. The process of structural and functional brain alterations leading to increased seizure susceptibility and eventually spontaneous seizures is called epileptogenesis (EPG) and can span months or even years. Detecting and monitoring the progression of EPG could allow for targeted early interventions that could slow down disease progression or even halt its development. Here, we propose an approach for staging EPG using deep neural networks and identify potential electroencephalography (EEG) biomarkers to distinguish different phases of EPG. Specifically, continuous intracranial EEG recordings were collected from a rodent model where epilepsy is induced by electrical perforant pathway stimulation (PPS). A deep neural network (DNN) is trained to distinguish EEG signals from before stimulation (baseline), shortly after the PPS and long after the PPS but before the first spontaneous seizure (FSS). Experimental results show that our proposed method can classify EEG signals from the three phases with an average area under the curve (AUC) of 0.93, 0.89, and 0.86. To the best of our knowledge, this represents the first successful attempt to stage EPG prior to the FSS using DNNs.", "venue": "BCB", "authors": ["Diyuan  Lu", "Sebastian  Bauer", "Valentin  Neubert", "Lara Sophie Costard", "Felix  Rosenow", "Jochen  Triesch"], "year": 2020, "n_citations": 2}
{"id": 1072834, "s2_id": "1696660f0aa90803f72ee806750597162c373529", "title": "Distributionally Robust Federated Averaging", "abstract": "In this paper, we study communication efficient distributed algorithms for distributionally robust federated learning via periodic averaging with adaptive sampling. In contrast to standard empirical risk minimization, due to the minimax structure of the underlying optimization problem, a key difficulty arises from the fact that the global parameter that controls the mixture of local losses can only be updated infrequently on the global stage. To compensate for this, we propose a Distributionally Robust Federated Averaging (DRFA) algorithm that employs a novel snapshotting scheme to approximate the accumulation of history gradients of the mixing parameter. We analyze the convergence rate of DRFA in both convex-linear and nonconvex-linear settings. We also generalize the proposed idea to objectives with regularization on the mixture parameter and propose a proximal variant, dubbed as DRFA-Prox, with provable convergence rates. We also analyze an alternative optimization method for regularized case in strongly-convex-strongly-concave and non-convex (under PL condition)-strongly-concave settings. To the best of our knowledge, this paper is the first to solve distributionally robust federated learning with reduced communication, and to analyze the efficiency of local descent methods on distributed minimax problems. We give corroborating experimental evidence for our theoretical results in federated learning settings.", "venue": "NeurIPS", "authors": ["Yuyang  Deng", "Mohammad Mahdi Kamani", "Mehrdad  Mahdavi"], "year": 2020, "n_citations": 22}
{"id": 1080180, "s2_id": "cfb6adb2038a74325d7ed8e2c6385eded6bf2b90", "title": "The Utility of Decorrelating Colour Spaces in Vector Quantised Variational Autoencoders", "abstract": "Vector quantised variational autoencoders (VQ-VAE) are characterised by three main components: 1) encoding visual data, 2) assigning $k$ different vectors in the so-called embedding space, and 3) decoding the learnt features. While images are often represented in RGB colour space, the specific organisation of colours in other spaces also offer interesting features, e.g. CIE L*a*b* decorrelates chromaticity into opponent axes. In this article, we propose colour space conversion, a simple quasi-unsupervised task, to enforce a network learning structured representations. To this end, we trained several instances of VQ-VAE whose input is an image in one colour space, and its output in another, e.g. from RGB to CIE L*a*b* (in total five colour spaces were considered). We examined the finite embedding space of trained networks in order to disentangle the colour representation in VQ-VAE models. Our analysis suggests that certain vectors encode hue and others luminance information. We further evaluated the quality of reconstructed images at low-level using pixel-wise colour metrics, and at high-level by inputting them to image classification and scene segmentation networks. We conducted experiments in three benchmark datasets: ImageNet, COCO and CelebA. Our results show, with respect to the baseline network (whose input and output are RGB), colour conversion to decorrelated spaces obtains 1-2 Delta-E lower colour difference and 5-10% higher classification accuracy. We also observed that the learnt embedding space is easier to interpret in colour opponent models.", "venue": "ArXiv", "authors": ["Arash  Akbarinia", "Raquel  Gil-Rodr'iguez", "Alban  Flachot", "Matteo  Toscani"], "year": 2020, "n_citations": 0}
{"id": 1081990, "s2_id": "04d1a26c2516dc14a765112a63ec60dc3cb3de72", "title": "Tree-Structured Composition in Neural Networks without Tree-Structured Architectures", "abstract": "Tree-structured neural networks encode a particular tree geometry for a sentence in the network design. However, these models have at best only slightly outperformed simpler sequence-based models. We hypothesize that neural sequence models like LSTMs are in fact able to discover and implicitly use recursive compositional structure, at least for tasks with clear cues to that structure in the data. We demonstrate this possibility using an artificial data task for which recursive compositional structure is crucial, and find an LSTM-based sequence model can indeed learn to exploit the underlying tree structure. However, its performance consistently lags behind that of tree models, even on large training sets, suggesting that tree-structured models are more effective at exploiting recursive structure.", "venue": "CoCo@NIPS", "authors": ["Samuel R. Bowman", "Christopher D. Manning", "Christopher  Potts"], "year": 2015, "n_citations": 53}
{"id": 1089498, "s2_id": "f24611539af3f3095cd98d2a0bcd2e337a5c308a", "title": "Tractable contextual bandits beyond realizability", "abstract": "Tractable contextual bandit algorithms often rely on the realizability assumption -- i.e., that the true expected reward model belongs to a known class, such as linear functions. We investigate issues that arise in the absence of realizability and note that the dynamics of adaptive data collection can lead commonly used bandit algorithms to learn a suboptimal policy. In this work, we present a tractable bandit algorithm that is not sensitive to the realizability assumption and computationally reduces to solving a constrained regression problem in every epoch. When realizability does not hold, our algorithm ensures the same guarantees on regret achieved by realizability-based algorithms under realizability, up to an additive term that accounts for the misspecification error. This extra term is proportional to T times the (2/5)-root of the mean squared error between the best model in the class and the true model, where T is the total number of time-steps. Our work sheds light on the bias-variance trade-off for tractable contextual bandits. This trade-off is not captured by algorithms that assume realizability, since under this assumption there exists an estimator in the class that attains zero bias.", "venue": "AISTATS", "authors": ["Sanath Kumar Krishnamurthy", "Vitor  Hadad", "Susan  Athey"], "year": 2021, "n_citations": 5}
{"id": 1090610, "s2_id": "8005ff193f47ebb6df3144c7a3c30b63b2056ad7", "title": "Group Component Analysis for Multiblock Data: Common and Individual Feature Extraction", "abstract": "Real-world data are often acquired as a collection of matrices rather than as a single matrix. Such multiblock data are naturally linked and typically share some common features while at the same time exhibiting their own individual features, reflecting the underlying data generation mechanisms. To exploit the linked nature of data, we propose a new framework for common and individual feature extraction (CIFE) which identifies and separates the common and individual features from the multiblock data. Two efficient algorithms termed common orthogonal basis extraction (COBE) are proposed to extract common basis is shared by all data, independent on whether the number of common components is known beforehand. Feature extraction is then performed on the common and individual subspaces separately, by incorporating dimensionality reduction and blind source separation techniques. Comprehensive experimental results on both the synthetic and real-world data demonstrate significant advantages of the proposed CIFE method in comparison with the state-of-the-art.", "venue": "IEEE Transactions on Neural Networks and Learning Systems", "authors": ["Guoxu  Zhou", "Andrzej  Cichocki", "Yu  Zhang", "Danilo P. Mandic"], "year": 2016, "n_citations": 131}
{"id": 1097420, "s2_id": "47f09bd5a21fc9aae1839351e9d08e5546a7f619", "title": "TSInsight: A Local-Global Attribution Framework for Interpretability in Time Series Data", "abstract": "With the rise in the employment of deep learning methods in safety-critical scenarios, interpretability is more essential than ever before. Although many different directions regarding interpretability have been explored for visual modalities, time series data has been neglected, with only a handful of methods tested due to their poor intelligibility. We approach the problem of interpretability in a novel way by proposing TSInsight, where we attach an auto-encoder to the classifier with a sparsity-inducing norm on its output and fine-tune it based on the gradients from the classifier and a reconstruction penalty. TSInsight learns to preserve features that are important for prediction by the classifier and suppresses those that are irrelevant, i.e., serves as a feature attribution method to boost the interpretability. In contrast to most other attribution frameworks, TSInsight is capable of generating both instance-based and model-based explanations. We evaluated TSInsight along with nine other commonly used attribution methods on eight different time series datasets to validate its efficacy. The evaluation results show that TSInsight naturally achieves output space contraction; therefore, it is an effective tool for the interpretability of deep time series models.", "venue": "Sensors", "authors": ["Shoaib Ahmed Siddiqui", "Dominique  Mercier", "Andreas  Dengel", "Sheraz  Ahmed"], "year": 2021, "n_citations": 5}
{"id": 1106257, "s2_id": "db16b6859003d7026e18c4a08597923c57e84ac1", "title": "Lenses and Learners", "abstract": "Lenses are a well-established structure for modelling bidirectional transformations, such as the interactions between a database and a view of it. Lenses may be symmetric or asymmetric, and may be composed, forming the morphisms of a monoidal category. More recently, the notion of a learner has been proposed: these provide a compositional way of modelling supervised learning algorithms, and again form the morphisms of a monoidal category. In this paper, we show that the two concepts are tightly linked. We show both that there is a faithful, identity-on-objects symmetric monoidal functor embedding a category of asymmetric lenses into the category of learners, and furthermore there is such a functor embedding the category of learners into a category of symmetric lenses.", "venue": "Bx@PLW", "authors": ["Brendan  Fong", "Michael  Johnson"], "year": 2019, "n_citations": 14}
{"id": 1113757, "s2_id": "f6a28ad30470efcd960c22b567918c7f44cd2d31", "title": "A punishment voting algorithm based on super categories construction for acoustic scene classification", "abstract": "In acoustic scene classification researches, audio segment is usually split into multiple samples. Majority voting is then utilized to ensemble the results of the samples. In this paper, we propose a punishment voting algorithm based on the super categories construction method for acoustic scene classification. Specifically, we propose a DenseNet-like model as the base classifier. The base classifier is trained by the CQT spectrograms generated from the raw audio segments. Taking advantage of the results of the base classifier, we propose a super categories construction method using the spectral clustering. Super classifiers corresponding to the constructed super categories are further trained. Finally, the super classifiers are utilized to enhance the majority voting of the base classifier by punishment voting. Experiments show that the punishment voting obviously improves the performances on both the DCASE2017 Development dataset and the LITIS Rouen dataset.", "venue": "ArXiv", "authors": ["Weiping  Zheng", "Zhenyao  Mo", "Jiantao  Yi"], "year": 2018, "n_citations": 0}
{"id": 1120072, "s2_id": "e8032ef2f8b0506ce2e0a98917bbbfa3d36f787d", "title": "Severity and Mortality Prediction Models to Triage Indian COVID-19 Patients", "abstract": "As the second wave in India mitigates, COVID-19 has now infected about 29 million patients countrywide, leading to more than 350 thousand people dead. As the infections surged, the strain on the medical infrastructure in the country became apparent. While the country vaccinates its population, opening up the economy may lead to an increase in infection rates. In this scenario, it is essential to effectively utilize the limited hospital resources by an informed patient triaging system based on clinical parameters. Here, we present two interpretable machine learning models predicting the clinical outcomes, severity, and mortality, of the patients based on routine non-invasive surveillance of blood parameters from one of the largest cohorts of Indian patients at the day of admission. Patient severity and mortality prediction models achieved 86.3% and 88.06% accuracy, respectively, with an AUC-ROC of 0.91 and 0.92. We have integrated both the models in a user-friendly web app calculator, https://triage-COVID-19.herokuapp.com/, to showcase the potential deployment of such efforts at scale.", "venue": "ArXiv", "authors": ["Samarth  Bhatia", "Yukti  Makhija", "Shalendra  Singh", "Ishaan  Gupta"], "year": 2021, "n_citations": 0}
{"id": 1127516, "s2_id": "e6ada253d546d26a0938ed6d7d669c2d73f6550d", "title": "SlimNets: An Exploration of Deep Model Compression and Acceleration", "abstract": "Deep neural networks have achieved increasingly accurate results on a wide variety of complex tasks. However, much of this improvement is due to the growing use and availability of computational resources (e.g use of GPUs, more layers, more parameters, etc). Most state-of-the-art deep networks, despite performing well, over-parameterize approximate functions and take a significant amount of time to train. With increased focus on deploying deep neural networks on resource constrained devices like smart phones, there has been a push to evaluate why these models are so resource hungry and how they can be made more efficient. This work evaluates and compares three distinct methods for deep model compression and acceleration: weight pruning, low rank factorization, and knowledge distillation. Comparisons on VGG nets trained on CIFAR10 show that each of the models on their own are effective, but that the true power lies in combining them. We show that by combining pruning and knowledge distillation methods we can create a compressed network 85 times smaller than the original, all while retaining 96% of the original model's accuracy.", "venue": "2018 IEEE High Performance extreme Computing Conference (HPEC)", "authors": ["Ini  Oguntola", "Subby  Olubeko", "Chris  Sweeney"], "year": 2018, "n_citations": 7}
{"id": 1141302, "s2_id": "1aae51526f8a9d27cc973d98223a909af0e82cd7", "title": "Generating Natural Questions from Images for Multimodal Assistants", "abstract": "Generating natural, diverse, and meaningful questions from images is an essential task for multimodal assistants as it confirms whether they have understood the object and scene in the images properly. The research in visual question answering (VQA) and visual question generation (VQG) is a great step. However, this research does not capture questions that a visually-abled person would ask multimodal assistants. Recently published datasets such as KB-VQA, FVQA, and OK-VQA try to collect questions that look for external knowledge which makes them appropriate for multimodal assistants. However, they still contain many obvious and common-sense questions that humans would not usually ask a digital assistant. In this paper, we provide a new benchmark dataset that contains questions generated by human annotators keeping in mind what they would ask multimodal digital assistants. Large scale annotations for thousands of images are expensive and time-consuming, so we also present an effective way of automatically generating questions from unseen images. In this paper, we present an approach for generating diverse and meaningful questions that consider image content and metadata of image (e.g., location, associated keyword). We evaluate our approach using standard evaluation metrics such as BLEU, METEOR, ROUGE, and CIDEr to show the relevance of generated questions with human-provided questions. We also measure the diversity of generated questions using generative strength and inventiveness metrics. We report new state-of-the-art results on the public and our datasets.", "venue": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Alkesh  Patel", "Akanksha  Bindal", "Hadas  Kotek", "Christopher  Klein", "Jason  Williams"], "year": 2021, "n_citations": 1}
{"id": 1141438, "s2_id": "1adf323af00e6dedf6cc3befbc4d4929779eb61d", "title": "CBCT-to-CT synthesis with a single neural network for head-and-neck, lung and breast cancer adaptive radiotherapy", "abstract": "Purpose: CBCT-based adaptive radiotherapy requires daily images for accurate dose calculations. This study investigates the feasibility of applying a single convolutional network to facilitate CBCT-to-CT synthesis for head-and-neck, lung, and breast cancer patients. Methods: Ninety-nine patients diagnosed with head-and-neck, lung or breast cancer undergoing radiotherapy with CBCT-based position verification were included in this study. CBCTs were registered to planning CTs according to clinical procedures. Three cycle-consistent generative adversarial networks (cycle-GANs) were trained in an unpaired manner on 15 patients per anatomical site generating synthetic-CTs (sCTs). Another network was trained with all the anatomical sites together. Performances of all four networks were compared and evaluated for image similarity against rescan CT (rCT). Clinical plans were recalculated on CT and sCT and analysed through voxel-based dose differences and {\\gamma}-analysis. Results: A sCT was generated in 10 seconds. Image similarity was comparable between models trained on different anatomical sites and a single model for all sites. Mean dose differences 95% were achieved for all sites. Conclusions: Cycle-GAN reduced CBCT artefacts and increased HU similarity to CT, enabling sCT-based dose calculations. The speed of the network can facilitate on-line adaptive radiotherapy using a single network for head-and-neck, lung and breast cancer patients.", "venue": "ArXiv", "authors": ["Matteo  Maspero", "Mark HF Savenije", "Tristan CF van Heijst", "Joost JC Verhoeff", "Alexis NTJ Kotte", "Anette C Houweling", "Cornelis AT van den Berg"], "year": 2019, "n_citations": 7}
{"id": 1158950, "s2_id": "0054eb42d8ad63b1988fe32df6284762619dcada", "title": "Accelerated Gradient Descent Escapes Saddle Points Faster than Gradient Descent", "abstract": "Nesterov's accelerated gradient descent (AGD), an instance of the general family of \"momentum methods\", provably achieves faster convergence rate than gradient descent (GD) in the convex setting. However, whether these methods are superior to GD in the nonconvex setting remains open. This paper studies a simple variant of AGD, and shows that it escapes saddle points and finds a second-order stationary point in $\\tilde{O}(1/\\epsilon^{7/4})$ iterations, faster than the $\\tilde{O}(1/\\epsilon^{2})$ iterations required by GD. To the best of our knowledge, this is the first Hessian-free algorithm to find a second-order stationary point faster than GD, and also the first single-loop algorithm with a faster rate than GD even in the setting of finding a first-order stationary point. Our analysis is based on two key ideas: (1) the use of a simple Hamiltonian function, inspired by a continuous-time perspective, which AGD monotonically decreases per step even for nonconvex functions, and (2) a novel framework called improve or localize, which is useful for tracking the long-term behavior of gradient-based optimization algorithms. We believe that these techniques may deepen our understanding of both acceleration algorithms and nonconvex optimization.", "venue": "COLT", "authors": ["Chi  Jin", "Praneeth  Netrapalli", "Michael I. Jordan"], "year": 2018, "n_citations": 177}
{"id": 1165555, "s2_id": "942bb6931d641a782cbb0eb5fccd20c3954e887f", "title": "Leveraging the Power of Place: A Data-Driven Decision Helper to Improve the Location Decisions of Economic Immigrants", "abstract": "A growing number of countries have established programs to attract immigrants who can contribute to their economy. Research suggests that an immigrant's initial arrival location plays a key role in shaping their economic success. Yet immigrants currently lack access to personalized information that would help them identify optimal destinations. Instead, they often rely on availability heuristics, which can lead to the selection of sub-optimal landing locations, lower earnings, elevated outmigration rates, and concentration in the most well-known locations. To address this issue and counteract the effects of cognitive biases and limited information, we propose a data-driven decision helper that draws on behavioral insights, administrative data, and machine learning methods to inform immigrants' location decisions. The decision helper provides personalized location recommendations that reflect immigrants' preferences as well as data-driven predictions of the locations where they maximize their expected earnings given their profile. We illustrate the potential impact of our approach using backtests conducted with administrative data that links landing data of recent economic immigrants from Canada's Express Entry system with their earnings retrieved from tax records. Simulations across various scenarios suggest that providing location recommendations to incoming economic immigrants can increase their initial earnings and lead to a mild shift away from the most populous landing destinations. Our approach can be implemented within existing institutional structures at minimal cost, and offers governments an opportunity to harness their administrative data to improve outcomes for economic immigrants.", "venue": "ArXiv", "authors": ["Jeremy  Ferwerda", "Nicholas  Adams-Cohen", "Kirk  Bansak", "Jennifer  Fei", "Duncan  Lawrence", "Jeremy M. Weinstein", "Jens  Hainmueller"], "year": 2020, "n_citations": 0}
{"id": 1169503, "s2_id": "840310e4c713f347742cb00680b568fa9f3af181", "title": "Detecting Memorization in ReLU Networks", "abstract": "We propose a new notion of `non-linearity' of a network layer with respect to an input batch that is based on its proximity to a linear system, which is reflected in the non-negative rank of the activation matrix. We measure this non-linearity by applying non-negative factorization to the activation matrix. Considering batches of similar samples, we find that high non-linearity in deep layers is indicative of memorization. Furthermore, by applying our approach layer-by-layer, we find that the mechanism for memorization consists of distinct phases. We perform experiments on fully-connected and convolutional neural networks trained on several image and audio datasets. Our results demonstrate that as an indicator for memorization, our technique can be used to perform early stopping.", "venue": "ArXiv", "authors": ["Edo  Collins", "Siavash Arjomand Bigdeli", "Sabine  S\u00fcsstrunk"], "year": 2018, "n_citations": 3}
{"id": 1171884, "s2_id": "f450b07faf4d6c587bae2be8c94bb1b76b05388f", "title": "Federated Transfer Learning for EEG Signal Classification", "abstract": "The success of deep learning (DL) methods in the Brain-Computer Interfaces (BCI) field for classification of electroencephalographic (EEG) recordings has been restricted by the lack of large datasets. Privacy concerns associated with EEG signals limit the possibility of constructing a large EEG-BCI dataset by the conglomeration of multiple small ones for jointly training machine learning models. Hence, in this paper, we propose a novel privacy-preserving DL architecture named federated transfer learning (FTL) for EEG classification that is based on the federated learning framework. Working with the single-trial covariance matrix, the proposed architecture extracts common discriminative information from multi-subject EEG data with the help of domain adaptation techniques. We evaluate the performance of the proposed architecture on the PhysioNet dataset for 2-class motor imagery classification. While avoiding the actual data sharing, our FTL approach achieves 2% higher classification accuracy in a subject-adaptive analysis. Also, in the absence of multi-subject data, our architecture provides 6% better accuracy compared to other state-of-the-art DL architectures.", "venue": "2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)", "authors": ["Ce  Ju", "Dashan  Gao", "Ravikiran  Mane", "Ben  Tan", "Yang  Liu", "Cuntai  Guan"], "year": 2020, "n_citations": 13}
{"id": 1199449, "s2_id": "444470335d06646c064797dbdbf4e23b662c2a41", "title": "Communication optimization strategies for distributed deep neural network training: A survey", "abstract": "Abstract Recent trends in high-performance computing and deep learning have led to the proliferation of studies on large-scale deep neural network training. However, the frequent communication requirements among computation nodes drastically slows the overall training speeds, which causes bottlenecks in distributed training, particularly in clusters with limited network bandwidths. To mitigate the drawbacks of distributed communications, researchers have proposed various optimization strategies. In this paper, we provide a comprehensive survey of communication strategies from both an algorithm viewpoint and a computer network perspective. Algorithm optimizations focus on reducing the communication volumes used in distributed training, while network optimizations focus on accelerating the communications between distributed devices. At the algorithm level, we describe how to reduce the number of communication rounds and transmitted bits per round. In addition, we elucidate how to overlap computation and communication. At the network level, we discuss the effects caused by network infrastructures, including logical communication schemes and network protocols. Finally, we extrapolate the potential future challenges and new research directions to accelerate communications for distributed deep neural network training.", "venue": "J. Parallel Distributed Comput.", "authors": ["Shuo  Ouyang", "Dezun  Dong", "Yemao  Xu", "Liquan  Xiao"], "year": 2021, "n_citations": 4}
{"id": 1216967, "s2_id": "99d4382c863869413d99ad07e6b1f1fc245397b9", "title": "Learning walk and trot from the same objective using different types of exploration", "abstract": "In quadruped gait learning, policy search methods that scale high dimensional continuous action spaces are commonly used. In most approaches, it is necessary to introduce prior knowledge on the gaits to limit the highly non-convex search space of the policies. In this work, we propose a new approach to encode the symmetry properties of the desired gaits, on the initial covariance of the Gaussian search distribution, allowing for strategic exploration. Using episode-based likelihood ratio policy gradient and relative entropy policy search, we learned the gaits walk and trot on a simulated quadruped. Comparing these gaits to random gaits learned by initialized diagonal covariance matrix, we show that the performance can be significantly enhanced.", "venue": "ArXiv", "authors": ["Zinan  Liu", "Kai  Ploeger", "Svenja  Stark", "Elmar  Rueckert", "Jan  Peters"], "year": 2019, "n_citations": 0}
{"id": 1217926, "s2_id": "4e3c384e82abdcd471494a75905e9f7b78c1f5eb", "title": "Generalized Speedy Q-Learning", "abstract": "In this letter, we derive a generalization of the Speedy Q-learning (SQL) algorithm that was proposed in the Reinforcement Learning (RL) literature to handle slow convergence of Watkins\u2019 Q-learning. In most RL algorithms such as Q-learning, the Bellman equation and the Bellman operator play an important role. It is possible to generalize the Bellman operator using the technique of successive relaxation. We use the generalized Bellman operator to derive a simple and efficient family of algorithms called Generalized Speedy Q-learning (GSQL-<inline-formula> <tex-math notation=\"LaTeX\">$w$ </tex-math></inline-formula>) and analyze its finite time performance. We show that GSQL-<inline-formula> <tex-math notation=\"LaTeX\">$w$ </tex-math></inline-formula> has an improved finite time performance bound compared to SQL for the case when the relaxation parameter <inline-formula> <tex-math notation=\"LaTeX\">$w$ </tex-math></inline-formula> is greater than 1. This improvement is a consequence of the contraction factor of the generalized Bellman operator being less than that of the standard Bellman operator. Numerical experiments are provided to demonstrate the empirical performance of the GSQL-<inline-formula> <tex-math notation=\"LaTeX\">$w$ </tex-math></inline-formula> algorithm.", "venue": "IEEE Control Systems Letters", "authors": ["Indu  John", "Chandramouli  Kamanchi", "Shalabh  Bhatnagar"], "year": 2020, "n_citations": 5}
{"id": 1218215, "s2_id": "ba63671598d2cf8de0a069b17560e0eabb6c400c", "title": "Vehicle Route Prediction through Multiple Sensors Data Fusion", "abstract": "Vehicle route prediction is one of the significant tasks in vehicles mobility. It is one of the means to reduce the accidents and increase comfort in human life. The task of route prediction becomes simpler with the development of certain machine learning and deep learning libraries. Meanwhile, the security and privacy issues are always lying in the vehicle communication as well as in route prediction. Therefore, we proposed a framework which will reduce these issues in vehicle communication and predict the route of vehicles in crossroads. Specifically, our proposed framework consists of two modules and both are working in sequence. The first module of our framework using a deep learning for recognizing the vehicle license plate number. Then, the second module using supervised learning algorithm of machine learning for predicting the route of the vehicle by using velocity difference and previous mobility patterns as the features of machine learning algorithm. Experiment results shows that accuracy of our framework.", "venue": "ArXiv", "authors": ["Ali  Nawaz", "Attique Ur Rehman"], "year": 2020, "n_citations": 0}
{"id": 1220304, "s2_id": "50e114953ab1b3bff6d023cf79eb539cdeeb23ea", "title": "The Information Geometry of Mirror Descent", "abstract": "We prove the equivalence of two online learning algorithms: 1) mirror descent and 2) natural gradient descent. Both mirror descent and natural gradient descent are generalizations of online gradient descent when the parameter of interest lies on a non-Euclidean manifold. Natural gradient descent selects the steepest descent along a Riemannian manifold by multiplying the standard gradient by the inverse of the metric tensor. Mirror descent induces non-Euclidean structure by solving iterative optimization problems using different proximity functions. In this paper, we prove that mirror descent induced by Bregman divergence proximity functions is equivalent to the natural gradient descent algorithm on the dual Riemannian manifold. We use techniques from convex analysis and connections between Riemannian manifolds, Bregman divergences, and convexity to prove this result. This equivalence between natural gradient descent and mirror descent, implies that: 1) mirror descent is the steepest descent direction along the Riemannian manifold corresponding to the choice of Bregman divergence and 2) mirror descent with log-likelihood loss applied to parameter estimation in exponential families asymptotically achieves the classical Crame\u0301r-Rao lower bound.", "venue": "IEEE Transactions on Information Theory", "authors": ["Garvesh  Raskutti", "Sayan  Mukherjee"], "year": 2015, "n_citations": 67}
{"id": 1224892, "s2_id": "5615769ad70a42ab8ee1c05fda2021c05a84e375", "title": "A Short Survey on Data Clustering Algorithms", "abstract": "With rapidly increasing data, clustering algorithms are important tools for data analytics in modern research. They have been successfully applied to a wide range of domains, for instance, bioinformatics, speech recognition, and financial analysis. Formally speaking, given a set of data instances, a clustering algorithm is expected to divide the set of data instances into the subsets which maximize the intra-subset similarity and inter-subset dissimilarity, where a similarity measure is defined beforehand. In this work, the state-of-the-arts clustering algorithms are reviewed from design concept to methodology, Different clustering paradigms are discussed. Advanced clustering algorithms are also discussed. After that, the existing clustering evaluation metrics are reviewed. A summary with future insights is provided at the end.", "venue": "2015 Second International Conference on Soft Computing and Machine Intelligence (ISCMI)", "authors": ["Ka-Chun  Wong"], "year": 2015, "n_citations": 45}
{"id": 1225830, "s2_id": "317b1dec6d4f950d4607a80df32447827da4799a", "title": "Robust Reinforcement Learning using Adversarial Populations", "abstract": "Reinforcement Learning (RL) is an effective tool for controller design but can struggle with issues of robustness, failing catastrophically when the underlying system dynamics are perturbed. The Robust RL formulation tackles this by adding worst-case adversarial noise to the dynamics and constructing the noise distribution as the solution to a zero-sum minimax game. However, existing work on learning solutions to the Robust RL formulation has primarily focused on training a single RL agent against a single adversary. In this work, we demonstrate that using a single adversary does not consistently yield robustness to dynamics variations under standard parametrizations of the adversary; the resulting policy is highly exploitable by new adversaries. We propose a population-based augmentation to the Robust RL formulation in which we randomly initialize a population of adversaries and sample from the population uniformly during training. We empirically validate across robotics benchmarks that the use of an adversarial population results in a more robust policy that also improves out-of-distribution generalization. Finally, we demonstrate that this approach provides comparable robustness and generalization as domain randomization on these benchmarks while avoiding a ubiquitous domain randomization failure mode.", "venue": "ArXiv", "authors": ["Eugene  Vinitsky", "Yuqing  Du", "Kanaad  Parvate", "Kathy  Jang", "Pieter  Abbeel", "Alexandre  Bayen"], "year": 2020, "n_citations": 13}
{"id": 1240185, "s2_id": "db22a85a1f00201b89a07262d6b82fe8923c82f8", "title": "End-to-End Entity Classification on Multimodal Knowledge Graphs", "abstract": "End-to-end multimodal learning on knowledge graphs has been left largely unaddressed. Instead, most end-to-end models such as message passing networks learn solely from the relational information encoded in graphs' structure: raw values, or literals, are either omitted completely or are stripped from their values and treated as regular nodes. In either case we lose potentially relevant information which could have otherwise been exploited by our learning methods. To avoid this, we must treat literals and non-literals as separate cases. We must also address each modality separately and accordingly: numbers, texts, images, geometries, et cetera. We propose a multimodal message passing network which not only learns end-to-end from the structure of graphs, but also from their possibly divers set of multimodal node features. Our model uses dedicated (neural) encoders to naturally learn embeddings for node features belonging to five different types of modalities, including images and geometries, which are projected into a joint representation space together with their relational information. We demonstrate our model on a node classification task, and evaluate the effect that each modality has on the overall performance. Our result supports our hypothesis that including information from multiple modalities can help our models obtain a better overall performance.", "venue": "ArXiv", "authors": ["W. X. Wilcke", "Peter  Bloem", "V. de Boer", "R. H. van t Veer", "F. A. H. van Harmelen"], "year": 2020, "n_citations": 9}
{"id": 1247579, "s2_id": "2d96c2f8c11ff95bd3fb5d9ba797beb63f01ab07", "title": "Multi-Source Deep Domain Adaptation with Weak Supervision for Time-Series Sensor Data", "abstract": "Domain adaptation (DA) offers a valuable means to reuse data and models for new problem domains. However, robust techniques have not yet been considered for time series data with varying amounts of data availability. In this paper, we make three main contributions to fill this gap. First, we propose a novel Convolutional deep Domain Adaptation model for Time Series data (CoDATS) that significantly improves accuracy and training time over state-of-the-art DA strategies on real-world sensor data benchmarks. By utilizing data from multiple source domains, we increase the usefulness of CoDATS to further improve accuracy over prior single-source methods, particularly on complex time series datasets that have high variability between domains. Second, we propose a novel Domain Adaptation with Weak Supervision (DA-WS) method by utilizing weak supervision in the form of target-domain label distributions, which may be easier to collect than additional data labels. Third, we perform comprehensive experiments on diverse real-world datasets to evaluate the effectiveness of our domain adaptation and weak supervision methods. Results show that CoDATS for single-source DA significantly improves over the state-of-the-art methods, and we achieve additional improvements in accuracy using data from multiple source domains and weakly supervised signals.", "venue": "KDD", "authors": ["Garrett  Wilson", "Janardhan Rao Doppa", "Diane J. Cook"], "year": 2020, "n_citations": 12}
{"id": 1266371, "s2_id": "2ba48a667ac6eba7cf97b31c08a14bfcbd3c21c7", "title": "Supervised detection of anomalous light-curves in massive astronomical catalogs", "abstract": "The development of synoptic sky surveys has led to a massive amount of data for which resources needed for analysis are beyond human capabilities. To process this information and to extract all possible knowledge, machine learning techniques become necessary. Here we present a new method to automatically discover unknown variable objects in large astronomical catalogs. With the aim of taking full advantage of all the information we have about known objects, our method is based on a supervised algorithm. In particular, we train a random forest classifier using known variability classes of objects and obtain votes for each of the objects in the training set. We then model this voting distribution with a Bayesian network and obtain the joint voting distribution among the training objects. Consequently, an unknown object is considered as an outlier insofar it has a low joint probability. Our method is suitable for exploring massive datasets given that the training process is performed offline. We tested our algorithm on 20 millions light-curves from the MACHO catalog and generated a list of anomalous candidates. We divided the candidates into two main classes of outliers: artifacts and intrinsic outliers. Artifacts were principally due to air mass variation, seasonal variation, bad calibration or instrumental errors and were consequently removed from our outlier list and added to the training set. After retraining, we selected about 4000 objects, which we passed to a post analysis stage by perfoming a cross-match with all publicly available catalogs. Within these candidates we identified certain known but rare objects such as eclipsing Cepheids, blue variables, cataclysmic variables and X-ray sources. For some outliers there were no additional information. Among them we identified three unknown variability types and few individual outliers that will be followed up for a deeper analysis.", "venue": "ArXiv", "authors": ["Isadora  nun", "Karim  Pichara", "Pavlos  Protopapas", "Dae-Won  Kim"], "year": 2014, "n_citations": 36}
{"id": 1269558, "s2_id": "84c7ef9277e5f71fd0abb6f302d8bd01879b56b2", "title": "QLBS: Q-Learner in the Black-Scholes (-Merton) Worlds", "abstract": "This paper presents a discrete-time option pricing model that is rooted in Reinforcement Learning (RL), and more specifically in the famous Q-Learning method of RL. We construct a risk-adjusted Markov Decision Process for a discrete-time version of the classical Black-Scholes-Merton (BSM) model, where the option price is an optimal Q-function. Pricing is done by learning to dynamically optimize risk-adjusted returns for an option replicating portfolio, as in the Markowitz portfolio theory. Using Q-Learning and related methods, once created in a parametric setting, the model is able to go model-free and learn to price and hedge an option directly from data generated from a dynamic replicating portfolio which is rebalanced at discrete times. If the world is according to BSM, our risk-averse Q-Learner converges, given enough training data, to the true BSM price and hedge ratio of the option in the continuous time limit, even if hedges applied at the stage of data generation are completely random (i.e. it can learn the BSM model itself, too!), because Q-Learning is an off-policy algorithm. If the world is different from a BSM world, the Q-Learner will find it out as well, because Q-Learning is a model-free algorithm. For finite time steps, the Q-Learner is able to efficiently calculate both the optimal hedge and optimal price for the option directly from trading data, and without an explicit model of the world. This suggests that RL may provide efficient data-driven and model-free methods for optimal pricing and hedging of options, once we depart from the academic continuous-time limit, and vice versa, option pricing methods developed in Mathematical Finance may be viewed as special cases of model-based Reinforcement Learning. Our model only needs basic linear algebra (plus Monte Carlo simulation, if we work with synthetic data).", "venue": "ArXiv", "authors": ["Igor  Halperin"], "year": 2017, "n_citations": 43}
{"id": 1274906, "s2_id": "f8bcf521f0cab6fa0a7bb87ea96a908916a8f426", "title": "DNN-Based Source Enhancement to Increase Objective Sound Quality Assessment Score", "abstract": "We propose a training method for deep neural network (DNN) based source enhancement to increase objective sound quality assessment (OSQA) scores such as the perceptual evaluation of speech quality. In many conventional studies, DNNs have been used as a mapping function to estimate time\u2013frequency masks and trained to minimize an analytically tractable objective function such as the mean squared error (MSE). Since OSQA scores have been used widely for sound-quality evaluation, constructing DNNs to increase OSQA scores would be better than using the minimum MSE to create high-quality output signals. However, since most OSQA scores are not analytically tractable, i.e., they are black boxes, the gradient of the objective function cannot be calculated by simply applying backpropagation. To calculate the gradient of the OSQA-based objective function, we formulated a DNN optimization scheme on the basis of black-box optimization, which is used for training a computer that plays a game. For a black-box-optimization scheme, we adopt the policy gradient method for calculating the gradient on the basis of a sampling algorithm. To simulate output signals using the sampling algorithm, DNNs are used to estimate the probability density function of the output signals that maximize OSQA scores. The OSQA scores are calculated from the simulated output signals, and the DNNs are trained to increase the probability of generating the simulated output signals that achieve high OSQA scores. Through several experiments, we found that OSQA scores significantly increased by applying the proposed method, even though the MSE was not minimized.", "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing", "authors": ["Yuma  Koizumi", "Kenta  Niwa", "Yusuke  Hioka", "Kazunori  Kobayashi", "Yoichi  Haneda"], "year": 2018, "n_citations": 40}
{"id": 1275537, "s2_id": "6fea597ec5ea069d12d8b2390ae696043a3f02bf", "title": "DID-eFed: Facilitating Federated Learning as a Service with Decentralized Identities", "abstract": "We have entered the era of big data, and it is considered to be the \u201dfuel\u201d for the flourishing of artificial intelligence applications. The enactment of the EU General Data Protection Regulation (GDPR) raises concerns about individuals\u2019 privacy in big data. Federated learning (FL) emerges as a functional solution that can help build high-performance models shared among multiple parties while still complying with user privacy and data confidentiality requirements. Although FL has been intensively studied and used in real applications, there is still limited research related to its prospects and applications as a FLaaS (Federated Learning as a Service) to interested 3rd parties. In this paper, we present a FLaaS system: DID-eFed, where FL is facilitated by decentralized identities (DID) and a smart contract. DID enables a more flexible and credible decentralized access management in our system, while the smart contract offers a frictionless and less error-prone process. We describe particularly the scenario where our DID-eFed enables the FLaaS among hospitals and research institutions.", "venue": "EASE", "authors": ["Jiahui  Geng", "Neel  Kanwal", "Martin Gilje Jaatun", "Chunming  Rong"], "year": 2021, "n_citations": 0}
{"id": 1286478, "s2_id": "5862ea6fc01f23ff1ccd5faad90cbb538c42e1f3", "title": "Critical initialisation for deep signal propagation in noisy rectifier neural networks", "abstract": "Stochastic regularisation is an important weapon in the arsenal of a deep learning practitioner. However, despite recent theoretical advances, our understanding of how noise influences signal propagation in deep neural networks remains limited. By extending recent work based on mean field theory, we develop a new framework for signal propagation in stochastic regularised neural networks. Our \\textit{noisy signal propagation} theory can incorporate several common noise distributions, including additive and multiplicative Gaussian noise as well as dropout. We use this framework to investigate initialisation strategies for noisy ReLU networks. We show that no critical initialisation strategy exists using additive noise, with signal propagation exploding regardless of the selected noise distribution. For multiplicative noise (e.g.\\ dropout), we identify alternative critical initialisation strategies that depend on the second moment of the noise distribution. Simulations and experiments on real-world data confirm that our proposed initialisation is able to stably propagate signals in deep networks, while using an initialisation disregarding noise fails to do so. Furthermore, we analyse correlation dynamics between inputs. Stronger noise regularisation is shown to reduce the depth to which discriminatory information about the inputs to a noisy ReLU network is able to propagate, even when initialised at criticality. We support our theoretical predictions for these trainable depths with simulations, as well as with experiments on MNIST and CIFAR-10.", "venue": "NeurIPS", "authors": ["Arnu  Pretorius", "Elan Van Biljon", "Steve  Kroon", "Herman  Kamper"], "year": 2018, "n_citations": 16}
{"id": 1292060, "s2_id": "358e3e863722acdeaa9e1d79b439c38037b9f834", "title": "A Deep Neural Network for Audio Classification with a Classifier Attention Mechanism", "abstract": "Audio classification is considered as a challenging problem in pattern recognition. Recently, many algorithms have been proposed using deep neural networks. In this paper, we introduce a new attention-based neural network architecture called Classifier-Attention-Based Convolutional Neural Network (CAB-CNN). The algorithm uses a newly designed architecture consisting of a list of simple classifiers and an attention mechanism as a classifier selector. This design significantly reduces the number of parameters required by the classifiers and thus their complexities. In this way, it becomes easier to train the classifiers and achieve a high and steady performance. Our claims are corroborated by the experimental results. Compared to the state-of-the-art algorithms, our algorithm achieves more than 10% improvements on all selected test scores.", "venue": "ArXiv", "authors": ["Haoye  Lu", "Haolong  Zhang", "Amit  Nayak"], "year": 2020, "n_citations": 5}
{"id": 1295782, "s2_id": "2dc6176d287b034aa71872ff5356cff45fd24645", "title": "Visualizing and understanding Sum-Product Networks", "abstract": "Sum-Product Networks (SPNs) are deep tractable probabilistic models by which several kinds of inference queries can be answered exactly and in a tractable time. They have been largely used as black box density estimators, assessed by comparing their likelihood scores on different tasks. In this paper we explore and exploit the inner representations learned by SPNs. By taking a closer look at the inner workings of SPNs, we aim to better understand what and how meaningful the representations they learn are, as in a classic Representation Learning framework. We firstly propose an interpretation of SPNs as Multi-Layer Perceptrons, we then devise several criteria to extract representations from SPNs and finally we empirically evaluate them in several (semi-)supervised tasks showing they are competitive against classical feature extractors like RBMs, DBNs and deep probabilistic autoencoders, like MADEs and VAEs.", "venue": "Machine Learning", "authors": ["Antonio  Vergari", "Nicola Di Mauro", "Floriana  Esposito"], "year": 2018, "n_citations": 29}
{"id": 1306239, "s2_id": "c7358b5c104ba6ddae826e0ff07f98d37a816074", "title": "The social dilemma in artificial intelligence development and why we have to solve it", "abstract": "While the demand for ethical artificial intelligence (AI) systems increases, the number of unethical uses of AI accelerates, even though there is no shortage of ethical guidelines. We argue that a possible underlying cause for this is that AI developers face a social dilemma in AI development ethics, preventing the widespread adaptation of ethical best practices. We define the social dilemma for AI development and describe why the current crisis in AI development ethics cannot be solved without relieving AI developers of their social dilemma. We argue that AI development must be professionalised to overcome the social dilemma, and discuss how medicine can be used as a template in this process.", "venue": "AI and Ethics", "authors": ["Inga  Strumke", "Marija  Slavkovik", "Vince I. Madai"], "year": 2021, "n_citations": 0}
{"id": 1347899, "s2_id": "abed4e91316b8916ca0d2c22b2cb27cd1c19e760", "title": "Sparse One-Time Grab Sampling of Inliers", "abstract": "Estimating structures in \"big data\" and clustering them are among the most fundamental problems in computer vision, pattern recognition, data mining, and many other other research fields. Over the past few decades, many studies have been conducted focusing on different aspects of these problems. One of the main approaches that is explored in the literature to tackle the problems of size and dimensionality is sampling subsets of the data in order to estimate the characteristics of the whole population, e.g. estimating the underlying clusters or structures in the data. In this paper, we propose a `one-time-grab' sampling algorithm\\cite{jaberi2015swift,jaberi2018sparse}. This method can be used as the front end to any supervised or unsupervised clustering method. Rather than focusing on the strategy of maximizing the probability of sampling inliers, our goal is to minimize the number of samples needed to instantiate all underlying model instances. More specifically, our goal is to answer the following question: {\\em `Given a very large population of points with $C$ embedded structures and gross outliers, what is the minimum number of points $r$ to be selected randomly in one grab in order to make sure with probability $P$ that at least $\\varepsilon$ points are selected on each structure, where $\\varepsilon$ is the number of degrees of freedom of each structure.'}", "venue": "ArXiv", "authors": ["Maryam  Jaberi", "Marianna  Pensky", "Hassan  Foroosh"], "year": 2019, "n_citations": 0}
{"id": 1351607, "s2_id": "8e5b2c00444f517ff12765ae2597108f544b00d7", "title": "Attention! A Lightweight 2D Hand Pose Estimation Approach", "abstract": "Vision based human pose estimation is an non-invasive technology for Human-Computer Interaction (HCI). The direct use of the hand as an input device provides an attractive interaction method, with no need for specialized sensing equipment, such as exoskeletons, gloves etc, but a camera. Traditionally, HCI is employed in various applications spreading in areas including manufacturing, surgery, entertainment industry and architecture, to mention a few. Deployment of vision based human pose estimation algorithms can give a breath of innovation to these applications. In this article, we present a novel Convolutional Neural Network architecture, reinforced with a Self-Attention module. Our proposed model can be deployed on an embedded system due to its lightweight nature with just 1.9 Million parameters. The source code and qualitative results are publicly available.", "venue": "IEEE Sensors Journal", "authors": ["Nicholas  Santavas", "Ioannis  Kansizoglou", "Loukas  Bampis", "Evangelos  Karakasis", "Antonios  Gasteratos"], "year": 2021, "n_citations": 8}
{"id": 1356926, "s2_id": "cf4d0747b083ded8c9aa6a7026bd7a5af1f98f29", "title": "Showing Your Offline Reinforcement Learning Work: Online Evaluation Budget Matters", "abstract": "Over the recent years, vast progress has been made in Offline Reinforcement Learning (Offline-RL) for various decision-making domains: from finance to robotics. However, comparing and reporting new Offline-RL algorithms has been noted as underdeveloped: (1) use of unlimited online evaluation budget for hyperparameter search (2) sidestepping offline policy selection (3) ad-hoc performance statistics reporting. In this work, we propose an evaluation technique addressing these issues, Expected Online Performance, that provides a performance estimate for a best-found policy given a fixed online evaluation budget. Using our approach, we can estimate the number of online evaluations required to surpass a given behavioral policy performance. Applying it to several Offline-RL baselines, we find that with a limited online evaluation budget, (1) Behavioral Cloning constitutes a strong baseline over various expert levels and data regimes, and (2) offline uniform policy selection is competitive with value-based approaches. We hope the proposed technique will make it into the toolsets of Offline-RL practitioners to help them arrive at informed conclusions when deploying RL in real-world systems. Introduction In recent years, significant success has been achieved in applying Reinforcement Learning (RL) to different real-world scenarios (Chen et al. 2019; Tang et al. 2019; Gauci et al. 2019). Nevertheless, RL algorithms are known as being hypersensitive to the choice of hyperparameters (Henderson et al. 2018), which is one of the reasons why their results are usually reported for a narrow range of values. Consequently, they are primarily run in simulated environments before being transferred and deployed to real-world systems. However, beyond the scope of cheap simulated environments, collecting new data in many real-world domains is too tricky and cost-ineffective, making it unrealistic to train an online RL agent for such applications. Fortunately, these systems could already store enough logged data about previously made decisions, making it possible to use other machine learning techniques. Copyright \u00a9 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. 1 3 5 7 9 11 13 15 17 19 21 23 25 27 30 Policies Evaluated Online -30% -25% -20% -15% -10% -5% 0% +5% +10% Ex pe ct ed O nl in e Pe rf or m an ce BC CQL TD3+BC Behavioral Policy", "venue": "ArXiv", "authors": ["Vladislav  Kurenkov", "Sergey  Kolesnikov"], "year": 2021, "n_citations": 0}
{"id": 1369881, "s2_id": "7cea6bd172bb5cf4fb7b6dd6d348df8c2fe04ea1", "title": "Exploiting Smoothness in Statistical Learning, Sequential Prediction, and Stochastic Optimization", "abstract": "In the last several years, the intimate connection between convex optimization and learning problems, in both statistical and sequential frameworks, has shifted the focus of algorithmic machine learning to examine this interplay. In particular, on one hand, this intertwinement brings forward new challenges in reassessment of the performance of learning algorithms including generalization and regret bounds under the assumptions imposed by convexity such as analytical properties of loss functions (e.g., Lipschitzness, strong convexity, and smoothness). On the other hand, emergence of datasets of an unprecedented size, demands the development of novel and more efficient optimization algorithms to tackle large-scale learning problems. \nThe overarching goal of this thesis is to reassess the smoothness of loss functions in statistical learning, sequential prediction/online learning, and stochastic optimization and explicate its consequences. In particular we examine how smoothness of loss function could be beneficial or detrimental in these settings in terms of sample complexity, statistical consistency, regret analysis, and convergence rate, and investigate how smoothness can be leveraged to devise more efficient learning algorithms.", "venue": "ArXiv", "authors": ["Mehrdad  Mahdavi"], "year": 2014, "n_citations": 4}
{"id": 1376697, "s2_id": "ce7a814e3544d4dad0520e8fc25c5b3a8f794778", "title": "PLAN-B: Predicting Likely Alternative Next Best Sequences for Action Prediction", "abstract": "Action prediction focuses on anticipating actions before they happen. Recent works leverage probabilistic approaches to describe future uncertainties and sample future actions. However, these methods cannot easily find all alternative predictions, which are essential given the inherent unpredictability of the future, and current evaluation protocols do not measure a system\u2019s ability to find such alternatives. We re-examine action prediction in terms of its ability to predict not only the top predictions, but also top alternatives with the accuracy@k metric. In addition, we propose Choice F1: a metric inspired by F1 score which evaluates a prediction system\u2019s ability to find all plausible futures while keeping only the most probable ones. To evaluate this problem, we present a novel method, Predicting the Likely Alternative Next Best, or PLAN-B, for action prediction which automatically finds the set of most likely alternative futures. PLAN-B consists of two novel components: (i) a Choice Table which ensures that all possible futures are found, and (ii) a \u201cCollaborative\u201d RNN system which combines both action sequence and feature information. We demonstrate that our system outperforms state-of-the-art results on benchmark datasets.", "venue": "ArXiv", "authors": ["Dan  Scarafoni", "Irfan  Essa", "Thomas  Ploetz"], "year": 2021, "n_citations": 1}
{"id": 1381271, "s2_id": "c1a25c1e9fb89674db2e32feef5056b09b7edee8", "title": "Improving Explainability of Image Classification in Scenarios with Class Overlap: Application to COVID-19 and Pneumonia", "abstract": "Trust in predictions made by machine learning models is increased if the model generalizes well on previously unseen samples and when inference is accompanied by cogent explanations of the reasoning behind predictions. In the image classification domain, generalization can be assessed through accuracy, sensitivity, and specificity. Explainability can be assessed by how well the model localizes the object of interest within an image. However, both generalization and explainability through localization are degraded in scenarios with significant overlap between classes. We propose a method based on binary expert networks that enhances the explainability of image classifications through better localization by mitigating the model uncertainty induced by class overlap. Our technique performs discriminative localization on images that contain features with significant class overlap, without explicitly training for localization. Our method is particularly promising in real-world class overlap scenarios, such as COVID-19 and pneumonia, where expertly labeled data for localization is not readily available. This can be useful for early, rapid, and trustworthy screening for COVID-19.", "venue": "2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)", "authors": ["Edward  Verenich", "Alvaro  Velasquez", "Nazar  Khan", "Faraz  Hussain"], "year": 2020, "n_citations": 1}
{"id": 1387565, "s2_id": "cc336399d4a87cb80213b527387e7d5e800f112c", "title": "Self Regulated Learning Mechanism for Data Efficient Knowledge Distillation", "abstract": "Existing methods for distillation do not efficiently utilize the training data. This work presents a novel approach to perform distillation using only a subset of the training data, making it more data-efficient. For this purpose, the training of the teacher model is modified to include self-regulation wherein a sample in the training set is used for updating model parameters in the backward pass either if it is misclassified or the model is not confident enough in its prediction. This modification restricts the participation of samples, unlike the conventional training method. The number of times a sample participates in the self-regulated training process is a measure of its significance towards the model's knowledge. The significance values are used to weigh the losses incurred on the corresponding samples in the distillation process. This method is named significance-based distillation. Two other methods are proposed for comparison where the student model learns by distillation and incorporating self-regulation as the teacher model, either utilizing the significance information computed during the teacher's training or not. These methods are named hybrid and regulated distillations, respectively. Experiments on benchmark datasets show that the proposed methods achieve similar performance as other state-of-the-art methods for knowledge distillation while utilizing a significantly less number of samples.", "venue": "2021 International Joint Conference on Neural Networks (IJCNN)", "authors": ["Sourav  Mishra", "Suresh  Sundaram"], "year": 2021, "n_citations": 1}
{"id": 1390178, "s2_id": "d7fd0659eed319b97ca4770fdc85b6cc3ba8bd69", "title": "Quantum pattern recognition in photonic circuits", "abstract": "This paper proposes a machine learning method to characterize photonic states via a simple optical circuit and data processing of photon number distributions, such as photonic patterns. The input states consist of two coherent states used as references and a two-mode unknown state to be studied. We successfully trained supervised learning algorithms that can predict the degree of entanglement in the two-mode state as well as perform the full tomography of one photonic mode, obtaining satisfactory values in the considered regression metrics.", "venue": "Quantum Science and Technology", "authors": ["Rui  Wang", "Carlos  Hernani-Morales", "Jos\u00e9 D Mart\u00edn-Guerrero", "Enrique  Solano", "Francisco  Albarr\u00e1n-Arriagada"], "year": 2021, "n_citations": 0}
{"id": 1394537, "s2_id": "a73d7982b01c3308cf54ecac9aa9f929a43bc4d4", "title": "Personalized Education at Scale", "abstract": "Tailoring the presentation of information to the needs of individual students leads to massive gains in student outcomes~\\cite{bloom19842}. This finding is likely due to the fact that different students learn differently, perhaps as a result of variation in ability, interest or other factors~\\cite{schiefele1992interest}. Adapting presentations to the educational needs of an individual has traditionally been the domain of experts, making it expensive and logistically challenging to do at scale, and also leading to inequity in educational outcomes. Increased course sizes and large MOOC enrollments provide an unprecedented access to student data. We propose that emerging technologies in reinforcement learning (RL), as well as semi-supervised learning, natural language processing, and computer vision are critical to leveraging this data to provide personalized education at scale.", "venue": "ArXiv", "authors": ["Sam  Saarinen", "Evan  Cater", "Michael L. Littman"], "year": 2018, "n_citations": 0}
{"id": 1397095, "s2_id": "db84e7c8a143237350d7bc8302c563e6d1014b37", "title": "Byzantine-Robust Variance-Reduced Federated Learning over Distributed Non-i.i.d. Data", "abstract": "We propose a Byzantine-robust variance-reduced stochastic gradient descent (SGD) method to solve the distributed finite-sum minimization problem when the data on the workers are not independent and identically distributed (i.i.d.). During the learning process, an unknown number of Byzantine workers may send malicious messages to the master node, leading to remarkable learning error. Most of the Byzantine-robust methods address this issue by using robust aggregation rules to aggregate the received messages, but rely on the assumption that all the regular workers have i.i.d. data, which is not the case in many federated learning applications. In light of the significance of reducing stochastic gradient noise for mitigating the effect of Byzantine attacks, we use a resampling strategy to reduce the impact of both inner variation (that describes the sample heterogeneity on every regular worker) and outer variation (that describes the sample heterogeneity among the regular workers), along with a stochastic average gradient algorithm (SAGA) to fully eliminate the inner variation. The variance-reduced messages are then aggregated with a robust geometric median operator. Under certain conditions, we prove that the proposed method reaches a neighborhood of the optimal solution with linear convergence rate, and the learning error is much smaller than those given by the state-of-the-art methods in the non-i.i.d. setting. Numerical experiments corroborate the theoretical results and show satisfactory performance of the proposed method.", "venue": "ArXiv", "authors": ["Jie  Peng", "Zhaoxian  Wu", "Qing  Ling"], "year": 2020, "n_citations": 2}
{"id": 1403798, "s2_id": "d585968ed58243a66545e11d75987e8406b6a6d4", "title": "Tight lower bounds for Dynamic Time Warping", "abstract": "Dynamic Time Warping (DTW) is a popular similarity measure for aligning and comparing time series. Due to DTW\u2019s high computation time, lower bounds are often employed to screen poor matches. Many alternative lower bounds have been proposed, providing a range of different trade-offs between tightness and computational efficiency. LB Keogh provides a useful trade-off in many applications. Two recent lower bounds, LB Improved and LB Enhanced, are substantially tighter than LB Keogh. All three have the same worst case computational complexity\u2014linear with respect to series length and constant with respect to window size. We present four new DTW lower bounds in the same complexity class. LB Petitjean is substantially tighter than LB Improved, with only modest additional computational overhead. LB Webb is more efficient than LB Improved, while often providing a tighter bound. LB Webb is always tighter than LB Keogh. The parameter free LB Webb is usually tighter than LB Enhanced. A parameterized variant, LB Webb Enhanced, is always tighter than LB Enhanced. A further variant, LB Webb\u2217, is useful for some constrained distance functions. In extensive experiments, LB Webb proves to be very effective for nearest neighbor search.", "venue": "Pattern Recognit.", "authors": ["Geoffrey I. Webb", "Francois  Petitjean"], "year": 2021, "n_citations": 1}
{"id": 1406790, "s2_id": "b921fb66eaa009f813187bb3936d6fb86cb98078", "title": "Deep Probabilistic Ensembles: Approximate Variational Inference through KL Regularization", "abstract": "In this paper, we introduce Deep Probabilistic Ensembles (DPEs), a scalable technique that uses a regularized ensemble to approximate a deep Bayesian Neural Network (BNN). We do so by incorporating a KL divergence penalty term into the training objective of an ensemble, derived from the evidence lower bound used in variational inference. We evaluate the uncertainty estimates obtained from our models for active learning on visual classification. Our approach steadily improves upon active learning baselines as the annotation budget is increased.", "venue": "ArXiv", "authors": ["Kashyap  Chitta", "Jose M. Alvarez", "Adam  Lesnikowski"], "year": 2018, "n_citations": 4}
{"id": 1411687, "s2_id": "677dc36a220204f9112afb01f35a1dc3779bc0f7", "title": "Value-aware Quantization for Training and Inference of Neural Networks", "abstract": "We propose a novel value-aware quantization which applies aggressively reduced precision to the majority of data while separately handling a small amount of large data in high precision, which reduces total quantization errors under very low precision. We present new techniques to apply the proposed quantization to training and inference. The experiments show that our method with 3-bit activations (with 2% of large ones) can give the same training accuracy as full-precision one while offering significant (41.6% and 53.7%) reductions in the memory cost of activations in ResNet-152 and Inception-v3 compared with the state-of-the-art method. Our experiments also show that deep networks such as Inception-v3, ResNet-101 and DenseNet-121 can be quantized for inference with 4-bit weights and activations (with 1% 16-bit data) within 1% top-1 accuracy drop.", "venue": "ECCV", "authors": ["Eunhyeok  Park", "Sungjoo  Yoo", "Peter  Vajda"], "year": 2018, "n_citations": 80}
{"id": 1412540, "s2_id": "b50d249fcb80ac372629036895c91cf4efcf9e3b", "title": "One-Shot GAN Generated Fake Face Detection", "abstract": "Fake face detection is a significant challenge for intelligent systems as generative models become more powerful every single day. As the quality of fake faces increases, the trained models become more and more inefficient to detect the novel fake faces, since the corresponding training data is considered outdated. In this case, robust One-Shot learning methods is more compatible with the requirements of changeable training data. In this paper, we propose a universal One-Shot GAN generated fake face detection method which can be used in significantly different areas of anomaly detection. The proposed method is based on extracting out-of-context objects from faces via scene understanding models. To do so, we use state of the art scene understanding and object detection methods as a pre-processing tool to detect the weird objects in the face. Second, we create a bag of words given all the detected out-of-context objects per all training data. This way, we transform each image into a sparse vector where each feature represents the confidence score related to each detected object in the image. Our experiments show that, we can discriminate fake faces from real ones in terms of out-of-context features. It means that, different sets of objects are detected in fake faces comparing to real ones when we analyze them with scene understanding and object detection models. We prove that, the proposed method can outperform previous methods based on our experiments on Style-GAN generated fake faces.", "venue": "ArXiv", "authors": ["Hadi  Mansourifar", "Weidong  Shi"], "year": 2020, "n_citations": 4}
{"id": 1423170, "s2_id": "edb19d0c5a422ee890f3799d217d9dc456cf4769", "title": "Distributed Training with Heterogeneous Data: Bridging Median- and Mean-Based Algorithms", "abstract": "Recently, there is a growing interest in the study of median-based algorithms for distributed non-convex optimization. Two prominent such algorithms include signSGD with majority vote, an effective approach for communication reduction via 1-bit compression on the local gradients, and medianSGD, an algorithm recently proposed to ensure robustness against Byzantine workers. The convergence analyses for these algorithms critically rely on the assumption that all the distributed data are drawn iid from the same distribution. However, in applications such as Federated Learning, the data across different nodes or machines can be inherently heterogeneous, which violates such an iid assumption. This work analyzes signSGD and medianSGD in distributed settings with heterogeneous data. We show that these algorithms are non-convergent whenever there is some disparity between the expected median and mean over the local gradients. To overcome this gap, we provide a novel gradient correction mechanism that perturbs the local gradients with noise, together with a series results that provable close the gap between mean and median of the gradients. The proposed methods largely preserve nice properties of these methods, such as the low per-iteration communication complexity of signSGD, and further enjoy global convergence to stationary solutions. Our perturbation technique can be of independent interest when one wishes to estimate mean through a median estimator.", "venue": "NeurIPS", "authors": ["Xiangyi  Chen", "Tiancong  Chen", "Haoran  Sun", "Zhiwei Steven Wu", "Mingyi  Hong"], "year": 2020, "n_citations": 30}
{"id": 1436859, "s2_id": "68a97d3f89622ff9a2873f409389f6797ca3a60c", "title": "Greedy AutoAugment", "abstract": "A major problem in data augmentation is to ensure that the generated new samples cover the search space. This is a challenging problem and requires exploration for data augmentation policies to ensure their effectiveness in covering the search space. In this paper, we propose Greedy AutoAugment as a highly efficient search algorithm to find the best augmentation policies. We use a greedy approach to reduce the exponential growth of the number of possible trials to linear growth. The Greedy Search also helps us to lead the search towards the sub-policies with better results, which eventually helps to increase the accuracy. The proposed method can be used as a reliable addition to the current artifitial neural networks. Our experiments on four datasets (Tiny ImageNet, CIFAR-10, CIFAR-100, and SVHN) show that Greedy AutoAugment provides better accuracy, while using 360 times fewer computational resources.", "venue": "Pattern Recognit. Lett.", "authors": ["Alireza  Naghizadeh", "Mohammadsajad  Abavisani", "Dimitris N. Metaxas"], "year": 2020, "n_citations": 7}
{"id": 1448525, "s2_id": "002285ade41b9e1313f9c914b99e68b62fab7ff1", "title": "Scalable Recollections for Continual Lifelong Learning", "abstract": "Given the recent success of Deep Learning applied to a variety of single tasks, it is natural to consider more human-realistic settings. Perhaps the most difficult of these settings is that of continual lifelong learning, where the model must learn online over a continuous stream of non-stationary data. A successful continual lifelong learning system must have three key capabilities: it must learn and adapt over time, it must not forget what it has learned, and it must be efficient in both training time and memory. Recent techniques have focused their efforts primarily on the first two capabilities while questions of efficiency remain largely unexplored. In this paper, we consider the problem of efficient and effective storage of experiences over very large time-frames. In particular we consider the case where typical experiences are O(n) bits and memories are limited to O(k) bits for k", "venue": "AAAI", "authors": ["Matthew  Riemer", "Tim  Klinger", "Djallel  Bouneffouf", "Michele  Franceschini"], "year": 2019, "n_citations": 27}
{"id": 1456969, "s2_id": "cb4b4e55dae1083e84885c94cbe9d5d8de600fed", "title": "Topology Based Scalable Graph Kernels", "abstract": "We propose a new graph kernel for graph classification and comparison using Ollivier Ricci curvature. The Ricci curvature of an edge in a graph describes the connectivity in the local neighborhood. An edge in a densely connected neighborhood has positive curvature and an edge serving as a local bridge has negative curvature. We use the edge curvature distribution to form a graph kernel which is then used to compare and cluster graphs. The curvature kernel uses purely the graph topology and thereby works for settings when node attributes are not available.", "venue": "ArXiv", "authors": ["Kin Sum Liu", "Chien-Chun  Ni", "Yu-Yao  Lin", "Jie  Gao"], "year": 2019, "n_citations": 0}
{"id": 1463471, "s2_id": "a5696369c85bf5e6cb600a0187bdf19c27a53eb4", "title": "Feature grouping from spatially constrained multiplicative interaction", "abstract": "We present a feature learning model that learns to encode relationships between images. The model is defined as a Gated Boltzmann Machine, which is constrained such that hidden units that are nearby in space can gate each other's connections. We show how frequency/orientation \"columns\" as well as topographic filter maps follow naturally from training the model on image pairs. The model also helps explain why square-pooling models yield feature groups with similar grouping properties. Experimental results on synthetic image transformations show that spatially constrained gating is an effective way to reduce the number of parameters and thereby to regularize a transformation-learning model.", "venue": "ICLR", "authors": ["Felix  Bauer", "Roland  Memisevic"], "year": 2013, "n_citations": 2}
{"id": 1466493, "s2_id": "cecd22bf53eb949becf937aac9f9488ccfee1e0d", "title": "Break the Ceiling: Stronger Multi-scale Deep Graph Convolutional Networks", "abstract": "Recently, neural network based approaches have achieved significant improvement for solving large, complex, graph-structured problems. However, their bottlenecks still need to be addressed, and the advantages of multi-scale information and deep architectures have not been sufficiently exploited. In this paper, we theoretically analyze how existing Graph Convolutional Networks (GCNs) have limited expressive power due to the constraint of the activation functions and their architectures. We generalize spectral graph convolution and deep GCN in block Krylov subspace forms and devise two architectures, both with the potential to be scaled deeper but each making use of the multi-scale information in different ways. We further show that the equivalence of these two architectures can be established under certain conditions. On several node classification tasks, with or without the help of validation, the two new architectures achieve better performance compared to many state-of-the-art methods.", "venue": "NeurIPS", "authors": ["Sitao  Luan", "Mingde  Zhao", "Xiao-Wen  Chang", "Doina  Precup"], "year": 2019, "n_citations": 63}
{"id": 1470934, "s2_id": "9c30992cad49948068d5fb9ca7a63c8920e8926e", "title": "Understanding the Impact of Model Incoherence on Convergence of Incremental SGD with Random Reshuffle", "abstract": "Although SGD with random reshuffle has been widely-used in machine learning applications, there is a limited understanding of how model characteristics affect the convergence of the algorithm. In this work, we introduce model incoherence to characterize the diversity of model characteristics and study its impact on convergence of SGD with random reshuffle under weak strong convexity. Specifically, minimizer incoherence measures the discrepancy between the global minimizers of a sample loss and those of the total loss and affects the convergence error of SGD with random reshuffle. In particular, we show that the variable sequence generated by SGD with random reshuffle converges to a certain global minimizer of the total loss under full minimizer coherence. The other curvature incoherence measures the quality of condition numbers of the sample losses and determines the convergence rate of SGD. With model incoherence, our results show that SGD has a faster convergence rate and smaller convergence error under random reshuffle than those under random sampling, and hence provide justifications to the superior practical performance of SGD with random reshuffle.", "venue": "ICML", "authors": ["Shaocong  Ma", "Yi  Zhou"], "year": 2020, "n_citations": 2}
{"id": 1471568, "s2_id": "5e28a8c63af7ae272ea6f9379a43dff685fdaf2c", "title": "Image Colorization: A Survey and Dataset", "abstract": "Image colorization is an essential image processing and computer vision branch to colorize images and videos. Recently, deep learning techniques progressed notably for image colorization. This article presents a comprehensive survey of recent state-of-the-art colorization using deep learning algorithms, describing their fundamental block architectures in terms of skip connections, input etc. as well as optimizers, loss functions, training protocols, and training data etc. Generally, we can roughly categorize the existing colorization techniques into seven classes. Besides, we also provide some additional essential issues, such as benchmark datasets and evaluation metrics. We also introduce a new dataset specific to colorization and perform an experimental evaluation of the publicly available methods. In the last section, we discuss the limitations, possible solutions, and future research directions of the rapidly evolving topic of deep image colorization that the community should further address. Dataset and Codes for evaluation will be publicly available at this https URL", "venue": "ArXiv", "authors": ["Saeed  Anwar", "Muhammad  Tahir", "Chongyi  Li", "Ajmal  Mian", "Fahad Shahbaz Khan", "Abdul Wahab Muzaffar"], "year": 2020, "n_citations": 10}
{"id": 1477491, "s2_id": "edd3553f1af38f2bb9150deef89b1aa082cda363", "title": "Automatic moth detection from trap images for pest management", "abstract": "We propose a convolutional neural network-based automatic moth detection pipeline.We describe a set of methods for preprocessing raw moth trap images.Our method shows promising performance on a codling moth dataset from images collected in the field.Our species-agnostic method can be easily adapted to different pests and/or environments. Monitoring the number of insect pests is a crucial component in pheromone-based pest management systems. In this paper, we propose an automatic detection pipeline based on deep learning for identifying and counting pests in images taken inside field traps. Applied to a commercial codling moth dataset, our method shows promising performance both qualitatively and quantitatively. Compared to previous attempts at pest detection, our approach uses no pest-specific engineering which enables it to adapt to other species and environments with minimal human effort. It is amenable to implementation on parallel hardware and therefore capable of deployment in settings where real-time performance is required.", "venue": "Comput. Electron. Agric.", "authors": ["Weiguang  Ding", "Graham W. Taylor"], "year": 2016, "n_citations": 164}
{"id": 1486713, "s2_id": "ecf6f776eeb683802a331f13ff637f38dc6b2892", "title": "Math Programming based Reinforcement Learning for Multi-Echelon Inventory Management", "abstract": "Reinforcement Learning has lead to considerable break-throughs in diverse areas such as robotics, games and many others. But the application to RL in complex real-world decision making problems remains limited. Many problems in Operations Management (inventory and revenue management, for example) are characterized by large action spaces and stochastic system dynamics. These characteristics make the problem considerably harder to solve for existing RL methods that rely on enumeration techniques to solve per step action problems. To resolve these issues, we develop Programmable Actor Reinforcement Learning (PARL), a policy iteration method that uses techniques from integer programming and sample average approximation. Analytically, we show that the for a given critic, the learned policy in each iteration converges to the optimal policy as the underlying samples of the uncertainty go to infinity. Practically, we show that a properly selected discretization of the underlying uncertain distribution can yield near optimal actor policy even with very few samples from the underlying uncertainty. We then apply our algorithm to real-world inventory management problems with complex supply chain structures and show that PARL outperforms state-of-the-art RL and inventory optimization methods in these settings. We find that PARL outperforms commonly used base stock heuristic by 51.3% and RL based methods by up to 9.58% on average across different supply chain environments.", "venue": "SSRN Electronic Journal", "authors": ["Pavithra  Harsha", "Ashish  Jagmohan", "Jayant  Kalagnanam", "Brian  Quanz", "Divya  Singhvi"], "year": 2021, "n_citations": 0}
{"id": 1503224, "s2_id": "266f59109013a84c78ea038aed6b824504ec0936", "title": "Lightweight Convolutional Neural Networks By Hypercomplex Parameterization", "abstract": "Hypercomplex neural networks have proved to reduce the overall number of parameters while ensuring valuable performances by leveraging the properties of Clifford algebras. Recently, hypercomplex linear layers have been further improved by involving efficient parameterized Kronecker products. In this paper, we define the parameterization of hypercomplex convolutional layers to develop lightweight and efficient large-scale convolutional models. Our method grasps the convolution rules and the filters organization directly from data without requiring a rigidly predefined domain structure to follow. The proposed approach is flexible to operate in any user-defined or tuned domain, from 1D to nD regardless of whether the algebra rules are preset. Such a malleability allows processing multidimensional inputs in their natural domain without annexing further dimensions, as done, instead, in quaternion neural networks for 3D inputs like color images. As a result, the proposed method operates with 1/n free parameters as regards its analog in the real domain. We demonstrate the versatility of this approach to multiple domains of application by performing experiments on various image datasets as well as audio datasets in which our method outperforms real and quaternionvalued counterparts.", "venue": "ArXiv", "authors": ["Eleonora  Grassucci", "Aston  Zhang", "Danilo  Comminiello"], "year": 2021, "n_citations": 0}
{"id": 1514799, "s2_id": "a1243419d9311f4aa3892272e4633eb34aede448", "title": "A Non-Asymptotic Analysis for Stein Variational Gradient Descent", "abstract": "We study the Stein Variational Gradient Descent (SVGD) algorithm, which optimises a set of particles to approximate a target probability distribution $\\pi\\propto e^{-V}$ on $\\mathbb{R}^d$. In the population limit, SVGD performs gradient descent in the space of probability distributions on the KL divergence with respect to $\\pi$, where the gradient is smoothed through a kernel integral operator. In this paper, we provide a novel finite time analysis for the SVGD algorithm. We obtain a descent lemma establishing that the algorithm decreases the objective at each iteration, and provably converges, with less restrictive assumptions on the step size than required in earlier analyses. We further provide a guarantee on the convergence rate in Kullback-Leibler divergence, assuming $\\pi$ satisfies a Stein log-Sobolev inequality as in Duncan et al. (2019), which takes into account the geometry induced by the smoothed KL gradient.", "venue": "NeurIPS", "authors": ["Anna  Korba", "Adil  Salim", "Michael  Arbel", "Giulia  Luise", "Arthur  Gretton"], "year": 2020, "n_citations": 14}
{"id": 1518366, "s2_id": "af963b51c98fccbabff615f8d40737482ac471bd", "title": "Algorithm based on one monocular video delivers highly valid and reliable gait parameters", "abstract": "Despite its paramount importance for manifold use cases (e.g., in the health care industry, sports, rehabilitation and fitness assessment), sufficiently valid and reliable gait parameter measurement is still limited to high-tech gait laboratories mostly. Here, we demonstrate the excellent validity and test\u2013retest repeatability of a novel gait assessment system which is built upon modern convolutional neural networks to extract three-dimensional skeleton joints from monocular frontal-view videos of walking humans. The validity study is based on a comparison to the GAITRite pressure-sensitive walkway system. All measured gait parameters (gait speed, cadence, step length and step time) showed excellent concurrent validity for multiple walk trials at normal and fast gait speeds. The test\u2013retest-repeatability is on the same level as the GAITRite system. In conclusion, we are convinced that our results can pave the way for cost, space and operationally effective gait analysis in broad mainstream applications. Most sensor-based systems are costly, must be operated by extensively trained personnel (e.g., motion capture systems) or\u2014even if not quite as costly\u2014still possess considerable complexity (e.g., wearable sensors). In contrast, a video sufficient for the assessment method presented here can be obtained by anyone, without much training, via a smartphone camera.", "venue": "Scientific reports", "authors": ["Arash  Azhand", "Sophie  Rabe", "Swantje  M\u00fcller", "Igor  Sattler", "Anika  Steinert"], "year": 2021, "n_citations": 2}
{"id": 1527648, "s2_id": "22319ca57932899f4de93c1b0dbf9f705a1d52ea", "title": "RB-CCR: Radial-Based Combined Cleaning and Resampling algorithm for imbalanced data classification", "abstract": "Real-world classification domains, such as medicine, health and safety, and finance, often exhibit imbalanced class priors and have asynchronous misclassification costs. In such cases, the classification model must achieve a high recall without significantly impacting precision. Resampling the training data is the standard approach to improving classification performance on imbalanced binary data. However, the state-of-the-art methods ignore the local joint distribution of the data or correct it as a post-processing step. This can causes sub-optimal shifts in the training distribution, particularly when the target data distribution is complex. In this paper, we propose Radial-Based Combined Cleaning and Resampling (RB-CCR). RB-CCR utilizes the concept of class potential to refine the energy-based resampling approach of CCR. In particular, RB-CCR exploits the class potential to accurately locate sub-regions of the data-space for synthetic oversampling. The category sub-region for oversampling can be specified as an input parameter to meet domain-specific needs or be automatically selected via cross-validation. Our $$5\\times 2$$\n \n 5\n \u00d7\n 2\n \n cross-validated results on 57 benchmark binary datasets with 9 classifiers show that RB-CCR achieves a better precision-recall trade-off than CCR and generally out-performs the state-of-the-art resampling methods in terms of AUC and G-mean.", "venue": "Mach. Learn.", "authors": ["Michal  Koziarski", "Colin  Bellinger", "Michal  Wo'zniak"], "year": 2021, "n_citations": 1}
{"id": 1528370, "s2_id": "043654af2c7bed382b42483c02acfd5e80682690", "title": "Semantics of higher-order probabilistic programs with conditioning", "abstract": "We present a denotational semantics for higher-order probabilistic programs in terms of linear operators between Banach spaces. Our semantics is rooted in the classical theory of Banach spaces and their tensor products, but bears similarities with the well-known semantics of higher-order programs a la Scott through the use of ordered Banach spaces which allow definitions in terms of fixed points. Our semantics is a model of intuitionistic linear logic: it is based on a symmetric monoidal closed category of ordered Banach spaces which treats randomness as a linear resource, but by constructing an exponential comonad we can also accommodate non-linear reasoning. We apply our semantics to the verification of the classical Gibbs sampling algorithm.", "venue": "Proc. ACM Program. Lang.", "authors": ["Fredrik  Dahlqvist", "Dexter  Kozen"], "year": 2020, "n_citations": 20}
{"id": 1540716, "s2_id": "89f116cc57a16c9da0c84e91472d949508f337c2", "title": "MLModelCI: An Automatic Cloud Platform for Efficient MLaaS", "abstract": "MLModelCI provides multimedia researchers and developers with a one-stop platform for efficient machine learning (ML) services. The system leverages DevOps techniques to optimize, test, and manage models. It also containerizes and deploys these optimized and validated models as cloud services (MLaaS). In its essence, MLModelCI serves as a housekeeper to help users publish models. The models are first automatically converted to optimized formats for production purpose and then profiled under different settings (e.g., batch size and hardware). The profiling information can be used as guidelines for balancing the trade-off between performance and cost of MLaaS. Finally, the system dockerizes the models for ease of deployment to cloud environments. A key feature of MLModelCI is the implementation of a controller, which allows elastic evaluation which only utilizes idle workers while maintaining online service quality. Our system bridges the gap between current ML training and serving systems and thus free developers from manual and tedious work often associated with service deployment. We release the platform as an open-source project on GitHub under Apache 2.0 license, with the aim that it will facilitate and streamline more large-scale ML applications and research projects.", "venue": "ACM Multimedia", "authors": ["Huaizheng  Zhang", "Yuanming  Li", "Yizheng  Huang", "Yonggang  Wen", "Jianxiong  Yin", "Kyle  Guan"], "year": 2020, "n_citations": 5}
{"id": 1545179, "s2_id": "4ec3f7e194099dafdc5b734e506c85acda89853f", "title": "Joint Symmetry Detection and Shape Matching for Non-Rigid Point Cloud", "abstract": "Despite the success of deep functional maps in non-rigid 3D shape matching, there exists no learning framework that models both self-symmetry and shape matching simultaneously. This is despite the fact that errors due to symmetry mismatch are a major challenge in non-rigid shape matching. In this paper, we propose a novel framework that simultaneously learns both self symmetry as well as a pairwise map between a pair of shapes. Our key idea is to couple a self symmetry map and a pairwise map through a regularization term that provides a joint constraint on both of them, thereby, leading to more accurate maps. We validate our method on several benchmarks where it outperforms many competitive baselines on both tasks.", "venue": "ArXiv", "authors": ["Abhishek  Sharma", "Maks  Ovsjanikov"], "year": 2021, "n_citations": 0}
{"id": 1556493, "s2_id": "aaf08e37bcd0f4624d8eb04f301bfa98b0456641", "title": "Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex", "abstract": "We discuss relations between Residual Networks (ResNet), Recurrent Neural Networks (RNNs) and the primate visual cortex. We begin with the observation that a shallow RNN is exactly equivalent to a very deep ResNet with weight sharing among the layers. A direct implementation of such a RNN, although having orders of magnitude fewer parameters, leads to a performance similar to the corresponding ResNet. We propose 1) a generalization of both RNN and ResNet architectures and 2) the conjecture that a class of moderately deep RNNs is a biologically-plausible model of the ventral stream in visual cortex. We demonstrate the eectiveness of the architectures by testing them on the CIFAR-10 dataset.", "venue": "ArXiv", "authors": ["Qianli  Liao", "Tomaso A. Poggio"], "year": 2016, "n_citations": 215}
{"id": 1558982, "s2_id": "9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d", "title": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems", "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.", "venue": "ArXiv", "authors": ["Mart\u00edn  Abadi", "Ashish  Agarwal", "Paul  Barham", "Eugene  Brevdo", "Zhifeng  Chen", "Craig  Citro", "Gregory S. Corrado", "Andy  Davis", "Jeffrey  Dean", "Matthieu  Devin", "Sanjay  Ghemawat", "Ian J. Goodfellow", "Andrew  Harp", "Geoffrey  Irving", "Michael  Isard", "Yangqing  Jia", "Rafal  J\u00f3zefowicz", "Lukasz  Kaiser", "Manjunath  Kudlur", "Josh  Levenberg", "Dan  Man\u00e9", "Rajat  Monga", "Sherry  Moore", "Derek Gordon Murray", "Chris  Olah", "Mike  Schuster", "Jonathon  Shlens", "Benoit  Steiner", "Ilya  Sutskever", "Kunal  Talwar", "Paul A. Tucker", "Vincent  Vanhoucke", "Vijay  Vasudevan", "Fernanda B. Vi\u00e9gas", "Oriol  Vinyals", "Pete  Warden", "Martin  Wattenberg", "Martin  Wicke", "Yuan  Yu", "Xiaoqiang  Zheng"], "year": 2016, "n_citations": 8857}
{"id": 1559641, "s2_id": "842a2b757dd46a906173c9e17032004f8183f6be", "title": "Scalable Inference of Sparsely-changing Markov Random Fields with Strong Statistical Guarantees", "abstract": "In this paper, we study the problem of inferring time-varying Markov random fields (MRF), where the underlying graphical model is both sparse and changes sparsely over time. Most of the existing methods for the inference of time-varying MRFs rely on the regularized maximum likelihood estimation (MLE), that typically suffer from weak statistical guarantees and high computational time. Instead, we introduce a new class of constrained optimization problems for the inference of sparsely-changing MRFs. The proposed optimization problem is formulated based on the exact `0 regularization, and can be solved in near-linear time and memory. Moreover, we show that the proposed estimator enjoys a provably small estimation error. As a special case, we derive sharp statistical guarantees for the inference of sparselychanging Gaussian MRFs (GMRF) in the high-dimensional regime, showing that such problems can be learned with as few as one sample per time. Our proposed method is extremely efficient in practice: it can accurately estimate sparsely-changing graphical models with more than 500 million variables in less than one hour.", "venue": "ArXiv", "authors": ["Salar  Fattahi", "Andres  Gomez"], "year": 2021, "n_citations": 2}
{"id": 1563451, "s2_id": "86b4878b65e2f9c9ada00bbdae1213edc84f2dba", "title": "Deeply Learned Spectral Total Variation Decomposition", "abstract": "Non-linear spectral decompositions of images based on one-homogeneous functionals such as total variation have gained considerable attention in the last few years. Due to their ability to extract spectral components corresponding to objects of different size and contrast, such decompositions enable filtering, feature transfer, image fusion and other applications. However, obtaining this decomposition involves solving multiple non-smooth optimisation problems and is therefore computationally highly intensive. In this paper, we present a neural network approximation of a non-linear spectral decomposition. We report up to four orders of magnitude ($\\times 10,000$) speedup in processing of mega-pixel size images, compared to classical GPU implementations. Our proposed network, TVSpecNET, is able to implicitly learn the underlying PDE and, despite being entirely data driven, inherits invariances of the model based transform. To the best of our knowledge, this is the first approach towards learning a non-linear spectral decomposition of images. Not only do we gain a staggering computational advantage, but this approach can also be seen as a step towards studying neural networks that can decompose an image into spectral components defined by a user rather than a handcrafted functional.", "venue": "NeurIPS", "authors": ["Tamara G. Grossmann", "Yury  Korolev", "Guy  Gilboa", "Carola-Bibiane  Sch\u00f6nlieb"], "year": 2020, "n_citations": 0}
{"id": 1565798, "s2_id": "f9b7223564f2ff070c73691e2912687a03794a8d", "title": "Self-supervised Autoregressive Domain Adaptation for Time Series Data", "abstract": "Unsupervised domain adaptation (UDA) has successfully addressed the domain shift problem for visual applications. Yet, these approaches may have limited performance for time series data due to the following reasons. First, they mainly rely on large-scale dataset (i.e., ImageNet) for the source pretraining, which is not applicable for time-series data. Second, they ignore the temporal dimension on the feature space of the source and target domains during the domain alignment step. Last, most of prior UDA methods can only align the global features without considering the fine-grained class distribution of the target domain. To address these limitations, we propose a SeLf-supervised AutoRegressive Domain Adaptation (SLARDA) framework. In particular, we first design a self-supervised learning module which utilizes forecasting as an auxiliary task to improve the transferability of the source features. Second, we propose a novel autoregressive domain adaptation technique that incorporates temporal dependency of both source and target features during domain alignment. Finally, we develop an ensemble teacher model to align the class-wise distribution in the target domain via confident pseudo labeling approach. Extensive experiments have been conducted on three real-world time series applications with 30 cross-domain scenarios. Results demonstrate that our proposed SLARDA method significantly outperforms the state-ofthe-art approaches for time series domain adaptation. Our source code is available at: https://github.com/mohamedr002/SLARDA.", "venue": "ArXiv", "authors": ["Mohamed  Ragab", "Emadeldeen  Eldele", "Zhenghua  Chen", "Min  Wu", "Chee-Keong  Kwoh", "Xiaoli  Li"], "year": 2021, "n_citations": 0}
{"id": 1570781, "s2_id": "b2eae6e7390609087583ec53cf06fea522f659c4", "title": "On Simple Reactive Neural Networks for Behaviour-Based Reinforcement Learning", "abstract": "We present a behaviour-based reinforcement learning approach, inspired by Brook\u2019s subsumption architecture, in which simple fully connected networks are trained as reactive behaviours. Our working assumption is that a pick and place robotic task can be simplified by leveraging domain knowledge of a robotics developer to decompose and train reactive behaviours; namely, approach, grasp, and retract. Then the robot autonomously learns how to combine reactive behaviours via an Actor-Critic architecture. We use an Actor-Critic policy to determine the activation and inhibition mechanisms of the reactive behaviours in a particular temporal sequence. We validate our approach in a simulated robot environment where the task is about picking a block and taking it to a target position while orienting the gripper from a top grasp. The latter represents an extra degree-of-freedom of which current end-to-end reinforcement learning approaches fail to generalise. Our findings suggest that robotic learning can be more effective if each behaviour is learnt in isolation and then combined them to accomplish the task. That is, our approach learns the pick and place task in 8,000 episodes, which represents a drastic reduction in the number of training episodes required by an end-to-end approach ( 95,000 episodes) and existing state-of-the-art algorithms.", "venue": "2020 IEEE International Conference on Robotics and Automation (ICRA)", "authors": ["Ameya  Pore", "Gerardo  Aragon-Camarasa"], "year": 2020, "n_citations": 3}
{"id": 1581278, "s2_id": "3b2ecf95d002afdfeb450f9775e30d80879074e5", "title": "Complex Human Action Recognition in Live Videos Using Hybrid FR-DL Method", "abstract": "Automated human action recognition is one of the most attractive and practical research fields in computer vision, in spite of its high computational costs. In such systems, the human action labelling is based on the appearance and patterns of the motions in the video sequences; however, the conventional methodologies and classic neural networks cannot use temporal information for action recognition prediction in the upcoming frames in a video sequence. On the other hand, the computational cost of the preprocessing stage is high. In this paper, we address challenges of the preprocessing phase, by an automated selection of representative frames among the input sequences. Furthermore, we extract the key features of the representative frame rather than the entire features. We propose a hybrid technique using background subtraction and HOG, followed by application of a deep neural network and skeletal modelling method. The combination of a CNN and the LSTM recursive network is considered for feature selection and maintaining the previous information, and finally, a Softmax-KNN classifier is used for labelling human activities. We name our model as Feature Reduction & Deep Learning based action recognition method, or FR-DL in short. To evaluate the proposed method, we use the UCF dataset for the benchmarking which is widely-used among researchers in action recognition research. The dataset includes 101 complicated activities in the wild. Experimental results show a significant improvement in terms of accuracy and speed in comparison with six state-of-the-art articles.", "venue": "ArXiv", "authors": ["Fatemeh  Serpush", "Mahdi  Rezaei"], "year": 2020, "n_citations": 4}
{"id": 1597722, "s2_id": "33471e37ed8451358d38d8aebf95d760941cc810", "title": "Learning Syllogism with Euler Neural-Networks", "abstract": "Traditional neural networks represent everything as a vector, and are able to approximate a subset of logical reasoning to a certain degree. As basic logic relations are better represented by topological relations between regions, we propose a novel neural network that represents everything as a ball and is able to learn topological configuration as an Euler diagram. So comes the name Euler Neural-Network (ENN). The central vector of a ball is a vector that can inherit representation power of traditional neural network. ENN distinguishes four spatial statuses between balls, namely, being disconnected, being partially overlapped, being part of, being inverse part of. Within each status, ideal values are defined for efficient reasoning. A novel back-propagation algorithm with six Rectified Spatial Units (ReSU) can optimize an Euler diagram representing logical premises, from which logical conclusion can be deduced. In contrast to traditional neural network, ENN can precisely represent all 24 different structures of Syllogism. Two large datasets are created: one extracted from WordNet-3.0 covers all types of Syllogism reasoning, the other extracted all family relations from DBpedia. Experiment results approve the superior power of ENN in logical representation and reasoning. Datasets and source code are available upon request.", "venue": "ArXiv", "authors": ["Tiansi  Dong", "Chengjiang  Li", "Christian  Bauckhage", "Juanzi  Li", "Stefan  Wrobel", "Armin B. Cremers"], "year": 2020, "n_citations": 0}
{"id": 1611651, "s2_id": "f136a0fdc2065485c83396ae41d431395de51af4", "title": "A Novice-Reviewer Experiment to Address Scarcity of Qualified Reviewers in Large Conferences", "abstract": "Conference peer review constitutes a human-computation process whose importance cannot be overstated: not only it identifies the best submissions for acceptance, but, ultimately, it impacts the future of the whole research area by promoting some ideas and restraining others. A surge in the number of submissions received by leading AI conferences has challenged the sustainability of the review process by increasing the burden on the pool of qualified reviewers which is growing at a much slower rate. In this work, we consider the problem of reviewer recruiting with a focus on the scarcity of qualified reviewers in large conferences. Specifically, we design a procedure for (i) recruiting reviewers from the population not typically covered by major conferences and (ii) guiding them through the reviewing pipeline. In conjunction with the ICML 2020 \u2014 a large, top-tier machine learning conference \u2014 we recruit a small set of reviewers through our procedure and compare their performance with the general population of ICML reviewers. Our experiment reveals that a combination of the recruiting and guiding mechanisms allows for a principled enhancement of the reviewer pool and results in reviews of superior quality compared to the conventional pool of reviews as evaluated by senior members of the program committee (meta-reviewers).", "venue": "AAAI", "authors": ["Ivan  Stelmakh", "Nihar B. Shah", "Aarti  Singh", "Hal  Daum'e"], "year": 2021, "n_citations": 9}
{"id": 1616236, "s2_id": "10225767a0895155ded3e5b5ad1a6fe6f4c126b3", "title": "Propagating Asymptotic-Estimated Gradients for Low Bitwidth Quantized Neural Networks", "abstract": "The quantized neural networks (QNNs) can be useful for neural network acceleration and compression, but during the training process they pose a challenge: how to propagate the gradient of loss function through the graph flow with a derivative of 0 almost everywhere. In response to this non-differentiable situation, we propose a novel Asymptotic-Quantized Estimator (AQE) to estimate the gradient. In particular, during back-propagation, the graph that relates inputs to output remains smoothness and differentiability. At the end of training, the weights and activations have been quantized to low-precision because of the asymptotic behaviour of AQE. Meanwhile, we propose a M-bit Inputs and N-bit Weights Network (MINW-Net) trained by AQE, a quantized neural network with 1\u20133 bits weights and activations. In the inference phase, we can use XNOR or SHIFT operations instead of convolution operations to accelerate the MINW-Net. Our experiments on CIFAR datasets demonstrate that our AQE is well defined, and the QNNs with AQE perform better than that with Straight-Through Estimator (STE). For example, in the case of the same ConvNet that has 1-bit weights and activations, our MINW-Net with AQE can achieve a prediction accuracy 1.5% higher than the Binarized Neural Network (BNN) with STE. The MINW-Net, which is trained from scratch by AQE, can achieve comparable classification accuracy as 32-bit counterparts on CIFAR test sets. Extensive experimental results on ImageNet dataset show great superiority of the proposed AQE and our MINW-Net achieves comparable results with other state-of-the-art QNNs.", "venue": "IEEE Journal of Selected Topics in Signal Processing", "authors": ["Jun  Chen", "Yong  Liu", "Hao  Zhang", "Shengnan  Hou", "Jian  Yang"], "year": 2020, "n_citations": 2}
{"id": 1618126, "s2_id": "efe9635e65e130d53b3d9da19b27d07a820d4697", "title": "Outlier Robust Online Learning", "abstract": "We consider the problem of learning from noisy data in practical settings where the size of data is too large to store on a single machine. More challenging, the data coming from the wild may contain malicious outliers. To address the scalability and robustness issues, we present an online robust learning (ORL) approach. ORL is simple to implement and has provable robustness guarantee -- in stark contrast to existing online learning approaches that are generally fragile to outliers. We specialize the ORL approach for two concrete cases: online robust principal component analysis and online linear regression. We demonstrate the efficiency and robustness advantages of ORL through comprehensive simulations and predicting image tags on a large-scale data set. We also discuss extension of the ORL to distributed learning and provide experimental evaluations.", "venue": "ArXiv", "authors": ["Jiashi  Feng", "Huan  Xu", "Shie  Mannor"], "year": 2017, "n_citations": 6}
{"id": 1619324, "s2_id": "639a5fdfb2483dba159e0515654e97d5106d199d", "title": "Research issues in mining user behavioral rules for context-aware intelligent mobile applications", "abstract": "Context awareness in smart mobile applications is a growing area of study because of its intelligence in the applications. To build context-aware intelligent applications, mining contextual behavioral rules of individual smartphone users utilizing their phone log data is the key. However, to mine these rules, a number of issues, such as the quality of smartphone data, understanding the relevancy of contexts, discretization of continuous contextual data, discovery of useful behavioral rules of individuals and their ordering, knowledge-based interactive post-mining for semantic understanding, and dynamic updating and management of rules according to their present behavior, are investigated. In this paper, we briefly discuss these issues and their potential solution directions for mining individuals\u2019 behavioral rules, for the purpose of building various context-aware intelligent mobile applications. We also summarize a number of real-life rule-based applications that intelligently assist individual smartphone users according to their behavioral rules in their daily activities.", "venue": "Iran Journal of Computer Science", "authors": ["Iqbal H. Sarker"], "year": 2018, "n_citations": 8}
{"id": 1638829, "s2_id": "765dcaf34e182df21c2f4361aa073691e5902df0", "title": "Lifelong Federated Reinforcement Learning: A Learning Architecture for Navigation in Cloud Robotic Systems", "abstract": "This letter was motivated by the problem of how to make robots fuse and transfer their experience so that they can effectively use prior knowledge and quickly adapt to new environments. To address the problem, we present a learning architecture for navigation in cloud robotic systems: Lifelong Federated Reinforcement Learning (LFRL). In the letter, we propose a knowledge fusion algorithm for upgrading a shared model deployed on the cloud. Then, effective transfer learning methods in LFRL are introduced. LFRL is consistent with human cognitive science and fits well in cloud robotic systems. Experiments show that LFRL greatly improves the efficiency of reinforcement learning for robot navigation. The cloud robotic system deployment also shows that LFRL is capable of fusing prior knowledge. In addition, we release a cloud robotic navigation-learning website to provide the service based on LFRL: www.shared-robotics.com.", "venue": "IEEE Robotics and Automation Letters", "authors": ["Boyi  Liu", "Lujia  Wang", "Ming  Liu"], "year": 2019, "n_citations": 97}
{"id": 1643027, "s2_id": "96d09c3cadc59ed3538580abc777bb31a50b4791", "title": "Regularized Adversarial Sampling and Deep Time-aware Attention for Click-Through Rate Prediction", "abstract": "Improving the performance of click-through rate (CTR) prediction remains one of the core tasks in online advertising systems. With the rise of deep learning, CTR prediction models with deep networks remarkably enhance model capacities. In deep CTR models, exploiting users' historical data is essential for learning users' behaviors and interests. As existing CTR prediction works neglect the importance of the temporal signals when embed users' historical clicking records, we propose a time-aware attention model which explicitly uses absolute temporal signals for expressing the users' periodic behaviors and relative temporal signals for expressing the temporal relation between items. Besides, we propose a regularized adversarial sampling strategy for negative sampling which eases the classification imbalance of CTR data and can make use of the strong guidance provided by the observed negative CTR samples. The adversarial sampling strategy significantly improves the training efficiency, and can be co-trained with the time-aware attention model seamlessly. Experiments are conducted on real-world CTR datasets from both in-station and out-station advertising places.", "venue": "CIKM", "authors": ["Yikai  Wang", "Liang  Zhang", "Quanyu  Dai", "Fuchun  Sun", "Bo  Zhang", "Yang  He", "Weipeng  Yan", "Yongjun  Bao"], "year": 2019, "n_citations": 6}
{"id": 1643179, "s2_id": "533a23528b0188a159f0af2a995eb7889f5dd075", "title": "Feature Selection Tutorial with Python Examples", "abstract": "In Machine Learning, feature selection entails selecting a subset of the available features in a dataset to use for model development. There are many motivations for feature selection, it may result in better models, it may provide insight into the data and it may deliver economies in data gathering or data processing. For these reasons feature selection has received a lot of attention in data analytics research. In this paper we provide an overview of the main methods and present practical examples with Python implementations. While the main focus is on supervised feature selection techniques, we also cover some feature transformation methods.", "venue": "ArXiv", "authors": ["Padraig  Cunningham", "Bahavathy  Kathirgamanathan", "Sarah Jane Delany"], "year": 2021, "n_citations": 1}
{"id": 1648371, "s2_id": "caa41db159a4ca95e043019826039c0ee1e916a9", "title": "Overlapping Communities Detection via Measure Space Embedding", "abstract": "We present a new algorithm for community detection. The algorithm uses random walks to embed the graph in a space of measures, after which a modification of $k$-means in that space is applied. The algorithm is therefore fast and easily parallelizable. We evaluate the algorithm on standard random graph benchmarks, including some overlapping community benchmarks, and find its performance to be better or at least as good as previously known algorithms. We also prove a linear time (in number of edges) guarantee for the algorithm on a $p,q$-stochastic block model with $p \\geq c\\cdot N^{-\\frac{1}{2} + \\epsilon}$ and $p-q \\geq c' \\sqrt{p N^{-\\frac{1}{2} + \\epsilon} \\log N}$.", "venue": "ArXiv", "authors": ["Mark  Kozdoba", "Shie  Mannor"], "year": 2015, "n_citations": 0}
{"id": 1654508, "s2_id": "0de4523a5175b5e8f584e68a3e6fa00240e51785", "title": "Programs as Black-Box Explanations", "abstract": "Recent work in model-agnostic explanations of black-box machine learning has demonstrated that interpretability of complex models does not have to come at the cost of accuracy or model flexibility. However, it is not clear what kind of explanations, such as linear models, decision trees, and rule lists, are the appropriate family to consider, and different tasks and models may benefit from different kinds of explanations. Instead of picking a single family of representations, in this work we propose to use \"programs\" as model-agnostic explanations. We show that small programs can be expressive yet intuitive as explanations, and generalize over a number of existing interpretable families. We propose a prototype program induction method based on simulated annealing that approximates the local behavior of black-box classifiers around a specific prediction using random perturbations. Finally, we present preliminary application on small datasets and show that the generated explanations are intuitive and accurate for a number of classifiers.", "venue": "ArXiv", "authors": ["Sameer  Singh", "Marco T\u00falio Ribeiro", "Carlos  Guestrin"], "year": 2016, "n_citations": 34}
{"id": 1668807, "s2_id": "c894c631bad4d2a37ea41c3defd4998640e62f2e", "title": "Real-Time Workload Classification during Driving using HyperNetworks", "abstract": "Classifying human cognitive states from behavioral and physiological signals is a challenging problem with important applications in robotics. The problem is challenging due to the data variability among individual users, and sensor artefacts. In this work, we propose an end-to-end framework for real-time cognitive workload classification with mixture Hyper Long Short Term Memory Networks (m-HyperLSTM), a novel variant of HyperNetworks. Evaluating the proposed approach on an eye-gaze pattern dataset collected from simulated driving scenarios of different cognitive demands, we show that the proposed framework outperforms previous baseline methods and achieves 83.9% precision and 87.8% recall during test. We also demonstrate the merit of our proposed architecture by showing improved performance over other LSTM-based methods.", "venue": "2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "authors": ["Ruohan  Wang", "Pierluigi Vito Amadori", "Yiannis  Demiris"], "year": 2018, "n_citations": 8}
{"id": 1680121, "s2_id": "e4b2a800f78342de4ce9d7b5c665ba96904e23ad", "title": "Improved Structural Discovery and Representation Learning of Multi-Agent Data", "abstract": "Central to all machine learning algorithms is data representation. For multi-agent systems, selecting a representation which adequately captures the interactions among agents is challenging due to the latent group structure which tends to vary depending on context. However, in multi-agent systems with strong group structure, we can simultaneously learn this structure and map a set of agents to a consistently ordered representation for further learning. In this paper, we present a dynamic alignment method which provides a robust ordering of structured multi-agent data enabling representation learning to occur in a fraction of the time of previous methods. We demonstrate the value of this approach using a large amount of soccer tracking data from a professional league.", "venue": "ArXiv", "authors": ["Jennifer  Hobbs", "Matthew  Holbrook", "Nathan  Frank", "Long  Sha", "Patrick  Lucey"], "year": 2019, "n_citations": 2}
{"id": 1687430, "s2_id": "bda89e0d181eda7e49ea831225eda86d075e111c", "title": "Towards Conceptual Compression", "abstract": "We introduce a simple recurrent variational auto-encoder architecture that significantly improves image modeling. The system represents the state-of-the-art in latent variable models for both the ImageNet and Omniglot datasets. We show that it naturally separates global conceptual information from lower level details, thus addressing one of the fundamentally desired properties of unsupervised learning. Furthermore, the possibility of restricting ourselves to storing only global information about an image allows us to achieve high quality 'conceptual compression'.", "venue": "NIPS", "authors": ["Karol  Gregor", "Frederic  Besse", "Danilo Jimenez Rezende", "Ivo  Danihelka", "Daan  Wierstra"], "year": 2016, "n_citations": 197}
{"id": 1690846, "s2_id": "c44316534ae40a9785acbdc5b3035c2e4458541f", "title": "Spectro-Temporal RF Identification using Deep Learning", "abstract": "RF emissions\u2019 detection, classification, and spectro-temporal localization are crucial not only for tasks relating to understanding, managing, and protecting the RF spectrum, but also for safety and security applications such as detecting intruding drones or jammers. Achieving this goal for wideband spectrum and in real-time performance is a challenging problem. We present WRIST, a Wideband, Real-time RF Identification system with Spectro-Temporal detection, framework and system. Our resulting deep learning model is capable to detect, classify, and precisely locate RF emissions in time and frequency using RF samples of 100MHz spectrum in real-time (over 6Gbps incoming I&Q streams). Such capabilities are made feasible by leveraging a deep learning-based one-stage object detection framework, and transfer learning to a multi-channel image-based RF signals representation. We also introduce an iterative training approachwhich leverages synthesized and augmented RF data to efficiently build large labelled datasets of RF emissions (SPREAD). WRIST\u2019s detector achieves 90 mean Average Precision even in extremely congested environment in the wild. WRIST model classifies five technologies (Bluetooth, Lightbridge, Wi-Fi, XPD, and ZigBee) and is easily extendable to others. We are making our curated and annotated dataset available to the whole community. It consists of nearly 1 million fully-labelled RF emissions collected from various off-the-shelf wireless radios in a range of environments and spanning the five classes of emissions.", "venue": "ArXiv", "authors": ["Hai N. Nguyen", "Marinos  Vomvas", "Triet Vo Huu", "Guevara  Noubir"], "year": 2021, "n_citations": 0}
{"id": 1718563, "s2_id": "8ff5b1de09aee5dcfbb5080eb331d628eaea2908", "title": "Neuromodulated Goal-Driven Perception in Uncertain Domains", "abstract": "In uncertain domains, the goals are often unknown and need to be predicted by the organism or system. In this paper, contrastive excitation backprop (c-EB) was used in a goal-driven perception task with pairs of noisy MNIST digits, where the system had to increase attention to one of the two digits corresponding to a goal (i.e., even, odd, low value, or high value) and decrease attention to the distractor digit or noisy background pixels. Because the valid goal was unknown, an online learning model based on the cholinergic and noradrenergic neuromodulatory systems was used to predict a noisy goal (expected uncertainty) and re-adapt when the goal changed (unexpected uncertainty). This neurobiologically plausible model demonstrates how neuromodulatory systems can predict goals in uncertain domains and how attentional mechanisms can enhance the perception of that goal.", "venue": "ArXiv", "authors": ["Xinyun  Zou", "Soheil  Kolouri", "Praveen K. Pilly", "Jeffrey L. Krichmar"], "year": 2019, "n_citations": 0}
{"id": 1718982, "s2_id": "30d7d9f650c626137b1bac186786c13bbaf9c81f", "title": "CheMixNet: Mixed DNN Architectures for Predicting Chemical Properties using Multiple Molecular Representations", "abstract": "SMILES is a linear representation of chemical structures which encodes the connection table, and the stereochemistry of a molecule as a line of text with a grammar structure denoting atoms, bonds, rings and chains, and this information can be used to predict chemical properties. Molecular fingerprints are representations of chemical structures, successfully used in similarity search, clustering, classification, drug discovery, and virtual screening and are a standard and computationally efficient abstract representation where structural features are represented as a bit string. Both SMILES and molecular fingerprints are different representations for describing the structure of a molecule. There exist several predictive models for learning chemical properties based on either SMILES or molecular fingerprints. Here, our goal is to build predictive models that can leverage both these molecular representations. In this work, we present CheMixNet -- a set of neural networks for predicting chemical properties from a mixture of features learned from the two molecular representations -- SMILES as sequences and molecular fingerprints as vector inputs. We demonstrate the efficacy of CheMixNet architectures by evaluating on six different datasets. The proposed CheMixNet models not only outperforms the candidate neural architectures such as contemporary fully connected networks that uses molecular fingerprints and 1-D CNN and RNN models trained SMILES sequences, but also other state-of-the-art architectures such as Chemception and Molecular Graph Convolutions.", "venue": "ArXiv", "authors": ["Arindam  Paul", "Dipendra  Jha", "Reda  Al-Bahrani", "Wei-keng  Liao", "Alok N. Choudhary", "Ankit  Agrawal"], "year": 2018, "n_citations": 23}
{"id": 1730708, "s2_id": "3e47215717ccb510b33c7eb0ee3d82e2bbe6be53", "title": "Representational Capacity of Deep Neural Networks - A Computing Study", "abstract": "There is some theoretical evidence that deep neural networks with multiple hidden layers have a potential for more efficient representation of multidimensional mappings than shallow networks with a single hidden layer. The question is whether it is possible to exploit this theoretical advantage for finding such representations with help of numerical training methods. Tests using prototypical problems with a known mean square minimum did not confirm this hypothesis. Minima found with the help of deep networks have always been worse than those found using shallow networks. This does not directly contradict the theoretical findings---it is possible that the superior representational capacity of deep networks is genuine while finding the mean square minimum of such deep networks is a substantially harder problem than with shallow ones.", "venue": "KDIR", "authors": ["Bernhard  Bermeitinger", "Tomas  Hrycej", "Siegfried  Handschuh"], "year": 2019, "n_citations": 1}
{"id": 1733848, "s2_id": "510d98681e5e85fb1265513728f16e2543ae1b4b", "title": "Hypergraph Neural Networks", "abstract": "In this paper, we present a hypergraph neural networks (HGNN) framework for data representation learning, which can encode high-order data correlation in a hypergraph structure. Confronting the challenges of learning representation for complex data in real practice, we propose to incorporate such data structure in a hypergraph, which is more flexible on data modeling, especially when dealing with complex data. In this method, a hyperedge convolution operation is designed to handle the data correlation during representation learning. In this way, traditional hypergraph learning procedure can be conducted using hyperedge convolution operations efficiently. HGNN is able to learn the hidden layer representation considering the high-order data structure, which is a general framework considering the complex data correlations. We have conducted experiments on citation network classification and visual object recognition tasks and compared HGNN with graph convolutional networks and other traditional methods. Experimental results demonstrate that the proposed HGNN method outperforms recent state-of-theart methods. We can also reveal from the results that the proposed HGNN is superior when dealing with multi-modal data compared with existing methods.", "venue": "AAAI", "authors": ["Yifan  Feng", "Haoxuan  You", "Zizhao  Zhang", "Rongrong  Ji", "Yue  Gao"], "year": 2019, "n_citations": 209}
{"id": 1738778, "s2_id": "f8deb92dc04f282eb22ccdbf71e78e2f382df2d5", "title": "Application of Convolutional Neural Network to Predict Airfoil Lift Coefficient", "abstract": "The adaptability of the convolutional neural network (CNN) technique for aerodynamic meta-modeling tasks is probed in this work. The primary objective is to develop suitable CNN architecture for variable flow conditions and object geometry, in addition to identifying a sufficient data preparation process. Multiple CNN structures were trained to learn the lift coefficients of the airfoils with a variety of shapes in multiple flow Mach numbers, Reynolds numbers, and diverse angles of attack. This is conducted to illustrate the concept of the technique. A multi-layered perceptron (MLP) is also used for the training sets. The MLP results are compared with that of the CNN results. The newly proposed meta-modeling concept has been found to be comparable with the MLP in learning capability; and more importantly, our CNN model exhibits a competitive prediction accuracy with minimal constraints in a geometric representation.", "venue": "ArXiv", "authors": ["Yao  Zhang", "WoongJe  Sung", "Dimitri N. Mavris"], "year": 2017, "n_citations": 76}
{"id": 1740640, "s2_id": "94ac235b4d9dfb4795e81defd86833e0db90d9f3", "title": "Needmining: identifying micro Blog Data containing Customer Needs", "abstract": "The design of new products and services starts with the identification of needs of potential customers or users. Many existing methods like observations, surveys, and experiments draw upon specific efforts to elicit unsatisfied needs from individuals. At the same time, a huge amount of user-generated content in micro blogs is freely accessible at no cost. While this information is already analyzed to monitor sentiments towards existing offerings, it has not yet been tapped for the elicitation of needs. In this paper, we lay an important foundation for this endeavor: we propose a Machine Learning approach to identify those posts that do express needs. Our evaluation of tweets in the e-mobility domain demonstrates that the small share of relevant tweets can be identified with remarkable precision or recall results. Applied to huge data sets, the developed method should enable scalable need elicitation support for innovation managers - across thousands of users, and thus augment the service design tool set available to him.", "venue": "ECIS", "authors": ["Niklas  Kuehl", "Jan  Scheurenbrand", "Gerhard  Satzger"], "year": 2016, "n_citations": 18}
{"id": 1747022, "s2_id": "1f1d3f0f32582c485a44ba98eca13ced8e3747c0", "title": "Piecewise Linear Regression via a Difference of Convex Functions", "abstract": "We present a new piecewise linear regression methodology that utilizes fitting a difference of convex functions (DC functions) to the data. These are functions $f$ that may be represented as the difference $\\phi_1 - \\phi_2$ for a choice of convex functions $\\phi_1, \\phi_2$. The method proceeds by estimating piecewise-liner convex functions, in a manner similar to max-affine regression, whose difference approximates the data. The choice of the function is regularised by a new seminorm over the class of DC functions that controls the $\\ell_\\infty$ Lipschitz constant of the estimate. The resulting methodology can be efficiently implemented via Quadratic programming even in high dimensions, and is shown to have close to minimax statistical risk. We empirically validate the method, showing it to be practically implementable, and to have comparable performance to existing regression/classification methods on real-world datasets.", "venue": "ICML", "authors": ["Ali  Siahkamari", "Aditya  Gangrade", "Brian  Kulis", "Venkatesh  Saligrama"], "year": 2020, "n_citations": 2}
{"id": 1755604, "s2_id": "b443b37d486d7c9e26617f37006c5a67170eb0f3", "title": "Wake-Cough: cough spotting and cougher identification for personalised long-term cough monitoring", "abstract": "We present 'wake-cough', an application of wake-word spotting to coughs using Resnet50 and identifying coughers using i-vectors, for the purpose of a long-term, personalised cough monitoring system. Coughs, recorded in a quiet (73$\\pm$5 dB) and noisy (34$\\pm$17 dB) environment, were used to extract i-vectors, x-vectors and d-vectors, used as features to the classifiers. The system achieves 90.02\\% accuracy from an MLP to discriminate 51 coughers using 2-sec long cough segments in the noisy environment. When discriminating between 5 and 14 coughers using longer (100 sec) segments in the quiet environment, this accuracy rises to 99.78\\% and 98.39\\% respectively. Unlike speech, i-vectors outperform x-vectors and d-vectors in identifying coughers. These coughs were added as an extra class in the Google Speech Commands dataset and features were extracted by preserving the end-to-end time-domain information in an event. The highest accuracy of 88.58\\% is achieved in spotting coughs among 35 other trigger phrases using a Resnet50. Wake-cough represents a personalised, non-intrusive, cough monitoring system, which is power efficient as using wake-word detection method can keep a smartphone-based monitoring device mostly dormant. This makes wake-cough extremely attractive in multi-bed ward environments to monitor patient's long-term recovery from lung ailments such as tuberculosis and COVID-19.", "venue": "ArXiv", "authors": ["Madhurananda  Pahar", "Marisa  Klopper", "Byron  Reeve", "Rob  Warren", "Grant  Theron", "Andreas  Diacon", "Thomas  Niesler"], "year": 2021, "n_citations": 0}
{"id": 1760778, "s2_id": "bc87279d4b32a425377ff18ab63f7ecf95ff228c", "title": "Rethinking embedding coupling in pre-trained language models", "abstract": "We re-evaluate the standard practice of sharing weights between input and output embeddings in state-of-the-art pre-trained language models. We show that decoupled embeddings provide increased modeling flexibility, allowing us to significantly improve the efficiency of parameter allocation in the input embedding of multilingual models. By reallocating the input embedding parameters in the Transformer layers, we achieve dramatically better performance on standard natural language understanding tasks with the same number of parameters during fine-tuning. We also show that allocating additional capacity to the output embedding provides benefits to the model that persist through the fine-tuning stage even though the output embedding is discarded after pre-training. Our analysis shows that larger output embeddings prevent the model's last layers from overspecializing to the pre-training task and encourage Transformer representations to be more general and more transferable to other tasks and languages. Harnessing these findings, we are able to train models that achieve strong performance on the XTREME benchmark without increasing the number of parameters at the fine-tuning stage.", "venue": "ICLR", "authors": ["Hyung Won Chung", "Thibault  F'evry", "Henry  Tsai", "Melvin  Johnson", "Sebastian  Ruder"], "year": 2021, "n_citations": 16}
{"id": 1767193, "s2_id": "705bf5166045b97744b619661a53372ef72dd013", "title": "Ensemble Maximum Entropy Classification and Linear Regression for Author Age Prediction", "abstract": "The evolution of the Internet has created an abundance of unstructured data on the web, a significant part of which is textual. The task of author profiling seeks to find the demographics of people solely from their linguistic and content-based features in text. The ability to describe traits of authors clearly has applications in fields such as security and forensics, as well as marketing. Instead of seeing age as just a classification problem, we also frame age as a regression one, but use an ensemble chain method that incorporates the power of both classification and regression to learn the author's exact age.", "venue": "2017 IEEE International Conference on Information Reuse and Integration (IRI)", "authors": ["Joey  Hong", "Chris  Mattmann", "Paul M. Ramirez"], "year": 2017, "n_citations": 5}
{"id": 1773414, "s2_id": "4f728b8e5c4dccfcc0f00b1bca61d3e9e11969f8", "title": "A Bayesian non-parametric method for clustering high-dimensional binary data", "abstract": "In many real life problems, objects are described by large number of binary features. For instance, documents are characterized by presence or absence of certain keywords; cancer patients are characterized by presence or absence of certain mutations etc. In such cases, grouping together similar objects/profiles based on such high dimensional binary features is desirable, but challenging. Here, I present a Bayesian non parametric algorithm for clustering high dimensional binary data. It uses a Dirichlet Process (DP) mixture model and simulated annealing to not only cluster binary data, but also find optimal number of clusters in the data. The performance of the algorithm was evaluated and compared with other algorithms using simulated datasets. It outperformed all other clustering methods that were tested in the simulation studies. It was also used to cluster real datasets arising from document analysis, handwritten image analysis and cancer research. It successfully divided a set of documents based on their topics, hand written images based on different styles of writing digits and identified tissue and mutation specificity of chemotherapy treatments.", "venue": "ArXiv", "authors": ["Tapesh  Santra"], "year": 2016, "n_citations": 7}
{"id": 1782533, "s2_id": "057fae7b0d8017a110007aafa03861be55f08548", "title": "Explainable Matrix - Visualization for Global and Local Interpretability of Random Forest Classification Ensembles", "abstract": "Over the past decades, classification models have proven to be essential machine learning tools given their potential and applicability in various domains. In these years, the north of the majority of the researchers had been to improve quantitative metrics, notwithstanding the lack of information about models' decisions such metrics convey. This paradigm has recently shifted, and strategies beyond tables and numbers to assist in interpreting models' decisions are increasing in importance. Part of this trend, visualization techniques have been extensively used to support classification models' interpretability, with a significant focus on rule-based models. Despite the advances, the existing approaches present limitations in terms of visual scalability, and the visualization of large and complex models, such as the ones produced by the Random Forest (RF) technique, remains a challenge. In this paper, we propose Explainable Matrix (ExMatrix), a novel visualization method for RF interpretability that can handle models with massive quantities of rules. It employs a simple yet powerful matrix-like visual metaphor, where rows are rules, columns are features, and cells are rules predicates, enabling the analysis of entire models and auditing classification results. ExMatrix applicability is confirmed via different examples, showing how it can be used in practice to promote RF models interpretability.", "venue": "IEEE Transactions on Visualization and Computer Graphics", "authors": ["M'ario Popolin Neto", "Fernando V. Paulovich"], "year": 2021, "n_citations": 11}
{"id": 1787767, "s2_id": "2946a53cf1640e7cf9c51b8b53817a64a8639723", "title": "Process Mining Model to Predict Mortality in Paralytic Ileus Patients", "abstract": "Paralytic Ileus (PI) patients are at high risk of death when admitted to the Intensive care unit (ICU), with mortality as high as 40%. There is minimal research concerning PI patient mortality prediction. There is a need for more accurate prediction modeling for ICU patients diagnosed with PI. This paper demonstrates performance improvements in predicting the mortality of ICU patients diagnosed with PI after 24 hours of being admitted. The proposed framework, PMPI(Process Mining Model to predict mortality of PI patients), is a modification of the work used for prediction of in-hospital mortality for ICU patients with diabetes. PMPI demonstrates similar if not better performance with an Area under the ROC Curve (AUC) score of 0.82 compared to the best results of the existing literature. PMPI uses patient medical history, the time related to the events, and demographic information for prediction. The PMPI prediction framework has the potential to help medical teams in making better decisions for treatment and care for ICU patients with PI to increase their life expectancy.", "venue": "ArXiv", "authors": ["Maryam  Pishgar", "Martha  Razo", "Julian  Theis", "Houshang  Darabi"], "year": 2021, "n_citations": 1}
{"id": 1798289, "s2_id": "57418744d5dec50bd3203d1209b7c4ab271b7456", "title": "Tight Bounds on Low-Degree Spectral Concentration of Submodular and XOS Functions", "abstract": "Submodular and fractionally subadditive (or equivalently XOS) functions play a fundamental role in combinatorial optimization, algorithmic game theory and machine learning. Motivated by learnability of these classes of functions from random examples, we consider the question of how well such functions can be approximated by low-degree polynomials in \u2113<sub>2</sub> norm over the uniform distribution. This question is equivalent to understanding the concentration of Fourier weight on low-degree coefficients, a central concept in Fourier analysis. Denoting the smallest degree sufficient to approximate f in \u2113<sub>2</sub> norm within \u2208 by deg<sub>\u2208</sub>(\u2113<sub>2</sub>)(f), we show that : For any submodular function f : {0, 1}<sup>n</sup> \u2192 [0, 1], deg<sub>\u2208</sub>(\u2113<sub>2</sub>)(f) = O(log(1/\u2208)/\u2208<sup>4/5</sup>) and there is a submodular function that requires degree \u03a9(1/\u2208<sup>4/5</sup>). : For any XOS function f : {0, 1} \u2192 [0, 1], deg<sub>\u2208</sub>(\u2113<sub>2</sub>) (f) = O(1/\u2208) and there exists an XOS function that requires degree \u03a9(1/\u2208). This improves on previous approaches that all showed an upper bound of O(1/\u2208<sup>2</sup>) for submodular [CKKL12], [FKV13], [FV13] and XOS [FV13] functions. The best previous lower bound was \u03a9(1/\u2208<sup>2/3</sup>) for monotone submodular functions [FKV13]. Our techniques reveal new structural properties of submodular and XOS functions and the upper bounds lead to nearly optimal PAC learning algorithms for these classes of functions.", "venue": "2015 IEEE 56th Annual Symposium on Foundations of Computer Science", "authors": ["Vitaly  Feldman", "Jan  Vondr\u00e1k"], "year": 2015, "n_citations": 13}
{"id": 1799916, "s2_id": "b0d362d61e7afdf8e13a0799203f9ce8deb66e7e", "title": "Machine Learning and the Internet of Things Enable Steam Flood Optimization for Improved Oil Production", "abstract": "Recently developed machine learning techniques, in association with the Internet of Things (IoT) allow for the implementation of a method of increasing oil production from heavy-oil wells. Steam flood injection, a widely used enhanced oil recovery technique, uses thermal and gravitational potential to mobilize and dilute heavy oil in situ to increase oil production. In contrast to traditional steam flood simulations based on principles of classic physics, we introduce here an approach using cutting-edge machine learning techniques that have the potential to provide a better way to describe the performance of steam flood. We propose a workflow to address a category of time-series data that can be analyzed with supervised machine learning algorithms and IoT. We demonstrate the effectiveness of the technique for forecasting oil production in steam flood scenarios. Moreover, we build an optimization system that recommends an optimal steam allocation plan, and show that it leads to a 3% improvement in oil production. We develop a minimum viable product on a cloud platform that can implement real-time data collection, transfer, and storage, as well as the training and implementation of a cloud-based machine learning model. This workflow also offers an applicable solution to other problems with similar time-series data structures, like predictive maintenance.", "venue": "ArXiv", "authors": ["Mi  Yan", "Jonathan C. MacDonald", "Chris T. Reaume", "Wesley  Cobb", "Tamas  Toth", "Sarah S. Karthigan"], "year": 2019, "n_citations": 1}
{"id": 1842059, "s2_id": "8706660fbf3110338bc794e354bc3d1c0075d230", "title": "Quantifying the Scanner-Induced Domain Gap in Mitosis Detection", "abstract": "Automated detection of mitotic figures in histopathology images has seen vast improvements, thanks to modern deep learning-based pipelines. Application of these methods, however, is in practice limited by strong variability of images between labs. This results in a domain shift of the images, which causes a performance drop of the models. Hypothesizing that the scanner device plays a decisive role in this effect, we evaluated the susceptibility of a standard mitosis detection approach to the domain shift introduced by using a different whole slide scanner. Our work is based on the MICCAI-MIDOG challenge 2021 data set, which includes 200 tumor cases of human breast cancer and four scanners. Our work indicates that the domain shift induced not by biochemical variability but purely by the choice of acquisition device is underestimated so far. Models trained on images of the same scanner yielded an average F1 score of 0.683, while models trained on a single other scanner only yielded an average F1 score of 0.325. Training on another multidomain mitosis dataset led to mean F1 scores of 0.52. We found this not to be reflected by domain-shifts measured as proxy A distance-derived metric.", "venue": "ArXiv", "authors": ["Marc  Aubreville", "Christof  Bertram", "Mitko  Veta", "Robert  Klopfleisch", "Nikolas  Stathonikos", "Katharina  Breininger", "Natalie ter Hoeve", "Francesco  Ciompi", "Andreas  Maier"], "year": 2021, "n_citations": 3}
{"id": 1848755, "s2_id": "7158add7b3b6036c365d8681ba980157786dbcc5", "title": "Taming Sparsely Activated Transformer with Stochastic Experts", "abstract": "Sparsely activated models (SAMs), such as Mixture-of-Experts (MoE), can easily scale to have outrageously large amounts of parameters without significant increase in computational cost. However, SAMs are reported to be parameter inefficient such that larger models do not always lead to better performance. While most on-going research focuses on improving SAMs models by exploring methods of routing inputs to experts, our analysis reveals that such research might not lead to the solution we expect, i.e., the commonly-used routing methods based on gating mechanisms do not work better than randomly routing inputs to experts. In this paper, we propose a new expert-based model, THOR (Transformer witH StOchastic ExpeRts). Unlike classic expert-based models, such as the Switch Transformer (Fedus et al., 2021), experts in THOR are randomly activated for each input during training and inference. THOR models are trained using a consistency regularized loss, where experts learn not only from training data but also from other experts as teachers, such that all the experts make consistent predictions. We validate the effectiveness of THOR on machine translation tasks. Results show that THOR models are more parameter efficient in that they significantly outperform the Transformer and MoE models across various settings. For example, in multilingual translation, THOR outperforms the Switch Transformer by 2 BLEU scores, and obtains the same BLEU score as that of a state-of-the-art MoE model (Kim et al., 2021) that is 18 times larger. Our code is publicly available at: https://github.com/microsoft/ Stochastic-Mixture-of-Experts.", "venue": "ArXiv", "authors": ["Simiao  Zuo", "Xiaodong  Liu", "Jian  Jiao", "Young Jin Kim", "Hany  Hassan", "Ruofei  Zhang", "Tuo  Zhao", "Jianfeng  Gao"], "year": 2021, "n_citations": 0}
{"id": 1850208, "s2_id": "44b013fa4409dd0109a954744b261565327f3872", "title": "Inferring Personalized Bayesian Embeddings for Learning from Heterogeneous Demonstration", "abstract": "For assistive robots and virtual agents to achieve ubiquity, machines will need to anticipate the needs of their human counterparts. The field of Learning from Demonstration (LfD) has sought to enable machines to infer predictive models of human behavior for autonomous robot control. However, humans exhibit heterogeneity in decision-making, which traditional LfD approaches fail to capture. To overcome this challenge, we propose a Bayesian LfD framework to infer an integrated representation of all human task demonstrators by inferring human-specific embeddings, thereby distilling their unique characteristics. We validate our approach is able to outperform state-of-the-art techniques on both synthetic and real-world data sets.", "venue": "ArXiv", "authors": ["Rohan R. Paleja", "Matthew C. Gombolay"], "year": 2019, "n_citations": 3}
{"id": 1851985, "s2_id": "d3759f651e26bffbc4ca3e41c7453d6800e0c682", "title": "Graph Robustness Benchmark: Benchmarking the Adversarial Robustness of Graph Machine Learning", "abstract": "Adversarial attacks on graphs have posed a major threat to the robustness of graph machine learning (GML) models. Naturally, there is an ever-escalating arms race between attackers and defenders. However, the strategies behind both sides are often not fairly compared under the same and realistic conditions. To bridge this gap, we present the Graph Robustness Benchmark (GRB) with the goal of providing a scalable, unified, modular, and reproducible evaluation for the adversarial robustness of GML models. GRB standardizes the process of attacks and defenses by 1) developing scalable and diverse datasets, 2) modularizing the attack and defense implementations, and 3) unifying the evaluation protocol in refined scenarios. By leveraging the GRB pipeline, the end-users can focus on the development of robust GML models with automated data processing and experimental evaluations. To support open and reproducible research on graph adversarial learning, GRB also hosts public leaderboards across different scenarios. As a starting point, we conduct extensive experiments to benchmark baseline techniques. GRB is open-source and welcomes contributions from the community. Datasets, codes, leaderboards are available at https://cogdl.ai/grb/home.", "venue": "ArXiv", "authors": ["Qinkai  Zheng", "Xu  Zou", "Yuxiao  Dong", "Yukuo  Cen", "Da  Yin", "Jiarong  Xu", "Yang  Yang", "Jie  Tang"], "year": 2021, "n_citations": 0}
{"id": 1860676, "s2_id": "6eebd1859ef5d1c83190ad494ad96f87880d2869", "title": "One-shot Text Field labeling using Attention and Belief Propagation for Structure Information Extraction", "abstract": "Structured information extraction from document images usually consists of three steps: text detection, text recognition, and text field labeling. While text detection and text recognition have been heavily studied and improved a lot in literature, text field labeling is less explored and still faces many challenges. Existing learning based methods for text labeling task usually require a large amount of labeled examples to train a specific model for each type of document. However, collecting large amounts of document images and labeling them is difficult and sometimes impossible due to privacy issues. Deploying separate models for each type of document also consumes a lot of resources. Facing these challenges, we explore one-shot learning for the text field labeling task. Existing one-shot learning methods for the task are mostly rule-based and have difficulty in labeling fields in crowded regions with few landmarks and fields consisting of multiple separate text regions. To alleviate these problems, we proposed a novel deep end-to-end trainable approach for one-shot text field labeling, which makes use of attention mechanism to transfer the layout information between document images. We further applied conditional random field on the transferred layout information for the refinement of field labeling. We collected and annotated a real-world one-shot field labeling dataset with a large variety of document types and conducted extensive experiments to examine the effectiveness of the proposed model. To stimulate research in this direction, the collected dataset and the one-shot model will be released (https://github.com/AlibabaPAI/one_shot_text_labeling).", "venue": "ACM Multimedia", "authors": ["Mengli  Cheng", "Minghui  Qiu", "Xing  Shi", "Jun  Huang", "Wei  Lin"], "year": 2020, "n_citations": 5}
{"id": 1865212, "s2_id": "d42322413d8f34552e86b2f9cc8e01a106312ab7", "title": "CubeTR: Learning to Solve The Rubiks Cube Using Transformers", "abstract": "Since its first appearance, transformers have been successfully used in wide ranging domains from computer vision to natural language processing. Application of transformers in Reinforcement Learning by reformulating it as a sequence modelling problem was proposed only recently. Compared to other commonly explored reinforcement learning problems, the Rubik\u2019s cube poses a unique set of challenges. The Rubik\u2019s cube has a single solved state for quintillions of possible configurations which leads to extremely sparse rewards. The proposed model CubeTR attends to longer sequences of actions and addresses the problem of sparse rewards. CubeTR learns how to solve the Rubik\u2019s cube from arbitrary starting states without any human prior, and after move regularisation, the lengths of solutions generated by it are expected to be very close to those given by algorithms used by expert human solvers. CubeTR provides insights to the generalisability of learning algorithms to higher dimensional cubes and the applicability of transformers in other relevant sparse reward scenarios.", "venue": "ArXiv", "authors": ["Mustafa Ebrahim Chasmai"], "year": 2021, "n_citations": 0}
{"id": 1868265, "s2_id": "3bba04f4153fdd6025efaea0b1b53b94157325c2", "title": "Sequential Gaussian Processes for Online Learning of Nonstationary Functions", "abstract": "Many machine learning problems can be framed in the context of estimating functions, and often these are time-dependent functions that are estimated in real-time as observations arrive. Gaussian processes (GPs) are an attractive choice for modeling real-valued nonlinear functions due to their flexibility and uncertainty quantification. However, the typical GP regression model suffers from several drawbacks: i) Conventional GP inference scales $O(N^{3})$ with respect to the number of observations; ii) updating a GP model sequentially is not trivial; and iii) covariance kernels often enforce stationarity constraints on the function, while GPs with non-stationary covariance kernels are often intractable to use in practice. To overcome these issues, we propose an online sequential Monte Carlo algorithm to fit mixtures of GPs that capture non-stationary behavior while allowing for fast, distributed inference. By formulating hyperparameter optimization as a multi-armed bandit problem, we accelerate mixing for real time inference. Our approach empirically improves performance over state-of-the-art methods for online GP estimation in the context of prediction for simulated non-stationary data and hospital time series data.", "venue": "ArXiv", "authors": ["Michael Minyi Zhang", "Bianca  Dumitrascu", "Sinead A. Williamson", "Barbara E. Engelhardt"], "year": 2019, "n_citations": 1}
{"id": 1882360, "s2_id": "9b5ef0ddbd913d966b7e313489bfaa43f283c2e6", "title": "Driver Safety Development: Real-Time Driver Drowsiness Detection System Based on Convolutional Neural Network", "abstract": "This paper focuses on the challenge of driver safety on the road and presents a novel system for driver drowsiness detection. In this system, to detect the falling sleep state of the driver as the sign of drowsiness, Convolutional Neural Networks (CNN) are used with regarding the two goals of real-time application, including high accuracy and fastness. Three networks introduced as a potential network for eye status classification in which one of them is a Fully Designed Neural Network (FD-NN) and others use Transfer Learning in VGG16 and VGG19 with extra designed layers (TL-VGG). Lack of an available and accurate eye dataset strongly feels in the area of eye closure detection. Therefore, a new comprehensive dataset proposed. The experimental results show the high accuracy and low computational complexity of the eye closure estimation and the ability of the proposed framework on drowsiness detection.", "venue": "SN Comput. Sci.", "authors": ["Maryam  Hashemi", "Alireza  Mirrashid", "Aliasghar Beheshti Shirazi"], "year": 2020, "n_citations": 2}
{"id": 1885919, "s2_id": "017386502557c27d4ffd575b17ed7c2aafed2d95", "title": "Item Tagging for Information Retrieval: A Tripartite Graph Neural Network based Approach", "abstract": "Tagging has been recognized as a successful practice to boost relevance matching for information retrieval (IR), especially when items lack rich textual descriptions. A lot of research has been done for either multi-label text categorization or image annotation. However, there is a lack of published work that targets at item tagging specifically for IR. Directly applying a traditional multi-label classification model for item tagging is sub-optimal, due to the ignorance of unique characteristics in IR. In this work, we propose to formulate item tagging as a link prediction problem between item nodes and tag nodes. To enrich the representation of items, we leverage the query logs available in IR tasks, and construct a query-item-tag tripartite graph. This formulation results in a TagGNN model that utilizes heterogeneous graph neural networks with multiple types of nodes and edges. Different from previous research, we also optimize both full tag prediction and partial tag completion cases in a unified framework via a primary-dual loss mechanism. Experimental results on both open and industrial datasets show that our TagGNN approach outperforms the state-of-the-art multi-label classification approaches.", "venue": "SIGIR", "authors": ["Kelong  Mao", "Xi  Xiao", "Jieming  Zhu", "Biao  Lu", "Ruiming  Tang", "Xiuqiang  He"], "year": 2020, "n_citations": 4}
{"id": 1891945, "s2_id": "768a3c9b428b8b9b3e5548dff0665055a61f3110", "title": "Maximum Entropy Multi-Task Inverse RL", "abstract": "Multi-task IRL allows for the possibility that the expert could be switching between multiple ways of solving the same problem, or interleaving demonstrations of multiple tasks. The learner aims to learn the multiple reward functions that guide these ways of solving the problem. We present a new method for multi-task IRL that generalizes the well-known maximum entropy approach to IRL by combining it with the Dirichlet process based clustering of the observed input. This yields a single nonlinear optimization problem, called MaxEnt Multi-task IRL, which can be solved using the Lagrangian relaxation and gradient descent methods. We evaluate MaxEnt Multi-task IRL in simulation on the robotic task of sorting onions on a processing line where the expert utilizes multiple ways of detecting and removing blemished onions. The method is able to learn the underlying reward functions to a high level of accuracy and it improves on the previous approaches to multi-task IRL.", "venue": "ArXiv", "authors": ["Saurabh  Arora", "Bikramjit  Banerjee", "Prashant  Doshi"], "year": 2020, "n_citations": 0}
{"id": 1905633, "s2_id": "f63d07fe2abf56a33547cce6c170a51d449e5846", "title": "PDH : Probabilistic Deep Hashing Based on Map Estimation of Hamming Distance", "abstract": "With the growth of image on the web, research on hashing which enables high-speed image retrieval has been actively studied. In recent years, various hashing methods based on deep neural networks have been proposed and achieved higher precision than the other hashing methods. In these methods, multiple losses for hash codes and the parameters of neural networks are defined. They generate hash codes that minimize the weighted sum of the losses. Therefore, an expert has to tune the weights for the losses heuristically, and the probabilistic optimality of the loss function cannot be explained. In order to generate explainable hash codes without weight tuning, we theoretically derive a single loss function with no hyperparameters for the hash code from the probability distribution of the images. By generating hash codes that minimize this loss function, highly accurate image retrieval with probabilistic optimality is performed. We evaluate the performance of hashing using MNIST, CIFAR-10, SVHN and show that the proposed method outperforms the state-of-the-art hashing methods.", "venue": "2019 IEEE International Conference on Image Processing (ICIP)", "authors": ["Yosuke  Kaga", "Masakazu  Fujio", "Kenta  Takahashi", "Tetsushi  Ohki", "Masakatsu  Nishigaki"], "year": 2019, "n_citations": 0}
{"id": 1907806, "s2_id": "7f671e03d2501938d9258b5b7b5c603e876415b3", "title": "Sequential Predictions based on Algorithmic Complexity", "abstract": "This paper studies sequence prediction based on the monotone Kolmogorov complexity Km=-logm, i.e. based on universal deterministic/one-part MDL. m is extremely close to Solomonoff's universal prior M, the latter being an excellent predictor in deterministic as well as probabilistic environments, where performance is measured in terms of convergence of posteriors or losses. Despite this closeness to M, it is difficult to assess the prediction quality of m, since little is known about the closeness of their posteriors, which are the important quantities for prediction. We show that for deterministic computable environments, the ''posterior'' and losses of m converge, but rapid convergence could only be shown on-sequence; the off-sequence convergence can be slow. In probabilistic environments, neither the posterior nor the losses converge, in general.", "venue": "J. Comput. Syst. Sci.", "authors": ["Marcus  Hutter"], "year": 2006, "n_citations": 11}
{"id": 1919458, "s2_id": "e967d97f031fba3e2368afcbdca07555bcb378aa", "title": "Hybrid Recommender System based on Autoencoders", "abstract": "A standard model for Recommender Systems is the Matrix Completion setting: given partially known matrix of ratings given by users (rows) to items (columns), infer the unknown ratings. In the last decades, few attempts where done to handle that objective with Neural Networks, but recently an architecture based on Autoencoders proved to be a promising approach. In current paper, we enhanced that architecture (i) by using a loss function adapted to input data with missing values, and (ii) by incorporating side information. The experiments demonstrate that while side information only slightly improve the test error averaged on all users/items, it has more impact on cold users/items.", "venue": "DLRS@RecSys", "authors": ["Florian  Strub", "J'er'emie  Mary", "Romaric  Gaudel"], "year": 2016, "n_citations": 149}
{"id": 1920014, "s2_id": "469c8d68e8582e1e2dfed92442707afd251dd989", "title": "Testing the Generalization of Neural Language Models for COVID-19 Misinformation Detection", "abstract": "A drastic rise in potentially life-threatening misinformation has been a by-product of the COVID-19 pandemic. Computational support to identify false information within the massive body of data on the topic is crucial to prevent harm. Researchers proposed many methods for flagging online misinformation related to COVID-19. However, these methods predominantly target specific content types (e.g., news) or platforms (e.g., Twitter). The methods' capabilities to generalize were largely unclear so far. We evaluate fifteen Transformer-based models on five COVID-19 misinformation datasets that include social media posts, news articles, and scientific papers to fill this gap. We show tokenizers and models tailored to COVID-19 data do not provide a significant advantage over general-purpose ones. Our study provides a realistic assessment of models for detecting COVID-19 misinformation. We expect that evaluating a broad spectrum of datasets and models will benefit future research in developing misinformation detection systems.", "venue": "ArXiv", "authors": ["Jan Philip Wahle", "Nischal  Ashok", "Terry  Ruas", "Norman  Meuschke", "Tirthankar  Ghosal", "Bela  Gipp"], "year": 2021, "n_citations": 1}
{"id": 1924263, "s2_id": "65baa7d5fb287426300db7cc0b6b7b2a035ecafc", "title": "Continuous Emotion Recognition via Deep Convolutional Autoencoder and Support Vector Regressor", "abstract": "Automatic facial expression recognition (FER) is an important research area in the emotion recognition and computer vision. Applications can be found in several domains such as medical treatment, driver fatigue surveillance, sociable robotics, and several other human-computer interaction systems. Therefore, it is crucial that the machine should be able to recognize the emotional state of the user with high accuracy. In recent years, deep neural networks have been used with great success in recognizing emotions. In this paper, we present a new model for continuous emotion recognition based on FER by using an unsupervised learning approach based on transfer learning and autoencoders. The proposed approach also includes preprocessing and post-processing techniques which contribute favorably to improving the performance of predicting the concordance correlation coefficient for arousal and valence dimensions. Experimental results for predicting spontaneous and natural emotions on the RECOLA 2016 dataset have shown that the proposed approach based on visual information can achieve concordance correlation coefficient of 0.516 and 0.264 for valence and arousal, respectively.", "venue": "2020 International Joint Conference on Neural Networks (IJCNN)", "authors": ["Sevegni Odilon Clement Allognon", "Alessandro L. Koerich", "Alceu de S. Britto"], "year": 2020, "n_citations": 1}
{"id": 1939962, "s2_id": "8976e91ccae57a20c29f3c9d88bf45b19973c952", "title": "Fixing a Broken ELBO", "abstract": "Recent work in unsupervised representation learning has focused on learning deep directed latent-variable models. Fitting these models by maximizing the marginal likelihood or evidence is typically intractable, thus a common approximation is to maximize the evidence lower bound (ELBO) instead. However, maximum likelihood training (whether exact or approximate) does not necessarily result in a good latent representation, as we demonstrate both theoretically and empirically. In particular, we derive variational lower and upper bounds on the mutual information between the input and the latent variable, and use these bounds to derive a rate-distortion curve that characterizes the tradeoff between compression and reconstruction accuracy. Using this framework, we demonstrate that there is a family of models with identical ELBO, but different quantitative and qualitative characteristics. Our framework also suggests a simple new method to ensure that latent variable models with powerful stochastic decoders do not ignore their latent code.", "venue": "ICML", "authors": ["Alexander A. Alemi", "Ben  Poole", "Ian  Fischer", "Joshua V. Dillon", "Rif A. Saurous", "Kevin  Murphy"], "year": 2018, "n_citations": 302}
{"id": 1949857, "s2_id": "82fa429abe1926cbf3fbbea9f8787f8238dfb4ec", "title": "On Data Preconditioning for Regularized Loss Minimization", "abstract": "In this work, we study data preconditioning, a well-known and long-existing technique, for boosting the convergence of first-order methods for regularized loss minimization in machine learning. It is well understood that the condition number of the problem, i.e., the ratio of the Lipschitz constant to the strong convexity modulus, has a harsh effect on the convergence of the first-order optimization methods. Therefore, minimizing a small regularized loss for achieving good generalization performance, yielding an ill conditioned problem, becomes the bottleneck for big data problems. We provide a theory on data preconditioning for regularized loss minimization. In particular, our analysis exhibits an appropriate data preconditioner that is similar to zero component analysis whitening. Exploiting the concepts of numerical rank and coherence, we characterize the conditions on the loss function and on the data under which data preconditioning can reduce the condition number and therefore boost the convergence for minimizing the regularized loss. To make the data preconditioning practically useful, we propose an efficient preconditioning method through random sampling. The preliminary experiments on simulated data sets and real data sets validate our theory.", "venue": "Machine Learning", "authors": ["Tianbao  Yang", "Rong  Jin", "Shenghuo  Zhu"], "year": 2015, "n_citations": 8}
{"id": 1956914, "s2_id": "f4748a79d1228973a82119e2a8e5159db818be6a", "title": "On the benefits of maximum likelihood estimation for Regression and Forecasting", "abstract": "We advocate for a practical Maximum Likelihood Estimation (MLE) approach for regression and forecasting, as an alternative to the typical approach of Empirical Risk Minimization (ERM) for a specific target metric. This approach is better suited to capture inductive biases such as prior domain knowledge in datasets, and can output post-hoc estimators at inference time that can optimize different types of target metrics. We present theoretical results to demonstrate that our approach is always competitive with any estimator for the target metric under some general conditions, and in many practical settings (such as Poisson Regression) can actually be much superior to ERM. We demonstrate empirically that our method instantiated with a well-designed general purpose mixture likelihood family can obtain superior performance over ERM for a variety of tasks across time-series forecasting and regression datasets with different data distributions.", "venue": "ArXiv", "authors": ["Pranjal  Awasthi", "Abhimanyu  Das", "Rajat  Sen", "Ananda Theertha Suresh"], "year": 2021, "n_citations": 0}
{"id": 1957100, "s2_id": "0a2a6ceb81855761e8e5d14ec43901714d455b92", "title": "Self-Adversarial Learning with Comparative Discrimination for Text Generation", "abstract": "Conventional Generative Adversarial Networks (GANs) for text generation tend to have issues of reward sparsity and mode collapse that affect the quality and diversity of generated samples. To address the issues, we propose a novel self-adversarial learning (SAL) paradigm for improving GANs' performance in text generation. In contrast to standard GANs that use a binary classifier as its discriminator to predict whether a sample is real or generated, SAL employs a comparative discriminator which is a pairwise classifier for comparing the text quality between a pair of samples. During training, SAL rewards the generator when its currently generated sentence is found to be better than its previously generated samples. This self-improvement reward mechanism allows the model to receive credits more easily and avoid collapsing towards the limited number of real samples, which not only helps alleviate the reward sparsity issue but also reduces the risk of mode collapse. Experiments on text generation benchmark datasets show that our proposed approach substantially improves both the quality and the diversity, and yields more stable performance compared to the previous GANs for text generation.", "venue": "ICLR", "authors": ["Wangchunshu  Zhou", "Tao  Ge", "Ke  Xu", "Furu  Wei", "Ming  Zhou"], "year": 2020, "n_citations": 8}
{"id": 1959484, "s2_id": "321331b997b6cd718552b0df919aeae2afcf3a7f", "title": "The Extended Littlestone's Dimension for Learning with Mistakes and Abstentions", "abstract": "This paper studies classification with an abstention option in the online setting. In this setting, examples arrive sequentially, the learner is given a hypothesis class $\\mathcal H$, and the goal of the learner is to either predict a label on each example or abstain, while ensuring that it does not make more than a pre-specified number of mistakes when it does predict a label. \nPrevious work on this problem has left open two main challenges. First, not much is known about the optimality of algorithms, and in particular, about what an optimal algorithmic strategy is for any individual hypothesis class. Second, while the realizable case has been studied, the more realistic non-realizable scenario is not well-understood. In this paper, we address both challenges. First, we provide a novel measure, called the Extended Littlestone's Dimension, which captures the number of abstentions needed to ensure a certain number of mistakes. Second, we explore the non-realizable case, and provide upper and lower bounds on the number of abstentions required by an algorithm to guarantee a specified number of mistakes.", "venue": "COLT", "authors": ["Chicheng  Zhang", "Kamalika  Chaudhuri"], "year": 2016, "n_citations": 13}
{"id": 1969596, "s2_id": "4ff9a9248dceb00a7d02073815c085911d5c0a59", "title": "Discovering Generalizable Skills via Automated Generation of Diverse Tasks", "abstract": "The learning efficiency and generalization ability of an intelligent agent can be greatly improved by utilizing a useful set of skills. However, the design of robot skills can often be intractable in real-world applications due to the prohibitive amount of effort and expertise that it requires. In this work, we introduce Skill Learning In Diversified Environments (SLIDE), a method to discover generalizable skills via automated generation of a diverse set of tasks. As opposed to prior work on unsupervised discovery of skills which incentivizes the skills to produce different outcomes in the same environment, our method pairs each skill with a unique task produced by a trainable task generator. To encourage generalizable skills to emerge, our method trains each skill to specialize in the paired task and maximizes the diversity of the generated tasks. A task discriminator defined on the robot behaviors in the generated tasks is jointly trained to estimate the evidence lower bound of the diversity objective. The learned skills can then be composed in a hierarchical reinforcement learning algorithm to solve unseen target tasks. We demonstrate that the proposed method can effectively learn a variety of robot skills in two tabletop manipulation domains. Our results suggest that the learned skills can effectively improve the robot\u2019s performance in various unseen target tasks compared to existing reinforcement learning and skill learning methods.", "venue": "Robotics: Science and Systems", "authors": ["Kuan  Fang", "Yuke  Zhu", "Silvio  Savarese", "Li  Fei-Fei"], "year": 2021, "n_citations": 1}
{"id": 1969622, "s2_id": "4593c28b0f19d6a8e4d53e96695d1f47ddc1bec7", "title": "Multi-Merge Budget Maintenance for Stochastic Gradient Descent SVM Training", "abstract": "Budgeted Stochastic Gradient Descent (BSGD) is a state-of-the-art technique for training large-scale kernelized support vector machines. The budget constraint is maintained incrementally by merging two points whenever the pre-defined budget is exceeded. The process of finding suitable merge partners is costly; it can account for up to 45% of the total training time. In this paper we investigate computationally more efficient schemes that merge more than two points at once. We obtain significant speed-ups without sacrificing accuracy.", "venue": "ArXiv", "authors": ["Sahar  Qaadan", "Tobias  Glasmachers"], "year": 2018, "n_citations": 0}
{"id": 1972998, "s2_id": "8c9a8f646851d3ec09d02678c9040e666204ffbd", "title": "A Dual Process Model for Optimizing Cross Entropy in Neural Networks", "abstract": "Minimizing cross-entropy is a widely used method for training artificial neural networks. Many training procedures based on backpropagation use cross-entropy directly as their loss function. Instead, this theoretical essay investigates a dual process model with two processes, in which one process minimizes the Kullback\u2013Leibler divergence while its dual counterpart minimizes the Shannon entropy. Postulating that learning consists of two dual processes complementing each other, the model defines an equilibrium state for both processes in which the loss function assumes its minimum. An advantage of the proposed model is that it allows deriving the optimal learning rate and momentum weight to update network weights for backpropagation. Furthermore, the model introduces the golden ratio and complex numbers as important new concepts in machine learning.", "venue": "ArXiv", "authors": ["Stefan  Jaeger"], "year": 2021, "n_citations": 0}
{"id": 1974867, "s2_id": "07507e1faf0c0d2e43360e09ed920c731a285625", "title": "BACON: Band-limited Coordinate Networks for Multiscale Scene Representation", "abstract": "Coordinate-based networks have emerged as a powerful tool for 3D representation and scene reconstruction. These networks are trained to map continuous input coordinates to the value of a signal at each point. Still, current architectures are black boxes: their spectral characteristics cannot be easily analyzed, and their behavior at unsupervised points is difficult to predict. Moreover, these networks are typically trained to represent a signal at a single scale, and so naive downsampling or upsampling results in artifacts. We introduce band-limited coordinate networks (BACON), a network architecture with an analytical Fourier spectrum. BACON has predictable behavior at unsupervised points, can be designed based on the spectral characteristics of the represented signal, and can represent signals at multiple scales without explicit supervision. We demonstrate BACON for multiscale neural representation of images, radiance fields, and 3D scenes using signed distance functions and show that it outperforms conventional single-scale coordinate networks in terms of interpretability and quality.", "venue": "ArXiv", "authors": ["David B. Lindell", "Dave Van Veen", "Jeong Joon Park", "Gordon  Wetzstein"], "year": 2021, "n_citations": 0}
{"id": 2007515, "s2_id": "a1f8b8226fe6d8c9a85d956d95d8cf062fa64c74", "title": "Automatic Grading of Knee Osteoarthritis on the Kellgren-Lawrence Scale from Radiographs Using Convolutional Neural Networks", "abstract": "The severity of knee osteoarthritis is graded using the 5-point Kellgren-Lawrence (KL) scale where healthy knees are assigned grade 0, and the subsequent grades 1-4 represent increasing severity of the affliction. Although several methods have been proposed in recent years to develop models that can automatically predict the KL grade from a given radiograph, most models have been developed and evaluated on datasets not sourced from India. These models fail to perform well on the radiographs of Indian patients. In this paper, we propose a novel method using convolutional neural networks to automatically grade knee radiographs on the KL scale. Our method works in two connected stages: in the first stage, an object detection model segments individual knees from the rest of the image; in the second stage, a regression model automatically grades each knee separately on the KL scale. We train our model using the publicly available Osteoarthritis Initiative (OAI) dataset and demonstrate that fine-tuning the model before evaluating it on a dataset from a private hospital significantly improves the mean absolute error from 1.09 (95% CI: 1.03-1.15) to 0.28 (95% CI: 0.25-0.32). Additionally, we compare classification and regression models built for the same task and demonstrate that regression outperforms classification.", "venue": "ArXiv", "authors": ["Sudeep  Kondal", "Viraj  Kulkarni", "Ashrika  Gaikwad", "Amit  Kharat", "Aniruddha  Pant"], "year": 2020, "n_citations": 1}
{"id": 2007700, "s2_id": "04ff36791ed6d19a0df4cb0038d486d892b9c1a8", "title": "Decoupled Asynchronous Proximal Stochastic Gradient Descent with Variance Reduction", "abstract": "In the era of big data, optimizing large scale machine learning problems becomes a challenging task and draws significant attention. Asynchronous optimization algorithms come out as a promising solution. Recently, decoupled asynchronous proximal stochastic gradient descent (DAP-SGD) is proposed to minimize a composite function. It is claimed to be able to off-loads the computation bottleneck from server to workers by allowing workers to evaluate the proximal operators, therefore, server just need to do element-wise operations. However, it still suffers from slow convergence rate because of the variance of stochastic gradient is nonzero. In this paper, we propose a faster method, decoupled asynchronous proximal stochastic variance reduced gradient descent method (DAP-SVRG). We prove that our method has linear convergence for strongly convex problem. Large-scale experiments are also conducted in this paper, and results demonstrate our theoretical analysis.", "venue": "ArXiv", "authors": ["Zhouyuan  Huo", "Bin  Gu", "Heng  Huang"], "year": 2016, "n_citations": 5}
{"id": 2015418, "s2_id": "429173b6033ce240e0b5930379417f703d0e38fe", "title": "A Review on Outlier/Anomaly Detection in Time Series Data", "abstract": "Recent advances in technology have brought major breakthroughs in data collection, enabling a large amount of data to be gathered over time and thus generating time series. Mining this data has become an important task for researchers and practitioners in the past few years, including the detection of outliers or anomalies that may represent errors or events of interest. This review aims to provide a structured and comprehensive state-of-the-art on unsupervised outlier detection techniques in the context of time series. To this end, a taxonomy is presented based on the main aspects that characterize an outlier detection technique.", "venue": "ACM Comput. Surv.", "authors": ["Ane  Bl'azquez-Garc'ia", "Angel  Conde", "Usue  Mori", "Jose A. Lozano"], "year": 2021, "n_citations": 56}
{"id": 2023484, "s2_id": "544e4e5df35e18ed1ec0c1f2ed4ea2470a990901", "title": "Characterization of Convex Objective Functions and Optimal Expected Convergence Rates for SGD", "abstract": "We study Stochastic Gradient Descent (SGD) with diminishing step sizes for convex objective functions. We introduce a definitional framework and theory that defines and characterizes a core property, called curvature, of convex objective functions. In terms of curvature we can derive a new inequality that can be used to compute an optimal sequence of diminishing step sizes by solving a differential equation. Our exact solutions confirm known results in literature and allows us to fully characterize a new regularizer with its corresponding expected convergence rates.", "venue": "ICML", "authors": ["Marten van Dijk", "Lam M. Nguyen", "Phuong Ha Nguyen", "Dzung T. Phan"], "year": 2019, "n_citations": 5}
{"id": 2024553, "s2_id": "5faa0c67eac6b52a20b3b18416d8c8010668bb8f", "title": "Twitter Sentiment on Affordable Care Act using Score Embedding", "abstract": "In this paper we introduce score embedding, a neural network based model to learn interpretable vector representations for words. Score embedding is a supervised method that takes advantage of the labeled training data and the neural network architecture to learn interpretable representations for words. Health care has been a controversial issue between political parties in the United States. In this paper we use the discussions on Twitter regarding different issues of affordable care act to identify the public opinion about the existing health care plans using the proposed score embedding. Our results indicate our approach effectively incorporates the sentiment information and outperforms or is at least comparable to the state-of-the-art methods and the negative sentiment towards \"TrumpCare\" was consistently greater than neutral and positive sentiment over time.", "venue": "ArXiv", "authors": ["Mohsen  Farhadloo"], "year": 2019, "n_citations": 1}
{"id": 2035411, "s2_id": "21f2d76d64126567a09af4e3db05e1f17a978be0", "title": "Natural continual learning: success is a journey, not (just) a destination", "abstract": "Biological agents are known to learn many different tasks over the course of their lives, and to be able to revisit previous tasks and behaviors with little to no loss in performance. In contrast, artificial agents are prone to \u2018catastrophic forgetting\u2019 whereby performance on previous tasks deteriorates rapidly as new ones are acquired. This shortcoming has recently been addressed using methods that encourage parameters to stay close to those used for previous tasks. This can be done by (i) using specific parameter regularizers that map out suitable destinations in parameter space, or (ii) guiding the optimization journey by projecting gradients into subspaces that do not interfere with previous tasks. However, these methods often exhibit subpar performance in both feedforward and recurrent neural networks, with recurrent networks being of interest to the study of neural dynamics supporting biological continual learning. In this work, we propose Natural Continual Learning (NCL), a new method that unifies weight regularization and projected gradient descent. NCL uses Bayesian weight regularization to encourage good performance on all tasks at convergence and combines this with gradient projection using the prior precision, which prevents catastrophic forgetting during optimization. Our method outperforms both standard weight regularization techniques and projection based approaches when applied to continual learning problems in feedforward and recurrent networks. Finally, the trained networks evolve task-specific dynamics that are strongly preserved as new tasks are learned, similar to experimental findings in biological circuits.", "venue": "ArXiv", "authors": ["Ta-Chu  Kao", "Kristopher T. Jensen", "Alberto  Bernacchia", "Guillaume  Hennequin"], "year": 2021, "n_citations": 1}
{"id": 2039639, "s2_id": "063700c45e10362f5642c08849348c41ee5b08a3", "title": "From Here to There: Video Inbetweening Using Direct 3D Convolutions", "abstract": "We consider the problem of generating plausible and diverse video sequences, when we are only given a start and an end frame. This task is also known as inbetweening, and it belongs to the broader area of stochastic video generation, which is generally approached by means of recurrent neural networks (RNN). In this paper, we propose instead a fully convolutional model to generate video sequences directly in the pixel domain. We first obtain a latent video representation using a stochastic fusion mechanism that learns how to incorporate information from the start and end frames. Our model learns to produce such latent representation by progressively increasing the temporal resolution, and then decode in the spatiotemporal domain using 3D convolutions. The model is trained end-to-end by minimizing an adversarial loss. Experiments on several widely-used benchmark datasets show that it is able to generate meaningful and diverse in-between video sequences, according to both quantitative and qualitative evaluations.", "venue": "ArXiv", "authors": ["Yunpeng  Li", "Dominik  Roblek", "Marco  Tagliasacchi"], "year": 2019, "n_citations": 17}
{"id": 2040234, "s2_id": "fce9e0740a928a17f7bd94f95630d5fd6b878931", "title": "The FAST Algorithm for Submodular Maximization", "abstract": "In this paper we describe a new algorithm called Fast Adaptive Sequencing Technique (FAST) for maximizing a monotone submodular function under a cardinality constraint $k$ whose approximation ratio is arbitrarily close to $1-1/e$, is $O(\\log(n) \\log^2(\\log k))$ adaptive, and uses a total of $O(n \\log\\log(k))$ queries. Recent algorithms have comparable guarantees in terms of asymptotic worst case analysis, but their actual number of rounds and query complexity depend on very large constants and polynomials in terms of precision and confidence, making them impractical for large data sets. Our main contribution is a design that is extremely efficient both in terms of its non-asymptotic worst case query complexity and number of rounds, and in terms of its practical runtime. We show that this algorithm outperforms any algorithm for submodular maximization we are aware of, including hyper-optimized parallel versions of state-of-the-art serial algorithms, by running experiments on large data sets. These experiments show FAST is orders of magnitude faster than the state-of-the-art.", "venue": "ICML", "authors": ["Adam  Breuer", "Eric  Balkanski", "Yaron  Singer"], "year": 2020, "n_citations": 14}
{"id": 2042011, "s2_id": "ed8d6cf4525abca986e9985728108a034351e671", "title": "Effect of the initial configuration of weights on the training and function of artificial neural networks", "abstract": "The function and performance of neural networks are largely determined by the evolution of their weights and biases in the process of training, starting from the initial configuration of these parameters to one of the local minima of the loss function. We perform the quantitative statistical characterization of the deviation of the weights of two-hidden-layer feedforward ReLU networks of various sizes trained via Stochastic Gradient Descent (SGD) from their initial random configuration. We compare the evolution of the distribution function of this deviation with the evolution of the loss during training. We observed that successful training via SGD leaves the network in the close neighborhood of the initial configuration of its weights. For each initial weight of a link we measured the distribution function of the deviation from this value after training and found how the moments of this distribution and its peak depend on the initial weight. We explored the evolution of these deviations during training and observed an abrupt increase within the overfitting region. This jump occurs simultaneously with a similarly abrupt increase recorded in the evolution of the loss function. Our results suggest that SGD\u2019s ability to efficiently find local minima is restricted to the vicinity of the random initial configuration of weights.", "venue": "Mathematics", "authors": ["R. J. Jesus", "M. L. Antunes", "R. A. da Costa", "S. N. Dorogovtsev", "J. F. F. Mendes", "R. L. Aguiar"], "year": 2021, "n_citations": 0}
{"id": 2048291, "s2_id": "f50b69c3b482b917af5c42922471b44ff4113102", "title": "Real-time Policy Distillation in Deep Reinforcement Learning", "abstract": "Policy distillation in deep reinforcement learning provides an effective way to transfer control policies from a larger network to a smaller untrained network without a significant degradation in performance. However, policy distillation is underexplored in deep reinforcement learning, and existing approaches are computationally inefficient, resulting in a long distillation time. In addition, the effectiveness of the distillation process is still limited to the model capacity. We propose a new distillation mechanism, called real-time policy distillation, in which training the teacher model and distilling the policy to the student model occur simultaneously. Accordingly, the teacher's latest policy is transferred to the student model in real time. This reduces the distillation time to half the original time or even less and also makes it possible for extremely small student models to learn skills at the expert level. We evaluated the proposed algorithm in the Atari 2600 domain. The results show that our approach can achieve full distillation in most games, even with compression ratios up to 1.7%.", "venue": "ArXiv", "authors": ["Yuxiang  Sun", "Pooyan  Fazli"], "year": 2019, "n_citations": 0}
{"id": 2051125, "s2_id": "85fd8f2975743ec14ff5bc5811edf0cdea09bdab", "title": "On component interactions in two-stage recommender systems", "abstract": "Thanks to their scalability, two-stage recommenders are used by many of today\u2019s largest online platforms, including YouTube, LinkedIn, and Pinterest. These systems produce recommendations in two steps: (i) multiple nominators\u2014tuned for low prediction latency\u2014preselect a small subset of candidates from the whole item pool; (ii) a slower but more accurate ranker further narrows down the nominated items, and serves to the user. Despite their popularity, the literature on two-stage recommenders is relatively scarce, and the algorithms are often treated as mere sums of their parts. Such treatment presupposes that the two-stage performance is explained by the behavior of the individual components in isolation. This is not the case: using synthetic and real-world data, we demonstrate that interactions between the ranker and the nominators substantially affect the overall performance. Motivated by these findings, we derive a generalization lower bound which shows that independent nominator training can lead to performance on par with uniformly random recommendations. We find that careful design of item pools, each assigned to a different nominator, alleviates these issues. As manual search for a good pool allocation is difficult, we propose to learn one instead using a Mixture-of-Experts based approach. This significantly improves both precision and recall at K.", "venue": "ArXiv", "authors": ["Jiri  Hron", "Karl  Krauth", "Michael I. Jordan", "Niki  Kilbertus"], "year": 2021, "n_citations": 1}
{"id": 2063375, "s2_id": "6d0f8427064a7eaa04947a2ba4c91c98efa734da", "title": "Get a Model! Model Hijacking Attack Against Machine Learning Models", "abstract": "Machine learning (ML) has established itself as a cornerstone for various critical applications ranging from autonomous driving to authentication systems. However, with this increasing adoption rate of machine learning models, multiple attacks have emerged. One class of such attacks is training time attack, whereby an adversary executes their attack before or during the machine learning model training. In this work, we propose a new training time attack against computer vision based machine learning models, namely model hijacking attack. The adversary aims to hijack a target model to execute a different task than its original one without the model owner noticing. Model hijacking can cause accountability and security risks since a hijacked model owner can be framed for having their model offering illegal or unethical services. Model hijacking attacks are launched in the same way as existing data poisoning attacks. However, one requirement of the model hijacking attack is to be stealthy, i.e., the data samples used to hijack the target model should look similar to the model\u2019s original training dataset. To this end, we propose two different model hijacking attacks, namely Chameleon and Adverse Chameleon, based on a novel encoder-decoder style ML model, namely the Camouflager. Our evaluation shows that both of our model hijacking attacks achieve a high attack success rate, with a negligible drop in model utility.1", "venue": "ArXiv", "authors": ["Ahmed  Salem", "Michael  Backes", "Yang  Zhang"], "year": 2021, "n_citations": 0}
{"id": 2071605, "s2_id": "336b3b71707ec92119234e304913fb03efeb9743", "title": "High resolution functional imaging through Lorentz transmission electron microscopy and differentiable programming", "abstract": "Lorentz transmission electron microscopy is a unique characterization technique that enables the simultaneous imaging of both the microstructure and functional properties of materials at high spatial resolution. The quantitative information such as magnetization and electric potentials is carried by the phase of the electron wave, and is lost during imaging. In order to understand the local interactions and develop structure-property relationships, it is necessary to retrieve the complete wavefunction of the electron wave, which requires solving for the phase shift of the electrons (phase retrieval). Here we have developed a method based on differentiable programming to solve the inverse problem of phase retrieval, using a series of defocused microscope images. We show that our method is robust and can outperform widely used \\textit{transport of intensity equation} in terms of spatial resolution and accuracy of the retrieved phase under same electron dose conditions. Furthermore, our method shares the same basic structure as advanced machine learning algorithms, and is easily adaptable to various other forms of phase retrieval in electron microscopy.", "venue": "ArXiv", "authors": ["Tao  Zhou", "Mathew  Cherukara", "Charudatta  Phatak"], "year": 2020, "n_citations": 0}
{"id": 2075261, "s2_id": "3a05f5a38d9281f55a60b0feffd89ba693c624ab", "title": "Revisiting Adversarially Learned Injection Attacks Against Recommender Systems", "abstract": "Recommender systems play an important role in modern information and e-commerce applications. While increasing research is dedicated to improving the relevance and diversity of the recommendations, the potential risks of state-of-the-art recommendation models are under-explored, that is, these models could be subject to attacks from malicious third parties, through injecting fake user interactions to achieve their purposes. This paper revisits the adversarially-learned injection attack problem, where the injected fake user \u2018behaviors\u2019 are learned locally by the attackers with their own model \u2013 one that is potentially different from the model under attack, but shares similar properties to allow attack transfer. We found that most existing works in literature suffer from two major limitations: (1) they do not solve the optimization problem precisely, making the attack less harmful than it could be, (2) they assume perfect knowledge for the attack, causing the lack of understanding for realistic attack capabilities. We demonstrate that the exact solution for generating fake users as an optimization problem could lead to a much larger impact. Our experiments on a real-world dataset reveal important properties of the attack, including attack transferability and its limitations. These findings can inspire useful defensive methods against this possible existing attack.", "venue": "RecSys", "authors": ["Jiaxi  Tang", "Hongyi  Wen", "Ke  Wang"], "year": 2020, "n_citations": 9}
{"id": 2078827, "s2_id": "958af62fbcb24e6f128abacd0f6fee81c02f4db7", "title": "False Discovery Rate Control via Debiased Lasso", "abstract": "We consider the problem of variable selection in high-dimensional statistical models where the goal is to report a set of variables, out of many predictors $X_1, \\dotsc, X_p$, that are relevant to a response of interest. For linear high-dimensional model, where the number of parameters exceeds the number of samples $(p>n)$, we propose a procedure for variables selection and prove that it controls the \\emph{directional} false discovery rate (FDR) below a pre-assigned significance level $q\\in [0,1]$. We further analyze the statistical power of our framework and show that for designs with subgaussian rows and a common precision matrix $\\Omega\\in\\mathbb{R}^{p\\times p}$, if the minimum nonzero parameter $\\theta_{\\min}$ satisfies $$\\sqrt{n} \\theta_{\\min} - \\sigma \\sqrt{2(\\max_{i\\in [p]}\\Omega_{ii})\\log\\left(\\frac{2p}{qs_0}\\right)} \\to \\infty\\,,$$ then this procedure achieves asymptotic power one. \nOur framework is built upon the debiasing approach and assumes the standard condition $s_0 = o(\\sqrt{n}/(\\log p)^2)$, where $s_0$ indicates the number of true positives among the $p$ features. Notably, this framework achieves exact directional FDR control without any assumption on the amplitude of unknown regression parameters, and does not require any knowledge of the distribution of covariates or the noise level. We test our method in synthetic and real data experiments to asses its performance and to corroborate our theoretical results.", "venue": "Electronic Journal of Statistics", "authors": ["Adel  Javanmard", "Hamid  Javadi"], "year": 2019, "n_citations": 32}
{"id": 2080158, "s2_id": "8e58dc63817a2a26e5a2ddad38d8b1d19d1c3795", "title": "Machine Unlearning", "abstract": "Once users have shared their data online, it is generally difficult for them to revoke access and ask for the data to be deleted. Machine learning (ML) exacerbates this problem because any model trained with said data may have memorized it, putting users at risk of a successful privacy attack exposing their information. Yet, having models unlearn is notoriously difficult.We introduce SISA training, a framework that expedites the unlearning process by strategically limiting the influence of a data point in the training procedure. While our framework is applicable to any learning algorithm, it is designed to achieve the largest improvements for stateful algorithms like stochastic gradient descent for deep neural networks. SISA training reduces the computational overhead associated with unlearning, even in the worst-case setting where unlearning requests are made uniformly across the training set. In some cases, the service provider may have a prior on the distribution of unlearning requests that will be issued by users. We may take this prior into account to partition and order data accordingly, and further decrease overhead from unlearning.Our evaluation spans several datasets from different domains, with corresponding motivations for unlearning. Under no distributional assumptions, for simple learning tasks, we observe that SISA training improves time to unlearn points from the Purchase dataset by 4.63\u00d7, and 2.45\u00d7 for the SVHN dataset, over retraining from scratch. SISA training also provides a speed-up of 1.36\u00d7 in retraining for complex learning tasks such as ImageNet classification; aided by transfer learning, this results in a small degradation in accuracy. Our work contributes to practical data governance in machine unlearning.", "venue": "2021 IEEE Symposium on Security and Privacy (SP)", "authors": ["Lucas  Bourtoule", "Varun  Chandrasekaran", "Christopher  Choquette-Choo", "Hengrui  Jia", "Adelin  Travers", "Baiwu  Zhang", "David  Lie", "Nicolas  Papernot"], "year": 2021, "n_citations": 43}
{"id": 2086983, "s2_id": "0aaa5f51faa9a5c03f788009cbf2288988880278", "title": "Open Category Detection with PAC Guarantees", "abstract": "Open category detection is the problem of detecting \"alien\" test instances that belong to categories or classes that were not present in the training data. In many applications, reliably detecting such aliens is central to ensuring the safety and accuracy of test set predictions. Unfortunately, there are no algorithms that provide theoretical guarantees on their ability to detect aliens under general assumptions. Further, while there are algorithms for open category detection, there are few empirical results that directly report alien detection rates. Thus, there are significant theoretical and empirical gaps in our understanding of open category detection. In this paper, we take a step toward addressing this gap by studying a simple, but practically-relevant variant of open category detection. In our setting, we are provided with a \"clean\" training set that contains only the target categories of interest and an unlabeled \"contaminated\" training set that contains a fraction $\\alpha$ of alien examples. Under the assumption that we know an upper bound on $\\alpha$, we develop an algorithm with PAC-style guarantees on the alien detection rate, while aiming to minimize false alarms. Empirical results on synthetic and standard benchmark datasets demonstrate the regimes in which the algorithm can be effective and provide a baseline for further advancements.", "venue": "ICML", "authors": ["Si  Liu", "Risheek  Garrepalli", "Thomas G. Dietterich", "Alan  Fern", "Dan  Hendrycks"], "year": 2018, "n_citations": 43}
{"id": 2092915, "s2_id": "3b91867718169e6ff4e4d70dd61323218111278a", "title": "Automatic Model Monitoring for Data Streams", "abstract": "Detecting concept drift is a well known problem that affects production systems. However, two important issues that are frequently not addressed in the literature are 1) the detection of drift when the labels are not immediately available; and 2) the automatic generation of explanations to identify possible causes for the drift. For example, a fraud detection model in online payments could show a drift due to a hot sale item (with an increase in false positives) or due to a true fraud attack (with an increase in false negatives) before labels are available. In this paper we propose SAMM, an automatic model monitoring system for data streams. SAMM detects concept drift using a time and space efficient unsupervised streaming algorithm and it generates alarm reports with a summary of the events and features that are important to explain it. SAMM was evaluated in five real world fraud detection datasets, each spanning periods up to eight months and totaling more than 22 million online transactions. We evaluated SAMM using human feedback from domain experts, by sending them 100 reports generated by the system. Our results show that SAMM is able to detect anomalous events in a model life cycle that are considered useful by the domain experts. Given these results, SAMM will be rolled out in a next version of Feedzai's Fraud Detection solution.", "venue": "ArXiv", "authors": ["F'abio  Pinto", "Marco O. P. Sampaio", "Pedro  Bizarro"], "year": 2019, "n_citations": 12}
{"id": 2093064, "s2_id": "b70f940ad3943dd03627052281f4651485ec0bf9", "title": "Cluster Trees on Manifolds", "abstract": "In this paper we investigate the problem of estimating the cluster tree for a density f supported on or near a smooth d-dimensional manifold M isometrically embedded in \u211dD. We analyze a modified version of a k-nearest neighbor based algorithm recently proposed by Chaudhuri and Dasgupta (2010). The main results of this paper show that under mild assumptions on f and M, we obtain rates of convergence that depend on d only but not on the ambient dimension D. Finally, we sketch a construction of a sample complexity lower bound instance for a natural class of manifold oblivious clustering algorithms.", "venue": "NIPS", "authors": ["Sivaraman  Balakrishnan", "Srivatsan  Narayanan", "Alessandro  Rinaldo", "Aarti  Singh", "Larry A. Wasserman"], "year": 2013, "n_citations": 35}
{"id": 2096638, "s2_id": "2db2b855fc4518aa02a446f1af5d5943385a7368", "title": "On the estimation of discrete choice models to capture irrational customer behaviors", "abstract": "The Random Utility Maximization model is by far the most adopted framework to estimate consumer choice behavior. However, behavioral economics has provided strong empirical evidence of irrational choice behavior, such as halo effects, that are incompatible with this framework. Models belonging to the Random Utility Maximization family may therefore not accurately capture such irrational behavior. Hence, more general choice models, overcoming such limitations, have been proposed. However, the flexibility of such models comes at the price of increased risk of overfitting. As such, estimating such models remains a challenge. In this work, we propose an estimation method for the recently proposed Generalized Stochastic Preference choice model, which subsumes the family of Random Utility Maximization models and is capable of capturing halo effects. Specifically, we show how to use partially-ranked preferences to efficiently model rational and irrational customer types from transaction data. Our estimation procedure is based on column generation, where relevant customer types are efficiently extracted by expanding a tree-like data structure containing the customer behaviors. Further, we propose a new dominance rule among customer types whose effect is to prioritize low orders of interactions among products. An extensive set of experiments assesses the predictive accuracy of the proposed approach. Our results show that accounting for irrational preferences can boost predictive accuracy by 12.5% on average, when tested on a real-world dataset from a large chain of grocery and drug stores.", "venue": "ArXiv", "authors": ["Sanjay Dominik Jena", "Andrea  Lodi", "Claudio  Sole"], "year": 2021, "n_citations": 0}
{"id": 2107575, "s2_id": "2fb59ebe271d6b007bb0429c1701fd1004782d1b", "title": "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation Learning via Mutual Information Maximization", "abstract": "This paper studies learning the representations of whole graphs in both unsupervised and semi-supervised scenarios. Graph-level representations are critical in a variety of real-world applications such as predicting the properties of molecules and community analysis in social networks. Traditional graph kernel based methods are simple, yet effective for obtaining fixed-length representations for graphs but they suffer from poor generalization due to hand-crafted designs. There are also some recent methods based on language models (e.g. graph2vec) but they tend to only consider certain substructures (e.g. subtrees) as graph representatives. Inspired by recent progress of unsupervised representation learning, in this paper we proposed a novel method called InfoGraph for learning graph-level representations. We maximize the mutual information between the graph-level representation and the representations of substructures of different scales (e.g., nodes, edges, triangles). By doing so, the graph-level representations encode aspects of the data that are shared across different scales of substructures. Furthermore, we further propose InfoGraph*, an extension of InfoGraph for semi-supervised scenarios. InfoGraph* maximizes the mutual information between unsupervised graph representations learned by InfoGraph and the representations learned by existing supervised methods. As a result, the supervised encoder learns from unlabeled data while preserving the latent semantic space favored by the current supervised task. Experimental results on the tasks of graph classification and molecular property prediction show that InfoGraph is superior to state-of-the-art baselines and InfoGraph* can achieve performance competitive with state-of-the-art semi-supervised models.", "venue": "ICLR", "authors": ["Fan-Yun  Sun", "Jordan  Hoffmann", "Jian  Tang"], "year": 2020, "n_citations": 197}
{"id": 2110961, "s2_id": "6c32e11b8b53dc6634cc44f8dfc0802220d95462", "title": "Withholding or withdrawing invasive interventions may not accelerate time to death among dying ICU patients", "abstract": "Background Critically ill patients may die despite invasive intervention. In this study, we examine trends in the application of two such treatments over a decade, namely, endotracheal ventilation and vasopressors and inotropes administration, as well as the impact of these trends on survival durations in patients who die within a month of ICU admission. Methods We considered observational data available from the MIMIC-III open-access ICU database and collected within a study period between year 2002 up to 2011. If a patient had multiple admissions to the ICU during the 30 days before death, only the first stay was analyzed, leading to a final set of 6,436 unique ICU admissions during the study period. We tested two hypotheses: (i) administration of invasive intervention during the ICU stay immediately preceding end-of-life would decrease over the study time period and (ii) time-to-death from ICU admission would also decrease, due to the decrease in invasive intervention administration. To investigate the latter hypothesis, we performed a subgroups analysis by considering patients with lowest and highest severity. To do so, we stratified the patients based on their SAPS I scores, and we considered patients within the first and the third tertiles of the score. We then assessed differences in trends within these groups between years 2002\u201305 vs. 2008\u201311. Results Comparing the period 2002\u20132005 vs. 2008\u20132011, we found a reduction in endotracheal ventilation among patients who died within 30 days of ICU admission (120.8 vs. 68.5 hours for the lowest severity patients, p<0.001; 47.7 vs. 46.0 hours for the highest severity patients, p = 0.004). This is explained in part by an increase in the use of non-invasive ventilation. Comparing the period 2002\u20132005 vs. 2008\u20132011, we found a reduction in the use of vasopressors and inotropes among patients with the lowest severity who died within 30 days of ICU admission (41.8 vs. 36.2 hours, p<0.001) but not among those with the highest severity. Despite a reduction in the use of invasive interventions, we did not find a reduction in the time to death between 2002\u20132005 vs. 2008\u20132011 (7.8 days vs. 8.2 days for the lowest severity patients, p = 0.32; 2.1 days vs. 2.0 days for the highest severity patients, p = 0.74). Conclusion We found that the reduction in the use of invasive treatments over time in patients with very poor prognosis did not shorten the time-to-death. These findings may be useful for goals of care discussions.", "venue": "PloS one", "authors": ["Daniele  Ramazzotti", "Peter  Clardy", "Leo Anthony Celi", "David J Stone", "Robert S Rudin"], "year": 2019, "n_citations": 2}
{"id": 2123766, "s2_id": "4b9e893a1825f9106b7232ddbdfa34d32a32802a", "title": "RPM-Net: Recurrent Prediction of Motion and Parts from Point Cloud", "abstract": "We introduce RPM-Net, a deep learning-based approach which simultaneously infers movable parts and hallucinates their motions from a single, un-segmented, and possibly partial, 3D point cloud shape. RPM-Net is a novel Recurrent Neural Network (RNN), composed of an encoder-decoder pair with interleaved Long Short-Term Memory (LSTM) components, which together predict a temporal sequence of pointwise displacements for the input point cloud. At the same time, the displacements allow the network to learn movable parts, resulting in a motion-based shape segmentation. Recursive applications of RPM-Net on the obtained parts can predict iner-level part motions, resulting in a hierarchical object segmentation. Furthermore, we develop a separate network to estimate part mobilities, e.g., per-part motion parameters, from the segmented motion sequence. Both networks learn deep predictive models from a training set that exempliies a variety of mobilities for diverse objects. We show results of simultaneous motion and part predictions from synthetic and real scans of 3D objects exhibiting a variety of part mobilities, possibly involving multiple movable parts.", "venue": "ArXiv", "authors": ["Zihao  Yan", "Ruizhen  Hu", "Xingguang  Yan", "Luanmin  Chen", "Oliver van Kaick", "Hao  Zhang", "Hui  Huang"], "year": 2020, "n_citations": 16}
{"id": 2125205, "s2_id": "1f0e1657063ea38cf225eaf1c1187ae7b2e4a0e0", "title": "Increasing Robustness to Spurious Correlations using Forgettable Examples", "abstract": "Neural NLP models tend to rely on spurious correlations between labels and input features to perform their tasks. Minority examples, i.e., examples that contradict the spurious correlations present in the majority of data points, have been shown to increase the out-of-distribution generalization of pre-trained language models. In this paper, we first propose using example forgetting to find minority examples without prior knowledge of the spurious correlations present in the dataset. Forgettable examples are instances either learned and then forgotten during training or never learned. We show empirically how these examples are related to minorities in our training sets. Then, we introduce a new approach to robustify models by fine-tuning our models twice, first on the full training data and second on the minorities only. We obtain substantial improvements in out-of-distribution generalization when applying our approach to the MNLI, QQP and FEVER datasets.", "venue": "EACL", "authors": ["Yadollah  Yaghoobzadeh", "Soroush  Mehri", "Remi  Tachet", "T. J. Hazen", "Alessandro  Sordoni"], "year": 2021, "n_citations": 9}
{"id": 2133321, "s2_id": "bd2d582ba03024841d1cb9c58c9e634787b23bac", "title": "AMR Quality Rating with a Lightweight CNN", "abstract": "Structured semantic sentence representations such as Abstract Meaning Representations (AMRs) are potentially useful in various NLP tasks. However, the quality of automatic parses can vary greatly and jeopardizes their usefulness. This can be mitigated by models that can accurately rate AMR quality in the absence of costly gold data, allowing us to inform downstream systems about an incorporated parse\u2019s trustworthiness or select among different candidate parses. In this work, we propose to transfer the AMR graph to the domain of images. This allows us to create a simple convolutional neural network (CNN) that imitates a human judge tasked with rating graph quality. Our experiments show that the method can rate quality more accurately than strong baselines, in several quality dimensions. Moreover, the method proves to be efficient and reduces the incurred energy consumption.", "venue": "AACL", "authors": ["Juri  Opitz"], "year": 2020, "n_citations": 3}
{"id": 2143803, "s2_id": "54ab174b00d730d2173a7a95535d52cc30b2ed95", "title": "SCANN: Synthesis of Compact and Accurate Neural Networks", "abstract": "Artificial neural networks (ANNs) have become the driving force behind recent artificial intelligence (AI) research. An important problem with implementing a neural network is the design of its architecture. Typically, such an architecture is obtained manually by exploring its hyperparameter space and kept fixed during training. This approach is both time-consuming and inefficient. Furthermore, modern neural networks often contain millions of parameters, whereas many applications require small inference models. Also, while ANNs have found great success in big-data applications, there is also significant interest in using ANNs for medium- and small-data applications that can be run on energy-constrained edge devices. To address these challenges, we propose a neural network synthesis methodology (SCANN) that can generate very compact neural networks without loss in accuracy for small and medium-size datasets. We also use dimensionality reduction methods to reduce the feature size of the datasets, so as to alleviate the curse of dimensionality. Our final synthesis methodology consists of three steps: dataset dimensionality reduction, neural network compression in each layer, and neural network compression with SCANN. We evaluate SCANN on the medium-size MNIST dataset by comparing our synthesized neural networks to the well-known LeNet-5 baseline. Without any loss in accuracy, SCANN generates a $46.3\\times$ smaller network than the LeNet-5 Caffe model. We also evaluate the efficiency of using dimensionality reduction alongside SCANN on nine small to medium-size datasets. Using this methodology enables us to reduce the number of connections in the network by up to $5078.7\\times$ (geometric mean: $82.1\\times$), with little to no drop in accuracy. We also show that our synthesis methodology yields neural networks that are much better at navigating the accuracy vs. energy efficiency space.", "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems", "authors": ["Shayan  Hassantabar", "Zeyu  Wang", "Niraj K. Jha"], "year": 2021, "n_citations": 23}
{"id": 2145798, "s2_id": "4a6bb8a202812e9b68465f7f710e027413ba8d68", "title": "Look-Ahead Screening Rules for the Lasso", "abstract": "The lasso is a popular method to induce shrinkage and sparsity in the solution vector (coefficients) of regression problems, particularly when there are many predictors relative to the number of observations. Solving the lasso in this high-dimensional setting can, however, be computationally demanding. Fortunately, this demand can be alleviated via the use of screening rules that discard predictors prior to fitting the model, leading to a reduced problem to be solved. In this paper, we present a new screening strategy: look-ahead screening. Our method uses safe screening rules to find a range of penalty values for which a given predictor cannot enter the model, thereby screening predictors along the remainder of the path. In experiments we show that these look-ahead screening rules outperform the active warm-start version of the Gap Safe rules.", "venue": "ArXiv", "authors": ["Johan  Larsson"], "year": 2021, "n_citations": 0}
{"id": 2152271, "s2_id": "3508e4789b3aadbf177af141b163fa88669a8496", "title": "Model-centric Data Manifold: the Data Through the Eyes of the Model", "abstract": "We discover that deep ReLU neural network classifiers can see a low-dimensional Riemannian manifold structure on data. Such structure comes via the local data matrix, a variation of the Fisher information matrix, where the role of the model parameters is taken by the data variables. We obtain a foliation of the data domain and we show that the dataset on which the model is trained lies on a leaf, the data leaf, whose dimension is bounded by the number of classification labels. We validate our results with some experiments with the MNIST dataset: paths on the data leaf connect valid images, while other leaves cover noisy images.", "venue": "ArXiv", "authors": ["Luca  Grementieri", "Rita  Fioresi"], "year": 2021, "n_citations": 0}
{"id": 2174235, "s2_id": "90bdcd465ea88f6fe19039f142871cc9a3500c99", "title": "Smooth Neighbors on Teacher Graphs for Semi-Supervised Learning", "abstract": "The recently proposed self-ensembling methods have achieved promising results in deep semi-supervised learning, which penalize inconsistent predictions of unlabeled data under different perturbations. However, they only consider adding perturbations to each single data point, while ignoring the connections between data samples. In this paper, we propose a novel method, called Smooth Neighbors on Teacher Graphs (SNTG). In SNTG, a graph is constructed based on the predictions of the teacher model, i.e., the implicit self-ensemble of models. Then the graph serves as a similarity measure with respect to which the representations of \"similar\" neighboring points are learned to be smooth on the low-dimensional manifold. We achieve state-of-the-art results on semi-supervised learning benchmarks. The error rates are 9.89%, 3.99% for CIFAR-10 with 4000 labels, SVHN with 500 labels, respectively. In particular, the improvements are significant when the labels are fewer. For the non-augmented MNIST with only 20 labels, the error rate is reduced from previous 4.81% to 1.36%. Our method also shows robustness to noisy labels.", "venue": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition", "authors": ["Yucen  Luo", "Jun  Zhu", "Mengxi  Li", "Yong  Ren", "Bo  Zhang"], "year": 2018, "n_citations": 153}
{"id": 2174255, "s2_id": "2ed3c69ca8b66301ecca049239d3be2543443084", "title": "A deep surrogate approach to efficient Bayesian inversion in PDE and integral equation models", "abstract": "We propose a novel deep learning approach to efficiently perform Bayesian inference in partial differential equation (PDE) and integral equation models over potentially high-dimensional parameter spaces. The contributions of this paper are two-fold; the first is the introduction of a neural network approach to approximating the solutions of Fredholm and Volterra integral equations of the first and second kind. The second is the description of a deep surrogate model which allows for efficient sampling from a Bayesian posterior distribution in which the likelihood depends on the solutions of PDEs or integral equations. For the latter, our method relies on the approximate representation of parametric solutions by neural networks. This deep learning approach allows the accurate and efficient approximation of parametric solutions in significantly higher dimensions than is possible using classical techniques. Since the approximated solutions are very cheap to evaluate, the solutions of Bayesian inverse problems over large parameter spaces are tractable using Markov chain Monte Carlo. We demonstrate the efficiency of our method using two real-world examples; these include Bayesian inference in the PDE and integral equation case for an example from electrochemistry, and Bayesian inference of a function-valued heat-transfer parameter with applications in aviation.", "venue": "ArXiv", "authors": ["Teo  Deveney", "Eike  Mueller", "Tony  Shardlow"], "year": 2019, "n_citations": 4}
{"id": 2194246, "s2_id": "13876262a977b332cd3594a7632b7381e634d406", "title": "A General Framework for Fair Regression", "abstract": "Fairness, through its many forms and definitions, has become an important issue facing the machine learning community. In this work, we consider how to incorporate group fairness constraints into kernel regression methods, applicable to Gaussian processes, support vector machines, neural network regression and decision tree regression. Further, we focus on examining the effect of incorporating these constraints in decision tree regression, with direct applications to random forests and boosted trees amongst other widespread popular inference techniques. We show that the order of complexity of memory and computation is preserved for such models and tightly binds the expected perturbations to the model in terms of the number of leaves of the trees. Importantly, the approach works on trained models and hence can be easily applied to models in current use and group labels are only required on training data.", "venue": "Entropy", "authors": ["Jack  Fitzsimons", "AbdulRahman Al Ali", "Michael  Osborne", "Stephen  Roberts"], "year": 2019, "n_citations": 11}
{"id": 2201836, "s2_id": "5efdea756e39b62809d98d57ff01f5a7ad71adf1", "title": "One-Pass Incomplete Multi-view Clustering", "abstract": "Real data are often with multiple modalities or from multiple heterogeneous sources, thus forming so-called multi-view data, which receives more and more attentions in machine learning. Multi-view clustering (MVC) becomes its important paradigm. In real-world applications, some views often suffer from instances missing. Clustering on such multi-view datasets is called incomplete multi-view clustering (IMC) and quite challenging. To date, though many approaches have been developed, most of them are offline and have high computational and memory costs especially for large scale datasets. To address this problem, in this paper, we propose an One-Pass Incomplete Multi-view Clustering framework (OPIMC). With the help of regularized matrix factorization and weighted matrix factorization, OPIMC can relatively easily deal with such problem. Different from the existing and sole online IMC method, OPIMC can directly get clustering results and effectively determine the termination of iteration process by introducing two global statistics. Finally, extensive experiments conducted on four real datasets demonstrate the efficiency and effectiveness of the proposed OPIMC method.", "venue": "AAAI", "authors": ["Menglei  Hu", "Songcan  Chen"], "year": 2019, "n_citations": 20}
{"id": 2208845, "s2_id": "0af7a08f716c96292940292bad55988139dd811f", "title": "PixMix: Dreamlike Pictures Comprehensively Improve Safety Measures", "abstract": "In real-world applications of machine learning, reliable and safe systems must consider measures of performance beyond standard test set accuracy. These other goals include out-of-distribution (OOD) robustness, prediction consistency, resilience to adversaries, calibrated uncertainty estimates, and the ability to detect anomalous inputs. However, improving performance towards these goals is often a balancing act that today\u2019s methods cannot achieve without sacrificing performance on other safety axes. For instance, adversarial training improves adversarial robustness but sharply degrades other classifier performance metrics. Similarly, strong data augmentation and regularization techniques often improve OOD robustness but harm anomaly detection, raising the question of whether a Pareto improvement on all existing safety measures is possible. To meet this challenge, we design a new data augmentation strategy utilizing the natural structural complexity of pictures such as fractals, which outperforms numerous baselines, is near Pareto-optimal, and roundly improves safety measures.", "venue": "ArXiv", "authors": ["Dan  Hendrycks", "Andy  Zou", "Mantas  Mazeika", "Leonard  Tang", "Dawn Xiaodong Song", "Jacob  Steinhardt"], "year": 2021, "n_citations": 1}
{"id": 2252740, "s2_id": "77873e0843113d5465417f5309f5ae258af52a6f", "title": "Representation Learning of Histopathology Images using Graph Neural Networks", "abstract": "Representation learning for Whole Slide Images (WSIs) is pivotal in developing image-based systems to achieve higher precision in diagnostic pathology. We propose a two-stage framework for WSI representation learning. We sample relevant patches using a color-based method and use graph neural networks to learn relations among sampled patches to aggregate the image information into a single vector representation. We introduce attention via graph pooling to automatically infer patches with higher relevance. We demonstrate the performance of our approach for discriminating two sub-types of lung cancers, Lung Adenocarcinoma (LUAD) & Lung Squamous Cell Carcinoma (LUSC). We collected 1,026 lung cancer WSIs with the 40\u00d7 magnification from The Cancer Genome Atlas (TCGA) dataset, the largest public repository of histopathology images and achieved state-of-the-art accuracy of 88.8% and AUC of 0.89 on lung cancer sub-type classification by extracting features from a pre-trained DenseNet model.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "authors": ["Mohammed  Adnan", "Shivam  Kalra", "Hamid R. Tizhoosh"], "year": 2020, "n_citations": 14}
{"id": 2255524, "s2_id": "c1adf94de62b9de1b9b70c2db60ce4d8916fe766", "title": "Detecting Dead Weights and Units in Neural Networks", "abstract": "Deep Neural Networks are highly over-parameterized and the size of the neural networks can be reduced significantly after training without any decrease in performance. One can clearly see this phenomenon in a wide range of architectures trained for various problems. Weight/channel pruning, distillation, quantization, matrix factorization are some of the main methods one can use to remove the redundancy to come up with smaller and faster models. \nThis work starts with a short informative chapter, where we motivate the pruning idea and provide the necessary notation. In the second chapter, we compare various saliency scores in the context of parameter pruning. Using the insights obtained from this comparison and stating the problems it brings we motivate why pruning units instead of the individual parameters might be a better idea. We propose some set of definitions to quantify and analyze units that don't learn and create any useful information. We propose an efficient way for detecting dead units and use it to select which units to prune. We get 5x model size reduction through unit-wise pruning on MNIST.", "venue": "ArXiv", "authors": ["Utku  Evci"], "year": 2018, "n_citations": 2}
{"id": 2260564, "s2_id": "ad66243aa5774880ddfa32b484946cc73e1559d6", "title": "Multimodal Deep Generative Models for Trajectory Prediction: A Conditional Variational Autoencoder Approach", "abstract": "Human behavior prediction models enable robots to anticipate how humans may react to their actions, and hence are instrumental to devising safe and proactive robot planning algorithms. However, modeling complex interaction dynamics and capturing the possibility of many possible outcomes in such interactive settings is very challenging, which has recently prompted the study of several different approaches. In this work, we provide a self-contained tutorial on a conditional variational autoencoder (CVAE) approach to human behavior prediction which, at its core, can produce a multimodal probability distribution over future human trajectories conditioned on past interactions and candidate robot future actions. Specifically, the goals of this tutorial paper are to review and build a taxonomy of state-of-the-art methods in human behavior prediction, from physics-based to purely data-driven methods, provide a rigorous yet easily accessible description of a data-driven, CVAE-based approach, highlight important design characteristics that make this an attractive model to use in the context of model-based planning for human-robot interactions, and provide important design considerations when using this class of models.", "venue": "IEEE Robotics and Automation Letters", "authors": ["Boris  Ivanovic", "Karen  Leung", "Edward  Schmerling", "Marco  Pavone"], "year": 2021, "n_citations": 14}
{"id": 2264913, "s2_id": "2bb4e8fe111e7c9269a68282e16b8a63eb193804", "title": "DeepDistance: A Multi-task Deep Regression Model for Cell Detection in Inverted Microscopy Images", "abstract": "This paper presents a new deep regression model, which we call DeepDistance, for cell detection in images acquired with inverted microscopy. This model considers cell detection as a task of finding most probable locations that suggest cell centers in an image. It represents this main task with a regression task of learning an inner distance metric. However, different than the previously reported regression based methods, the DeepDistance model proposes to approach its learning as a multi-task regression problem where multiple tasks are learned by using shared feature representations. To this end, it defines a secondary metric, normalized outer distance, to represent a different aspect of the problem and proposes to define its learning as complementary to the main cell detection task. In order to learn these two complementary tasks more effectively, the DeepDistance model designs a fully convolutional network (FCN) with a shared encoder path and end-to-end trains this FCN to concurrently learn the tasks in parallel. For further performance improvement on the main task, this paper also presents an extended version of the DeepDistance model that includes an auxiliary classification task and learns it in parallel to the two regression tasks by also sharing feature representations with them. DeepDistance uses the inner distances estimated by these FCNs in a detection algorithm to locate individual cells in a given image. In addition to this detection algorithm, this paper also suggests a cell segmentation algorithm that employs the estimated maps to find cell boundaries. Our experiments on three different human cell lines reveal that the proposed multi-task learning models, the DeepDistance model and its extended version, successfully identify the locations of cell as well as delineate their boundaries, even for the cell line that was not used in training, and improve the results of its counterparts.", "venue": "Medical Image Anal.", "authors": ["Can Fahrettin Koyuncu", "Gozde Nur Gunesli", "Reng\u00fcl  \u00c7etin-Atalay", "Cigdem  Demir"], "year": 2020, "n_citations": 9}
{"id": 2265017, "s2_id": "62bd0f02f3884f4c367c9abb8d8e2c4466eb0b4d", "title": "Subspace Detours: Building Transport Plans that are Optimal on Subspace Projections", "abstract": "Computing optimal transport (OT) between measures in high dimensions is doomed by the curse of dimensionality. A popular approach to avoid this curse is to project input measures on lower-dimensional subspaces (1D lines in the case of sliced Wasserstein distances), solve the OT problem between these reduced measures, and settle for the Wasserstein distance between these reductions, rather than that between the original measures. This approach is however difficult to extend to the case in which one wants to compute an OT map (a Monge map) between the original measures. Since computations are carried out on lower-dimensional projections, classical map estimation techniques can only produce maps operating in these reduced dimensions. We propose in this work two methods to extrapolate, from an transport map that is optimal on a subspace, one that is nearly optimal in the entire space. We prove that the best optimal transport plan that takes such \"subspace detours\" is a generalization of the Knothe-Rosenblatt transport. We show that these plans can be explicitly formulated when comparing Gaussian measures (between which the Wasserstein distance is commonly referred to as the Bures or Frechet distance). We provide an algorithm to select optimal subspaces given pairs of Gaussian measures, and study scenarios in which that mediating subspace can be selected using prior information. We consider applications to semantic mediation between elliptic word embeddings and domain adaptation with Gaussian mixture models.", "venue": "NeurIPS", "authors": ["Boris  Muzellec", "Marco  Cuturi"], "year": 2019, "n_citations": 16}
{"id": 2267896, "s2_id": "d678fc8f9edf96dd6852d4ad898691fec639631e", "title": "Orthogonally Decoupled Variational Fourier Features", "abstract": "Sparse inducing points have long been a standard method to fit Gaussian processes to big data. In the last few years, spectral methods that exploit approximations of the covariance kernel have shown to be competitive. In this work we exploit a recently introduced orthogonally decoupled variational basis to combine spectral methods and sparse inducing points methods. We show that the method is competitive with the state-of-the-art on synthetic and on real-world data.", "venue": "ArXiv", "authors": ["Dario  Azzimonti", "Manuel  Schurch", "Alessio  Benavoli", "Marco  Zaffalon"], "year": 2020, "n_citations": 0}
{"id": 2275740, "s2_id": "81bcbae2f547c6915dc14e7b0c3ff9ea6cff7d4f", "title": "On the Connection Between Adversarial Robustness and Saliency Map Interpretability", "abstract": "Recent studies on the adversarial vulnerability of neural networks have shown that models trained to be more robust to adversarial attacks exhibit more interpretable saliency maps than their non-robust counterparts. We aim to quantify this behavior by considering the alignment between input image and saliency map. We hypothesize that as the distance to the decision boundary grows,so does the alignment. This connection is strictly true in the case of linear models. We confirm these theoretical findings with experiments based on models trained with a local Lipschitz regularization and identify where the non-linear nature of neural networks weakens the relation.", "venue": "ICML", "authors": ["Christian  Etmann", "Sebastian  Lunz", "Peter  Maass", "Carola-Bibiane  Sch\u00f6nlieb"], "year": 2019, "n_citations": 65}
{"id": 2281017, "s2_id": "7bae62eb9b986eef4f143497c314d713f39cc0c3", "title": "A Targeted Universal Attack on Graph Convolutional Network", "abstract": "Graph-structured data exist in numerous applications in real life. As a state-of-the-art graph neural network, the graph convolutional network (GCN) plays an important role in processing graph-structured data. However, a recent study reported that GCNs are also vulnerable to adversarial attacks, which means that GCN models may suffer malicious attacks with unnoticeable modifications of the data. Among all the adversarial attacks on GCNs, there is a special kind of attack method called the universal adversarial attack, which generates a perturbation that can be applied to any sample and causes GCN models to output incorrect results. Although universal adversarial attacks in computer vision have been extensively researched, there are few research works on universal adversarial attacks on graph structured data. In this paper, we propose a targeted universal adversarial attack against GCNs. Our method employs a few nodes as the attack nodes. The attack capability of the attack nodes is enhanced through a small number of fake nodes connected to them. During an attack, any victim node will be misclassified by the GCN as the attack node class as long as it is linked to them. The experiments on three popular datasets show that the average attack success rate of the proposed attack on any victim node in the graph reaches 83% when using only 3 attack nodes and 6 fake nodes. We hope that our work will make the community aware of the threat of this type of attack and raise the attention given to its future defense.", "venue": "ArXiv", "authors": ["Jiazhu  Dai", "Weifeng  Zhu", "Xiangfeng  Luo"], "year": 2020, "n_citations": 1}
{"id": 2296937, "s2_id": "455d20cfe4670c8ad82e227983dab79561e46105", "title": "Order Optimal One-Shot Distributed Learning", "abstract": "We consider distributed statistical optimization in one-shot setting, where there are $m$ machines each observing $n$ i.i.d samples. Based on its observed samples, each machine then sends an $O(\\log(mn))$-length message to a server, at which a parameter minimizing an expected loss is to be estimated. We propose an algorithm called Multi-Resolution Estimator (MRE) whose expected error is no larger than $\\tilde{O}( m^{-1/\\max(d,2)} n^{-1/2})$, where $d$ is the dimension of the parameter space. This error bound meets existing lower bounds up to poly-logarithmic factors, and is thereby order optimal. The expected error of MRE, unlike existing algorithms, tends to zero as the number of machines ($m$) goes to infinity, even when the number of samples per machine ($n$) remains upper bounded by a constant. This property of the MRE algorithm makes it applicable in new machine learning paradigms where $m$ is much larger than $n$.", "venue": "NeurIPS", "authors": ["Arsalan  Sharif-Nassab", "Saber  Salehkaleybar", "S. Jamaloddin Golestani"], "year": 2019, "n_citations": 3}
{"id": 2310184, "s2_id": "b99022d76066130fa379fda1f766a030f923c56c", "title": "Boosting Ant Colony Optimization via Solution Prediction and Machine Learning", "abstract": "This paper introduces an enhanced meta-heuristic (ML-ACO) that combines machine learning (ML) and ant colony optimization (ACO) to solve combinatorial optimization problems. To illustrate the underlying mechanism of our enhanced algorithm, we start by describing a test problem -- the orienteering problem -- used to demonstrate the efficacy of ML-ACO. In this problem, the objective is to find a route that visits a subset of vertices in a graph within a time budget to maximize the collected score. In the first phase of our ML-ACO algorithm, an ML model is trained using a set of small problem instances where the optimal solution is known. Specifically, classification models are used to classify an edge as being part of the optimal route, or not, using problem-specific features and statistical measures. We have tested several classification models including graph neural networks, logistic regression and support vector machines. The trained model is then used to predict the probability that an edge in the graph of a test problem instance belongs to the corresponding optimal route. In the second phase, we incorporate the predicted probabilities into the ACO component of our algorithm. Here, the probability values bias sampling towards favoring those predicted high-quality edges when constructing feasible routes. We empirically show that ML-ACO generates results that are significantly better than the standard ACO algorithm, especially when the computational budget is limited. Furthermore, we show our algorithm is robust in the sense that (a) its overall performance is not sensitive to any particular classification model, and (b) it generalizes well to large and real-world problem instances. Our approach integrating ML with a meta-heuristic is generic and can be applied to a wide range of combinatorial optimization problems.", "venue": "ArXiv", "authors": ["Yuan  Sun", "Sheng  Wang", "Yunzhuang  Shen", "Xiaodong  Li", "Andreas T. Ernst", "Michael  Kirley"], "year": 2020, "n_citations": 0}
{"id": 2315713, "s2_id": "eead58e5b2437808559adcd816c7a0cdbec0a90a", "title": "Depth-Adaptive Transformer", "abstract": "State of the art sequence-to-sequence models for large scale tasks perform a fixed number of computations for each input sequence regardless of whether it is easy or hard to process. In this paper, we train Transformer models which can make output predictions at different stages of the network and we investigate different ways to predict how much computation is required for a particular sequence. Unlike dynamic computation in Universal Transformers, which applies the same set of layers iteratively, we apply different layers at every step to adjust both the amount of computation as well as the model capacity. On IWSLT German-English translation our approach matches the accuracy of a well tuned baseline Transformer while using less than a quarter of the decoder layers.", "venue": "ICLR", "authors": ["Maha  Elbayad", "Jiatao  Gu", "Edouard  Grave", "Michael  Auli"], "year": 2020, "n_citations": 44}
{"id": 2321009, "s2_id": "b8b5abbd1545f76dc482457cd3d8660ca996d504", "title": "Feature Exploration for Almost Zero-Resource ASR-Free Keyword Spotting Using a Multilingual Bottleneck Extractor and Correspondence Autoencoders", "abstract": "We compare features for dynamic time warping (DTW) when used to bootstrap keyword spotting (KWS) in an almost zero-resource setting. Such quickly-deployable systems aim to support United Nations (UN) humanitarian relief efforts in parts of Africa with severely under-resourced languages. Our objective is to identify acoustic features that provide acceptable KWS performance in such environments. As supervised resource, we restrict ourselves to a small, easily acquired and independently compiled set of isolated keywords. For feature extraction, a multilingual bottleneck feature (BNF) extractor, trained on well-resourced out-of-domain languages, is integrated with a correspondence autoencoder (CAE) trained on extremely sparse in-domain data. On their own, BNFs and CAE features are shown to achieve a more than 2% absolute performance improvement over baseline MFCCs. However, by using BNFs as input to the CAE, even better performance is achieved, with a more than 11% absolute improvement in ROC AUC over MFCCs and more than twice as many top-10 retrievals for two evaluated languages, English and Luganda. We conclude that integrating BNFs with the CAE allows both large out-of-domain and sparse in-domain resources to be exploited for improved ASR-free keyword spotting.", "venue": "INTERSPEECH", "authors": ["Raghav  Menon", "Herman  Kamper", "Ewald van der  Westhuizen", "John  Quinn", "Thomas  Niesler"], "year": 2019, "n_citations": 18}
{"id": 2336920, "s2_id": "e0d89b3bfd1e260ecc017f94af107cb27999d4ce", "title": "NANCY: Neural Adaptive Network Coding methodologY for video distribution over wireless networks", "abstract": "This paper presents NANCY, a system that generates adaptive bit rates (ABR) for video and adaptive network coding rates (ANCR) using reinforcement learning (RL) for video distribution over wireless networks. NANCY trains a neural network model with rewards formulated as quality of experience (QoE) metrics. It performs joint optimization in order to select: (i) adaptive bit rates for future video chunks to counter variations in available bandwidth and (ii) adaptive network coding rates to encode the video chunk slices to counter packet losses in wireless networks. We present the design and implementation of NANCY, and evaluate its performance compared to state-of-the-art video rate adaptation algorithms including Pensieve and robustMPC. Our results show that NANCY provides 29.91% and 60.34% higher average QoE than Pensieve and robustMPC, respectively.", "venue": "GLOBECOM 2020 - 2020 IEEE Global Communications Conference", "authors": ["Paresh  Saxena", "Mandan  Naresh", "Manik  Gupta", "Anirudh  Achanta", "Sastri  Kota", "Smrati  Gupta"], "year": 2020, "n_citations": 1}
{"id": 2337286, "s2_id": "6a5fff7fa27408e9f25c88b685010d34f701ea36", "title": "Expanding boundaries of Gap Safe screening", "abstract": "Sparse optimization problems are ubiquitous in many fields such as statistics, signal/image processing and machine learning. This has led to the birth of many iterative algorithms to solve them. A powerful strategy to boost the performance of these algorithms is known as safe screening : it allows the early identification of zero coordinates in the solution, which can then be eliminated to reduce the problem\u2019s size and accelerate convergence. In this work, we extend the existing Gap Safe screening framework by relaxing the global strong-concavity assumption on the dual cost function. Instead, we exploit local regularity properties, that is, strong concavity on well-chosen subsets of the domain. The non-negativity constraint is also integrated to the existing framework. Besides making safe screening possible to a broader class of functions that includes \u03b2-divergences (e.g., the Kullback-Leibler divergence), the proposed approach also improves upon the existing Gap Safe screening rules on previously applicable cases (e.g., logistic regression). The proposed general framework is exemplified by some notable particular cases: logistic function, \u03b2 = 1.5 and Kullback-Leibler divergences. Finally, we showcase the effectiveness of the proposed screening rules with different solvers (coordinate descent, multiplicative-update and proximal gradient algorithms) and different data sets (binary classification, hyperspectral and count data).", "venue": "ArXiv", "authors": ["Cassio  Dantas", "Emmanuel  Soubies", "C'edric  F'evotte"], "year": 2021, "n_citations": 0}
{"id": 2348709, "s2_id": "791ad7876370704b69184927403dc8eefb7c3f33", "title": "Predict then Interpolate: A Simple Algorithm to Learn Stable Classifiers", "abstract": "We propose Predict then Interpolate (PI), a simple algorithm for learning correlations that are stable across environments. The algorithm follows from the intuition that when using a classifier trained on one environment to make predictions on examples from another environment, its mistakes are informative as to which correlations are unstable. In this work, we prove that by interpolating the distributions of the correct predictions and the wrong predictions, we can uncover an oracle distribution where the unstable correlation vanishes. Since the oracle interpolation coefficients are not accessible, we use group distributionally robust optimization to minimize the worst-case risk across all such interpolations. We evaluate our method on both text classification and image classification. Empirical results demonstrate that our algorithm is able to learn robust classifiers (outperforms IRM by 23.85% on synthetic environments and 12.41% on natural environments). Our code and data are available at https://github.com/YujiaBao/ Predict-then-Interpolate.", "venue": "ICML", "authors": ["Yujia  Bao", "Shiyu  Chang", "Regina  Barzilay"], "year": 2021, "n_citations": 4}
{"id": 2354850, "s2_id": "0bde8d9367d1004c7396dd69cb27ed97dc2f8d77", "title": "MatConvNet: Convolutional Neural Networks for MATLAB", "abstract": "MatConvNet is an open source implementation of Convolutional Neural Networks (CNNs) with a deep integration in the MATLAB environment. The toolbox is designed with an emphasis on simplicity and flexibility. It exposes the building blocks of CNNs as easy-to-use MATLAB functions, providing routines for computing convolutions with filter banks, feature pooling, normalisation, and much more. MatConvNet can be easily extended, often using only MATLAB code, allowing fast prototyping of new CNN architectures. At the same time, it supports efficient computation on CPU and GPU, allowing to train complex models on large datasets such as ImageNet ILSVRC containing millions of training examples", "venue": "ACM Multimedia", "authors": ["Andrea  Vedaldi", "Karel  Lenc"], "year": 2015, "n_citations": 2713}
{"id": 2355553, "s2_id": "a4cec122a08216fe8a3bc19b22e78fbaea096256", "title": "Deep Learning", "abstract": "Machine-learning technology powers many aspects of modern society: from web searches to content filtering on social networks to recommendations on e-commerce websites, and it is increasingly present in consumer products such as cameras and smartphones. Machine-learning systems are used to identify objects in images, transcribe speech into text, match news items, posts or products with users\u2019 interests, and select relevant results of search. Increasingly, these applications make use of a class of techniques called deep learning. Conventional machine-learning techniques were limited in their ability to process natural data in their raw form. For decades, constructing a pattern-recognition or machine-learning system required careful engineering and considerable domain expertise to design a feature extractor that transformed the raw data (such as the pixel values of an image) into a suitable internal representation or feature vector from which the learning subsystem, often a classifier, could detect or classify patterns in the input. Representation learning is a set of methods that allows a machine to be fed with raw data and to automatically discover the representations needed for detection or classification. Deep-learning methods are representation-learning methods with multiple levels of representation, obtained by composing simple but non-linear modules that each transform the representation at one level (starting with the raw input) into a representation at a higher, slightly more abstract level. With the composition of enough such transformations, very complex functions can be learned. For classification tasks, higher layers of representation amplify aspects of the input that are important for discrimination and suppress irrelevant variations. An image, for example, comes in the form of an array of pixel values, and the learned features in the first layer of representation typically represent the presence or absence of edges at particular orientations and locations in the image. The second layer typically detects motifs by spotting particular arrangements of edges, regardless of small variations in the edge positions. The third layer may assemble motifs into larger combinations that correspond to parts of familiar objects, and subsequent layers would detect objects as combinations of these parts. The key aspect of deep learning is that these layers of features are not designed by human engineers: they are learned from data using a general-purpose learning procedure. Deep learning is making major advances in solving problems that have resisted the best attempts of the artificial intelligence community for many years. It has turned out to be very good at discovering intricate structures in high-dimensional data and is therefore applicable to many domains of science, business and government. In addition to beating records in image recognition and speech recognition, it has beaten other machine-learning techniques at predicting the activity of potential drug molecules, analysing particle accelerator data, reconstructing brain circuits, and predicting the effects of mutations in non-coding DNA on gene expression and disease. Perhaps more surprisingly, deep learning has produced extremely promising results for various tasks in natural language understanding, particularly topic classification, sentiment analysis, question answering and language translation. We think that deep learning will have many more successes in the near future because it requires very little engineering by hand, so it can easily take advantage of increases in the amount of available computation and data. New learning algorithms and architectures that are currently being developed for deep neural networks will only accelerate this progress.", "venue": "Nature", "authors": ["Ian  Goodfellow", "Yoshua  Bengio", "Aaron  Courville"], "year": 2015, "n_citations": 26169}
{"id": 2360569, "s2_id": "70fe236bdc5071ffd3b13bf518946702c9ba6895", "title": "An Entropy-based Learning Algorithm of Bayesian Conditional Trees", "abstract": "This article offers a modification of Chow and Liu's learning algorithm in the context of handwritten digit recognition. The modified algorithm directs the user to group digits into several classes consisting of digits that are hard to distinguish and then constructing an optimal conditional tree representation for each class of digits instead of for each single digit as done by Chow and Liu (1968). Advantages and extensions of the new method are discussed. Related works of Wong and Wang (1977) and Wong and Poon (1989) which offer a different entropy-based learning algorithm are shown to rest on inappropriate assumptions.", "venue": "UAI", "authors": ["Dan  Geiger"], "year": 1992, "n_citations": 74}
{"id": 2363169, "s2_id": "b51d23b2cd972a75c854ca7fe863122eeac895f6", "title": "Depth From Videos in the Wild: Unsupervised Monocular Depth Learning From Unknown Cameras", "abstract": "We present a novel method for simultaneous learning of depth, egomotion, object motion, and camera intrinsics from monocular videos, using only consistency across neighboring video frames as supervision signal. Similarly to prior work, our method learns by applying differentiable warping to frames and comparing the result to adjacent ones, but it provides several improvements: We address occlusions geometrically and differentiably, directly using the depth maps as predicted during training. We introduce randomized layer normalization, a novel powerful regularizer, and we account for object motion relative to the scene. To the best of our knowledge, our work is the first to learn the camera intrinsic parameters, including lens distortion, from video in an unsupervised manner, thereby allowing us to extract accurate depth and motion from arbitrary videos of unknown origin at scale. We evaluate our results on the Cityscapes, KITTI and EuRoC datasets, establishing new state of the art on depth prediction and odometry, and demonstrate qualitatively that depth prediction can be learned from a collection of YouTube videos. The code will be open sourced once anonymity is lifted.", "venue": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)", "authors": ["Ariel  Gordon", "Hanhan  Li", "Rico  Jonschkowski", "Anelia  Angelova"], "year": 2019, "n_citations": 161}
{"id": 2367424, "s2_id": "362844d766fc1c73e6877fe1740f1631d7fc26a5", "title": "DeepWiFi: Cognitive WiFi with Deep Learning", "abstract": "We present the DeepWiFi protocol, which hardens the baseline WiFi (IEEE 802.11ac) with deep learning and sustains high throughput by mitigating out-of-network interference. DeepWiFi is interoperable with baseline WiFi and builds upon the existing WiFi's PHY transceiver chain without changing the MAC frame format. Users run DeepWiFi for: i) RF front end processing; ii) spectrum sensing and signal classification; iii) signal authentication; iv) channel selection and access; v) power control; vi) modulation and coding scheme (MCS) adaptation; and vii) routing. DeepWiFi mitigates the effects of probabilistic, sensing-based, and adaptive jammers. RF front end processing applies a deep learning-based autoencoder to extract spectrum-representative features. Then a deep neural network is trained to classify waveforms reliably as idle, WiFi, or jammer. Utilizing channel labels, users effectively access idle or jammed channels, while avoiding interference with legitimate WiFi transmissions (authenticated by machine learning-based RF fingerprinting) resulting in higher throughput. Users optimize their transmit power for low probability of intercept/detection and their MCS to maximize link rates used by backpressure algorithm for routing. Supported by embedded platform implementation, DeepWiFi provides major throughput gains compared to baseline WiFi and another jamming-resistant protocol, especially when channels are likely to be jammed and the signal-to-interference-plus-noise-ratio is low.", "venue": "IEEE Transactions on Mobile Computing", "authors": ["Kemal  Davaslioglu", "Sohraab  Soltani", "Tugba  Erpek", "Yalin E. Sagduyu"], "year": 2021, "n_citations": 18}
{"id": 2369685, "s2_id": "e270ee0a279a624ebbf4a59ae679b786be16c510", "title": "Towards Automatic Evaluation of Dialog Systems: A Model-Free Off-Policy Evaluation Approach", "abstract": "Reliable automatic evaluation of dialogue systems under an interactive environment has long been overdue. An ideal environment for evaluating dialog systems, also known as the Turing test, needs to involve human interaction, which is usually not affordable for large scale experiments. Though researchers have attempted to use metrics for language generation tasks (e.g., perplexity, BLEU) or some model-based reinforcement learning methods (e.g., self-play evaluation) for automatic evaluation, these methods only show very weak correlation with the actual human evaluation in practice. To bridge such a gap, we propose a new framework named ENIGMA for estimating human evaluation scores based on recent advances of off-policy evaluation in reinforcement learning. ENIGMA only requires a handful of pre-collected experience data, and therefore does not involve human interaction with the target policy during the evaluation, making automatic evaluations feasible. More importantly, ENIGMA is model-free and agnostic to the behavior policies for collecting the experience data (see details in Section 2), which significantly alleviates the technical difficulties of modeling complex dialogue environments and human behaviors. Our experiments show that ENIGMA significantly outperforms existing methods in terms of correlation with human evaluation scores.", "venue": "EMNLP", "authors": ["Haoming  Jiang", "Bo  Dai", "Mengjiao  Yang", "Wei  Wei", "Tuo  Zhao"], "year": 2021, "n_citations": 3}
{"id": 2383044, "s2_id": "7f309eae95c9c5b8266f9b5c8d71a5c21c9d33fc", "title": "Features selection in NBA outcome prediction through Deep Learning", "abstract": "This manuscript is focused on features\u2019 definition for the outcome prediction of matches of NBA basketball championship. It is shown how models based on one a single feature (Elo rating or the relative victory frequency) have a quality of fit better than models using box-score predictors (e.g. the Four Factors). Features have been ex ante calculated for a dataset containing data of 16 NBA regular seasons, paying particular attention to home court factor. Models have been produced via Deep Learning, using cross validation.", "venue": "ArXiv", "authors": ["Manlio  Migliorati"], "year": 2021, "n_citations": 0}
{"id": 2387072, "s2_id": "ed49f2f4f35402a6bc2bdb152d5af138166fccd0", "title": "Health Monitoring of Industrial machines using Scene-Aware Threshold Selection", "abstract": "This paper presents an autoencoder based unsupervised approach to identify anomaly in an industrial machine using sounds produced by the machine. The proposed framework is trained using log-melspectrogram representations of the sound signal. In classification, our hypothesis is that the reconstruction error computed for an abnormal machine is larger than that of the a normal machine, since only normal machine sounds are being used to train the autoencoder. A threshold is chosen to discriminate between normal and abnormal machines. However, the threshold changes as surrounding conditions vary. To select an appropriate threshold irrespective of the surrounding, we propose a scene classification framework, which can classify the underlying surrounding. Hence, the threshold can be selected adaptively irrespective of the surrounding. The experiment evaluation is performed on MIMII dataset for industrial machines namely fan, pump, valve and slide rail. Our experiment analysis shows that utilizing adaptive threshold, the performance improves significantly as that obtained using the fixed threshold computed for a given surrounding only.", "venue": "ArXiv", "authors": ["Arshdeep  Singh", "Raju  Arvind", "Padmanabhan  Rajan"], "year": 2021, "n_citations": 0}
{"id": 2397512, "s2_id": "b17d48713965fa5d4dfbac943a0a084f4b642bfb", "title": "On the Convergence of Tsetlin Machines for the AND and the OR Operators", "abstract": "The Tsetlin Machine (TM) is a novel machine learning algorithm based on propositional logic, which has obtained the state-of-the-art performance on several pattern recognition problems. In previous studies, the convergence properties of TM for 1-bit operation and XOR operation have been analyzed. To make the analyses for the basic digital operations complete, in this article, we analyze the convergence when input training samples follow AND and OR operators respectively. Our analyses reveal that the TM can converge almost surely to reproduce AND and OR operators, which are learnt from training data over an infinite time horizon. The analyses on AND and OR operators, together with the previously analysed 1-bit and XOR operations, complete the convergence analyses on basic operators in Boolean algebra.", "venue": "ArXiv", "authors": ["Lei  Jiao", "Xuan  Zhang", "Ole-Christoffer  Granmo"], "year": 2021, "n_citations": 0}
{"id": 2399817, "s2_id": "becd1be0a7dc4b27cba2c1daeb7f25d373bc0e51", "title": "A Nonlinear Dimensionality Reduction Framework Using Smooth Geodesics", "abstract": "Existing dimensionality reduction methods are adept at revealing hidden underlying manifolds arising from high-dimensional data and thereby producing a low-dimensional representation. However, the smoothness of the manifolds produced by classic techniques over sparse and noisy data is not guaranteed. In fact, the embedding generated using such data may distort the geometry of the manifold and thereby produce an unfaithful embedding. Herein, we propose a framework for nonlinear dimensionality reduction that generates a manifold in terms of smooth geodesics that is designed to treat problems in which manifold measurements are either sparse or corrupted by noise. Our method generates a network structure for given high-dimensional data using a nearest neighbors search and then produces piecewise linear shortest paths that are defined as geodesics. Then, we fit points in each geodesic by a smoothing spline to emphasize the smoothness. The robustness of this approach for sparse and noisy datasets is demonstrated by the implementation of the method on synthetic and real-world datasets.", "venue": "Pattern Recognit.", "authors": ["Kelum  Gajamannage", "Randy C. Paffenroth", "Erik M. Bollt"], "year": 2019, "n_citations": 9}
{"id": 2403039, "s2_id": "0b29f2dd93294771cf687198b1dbcd7aec4a71a8", "title": "An Instance Transfer-Based Approach Using Enhanced Recurrent Neural Network for Domain Named Entity Recognition", "abstract": "Recently, neural networks have shown promising results for named entity recognition(NER), which needs a number of labeled data to for model training. When meeting a new domain (target domain) for NER, there is no or a few labeled data, which makes domain NER much more difficult. As NER has been researched for a long time, some similar domain already has well labeled data(source domain). Therefore, in this paper, we focus on domain NER by studying how to utilize the labeled data from such similar source domain for the new target domain. We design a kernel function based instance transfer strategy by getting similar labeled sentences from a source domain. Moreover, we propose an enhanced recurrent neural network (ERNN) by adding an additional layer that combines the source domain labeled data into traditional RNN structure. Comprehensive experiments are conducted on two datasets. The comparison results among HMM, CRF and RNN show that RNN performs better than others. When there is no labeled data in domain target, compared to directly using the source domain labeled data without selecting transferred instances, our enhanced RNN approach gets improvement from 0.8052 to 0.9328 in terms of F1 measure.", "venue": "IEEE Access", "authors": ["Chuanbo  Liu", "Chaojie  Fan", "Zhengju  Wang", "Yueqing  Sun"], "year": 2020, "n_citations": 1}
{"id": 2405025, "s2_id": "a963c08bfc6704722b90867792c0d1ae3ed21639", "title": "Towards Probabilistic Tensor Canonical Polyadic Decomposition 2.0: Automatic Tensor Rank Learning Using Generalized Hyperbolic Prior", "abstract": "Tensor rank learning for canonical polyadic decomposition (CPD) has long been deemed as an essential but challenging problem. In particular, since the tensor rank controls the complexity of the CPD model, its inaccurate learning would cause overfitting to noise or underfitting to the signal sources, and even destroy the interpretability of model parameters. However, the optimal determination of a tensor rank is known to be a non-deterministic polynomial-time hard (NP-hard) task. Rather than exhaustively searching for the best tensor rank via trial-and-error experiments, Bayesian inference under the Gaussian-gamma prior was introduced in the context of probabilistic CPD modeling and it was shown to be an effective strategy for automatic tensor rank determination. This triggered flourishing research on other structured tensor CPDs with automatic tensor rank learning. As the other side of the coin, these research works also reveal that the Gaussian-gamma model does not perform well for high-rank tensors or/and low signal-to-noise ratios (SNRs). To overcome these drawbacks, in this paper, we introduce a more advanced generalized hyperbolic (GH) prior to the probabilistic CPD model, which not only includes the Gaussian-gamma model as a special case, but also provides more flexibilities to adapt to different levels of sparsity. Based on this novel probabilistic model, an algorithm is developed under the framework of variational inference, where each update is obtained in a closed-form. Extensive numerical results, using synthetic data and real-world datasets, demonstrate the excellent performance of the proposed method in learning both low as well as high tensor ranks even for low SNR cases.", "venue": "ArXiv", "authors": ["Lei  Cheng", "Zhongtao  Chen", "Qingjiang  Shi", "Yik-Chung  Wu", "Sergios  Theodoridis"], "year": 2020, "n_citations": 3}
{"id": 2409133, "s2_id": "ed73a4b875fd5efd4066fa514d7857ec7de1e7ea", "title": "Dynamic Adversarial Patch for Evading Object Detection Models", "abstract": "Recent research shows that neural networks models used for computer vision (e.g., YOLO and Fast R-CNN) are vulnerable to adversarial evasion attacks. Most of the existing real-world adversarial attacks against object detectors use an adversarial patch which is attached to the target object (e.g., a carefully crafted sticker placed on a stop sign). This method may not be robust to changes in the camera's location relative to the target object; in addition, it may not work well when applied to nonplanar objects such as cars. In this study, we present an innovative attack method against object detectors applied in a real-world setup that addresses some of the limitations of existing attacks. Our method uses dynamic adversarial patches which are placed at multiple predetermined locations on a target object. An adversarial learning algorithm is applied in order to generate the patches used. The dynamic attack is implemented by switching between optimized patches dynamically, according to the camera's position (i.e., the object detection system's position). In order to demonstrate our attack in a real-world setup, we implemented the patches by attaching flat screens to the target object; the screens are used to present the patches and switch between them, depending on the current camera location. Thus, the attack is dynamic and adjusts itself to the situation to achieve optimal results. We evaluated our dynamic patch approach by attacking the YOLOv2 object detector with a car as the target object and succeeded in misleading it in up to 90% of the video frames when filming the car from a wide viewing angle range. We improved the attack by generating patches that consider the semantic distance between the target object and its classification. We also examined the attack's transferability among different car models and were able to mislead the detector 71% of the time.", "venue": "ArXiv", "authors": ["Shahar  Hoory", "Tzvika  Shapira", "Asaf  Shabtai", "Yuval  Elovici"], "year": 2020, "n_citations": 4}
{"id": 2411175, "s2_id": "2c740e574eea66fdcf473e15ed2c228baef2eccd", "title": "NIPS 2016 Tutorial: Generative Adversarial Networks", "abstract": "This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.", "venue": "ArXiv", "authors": ["Ian J. Goodfellow"], "year": 2017, "n_citations": 1043}
{"id": 2428179, "s2_id": "e86b223b4ee66ffb2f1fce8ca446505b57b04c2d", "title": "Predictive Collective Variable Discovery with Deep Bayesian Models", "abstract": "Extending spatio-temporal scale limitations of models for complex atomistic systems considered in biochemistry and materials science necessitates the development of enhanced sampling methods. The potential acceleration in exploring the configurational space by enhanced sampling methods depends on the choice of collective variables (CVs). In this work, we formulate the discovery of CVs as a Bayesian inference problem and consider the CVs as hidden generators of the full-atomistic trajectory. The ability to generate samples of the fine-scale atomistic configurations using limited training data allows us to compute estimates of observables as well as our probabilistic confidence on them. The methodology is based on emerging methodological advances in machine learning and variational inference. The discovered CVs are related to physicochemical properties which are essential for understanding mechanisms especially in unexplored complex systems. We provide a quantitative assessment of the CVs in terms of their predictive ability for alanine dipeptide (ALA-2) and ALA-15 peptide.", "venue": "The Journal of chemical physics", "authors": ["Markus  Sch\u00f6berl", "Nicholas  Zabaras", "Phaedon-Stelios  Koutsourelakis"], "year": 2019, "n_citations": 22}
{"id": 2438371, "s2_id": "d3850595d3ae7c73e9488054c9b437f75511b569", "title": "SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver", "abstract": "Integrating logical reasoning within deep learning architectures has been a major goal of modern AI systems. In this paper, we propose a new direction toward this goal by introducing a differentiable (smoothed) maximum satisfiability (MAXSAT) solver that can be integrated into the loop of larger deep learning systems. Our (approximate) solver is based upon a fast coordinate descent approach to solving the semidefinite program (SDP) associated with the MAXSAT problem. We show how to analytically differentiate through the solution to this SDP and efficiently solve the associated backward pass. We demonstrate that by integrating this solver into end-to-end learning systems, we can learn the logical structure of challenging problems in a minimally supervised fashion. In particular, we show that we can learn the parity function using single-bit supervision (a traditionally hard task for deep networks) and learn how to play 9x9 Sudoku solely from examples. We also solve a \"visual Sudok\" problem that maps images of Sudoku puzzles to their associated logical solutions by combining our MAXSAT solver with a traditional convolutional architecture. Our approach thus shows promise in integrating logical structures within deep learning.", "venue": "ICML", "authors": ["Po-Wei  Wang", "Priya L. Donti", "Bryan  Wilder", "J. Zico Kolter"], "year": 2019, "n_citations": 93}
{"id": 2441307, "s2_id": "6349e3170ab35c573b2becdbbd085821e7ac9c33", "title": "Disentangling brain heterogeneity via semi-supervised deep-learning and MRI: dimensional representations of Alzheimer's Disease", "abstract": "Heterogeneity of brain diseases is a challenge for precision diagnosis/prognosis. We describe and validate Smile-GAN (SeMI-supervised cLustEring-Generative Adversarial Network), a novel semi-supervised deep-clustering method, which dissects neuroanatomical heterogeneity, enabling identification of disease subtypes via their imaging signatures relative to controls. When applied to MRIs (2 studies; 2,832 participants; 8,146 scans) including cognitively normal individuals and those with cognitive impairment and dementia, Smile-GAN identified 4 neurodegenerative patterns/axes: P1, normal anatomy and highest cognitive performance; P2, mild/diffuse atrophy and more prominent executive dysfunction; P3, focal medial temporal atrophy and relatively greater memory impairment; P4, advanced neurodegeneration. Further application to longitudinal data revealed two distinct progression pathways: P1\u2192P2\u2192P4 and P1\u2192P3\u2192P4. Baseline expression of these patterns predicted the pathway and rate of future neurodegeneration. Pattern expression offered better yet complementary performance in predicting clinical progression, compared to amyloid/tau. These deep-learning derived biomarkers offer promise for precision diagnostics and targeted clinical trial recruitment.", "venue": "ArXiv", "authors": ["Zhijian  Yang", "Ilya M. Nasrallah", "Haochang  Shou", "Junhao  Wen", "Jimit  Doshi", "Mohamad  Habes", "Guray  Erus", "Ahmed  Abdulkadir", "Susan M. Resnick", "David  Wolk", "Christos  Davatzikos"], "year": 2021, "n_citations": 3}
{"id": 2442205, "s2_id": "6e57ceeb4afc55f9f1bc5cfe986082fbc5cb6add", "title": "A New Representation of Successor Features for Transfer across Dissimilar Environments", "abstract": "Transfer in reinforcement learning is usually achieved through generalisation across tasks. Whilst many studies have investigated transferring knowledge when the reward function changes, they have assumed that the dynamics of the environments remain consistent. Many real-world RL problems require transfer among environments with different dynamics. To address this problem, we propose an approach based on successor features in which we model successor feature functions with Gaussian Processes permitting the source successor features to be treated as noisy measurements of the target successor feature function. Our theoretical analysis proves the convergence of this approach as well as the bounded error on modelling successor feature functions with Gaussian Processes in environments with both different dynamics and rewards. We demonstrate our method on benchmark datasets and show that it outperforms current baselines.", "venue": "ICML", "authors": ["Majid  Abdolshah", "Hung  Le", "Thommen George Karimpanal", "Sunil  Gupta", "Santu  Rana", "Svetha  Venkatesh"], "year": 2021, "n_citations": 2}
{"id": 2450340, "s2_id": "4bccc10bc33c00d7341257fcf5ddb6786e54d34f", "title": "On Empirical Meaning of Randomness with Respect to a Real Parameter", "abstract": "We study the empirical meaning of randomness with respect to a family of probability distributions P\u03b8, where \u03b8 is a real parameter, using algorithmic randomness theory. In the case when for a computable probability distribution P\u03b8 an effectively strongly consistent estimate exists, we show that the Levin's a priory semicomputable semimeasure of the set of all P\u03b8-random sequences is positive if and only if the parameter \u03b8 is a computable real number. The different methods for generating \"meaningful\" P\u03b8-random sequences with noncomputable \u03b8 are discussed.", "venue": "CSR", "authors": ["Vladimir V. V'yugin"], "year": 2007, "n_citations": 2}
{"id": 2451955, "s2_id": "6382ee7792437cdcc1b1d53428a173f94ef20d4e", "title": "Reinforcement Learning in Linear Quadratic Deep Structured Teams: Global Convergence of Policy Gradient Methods", "abstract": "In this paper, we study the global convergence of model-based and model-free policy gradient descent and natural policy gradient descent algorithms for linear quadratic deep structured teams. In such systems, agents are partitioned into a few sub-populations wherein the agents in each subpopulation are coupled in the dynamics and cost function through a set of linear regressions of the states and actions of all agents. Every agent observes its local state and the linear regressions of states, called deep states. For a sufficiently small risk factor and/or sufficiently large population, we prove that model-based policy gradient methods globally converge to the optimal solution. Given an arbitrary number of agents, we develop model-free policy gradient and natural policy gradient algorithms for the special case of risk-neutral cost function. The proposed algorithms are scalable with respect to the number of agents due to the fact that the dimension of their policy space is independent of the number of agents in each sub-population. Simulations are provided to verify the theoretical results.", "venue": "2020 59th IEEE Conference on Decision and Control (CDC)", "authors": ["Vida  Fathi", "Jalal  Arabneydi", "Amir G. Aghdam"], "year": 2020, "n_citations": 6}
{"id": 2452959, "s2_id": "70ef336491d3d63b8e7d16f20777a0834aef598f", "title": "Tensor p-shrinkage nuclear norm for low-rank tensor completion", "abstract": "In this paper, a new definition of tensor p-shrinkage nuclear norm (p-TNN) is proposed based on tensor singular value decomposition (t-SVD). In particular, it can be proved that p-TNN is a better approximation of the tensor average rank than the tensor nuclear norm when p < 1. Therefore, by employing the p-shrinkage nuclear norm, a novel low-rank tensor completion (LRTC) model is proposed to estimate a tensor from its partial observations. Statistically, the upper bound of recovery error is provided for the LRTC model. Furthermore, an efficient algorithm, accelerated by the adaptive momentum scheme, is developed to solve the resulting nonconvex optimization problem. It can be further guaranteed that the algorithm enjoys a global convergence rate under the smoothness assumption. Numerical experiments conducted on both synthetic and real-world data sets verify our results and demonstrate the superiority of our p-TNN in LRTC problems over several state-of-the-art methods.", "venue": "Neurocomputing", "authors": ["Chunsheng  Liu", "Hong  Shan", "Chunlei  Chen"], "year": 2020, "n_citations": 9}
{"id": 2461355, "s2_id": "4875b31ed398de0839eb264177753fd560f9be19", "title": "Potato Crop Stress Identification in Aerial Images using Deep Learning-based Object Detection", "abstract": "Recent research on the application of remote sensing and deep learning-based analysis in precision agriculture demonstrated a potential for improved crop management and reduced environmental impacts of agricultural production. Despite the promising results, the practical relevance of these technologies for actual field deployment requires novel algorithms that are customized for analysis of agricultural images and robust to implementation on natural field imagery. The paper presents an approach for analyzing aerial images of a potato crop using deep neural networks. The main objective is to demonstrate automated spatial recognition of a healthy versus stressed crop at a plant level. Specifically, we examine premature plant senescence resulting in drought stress on Russet Burbank potato plants. The proposed deep learning model, named Retina-UNet-Ag, is a variant of Retina-UNet (Jaeger et al., 2018) and includes connections from low-level semantic dense representation maps to the feature pyramid network. The paper also introduces a dataset of field images acquired with a Parrot Sequoia camera carried by a Solo unmanned aerial vehicle. Experimental validation demonstrated the ability for distinguishing healthy and stressed plants in field images, achieving an average Dice score coefficient of 0.74. A comparison to related state-of-the-art deep learning models for object detection revealed that the presented approach is effective for the task at hand. The method applied here is conducive toward the assessment and recognition of potato crop stress (early plant senescence resulting from drought stress in this case) in natural aerial field images collected under real conditions.", "venue": "ArXiv", "authors": ["Sujata  Butte", "Aleksandar  Vakanski", "Kasia  Duellman", "Haotian  Wang", "Amin  Mirkouei"], "year": 2021, "n_citations": 3}
{"id": 2461700, "s2_id": "dddaf99e74dcae11d3d52a03aa524335f49a53a1", "title": "Bag-of-words representation for biomedical time series classification", "abstract": "Automatic analysis of biomedical time series such as electroencephalogram (EEG) and electrocardiographic (ECG) signals has attracted great interest in the community of biomedical engineering due to its important applications in medicine. In this work, a simple yet effective bag-of-words representation that is originally developed for text document analysis is extended for biomedical time series representation. In particular, similar to the bag-of-words model used in text document domain, the proposed method treats a time series as a text document and extracts local segments from the time series as words. The biomedical time series is then represented as a histogram of codewords, each entry of which is the count of a codeword appeared in the time series. Although the temporal order of the local segments is ignored, the bag-of-words representation is able to capture high-level structural information because both local and global structural information are well utilized. The performance of the bag-of-words model is validated on three datasets extracted from real EEG and ECG signals. The experimental results demonstrate that the proposed method is not only insensitive to parameters of the bag-of-words model such as local segment length and codebook size, but also robust to noise.", "venue": "Biomed. Signal Process. Control.", "authors": ["Jin  Wang", "Ping  Liu", "Mary Fenghua She", "Saeid  Nahavandi", "Abbas Z. Kouzani"], "year": 2013, "n_citations": 109}
{"id": 2467375, "s2_id": "725597072c76dad5caa92b7baa6e1c761addc300", "title": "Deep adversarial neural decoding", "abstract": "Here, we present a novel approach to solve the problem of reconstructing perceived stimuli from brain responses by combining probabilistic inference with deep learning. Our approach first inverts the linear transformation from latent features to brain responses with maximum a posteriori estimation and then inverts the nonlinear transformation from perceived stimuli to latent features with adversarial training of convolutional neural networks. We test our approach with a functional magnetic resonance imaging experiment and show that it can generate state-of-the-art reconstructions of perceived faces from brain activations.", "venue": "NIPS 2017", "authors": ["Yagmur  G\u00fc\u00e7l\u00fct\u00fcrk", "Umut  G\u00fc\u00e7l\u00fc", "Katja  Seeliger", "Sander  Bosch", "Rob van Lier", "Marcel van Gerven"], "year": 2017, "n_citations": 9}
{"id": 2482275, "s2_id": "78be0bc2a75e67daf63330f3178c131260cfdcac", "title": "No-Regret Non-Convex Online Meta-Learning", "abstract": "The online meta-learning framework is designed for the continual lifelong learning setting. It bridges two fields: meta-learning which tries to extract prior knowledge from past tasks for fast learning of future tasks, and online-learning which tackles the sequential setting where problems are revealed one by one. In this paper, we generalize the original framework from convex to non-convex setting, and introduce the local regret as the alternative performance measure. We then apply this framework to stochastic settings, and show theoretically that it enjoys a logarithmic local regret, and is robust to any hyperparameter initialization. The empirical test on a real-world task demonstrates its superiority compared with traditional methods.", "venue": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Zhenxun  Zhuang", "Yunlong  Wang", "Kezi  Yu", "Songtao  Lu"], "year": 2020, "n_citations": 9}
{"id": 2487575, "s2_id": "298871ffc51e71f23fb124fac68dee4b8bc1c134", "title": "Integrate-and-Fire Neurons for Low-Powered Pattern Recognition", "abstract": "Embedded systems acquire information about the real world from sensors and process it to make decisions and/or for transmission. In some situations, the relationship between the data and the decision is complex and/or the amount of data to transmit is large (e.g. in biologgers). Artificial Neural Networks (ANNs) can efficiently detect patterns in the input data which makes them suitable for decision making or compression of information for data transmission. However, ANNs require a substantial amount of energy which reduces the lifetime of batterypowered devices. Therefore, the use of Spiking Neural Networks can improve such systems by providing a way to efficiently process sensory data without being too energy-consuming. In this work, we introduce a low-powered neuron model called Integrate-and-Fire which exploits the charge and discharge properties of the capacitor. Using parallel and series RC circuits, we developed a trainable neuron model that can be expressed in a recurrent form. Finally, we trained its simulation with an artificially generated dataset of dog postures and implemented it as hardware that showed promising energetic properties.", "venue": "ICAISC", "authors": ["Florian  Bacho", "Dominique  Chu"], "year": 2021, "n_citations": 0}
{"id": 2496927, "s2_id": "45d0cdcb25c66d1dd749c3619472e1c06adecbc0", "title": "Generalized Linear Models with Structured Sparsity Estimators", "abstract": "In this paper, we introduce structured sparsity estimators in Generalized Linear Models. Structured sparsity estimators in the least squares loss are introduced by Stucky and van de Geer (2018) recently for fixed design and normal errors. We extend their results to debiased structured sparsity estimators with Generalized Linear Model based loss. Structured sparsity estimation means penalized loss functions with a possible sparsity structure used in the chosen norm. These include weighted group lasso, lasso and norms generated from convex cones. The significant difficulty is that it is not clear how to prove two oracle inequalities. The first one is for the initial penalized Generalized Linear Model estimator. Since it is not clear how a particular feasible-weighted nodewise regression may fit in an oracle inequality for penalized Generalized Linear Model, we need a second oracle inequality to get oracle bounds for the approximate inverse for the sample estimate of second-order partial derivative of Generalized Linear Model. Our contributions are fivefold: 1. We generalize the existing oracle inequality results in penalized Generalized Linear Models by proving the underlying conditions rather than assuming them. One of the key issues is the proof of a sample one-point margin condition and its use in an oracle inequality. 2. Our results cover even non sub-Gaussian errors and regressors. 3. We provide a feasible weighted nodewise regression proof which generalizes the results in the literature from a simple l1 norm usage to norms generated from convex cones. 4. We realize that norms used in feasible nodewise regression proofs should be weaker or equal to the norms in penalized Generalized Linear Model loss. 5. We can debias the first step estimator via getting an approximate inverse of the singular-sample second order partial derivative of Generalized Linear Model loss. With this debiasing, we can get uniformly consistent estimators and asymptotically honest confidence intervals for parameters of interest. Our simulations also show good power and excellent size of the tests based on structured sparsity estimation. North Carolina State University, Nelson Hall, Department of Economics, NC 27695. Email:mcaner@ncsu.edu.", "venue": "ArXiv", "authors": ["Mehmet  Caner"], "year": 2021, "n_citations": 0}
{"id": 2505210, "s2_id": "02fae389f1074f6fda9a958d53b78870014fa45d", "title": "Random projections through multiple optical scattering: Approximating Kernels at the speed of light", "abstract": "Random projections have proven extremely useful in many signal processing and machine learning applications. However, they often require either to store a very large random matrix, or to use a different, structured matrix to reduce the computational and memory costs. Here, we overcome this difficulty by proposing an analog, optical device, that performs the random projections literally at the speed of light without having to store any matrix in memory. This is achieved using the physical properties of multiple coherent scattering of coherent light in random media. We use this device on a simple task of classification with a kernel machine, and we show that, on the MNIST database, the experimental results closely match the theoretical performance of the corresponding kernel. This framework can help make kernel methods practical for applications that have large training sets and/or require real-time prediction. We discuss possible extensions of the method in terms of a class of kernels, speed, memory consumption and different problems.", "venue": "2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Alaa  Saade", "Francesco  Caltagirone", "Igor  Carron", "Laurent  Daudet", "Ang\u00e9lique  Dremeau", "Sylvain  Gigan", "Florent  Krzakala"], "year": 2016, "n_citations": 64}
{"id": 2509186, "s2_id": "1fd4694e7c2d9c872a427d50e81b5475056de6bc", "title": "Model-Based Reinforcement Learning for Atari", "abstract": "Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of 100k interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games SimPLe outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.", "venue": "ICLR", "authors": ["Lukasz  Kaiser", "Mohammad  Babaeizadeh", "Piotr  Milos", "Blazej  Osinski", "Roy H. Campbell", "Konrad  Czechowski", "Dumitru  Erhan", "Chelsea  Finn", "Piotr  Kozakowski", "Sergey  Levine", "Ryan  Sepassi", "George  Tucker", "Henryk  Michalewski"], "year": 2020, "n_citations": 332}
{"id": 2518209, "s2_id": "462a9064797bc69d0c1fb96a3d102b1762710178", "title": "NeuralFMU: Towards Structural Integration of FMUs into Neural Networks", "abstract": "This paper covers two major subjects: First, the presentation of a new open-source library called FMI.jl for integrating FMI into the Julia programming environment by providing the possibility to load, parameterize and simulate FMUs. Further, an extension to this library called FMIFlux.jl is introduced, that allows the integration of FMUs into a neural network topology to obtain a NeuralFMU. This structural combination of an industry typical black-box model and a data-driven machine learning model combines the different advantages of both modeling approaches in one single development environment. This allows for the usage of advanced data driven modeling techniques for physical effects that are difficult to model based on first principles.", "venue": "ArXiv", "authors": ["Tobias  Thummerer", "Josef  Kircher", "Lars  Mikelsons"], "year": 2021, "n_citations": 1}
{"id": 2530429, "s2_id": "9f7919a5677290ab2eca4fa8056bdbbf7c0b11d6", "title": "Group Normalization", "abstract": "Batch Normalization (BN) is a milestone technique in the development of deep learning, enabling various networks to train. However, normalizing along the batch dimension introduces problems --- BN's error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation. This limits BN's usage for training larger models and transferring features to computer vision tasks including detection, segmentation, and video, which require small batches constrained by memory consumption. In this paper, we present Group Normalization (GN) as a simple alternative to BN. GN divides the channels into groups and computes within each group the mean and variance for normalization. GN's computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On ResNet-50 trained in ImageNet, GN has 10.6% lower error than its BN counterpart when using a batch size of 2; when using typical batch sizes, GN is comparably good with BN and outperforms other normalization variants. Moreover, GN can be naturally transferred from pre-training to fine-tuning. GN can outperform its BN-based counterparts for object detection and segmentation in COCO, and for video classification in Kinetics, showing that GN can effectively replace the powerful BN in a variety of tasks. GN can be easily implemented by a few lines of code in modern libraries.", "venue": "ECCV", "authors": ["Yuxin  Wu", "Kaiming  He"], "year": 2018, "n_citations": 1357}
{"id": 2534554, "s2_id": "6aa1df50ddfe322b08e7350ef7488212ae26f75b", "title": "QFlow: A Learning Approach to High QoE Video Streaming at the Wireless Edge", "abstract": "The predominant use of wireless access networks is for media streaming applications, which are only gaining popularity as ever more devices become available for this purpose. However, current access networks treat all packets identically, and lack the agility to determine which clients are most in need of service at a given time. Software reconfigurability of networking devices has seen wide adoption, and this in turn implies that agile control policies can be now instantiated on access networks. The goal of this work is to design, develop and demonstrate QFlow, a learning approach to create a value chain from the application on one side, to algorithms operating over reconfigurable infrastructure on the other, so that applications are able to obtain necessary resources for optimal performance. Using YouTube video streaming as an example, we illustrate how QFlow is able to adaptively provide such resources and attain a high QoE for all clients at a wireless access point.", "venue": "IEEE/ACM Transactions on Networking", "authors": ["Rajarshi  Bhattacharyya", "Archana  Bura", "Desik  Rengarajan", "Mason  Rumuly", "Bainan  Xia", "Srinivas  Shakkottai", "Dileep  Kalathil", "Ricky K. P. Mok", "Amogh  Dhamdhere"], "year": 2021, "n_citations": 0}
{"id": 2537018, "s2_id": "c80e54ca811ee42c063076ee2542418c10e70195", "title": "A survey of benchmarking frameworks for reinforcement learning", "abstract": "Reinforcement learning has recently experienced increased prominence in the machine learning community. There are many approaches to solving reinforcement learning problems with new techniques developed constantly. When solving problems using reinforcement learning, there are various difficult challenges to overcome. To ensure progress in the field, benchmarks are important for testing new algorithms and comparing with other approaches. The reproducibility of results for fair comparison is therefore vital in ensuring that improvements are accurately judged. This paper provides an overview of different contributions to reinforcement learning benchmarking and discusses how they can assist researchers to address the challenges facing reinforcement learning. The contributions discussed are the most used and recent in the literature. The paper discusses the contributions in terms of implementation, tasks and provided algorithm implementations with benchmarks. The survey aims to bring attention to the wide range of reinforcement learning benchmarking tasks available and to encourage research to take place in a standardised manner. Additionally, this survey acts as an overview for researchers not familiar with the different tasks that can be used to develop and test new reinforcement learning algorithms.", "venue": "ArXiv", "authors": ["Belinda  Stapelberg", "Katherine M. Malan"], "year": 2020, "n_citations": 1}
{"id": 2541741, "s2_id": "121b6fcd5b6aa82ae7e5ad7cf21eee7e8cd63407", "title": "Neural Dynamical Systems: Balancing Structure and Flexibility in Physical Prediction", "abstract": "We introduce Neural Dynamical Systems (NDS), a method of learning dynamical models in various gray-box settings which incorporates prior knowledge in the form of systems of ordinary differential equations. NDS uses neural networks to estimate free parameters of the system, predicts residual terms, and numerically integrates over time to predict future states. A key insight is that many real dynamic systems of interest are hard to model because the dynamics may vary across rollouts. We mitigate this problem by taking a trajectory of prior states as the input to NDS and train it to re-estimate system parameters using the preceding trajectory. We find that NDS learns dynamics with higher accuracy and fewer samples than a variety of deep learning methods that do not incorporate the prior knowledge and methods from the system identification literature which do. We demonstrate these advantages first on synthetic dynamical systems and then on real data captured from deuterium shots from a nuclear fusion reactor.", "venue": "ArXiv", "authors": ["Viraj  Mehta", "Ian  Char", "Willie  Neiswanger", "Youngseog  Chung", "Andrew Oakleigh Nelson", "Mark D Boyer", "Egemen  Kolemen", "Jeff  Schneider"], "year": 2020, "n_citations": 5}
{"id": 2542247, "s2_id": "b8b7d31ebdfdf32f69ad5f880f2d3b7795d03253", "title": "From non-paying to premium: predicting user conversion in video games with ensemble learning", "abstract": "Retaining premium players is key to the success of free-to-play games, but most of them do not start purchasing right after joining the game. By exploiting the exceptionally rich datasets recorded by modern video games---which provide information on the individual behavior of each and every player---survival analysis techniques can be used to predict what players are more likely to become paying (or even premium) users and when, both in terms of time and game level, the conversion will take place. Here we show that a traditional semi-parametric model (Cox regression), a random survival forest (RSF) technique and a method based on conditional inference survival ensembles all yield very promising results. However, the last approach has the advantage of being able to correct the inherent bias in RSF models by dividing the procedure into two steps: first selecting the best predictor to perform the splitting and then the best split point for that covariate. The proposed conditional inference survival ensembles method could be readily used in operational environments for early identification of premium players and the parts of the game that may prompt them to become paying users. Such knowledge would allow developers to induce their conversion and, more generally, to better understand the needs of their players and provide them with a personalized experience, thereby increasing their engagement and paving the way to higher monetization.", "venue": "FDG", "authors": ["Anna  Guitart", "Shi Hui Tan", "Ana Fern\u00e1ndez del R\u00edo", "Pei Pei Chen", "\u00c1frica  Peri\u00e1\u00f1ez"], "year": 2019, "n_citations": 3}
{"id": 2549595, "s2_id": "b89ff374f139110003f9017cbb4e29c1155a5eb3", "title": "Coarse-to-fine Optimization for Speech Enhancement", "abstract": "In this paper, we propose the coarse-to-fine optimization for the task of speech enhancement. Cosine similarity loss [1] has proven to be an effective metric to measure similarity of speech signals. However, due to the large variance of the enhanced speech with even the same cosine similarity loss in high dimensional space, a deep neural network learnt with this loss might not be able to predict enhanced speech with good quality. Our coarse-to-fine strategy optimizes the cosine similarity loss for different granularities so that more constraints are added to the prediction from high dimension to relatively low dimension. In this way, the enhanced speech will better resemble the clean speech. Experimental results show the effectiveness of our proposed coarse-to-fine optimization in both discriminative models and generative models. Moreover, we apply the coarse-to-fine strategy to the adversarial loss in generative adversarial network (GAN) and propose dynamic perceptual loss, which dynamically computes the adversarial loss from coarse resolution to fine resolution. Dynamic perceptual loss further improves the accuracy and achieves state-of-the-art results compared with other generative models.", "venue": "INTERSPEECH", "authors": ["Jian  Yao", "Ahmad  Al-Dahle"], "year": 2019, "n_citations": 15}
{"id": 2550798, "s2_id": "75a643c9587249a9c1f87482d2c097e4460c2b08", "title": "Identification of Errors-in-Variables ARX Models Using Modified Dynamic Iterative PCA", "abstract": "Identification of autoregressive models with exogenous input (ARX) is a classical problem in system identification. This article considers the errors-in-variables (EIV) ARX model identification problem, where input measurements are also corrupted with noise. The recently proposed DIPCA technique solves the EIV identification problem but is only applicable to white measurement errors. We propose a novel identification algorithm based on a modified Dynamic Iterative Principal Components Analysis (DIPCA) approach for identifying the EIV-ARX model for single-input, single-output (SISO) systems where the output measurements are corrupted with coloured noise consistent with the ARX model. Most of the existing methods assume important parameters like input-output orders, delay, or noise-variances to be known. This work's novelty lies in the joint estimation of error variances, process order, delay, and model parameters. The central idea used to obtain all these parameters in a theoretically rigorous manner is based on transforming the lagged measurements using the appropriate error covariance matrix, which is obtained using estimated error variances and model parameters. Simulation studies on two systems are presented to demonstrate the efficacy of the proposed algorithm.", "venue": "ArXiv", "authors": ["Deepak  Maurya", "Arun K. Tangirala", "Shankar  Narasimhan"], "year": 2020, "n_citations": 0}
{"id": 2559456, "s2_id": "85eed639f7367c794a6d8b38619697af3efaacfe", "title": "Learning Deep Features via Congenerous Cosine Loss for Person Recognition", "abstract": "Person recognition aims at recognizing the same identity across time and space with complicated scenes and similar appearance. In this paper, we propose a novel method to address this task by training a network to obtain robust and representative features. The intuition is that we directly compare and optimize the cosine distance between two features - enlarging inter-class distinction as well as alleviating inner-class variance. We propose a congenerous cosine loss by minimizing the cosine distance between samples and their cluster centroid in a cooperative way. Such a design reduces the complexity and could be implemented via softmax with normalized inputs. Our method also differs from previous work in person recognition that we do not conduct a second training on the test subset. The identity of a person is determined by measuring the similarity from several body regions in the reference set. Experimental results show that the proposed approach achieves better classification accuracy against previous state-of-the-arts.", "venue": "ArXiv", "authors": ["Yu  Liu", "Hongyang  Li", "Xiaogang  Wang"], "year": 2017, "n_citations": 44}
{"id": 2565870, "s2_id": "79c6a97ff1e4aef7a911899ceeb3496493add70a", "title": "Dynamic Hawkes Processes for Discovering Time-evolving Communities' States behind Diffusion Processes", "abstract": "Sequences of events including infectious disease outbreaks, social network activities, and crimes are ubiquitous and the data on such events carry essential information about the underlying diffusion processes between communities (e.g., regions, online user groups). Modeling diffusion processes and predicting future events are crucial in many applications including epidemic control, viral marketing, and predictive policing. Hawkes processes offer a central tool for modeling the diffusion processes, in which the influence from the past events is described by the triggering kernel. However, the triggering kernel parameters, which govern how each community is influenced by the past events, are assumed to be static over time. In the real world, the diffusion processes depend not only on the influences from the past, but also the current (time-evolving) states of the communities, e.g., people's awareness of the disease and people's current interests. In this paper, we propose a novel Hawkes process model that is able to capture the underlying dynamics of community states behind the diffusion processes and predict the occurrences of events based on the dynamics. Specifically, we model the latent dynamic function that encodes these hidden dynamics by a mixture of neural networks. Then we design the triggering kernel using the latent dynamic function and its integral. The proposed method, termed DHP (Dynamic Hawkes Processes), offers a flexible way to learn complex representations of the time-evolving communities' states, while at the same time it allows to computing the exact likelihood, which makes parameter learning tractable. Extensive experiments on four real-world event datasets show that DHP outperforms five widely adopted methods for event prediction.", "venue": "KDD", "authors": ["Maya  Okawa", "Tomoharu  Iwata", "Yusuke  Tanaka", "Hiroyuki  Toda", "Takeshi  Kurashima", "Hisashi  Kashima"], "year": 2021, "n_citations": 0}
{"id": 2576338, "s2_id": "54cd75e17690e051fcac3ee0503ea35be406efa5", "title": "An Attribute-Aligned Strategy for Learning Speech Representation", "abstract": "Advancement in speech technology has brought convenience to our life. However, the concern is on the rise as speech signal contains multiple personal attributes, which would lead to either sensitive information leakage or bias toward decision. In this work, we propose an attribute-aligned learning strategy to derive speech representation that can flexibly address these issues by attribute-selection mechanism. Specifically, we propose a layered-representation variational autoencoder (LRVAE), which factorizes speech representation into attributesensitive nodes, to derive an identity-free representation for speech emotion recognition (SER), and an emotionless representation for speaker verification (SV). Our proposed method achieves competitive performances on identity-free SER and a better performance on emotionless SV, comparing to the current state-of-the-art method of using adversarial learning applied on a large emotion corpora, the MSP-Podcast. Also, our proposed learning strategy reduces the model and training process needed to achieve multiple privacy-preserving tasks.", "venue": "Interspeech 2021", "authors": ["Yu-Lin  Huang", "Bo-Hao  Su", "Y.-W. Peter Hong", "Chi-Chun  Lee"], "year": 2021, "n_citations": 0}
{"id": 2581542, "s2_id": "617dad3ccbbf9e93c4faf54e19e449649433a10d", "title": "Descent-to-Delete: Gradient-Based Methods for Machine Unlearning", "abstract": "We study the data deletion problem for convex models. By leveraging techniques from convex optimization and reservoir sampling, we give the first data deletion algorithms that are able to handle an arbitrarily long sequence of adversarial updates while promising both per-deletion run-time and steady-state error that do not grow with the length of the update sequence. We also introduce several new conceptual distinctions: for example, we can ask that after a deletion, the entire state maintained by the optimization algorithm is statistically indistinguishable from the state that would have resulted had we retrained, or we can ask for the weaker condition that only the observable output is statistically indistinguishable from the observable output that would have resulted from retraining. We are able to give more efficient deletion algorithms under this weaker deletion criterion.", "venue": "ALT", "authors": ["Seth  Neel", "Aaron  Roth", "Saeed  Sharifi-Malvajerdi"], "year": 2021, "n_citations": 22}
{"id": 2595261, "s2_id": "8bc910c4bca8a81e2803fadee982c544d47c5778", "title": "Collaborative Causal Discovery with Atomic Interventions", "abstract": "We introduce a new Collaborative Causal Discovery problem, through which we model a common scenario in which we have multiple independent entities each with their own causal graph, and the goal is to simultaneously learn all these causal graphs. We study this problem without the causal sufficiency assumption, using Maximal Ancestral Graphs (MAG) to model the causal graphs, and assuming that we have the ability to actively perform independent single vertex (or atomic) interventions on the entities. If the M underlying (unknown) causal graphs of the entities satisfy a natural notion of clustering, we give algorithms that leverage this property, and recovers all the causal graphs using roughly logarithmic inM number of atomic interventions per entity. These are significantly fewer than n atomic interventions per entity required to learn each causal graph separately, where n is the number of observable nodes in the causal graph. We complement our results with a lower bound and discuss various extensions of our collaborative setting.", "venue": "ArXiv", "authors": ["Raghavendra  Addanki", "Shiva Prasad Kasiviswanathan"], "year": 2021, "n_citations": 0}
{"id": 2613494, "s2_id": "c140d6b2daea73b4b39296de71ced2dbbeb37994", "title": "Learning to run a power network challenge for training topology controllers", "abstract": "For power grid operations, a large body of research focuses on using generation redispatching, load shedding or demand side management flexibilities. However, a less costly and potentially more flexible option would be grid topology reconfiguration, as already partially exploited by Coreso (European RSC) and RTE (French TSO) operations. Beyond previous work on branch switching, bus reconfigurations are a broader class of action and could provide some substantial benefits to route electricity and optimize the grid capacity to keep it within safety margins. Because of its non-linear and combinatorial nature, no existing optimal power flow solver can yet tackle this problem. We here propose a new framework to learn topology controllers through imitation and reinforcement learning. We present the design and the results of the first \"Learning to Run a Power Network\" challenge released with this framework. We finally develop a method providing performance upper-bounds (oracle), which highlights remaining unsolved challenges and suggests future directions of improvement.", "venue": "Electric Power Systems Research", "authors": ["Antoine  Marot", "Benjamin  Donnot", "Camilo  Romero", "Luca  Veyrin-Forrer", "Marvin  Lerousseau", "Balthazar  Donon", "Isabelle  Guyon"], "year": 2020, "n_citations": 20}
{"id": 2620821, "s2_id": "2b36ef6b792373fedf8b9ef5a818706849afd92e", "title": "Data-driven learning of non-autonomous systems", "abstract": "We present a numerical framework for recovering unknown non-autonomous dynamical systems with time-dependent inputs. To circumvent the difficulty presented by the non-autonomous nature of the system, our method transforms the solution state into piecewise integration of the system over a discrete set of time instances. The time-dependent inputs are then locally parameterized by using a proper model, for example, polynomial regression, in the pieces determined by the time instances. This transforms the original system into a piecewise parametric system that is locally time invariant. We then design a deep neural network structure to learn the local models. Once the network model is constructed, it can be iteratively used over time to conduct global system prediction. We provide theoretical analysis of our algorithm and present a number of numerical examples to demonstrate the effectiveness of the method.", "venue": "ArXiv", "authors": ["Tong  Qin", "Zhen  Chen", "John  Jakeman", "Dongbin  Xiu"], "year": 2020, "n_citations": 4}
{"id": 2625748, "s2_id": "49ee811e5c7af5980d3dfe791f6b18e0080ad566", "title": "Learning Koopman Invariant Subspaces for Dynamic Mode Decomposition", "abstract": "Spectral decomposition of the Koopman operator is attracting attention as a tool for the analysis of nonlinear dynamical systems. Dynamic mode decomposition is a popular numerical algorithm for Koopman spectral analysis; however, we often need to prepare nonlinear observables manually according to the underlying dynamics, which is not always possible since we may not have any a priori knowledge about them. In this paper, we propose a fully data-driven method for Koopman spectral analysis based on the principle of learning Koopman invariant subspaces from observed data. To this end, we propose minimization of the residual sum of squares of linear least-squares regression to estimate a set of functions that transforms data into a form in which the linear regression fits well. We introduce an implementation with neural networks and evaluate performance empirically using nonlinear dynamical systems and applications.", "venue": "NIPS", "authors": ["Naoya  Takeishi", "Yoshinobu  Kawahara", "Takehisa  Yairi"], "year": 2017, "n_citations": 166}
{"id": 2630820, "s2_id": "5176d8cb5e610c2539068e8e8b5e2ae0c717a892", "title": "Training Detection-Range-Frugal Cooperative Collision Avoidance Models for Quadcopters via Neuroevolution", "abstract": "Cooperative autonomous approaches to avoiding collisions among small Unmanned Aerial Vehicles (UAVs) is central to safe integration of UAVs within the civilian airspace. One potential online cooperative approach is the concept of reciprocal actions, where both UAVs take pre-trained mutually coherent actions that do not require active online coordination (thereby avoiding the computational burden and risk associated with it). This paper presents a learning based approach to train such reciprocal maneuvers. Neuroevolution, which uses evolutionary algorithms to simultaneously optimize the topology and weights of neural networks, is used as the learning method -- which operates over a set of sample approach scenarios. Unlike most existing work (that minimize travel distance, energy or risk), the training process here focuses on the objective of minimizing the required detection range; this has important practical implications w.r.t. alleviating the dependency on sophisticated sensing and their reliability under various environments. A specialized design of experiments and line search is used to identify the minimum detection range for each sample scenarios. In order to allow an efficient training process, a classifier is used to discard actions (without simulating them) where the controller would fail. The model obtained via neuroevolution is observed to generalize well to (i.e., successful collision avoidance over) unseen approach scenarios.", "venue": "AIAA Aviation 2019 Forum", "authors": ["Amir  Behjat", "Krushang  Gabani", "Souma  Chowdhury"], "year": 2019, "n_citations": 3}
{"id": 2635366, "s2_id": "75b32165fd7d2aa2f9881005db72d5cea1b94d4a", "title": "The Limit Points of (Optimistic) Gradient Descent in Min-Max Optimization", "abstract": "Motivated by applications in Optimization, Game Theory, and the training of Generative Adversarial Networks, the convergence properties of first order methods in min-max problems have received extensive study. It has been recognized that they may cycle, and there is no good understanding of their limit points when they do not. When they converge, do they converge to local min-max solutions? We characterize the limit points of two basic first order methods, namely Gradient Descent/Ascent (GDA) and Optimistic Gradient Descent Ascent (OGDA). We show that both dynamics avoid unstable critical points for almost all initializations. Moreover, for small step sizes and under mild assumptions, the set of \\{OGDA\\}-stable critical points is a superset of \\{GDA\\}-stable critical points, which is a superset of local min-max solutions (strict in some cases). The connecting thread is that the behavior of these dynamics can be studied from a dynamical systems perspective.", "venue": "NeurIPS", "authors": ["Constantinos  Daskalakis", "Ioannis  Panageas"], "year": 2018, "n_citations": 145}
{"id": 2641766, "s2_id": "fbc633ddafc4544341fb7edacfa91e6efea85b9c", "title": "Accelerated Jarzynski Estimator with Deterministic Virtual Trajectories", "abstract": "The Jarzynski estimator is a powerful tool that uses nonequilibrium statistical physics to numerically obtain partition functions of probability distributions. The estimator reconstructs partition functions with trajectories of simulated Langevin dynamics through the Jarzynski equality. However, the original estimator suffers from its slow convergence because it depends on rare trajectories of stochastic dynamics. In this paper we present a method to significantly accelerate the convergence by introducing deterministic virtual trajectories generated in augmented state space under Hamiltonian dynamics. We theoretically show that our approach achieves second-order acceleration compared to a naive estimator with Langevin dynamics and zero variance estimation on harmonic potentials. Moreover, we conduct numerical experiments on three multimodal distributions where the proposed method outperforms the conventional method, and provide theoretical explanations.", "venue": "ArXiv", "authors": ["Nobumasa  Ishida", "Yoshihiko  Hasegawa"], "year": 2021, "n_citations": 0}
{"id": 2642851, "s2_id": "5f625ad20b5aa170d612d3b8f4733e6067f7cfb4", "title": "LaPred: Lane-Aware Prediction of Multi-Modal Future Trajectories of Dynamic Agents", "abstract": "In this paper, we address the problem of predicting the future motion of a dynamic agent (called a target agent) given its current and past states as well as the information on its environment. It is paramount to develop a prediction model that can exploit the contextual information in both static and dynamic environments surrounding the target agent and generate diverse trajectory samples that are meaningful in a traffic context. We propose a novel prediction model, referred to as the lane-aware prediction (LaPred) network, which uses the instance-level lane entities extracted from a semantic map to predict the multi-modal future trajectories. For each lane candidate found in the neighborhood of the target agent, LaPred extracts the joint features relating the lane and the trajectories of the neighboring agents. Then, the features for all lane candidates are fused with the attention weights learned through a self-supervised learning task that identifies the lane candidate likely to be followed by the target agent. Using the instance-level lane information, LaPred can produce the trajectories compliant with the surroundings better than 2D raster image-based methods and generate the diverse future trajectories given multiple lane candidates. The experiments conducted on the public nuScenes dataset and Argo- verse dataset demonstrate that the proposed LaPred method significantly outperforms the existing prediction models, achieving state-of-the-art performance in the benchmarks.", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["ByeoungDo  Kim", "Seong Hyeon Park", "Seokhwan  Lee", "Elbek  Khoshimjonov", "Dongsuk  Kum", "Junsoo  Kim", "Jeong Soo Kim", "Jun Won Choi"], "year": 2021, "n_citations": 7}
{"id": 2647682, "s2_id": "7607f1290bfaa53704fcfdb1fdde1d57612373a6", "title": "On the Mathematical Understanding of ResNet with Feynman Path Integral", "abstract": "In this paper, we aim to understand Residual Network (ResNet) in a scientifically sound way by providing a bridge between ResNet and Feynman path integral. In particular, we prove that the effect of residual block is equivalent to partial differential equation, and the ResNet transforming process can be equivalently converted to Feynman path integral. These conclusions greatly help us mathematically understand the advantage of ResNet in addressing the gradient vanishing issue. More importantly, our analyses offer a path integral view of ResNet, and demonstrate that the output of certain network can be obtained by adding contributions of all paths. Moreover, the contribution of each path is proportional to e^{-S}, where S is the action given by time integral of Lagrangian L. This lays the solid foundation in the understanding of ResNet, and provides insights in the future design of convolutional neural network architecture. Based on these results, we have designed the network using partial differential operators, which further validates our theoritical analyses.", "venue": "ArXiv", "authors": ["Minghao  Yin", "Xiu  Li", "Yongbing  Zhang", "Shiqi  Wang"], "year": 2019, "n_citations": 1}
{"id": 2651290, "s2_id": "3425758023cea7580920c28d9f9d33b4d28c39e0", "title": "Label Dependent Deep Variational Paraphrase Generation", "abstract": "Generating paraphrases that are lexically similar but semantically different is a challenging task. Paraphrases of this form can be used to augment data sets for various NLP tasks such as machine reading comprehension and question answering with non-trivial negative examples. In this article, we propose a deep variational model to generate paraphrases conditioned on a label that specifies whether the paraphrases are semantically related or not. We also present new training recipes and KL regularization techniques that improve the performance of variational paraphrasing models. Our proposed model demonstrates promising results in enhancing the generative power of the model by employing label-dependent generation on paraphrasing datasets.", "venue": "ArXiv", "authors": ["Siamak  Shakeri", "Abhinav  Sethy"], "year": 2019, "n_citations": 2}
{"id": 2651457, "s2_id": "5dc16d4b89e67ef8436e23343addbca55ed5d90a", "title": "Learning to Generate Music With Sentiment", "abstract": "Deep Learning models have shown very promising results in automatically composing polyphonic music pieces. However, it is very hard to control such models in order to guide the compositions towards a desired goal. We are interested in controlling a model to automatically generate music with a given sentiment. This paper presents a generative Deep Learning model that can be directed to compose music with a given sentiment. Besides music generation, the same model can be used for sentiment analysis of symbolic music. We evaluate the accuracy of the model in classifying sentiment of symbolic music using a new dataset of video game soundtracks. Results show that our model is able to obtain good prediction accuracy. A user study shows that human subjects agreed that the generated music has the intended sentiment, however negative pieces can be ambiguous.", "venue": "ISMIR", "authors": ["Lucas  Ferreira", "E. James Whitehead"], "year": 2019, "n_citations": 15}
{"id": 2653359, "s2_id": "6c48ed6999b3415e2a92386658bf2f74ddabc458", "title": "Lottery Ticket Preserves Weight Correlation: Is It Desirable or Not?", "abstract": "In deep model compression, the recent finding \u201cLottery Ticket Hypothesis\u201d (LTH) (Frankle & Carbin, 2018) pointed out that there could exist a winning ticket (i.e., a properly pruned subnetwork together with original weight initialization) that can achieve competitive performance than the original dense network. However, it is not easy to observe such winning property in many scenarios, where for example, a relatively large learning rate is used even if it benefits training the original dense model. In this work, we investigate the underlying condition and rationale behind the winning property, and find that the underlying reason is largely attributed to the correlation between initialized weights and final-trained weights when the learning rate is not sufficiently large. Thus, the existence of winning property is correlated with an insufficient DNN pretraining, and is unlikely to occur for a well-trained DNN. To overcome this limitation, we propose the \u201cpruning & fine-tuning\u201d method that consistently outperforms lottery ticket sparse training under the same pruning algorithm and the same total training epochs. Extensive experiments over multiple deep models (VGG, ResNet, MobileNetv2) on different datasets have been conducted to justify our proposals.", "venue": "ICML", "authors": ["Ning  Liu", "Geng  Yuan", "Zhengping  Che", "Xuan  Shen", "Xiaolong  Ma", "Qing  Jin", "Jian  Ren", "Jian  Tang", "Sijia  Liu", "Yanzhi  Wang"], "year": 2021, "n_citations": 4}
{"id": 2653847, "s2_id": "dcaaac74ca08bedfb749cf7308442d782d9cdcbe", "title": "PSO-PS:Parameter Synchronization with Particle Swarm Optimization for Distributed Training of Deep Neural Networks", "abstract": "Parameter updating is an important stage in parallelism-based distributed deep learning. Synchronous methods are widely used in distributed training the Deep Neural Networks (DNNs). To reduce the communication and synchronization overhead of synchronous methods, decreasing the synchronization frequency (e.g., every n mini-batches) is a straightforward approach. However, it often suffers from poor convergence. In this paper, we propose a new algorithm of integrating Particle Swarm Optimization (PSO) into the distributed training process of DNNs to automatically compute new parameters. In the proposed algorithm, a computing work is encoded by a particle, the weights of DNNs and the training loss are modeled by the particle attributes. At each synchronization stage, the weights are updated by PSO from the sub weights gathered from all workers, instead of averaging the weights or the gradients. To verify the performance of the proposed algorithm, the experiments are performed on two commonly used image classification benchmarks: MNIST and CIFAR10, and compared with the peer competitors at multiple different synchronization configurations. The experimental results demonstrate the competitiveness of the proposed algorithm.", "venue": "2020 International Joint Conference on Neural Networks (IJCNN)", "authors": ["Qing  Ye", "Yuxuan  Han", "Yanan  sun", "JIancheng  Lv"], "year": 2020, "n_citations": 1}
{"id": 2662215, "s2_id": "126b8cccd1bcf2afc442ab3856855aeecacfcb03", "title": "Recurrent computations for visual pattern completion", "abstract": "Significance The ability to complete patterns and interpret partial information is a central property of intelligence. Deep convolutional network architectures have proved successful in labeling whole objects in images and capturing the initial 150 ms of processing along the ventral visual cortex. This study shows that human object recognition abilities remain robust when only small amounts of information are available due to heavy occlusion, but the performance of bottom-up computational models is impaired under limited visibility. The results provide combined behavioral, neurophysiological, and modeling insights showing how recurrent computations may help the brain solve the fundamental challenge of pattern completion. Making inferences from partial information constitutes a critical aspect of cognition. During visual perception, pattern completion enables recognition of poorly visible or occluded objects. We combined psychophysics, physiology, and computational models to test the hypothesis that pattern completion is implemented by recurrent computations and present three pieces of evidence that are consistent with this hypothesis. First, subjects robustly recognized objects even when they were rendered <15% visible, but recognition was largely impaired when processing was interrupted by backward masking. Second, invasive physiological responses along the human ventral cortex exhibited visually selective responses to partially visible objects that were delayed compared with whole objects, suggesting the need for additional computations. These physiological delays were correlated with the effects of backward masking. Third, state-of-the-art feed-forward computational architectures were not robust to partial visibility. However, recognition performance was recovered when the model was augmented with attractor-based recurrent connectivity. The recurrent model was able to predict which images of heavily occluded objects were easier or harder for humans to recognize, could capture the effect of introducing a backward mask on recognition behavior, and was consistent with the physiological delays along the human ventral visual stream. These results provide a strong argument of plausibility for the role of recurrent computations in making visual inferences from partial information.", "venue": "Proceedings of the National Academy of Sciences", "authors": ["Hanlin  Tang", "Martin  Schrimpf", "William  Lotter", "Charlotte  Moerman", "Ana  Paredes", "Josue  Ortega Caro", "Walter  Hardesty", "David  Cox", "Gabriel  Kreiman"], "year": 2018, "n_citations": 124}
{"id": 2666727, "s2_id": "3ed37cc1d35ddbb7e4caacd7fc30368424544b15", "title": "Bayesian graph convolutional neural networks for semi-supervised classification", "abstract": "Recently, techniques for applying convolutional neural networks to graph-structured data have emerged. Graph convolutional neural networks (GCNNs) have been used to address node and graph classification and matrix completion. Although the performance has been impressive, the current implementations have limited capability to incorporate uncertainty in the graph structure. Almost all GCNNs process a graph as though it is a ground-truth depiction of the relationship between nodes, but often the graphs employed in applications are themselves derived from noisy data or modelling assumptions. Spurious edges may be included; other edges may be missing between nodes that have very strong relationships. In this paper we adopt a Bayesian approach, viewing the observed graph as a realization from a parametric family of random graphs. We then target inference of the joint posterior of the random graph parameters and the node (or graph) labels. We present the Bayesian GCNN framework and develop an iterative learning procedure for the case of assortative mixed-membership stochastic block models. We present the results of experiments that demonstrate that the Bayesian formulation can provide better performance when there are very few labels available during the training process.", "venue": "AAAI", "authors": ["Yingxue  Zhang", "Soumyasundar  Pal", "Mark  Coates", "Deniz  \u00dcstebay"], "year": 2019, "n_citations": 92}
{"id": 2669884, "s2_id": "6df355b915a7e54cbb87171fa4249620578f6a6a", "title": "Graph Cuts Always Find a Global Optimum for Potts Models (With a Catch)", "abstract": "We prove that the $\\alpha$-expansion algorithm for MAP inference always returns a globally optimal assignment for Markov Random Fields with Potts pairwise potentials, with a catch: the returned assignment is only guaranteed to be optimal for an instance within a small perturbation of the original problem instance. In other words, all local minima with respect to expansion moves are global minima to slightly perturbed versions of the problem. On \"real-world\" instances, MAP assignments of small perturbations of the problem should be very similar to the MAP assignment(s) of the original problem instance. We design an algorithm that can certify whether this is the case in practice. On several MAP inference problem instances from computer vision, this algorithm certifies that MAP solutions to all of these perturbations are very close to solutions of the original instance. These results taken together give a cohesive explanation for the good performance of \"graph cuts\" algorithms in practice. Every local expansion minimum is a global minimum in a small perturbation of the problem, and all of these global minima are close to the original solution.", "venue": "ICML", "authors": ["Hunter  Lang", "David  Sontag", "Aravindan  Vijayaraghavan"], "year": 2021, "n_citations": 0}
{"id": 2682266, "s2_id": "d0f6ff43adf1b7e0e921cacc7292052c565f4e33", "title": "Introducing the Hidden Neural Markov Chain framework", "abstract": "Nowadays, neural network models achieve state-of-the-art results in many areas as computer vision or speech processing. For sequential data, especially for Natural Language Processing (NLP) tasks, Recurrent Neural Networks (RNNs) and their extensions, the Long Short Term Memory (LSTM) network and the Gated Recurrent Unit (GRU), are among the most used models, having a \u201ctermto-term\" sequence processing. However, if many works create extensions and improvements of the RNN, few have focused on developing other ways for sequential data processing with neural networks in a \u201cterm-to-term\" way. This paper proposes the original Hidden Neural Markov Chain (HNMC) framework, a new family of sequential neural models. They are not based on the RNN but on the Hidden Markov Model (HMM), a probabilistic graphical model. This neural extension is possible thanks to the recent Entropic Forward-Backward algorithm for HMM restoration. We propose three different models: the classic HNMC, the HNMC2, and the HNMC-CN. After describing our models\u2019 whole construction, we compare them with classic RNN and Bidirectional RNN (BiRNN) models for some sequence labeling tasks: Chunking, Part-Of-Speech Tagging, and Named Entity Recognition. For every experiment, whatever the architecture or the embedding method used, one of our proposed models has the best results. It shows this new neural sequential framework\u2019s potential, which can open the way to new models, and might eventually compete with the prevalent BiLSTM and BiGRU.", "venue": "ICAART", "authors": ["Elie  Azeraf", "Emmanuel  Monfrini", "Emmanuel  Vignon", "Wojciech  Pieczynski"], "year": 2021, "n_citations": 2}
{"id": 2684900, "s2_id": "7680ca2be41594e4e06883e6a997a08106bf52b1", "title": "Learning Large DAGs by Combining Continuous Optimization and Feedback Arc Set Heuristics", "abstract": "Bayesian networks represent relations between variables using a directed acyclic graph (DAG). Learning the DAG is an NP-hard problem and exact learning algorithms are feasible only for small sets of variables. We propose two scalable heuristics for learning DAGs in the linear structural equation case. Our methods learn the DAG by alternating between unconstrained gradient descent-based step to optimize an objective function and solving a maximum acyclic subgraph problem to enforce acyclicity. Thanks to this decoupling, our methods scale up beyond thousands of variables.", "venue": "ArXiv", "authors": ["Pierre  Gillot", "Pekka  Parviainen"], "year": 2021, "n_citations": 0}
{"id": 2686095, "s2_id": "6f35d9adf65c04f6414e2baab5dc1020c75e26ef", "title": "A Game Theoretic Framework for Model Based Reinforcement Learning", "abstract": "Model-based reinforcement learning (MBRL) has recently gained immense interest due to its potential for sample efficiency and ability to incorporate off-policy data. However, designing stable and efficient MBRL algorithms using rich function approximators have remained challenging. To help expose the practical challenges in MBRL and simplify algorithm design from the lens of abstraction, we develop a new framework that casts MBRL as a game between: (1) a policy player, which attempts to maximize rewards under the learned model; (2) a model player, which attempts to fit the real-world data collected by the policy player. For algorithm development, we construct a Stackelberg game between the two players, and show that it can be solved with approximate bi-level optimization. This gives rise to two natural families of algorithms for MBRL based on which player is chosen as the leader in the Stackelberg game. Together, they encapsulate, unify, and generalize many previous MBRL algorithms. Furthermore, our framework is consistent with and provides a clear basis for heuristics known to be important in practice from prior works. Finally, through experiments we validate that our proposed algorithms are highly sample efficient, match the asymptotic performance of model-free policy gradient, and scale gracefully to high-dimensional tasks like dexterous hand manipulation.", "venue": "ICML", "authors": ["Aravind  Rajeswaran", "Igor  Mordatch", "Vikash  Kumar"], "year": 2020, "n_citations": 38}
{"id": 2686807, "s2_id": "b3dae9529f3caeeec9cc6872e94aa690418acb22", "title": "Reinforcement Learning for Relation Classification From Noisy Data", "abstract": "Existing relation classification methods that rely on distant supervision assume that a bag of sentences mentioning an entity pair are all describing a relation for the entity pair. Such methods, performing classification at the bag level, cannot identify the mapping between a relation and a sentence, and largely suffers from the noisy labeling problem. In this paper, we propose a novel model for relation classification at the sentence level from noisy data. The model has two modules: an instance selector and a relation classifier. The instance selector chooses high-quality sentences with reinforcement learning and feeds the selected sentences into the relation classifier, and the relation classifier makes sentence-level prediction and provides rewards to the instance selector. The two modules are trained jointly to optimize the instance selection and relation classification processes. Experiment results show that our model can deal with the noise of data effectively and obtains better performance for relation classification at the sentence level.", "venue": "AAAI", "authors": ["Jun  Feng", "Minlie  Huang", "Li  Zhao", "Yang  Yang", "Xiaoyan  Zhu"], "year": 2018, "n_citations": 215}
{"id": 2703024, "s2_id": "6e8163988b77704ab7d106e217b3209fc16a1566", "title": "Classifying single-qubit noise using machine learning", "abstract": "Quantum characterization, validation, and verification (QCVV) techniques are used to probe, characterize, diagnose, and detect errors in quantum information processors (QIPs). An important component of any QCVV protocol is a mapping from experimental data to an estimate of a property of a QIP. Machine learning (ML) algorithms can help automate the development of QCVV protocols, creating such maps by learning them from training data. We identify the critical components of \"machine-learned\" QCVV techniques, and present a rubric for developing them. To demonstrate this approach, we focus on the problem of determining whether noise affecting a single qubit is coherent or stochastic (incoherent) using the data sets originally proposed for gate set tomography. We leverage known ML algorithms to train a classifier distinguishing these two kinds of noise. The accuracy of the classifier depends on how well it can approximate the \"natural\" geometry of the training data. We find GST data sets generated by a noisy qubit can reliably be separated by linear surfaces, although feature engineering can be necessary. We also show the classifier learned by a support vector machine (SVM) is robust under finite-sample noise.", "venue": "ArXiv", "authors": ["Travis L. Scholten", "Yi-Kai  Liu", "Kevin  Young", "Robin  Blume-Kohout"], "year": 2019, "n_citations": 4}
{"id": 2706087, "s2_id": "866b17a328736bbee7345e7a2af1658db7c5210e", "title": "Estimating Expected Calibration Errors", "abstract": "Uncertainty in probabilistic classifiers predictions is a key concern when models are used to support human decision making, in broader probabilistic pipelines or when sensitive automatic decisions have to be taken. Studies have shown that most models are not intrinsically well calibrated, meaning that their decision scores are not consistent with posterior probabilities. Hence being able to calibrate these models, or enforce calibration while learning them, has regained interest in recent literature. In this context, properly assessing calibration is paramount to quantify new contributions tackling calibration. However, there is room for improvement for commonly used metrics and evaluation of calibration could benefit from deeper analyses. Thus this paper focuses on the empirical evaluation of calibration metrics in the context of classification. More specifically it evaluates different estimators of the Expected Calibration Error (ECE), amongst which legacy estimators and some novel ones, proposed in this paper. We build an empirical procedure to quantify the quality of these ECE estimators, and use it to decide which estimator should be used in practice for different settings.", "venue": "ICANN", "authors": ["Nicolas  Posocco", "Antoine  Bonnefoy"], "year": 2021, "n_citations": 0}
{"id": 2708868, "s2_id": "2f6ba198967e7f08899e183368b4567e1ab6992d", "title": "Temporal Context Aggregation for Video Retrieval with Contrastive Learning", "abstract": "The current research focus on Content-Based Video Retrieval requires higher-level video representation describing the long-range semantic dependencies of relevant incidents, events, etc. However, existing methods commonly process the frames of a video as individual images or short clips, making the modeling of long-range semantic dependencies difficult. In this paper, we propose TCA (Temporal Context Aggregation for Video Retrieval), a video representation learning framework that incorporates longrange temporal information between frame-level features using the self-attention mechanism. To train it on video retrieval datasets, we propose a supervised contrastive learning method that performs automatic hard negative mining and utilizes the memory bank mechanism to increase the capacity of negative samples. Extensive experiments are conducted on multiple video retrieval tasks, such as CC WEB VIDEO, FIVR-200K, and EVVE. The proposed method shows a significant performance advantage (\u223c 17% mAP on FIVR-200K) over state-of-the-art methods with video-level features, and deliver competitive results with 22x faster inference time comparing with frame-level features.", "venue": "2021 IEEE Winter Conference on Applications of Computer Vision (WACV)", "authors": ["Jie  Shao", "Xin  Wen", "Bingchen  Zhao", "Xiangyang  Xue"], "year": 2021, "n_citations": 11}
{"id": 2726051, "s2_id": "ae5f9326be7728d3ba4b5e255c8679147fb7cf24", "title": "Scalable text and link analysis with mixed-topic link models", "abstract": "Many data sets contain rich information about objects, as well as pairwise relations between them. For instance, in networks of websites, scientific papers, and other documents, each node has content consisting of a collection of words, as well as hyperlinks or citations to other nodes. In order to perform inference on such data sets, and make predictions and recommendations, it is useful to have models that are able to capture the processes which generate the text at each node and the links between them. In this paper, we combine classic ideas in topic modeling with a variant of the mixed-membership block model recently developed in the statistical physics community. The resulting model has the advantage that its parameters, including the mixture of topics of each document and the resulting overlapping communities, can be inferred with a simple and scalable expectation-maximization algorithm. We test our model on three data sets, performing unsupervised topic classification and link prediction. For both tasks, our model outperforms several existing state-of-the-art methods, achieving higher accuracy with significantly less computation, analyzing a data set with 1.3 million words and 44 thousand links in a few minutes.", "venue": "KDD", "authors": ["Yaojia  Zhu", "Xiaoran  Yan", "Lise  Getoor", "Cristopher  Moore"], "year": 2013, "n_citations": 56}
{"id": 2726626, "s2_id": "2284559a0e21a8ce5af98cda11a8453da978b6dd", "title": "Ordinal UNLOC: Target Localization With Noisy and Incomplete Distance Measures", "abstract": "A main challenge in target localization arises from the lack of reliable distance measures. This issue is especially pronounced in indoor settings due to the presence of walls, floors, furniture, and other dynamically changing conditions, such as the movement of people and goods, varying temperature and air flows. Here, we develop a new computational framework to estimate the location of a target without the need for reliable distance measures. The method, which we term Ordinal UNLOC, uses only ordinal data obtained from comparing the signal strength from anchor pairs at known locations to the target. Our estimation technique utilizes rank aggregation, function learning as well as proximity-based unfolding optimization. As a result, it yields accurate target localization for common transmission models with unknown parameters and noisy observations that are reminiscent of practical settings. Our results are validated by both numerical simulations and hardware experiments.", "venue": "IEEE Internet of Things Journal", "authors": ["Mahesh K. Banavar", "Shandeepa  Wickramasinghe", "Monalisa  Achalla", "Jie  Sun"], "year": 2021, "n_citations": 0}
{"id": 2727942, "s2_id": "9ccab88476394179e9e7dcc5d0abe081b9dfac6d", "title": "Lattice rescoring strategies for long short term memory language models in speech recognition", "abstract": "Recurrent neural network (RNN) language models (LMs) and Long Short Term Memory (LSTM) LMs, a variant of RNN LMs, have been shown to outperform traditional N-gram LMs on speech recognition tasks. However, these models are computationally more expensive than N-gram LMs for decoding, and thus, challenging to integrate into speech recognizers. Recent research has proposed the use of lattice-rescoring algorithms using RNNLMs and LSTMLMs as an efficient strategy to integrate these models into a speech recognition system. In this paper, we evaluate existing lattice rescoring algorithms along with new variants on a YouTube speech recognition task. Lattice rescoring using LSTMLMs reduces the word error rate (WER) for this task by 8% relative to the WER obtained using an N-gram LM.", "venue": "2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)", "authors": ["Shankar  Kumar", "Michael  Nirschl", "Daniel Niels Holtmann-Rice", "Hank  Liao", "Ananda Theertha Suresh", "Felix X. Yu"], "year": 2017, "n_citations": 29}
{"id": 2742427, "s2_id": "df341594841ecc611169821efacffe1185e2902e", "title": "On Intrinsic Dataset Properties for Adversarial Machine Learning", "abstract": "Deep neural networks (DNNs) have played a key role in a wide range of machine learning applications. However, DNN classifiers are vulnerable to human-imperceptible adversarial perturbations, which can cause them to misclassify inputs with high confidence. Thus, creating robust DNNs which can defend against malicious examples is critical in applications where security plays a major role. In this paper, we study the effect of intrinsic dataset properties on the performance of adversarial attack and defense methods, testing on five popular image classification datasets - MNIST, Fashion-MNIST, CIFAR10/CIFAR100, and ImageNet. We find that input size and image contrast play key roles in attack and defense success. Our discoveries highlight that dataset design and data preprocessing steps are important to boost the adversarial robustness of DNNs. To our best knowledge, this is the first comprehensive work that studies the effect of intrinsic dataset properties on adversarial machine learning.", "venue": "ArXiv", "authors": ["Jeffrey Z. Pan", "Nicholas  Zufelt"], "year": 2020, "n_citations": 0}
{"id": 2744834, "s2_id": "6b7b21df3032ad0db31a7a293a8ae626423936f8", "title": "An exact algorithm for the stratification problem with proportional allocation", "abstract": "We report a new optimal resolution for the statistical stratification problem under proportional sampling allocation among strata. Consider a finite population of N units, a random sample of n units selected from this population and a number L of strata. Thus, we have to define which units belong to each stratum so as to minimize the variance of a total estimator for one desired variable of interest in each stratum, and consequently reduce the overall variance for such quantity. In order to solve this problem, an optimal algorithm based on the concept of minimal path in a graph is proposed and assessed. Computational results using real data from IBGE (Brazilian Central Statistical Office) are provided.", "venue": "Optim. Lett.", "authors": ["Jos\u00e9 Andre de Moura Brito", "Nelson  Maculan", "Maur\u00edcio  Lila", "Fl\u00e1vio  Montenegro"], "year": 2010, "n_citations": 6}
{"id": 2745797, "s2_id": "ec9b27d019fefadb5e97c8174ac889e831f483d7", "title": "The Neuro-Symbolic Concept Learner: Interpreting Scenes Words and Sentences from Natural Supervision", "abstract": "We propose the Neuro-Symbolic Concept Learner (NS-CL), a model that learns visual concepts, words, and semantic parsing of sentences without explicit supervision on any of them; instead, our model learns by simply looking at images and reading paired questions and answers. Our model builds an object-based scene representation and translates sentences into executable, symbolic programs. To bridge the learning of two modules, we use a neuro-symbolic reasoning module that executes these programs on the latent scene representation. Analogical to human concept learning, the perception module learns visual concepts based on the language description of the object being referred to. Meanwhile, the learned visual concepts facilitate learning new words and parsing new sentences. We use curriculum learning to guide the searching over the large compositional space of images and language. Extensive experiments demonstrate the accuracy and efficiency of our model on learning visual concepts, word representations, and semantic parsing of sentences. Further, our method allows easy generalization to new object attributes, compositions, language concepts, scenes and questions, and even new program domains. It also empowers applications including visual question answering and bidirectional image-text retrieval.", "venue": "ICLR", "authors": ["Jiayuan  Mao", "Chuang  Gan", "Pushmeet  Kohli", "Joshua B. Tenenbaum", "Jiajun  Wu"], "year": 2019, "n_citations": 276}
{"id": 2750206, "s2_id": "28fe6f9f4d841f9df5b290ecc44621cf07fa58ac", "title": "Fidelity and Privacy of Synthetic Medical Data", "abstract": "The digitization of medical records ushered in a new era of big data to clinical science, and with it the possibility that data could be shared, to multiply insights beyond what investigators could abstract from paper records. The need to share individual-level medical data to accelerate innovation in precision medicine continues to grow, and has never been more urgent, as scientists grapple with the COVID-19 pandemic. However, enthusiasm for the use of big data has been tempered by a fully appropriate concern for patient autonomy and privacy. That is, the ability to extract private or confidential information about an individual, in practice, renders it difficult to share data, since significant infrastructure and data governance must be established before data can be shared. Although HIPAA provided de-identification as an approved mechanism for data sharing, linkage attacks were identified as a major vulnerability. A variety of mechanisms have been established to avoid leaking private information, such as field suppression or abstraction, strictly limiting the amount of information that can be shared, or employing mathematical techniques such as differential privacy. Another approach, which we focus on here, is creating synthetic data that mimics the underlying data. For synthetic data to be a useful mechanism in support of medical innovation and a proxy for real-world evidence, one must demonstrate two properties of the synthetic dataset: (1) any analysis on the real data must be matched by analysis of the synthetic data (statistical fidelity) and (2) the synthetic data must preserve privacy, with minimal risk of re-identification (privacy guarantee). In this paper we propose a framework for quantifying the statistical fidelity and privacy preservation properties of synthetic datasets and demonstrate these metrics for synthetic data generated by Syntegra technology.", "venue": "ArXiv", "authors": ["Ofer  Mendelevitch", "Michael D. Lesh"], "year": 2021, "n_citations": 2}
{"id": 2783805, "s2_id": "c72aacf5381f3bf7d9518b0700bf675b11d6350d", "title": "Speaker Identification From Youtube Obtained Data", "abstract": "An efficient, and intuitive algorithm is presented for the identification of speakers from a long dataset (like YouTube long discussion, Cocktail party recorded audio or video).The goal of automatic speaker identification is to identify the number of different speakers and prepare a model for that speaker by extraction, characterization and speaker-specific information contained in the speech signal. It has many diverse application specially in the field of Surveillance, Immigrations at Airport, cyber security, transcription in multi-source of similar sound source, where it is difficult to assign transcription arbitrary. The most commonly speech parametrization used in speaker verification, K-mean, cepstral analysis, is detailed. Gaussian mixture modeling, which is the speaker modeling technique is then explained. Gaussian mixture models (GMM), perhaps the most robust machine learning algorithm has been introduced examine and judge carefully speaker identification in text independent. The application or employment of Gaussian mixture models for monitoring & Analysing speaker identity is encouraged by the familiarity, awareness, or understanding gained through experience that Gaussian spectrum depict the characteristics of speaker's spectral conformational pattern and remarkable ability of GMM to construct capricious densities after that we illustrate 'Expectation maximization' an iterative algorithm which takes some arbitrary value in initial estimation and carry on the iterative process until the convergence of value is observed,so by doing various number of experiments we are able to obtain 79 ~ 82% of identification rate using Vector quantization and 85 ~ 92.6% of identification rate using GMM modeling by Expectation maximization parameter estimation depending on variation of parameter.", "venue": "ArXiv", "authors": ["Nitesh Kumar Chaudhary"], "year": 2014, "n_citations": 0}
{"id": 2783983, "s2_id": "6e6b75ea8bb3b656b6637a359559e3cc51937cf7", "title": "Tensor Reordering for CNN Compression", "abstract": "We show how parameter redundancy in Convolutional Neural Network (CNN) filters can be effectively reduced by pruning in spectral domain. Specifically, the representation extracted via Discrete Co-sine Transform (DCT) is more conducive for pruning than the original space. By relying on a combination of weight tensor reshaping and reordering we achieve high levels of layer compression with just minor accuracy loss. Our approach is applied to compress pre-trained CNNs and we show that minor additional fine-tuning allows our method to recover the original model performance after a significant parameter reduction. We validate our approach on ResNet-50 and MobileNet-V2 architectures for ImageNet classification task.", "venue": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Matej  Ulicny", "Vladimir A. Krylov", "Rozenn  Dahyot"], "year": 2021, "n_citations": 0}
{"id": 2798424, "s2_id": "3ad4c43a00a1c382ac43faa9573f55f15d731127", "title": "Generating Multi-Categorical Samples with Generative Adversarial Networks", "abstract": "We propose a method to train generative adversarial networks on mutivariate feature vectors representing multiple categorical values. In contrast to the continuous domain, where GAN-based methods have delivered considerable results, GANs struggle to perform equally well on discrete data. We propose and compare several architectures based on multiple (Gumbel) softmax output layers taking into account the structure of the data. We evaluate the performance of our architecture on datasets with different sparsity, number of features, ranges of categorical values, and dependencies among the features. Our proposed architecture and method outperforms existing models.", "venue": "ArXiv", "authors": ["Ramiro  Camino", "Christian A. Hammerschmidt", "Radu  State"], "year": 2018, "n_citations": 28}
{"id": 2803015, "s2_id": "95f350c10e5ee9cbbf443ee94e34891fe33ca36f", "title": "Exponential ReLU Neural Network Approximation Rates for Point and Edge Singularities", "abstract": "We prove exponential expressivity with stable ReLU Neural Networks (ReLU NNs) in $H^1(\\Omega)$ for weighted analytic function classes in certain polytopal domains $\\Omega$, in space dimension $d=2,3$. Functions in these classes are locally analytic on open subdomains $D\\subset \\Omega$, but may exhibit isolated point singularities in the interior of $\\Omega$ or corner and edge singularities at the boundary $\\partial \\Omega$. The exponential expression rate bounds proved here imply uniform exponential expressivity by ReLU NNs of solution families for several elliptic boundary and eigenvalue problems with analytic data. The exponential approximation rates are shown to hold in space dimension $d = 2$ on Lipschitz polygons with straight sides, and in space dimension $d=3$ on Fichera-type polyhedral domains with plane faces. The constructive proofs indicate in particular that NN depth and size increase poly-logarithmically with respect to the target NN approximation accuracy $\\varepsilon>0$ in $H^1(\\Omega)$. The results cover in particular solution sets of linear, second order elliptic PDEs with analytic data and certain nonlinear elliptic eigenvalue problems with analytic nonlinearities and singular, weighted analytic potentials as arise in electron structure models. In the latter case, the functions correspond to electron densities that exhibit isolated point singularities at the positions of the nuclei. Our findings provide in particular mathematical foundation of recently reported, successful uses of deep neural networks in variational electron structure algorithms.", "venue": "ArXiv", "authors": ["Carlo  Marcati", "Joost A. A. Opschoor", "Philipp C. Petersen", "Christoph  Schwab"], "year": 2020, "n_citations": 2}
{"id": 2805180, "s2_id": "944233f0d63740dc160eb09665888cd23f246039", "title": "We Need No Pixels: Video Manipulation Detection Using Stream Descriptors", "abstract": "Manipulating video content is easier than ever. Due to the misuse potential of manipulated content, multiple detection techniques that analyze the pixel data from the videos have been proposed. However, clever manipulators should also carefully forge the metadata and auxiliary header information, which is harder to do for videos than images. In this paper, we propose to identify forged videos by analyzing their multimedia stream descriptors with simple binary classifiers, completely avoiding the pixel space. Using well-known datasets, our results show that this scalable approach can achieve a high manipulation detection score if the manipulators have not done a careful data sanitization of the multimedia stream descriptors.", "venue": "ArXiv", "authors": ["David  G\u00fcera", "Sriram  Baireddy", "Paolo  Bestagini", "Stefano  Tubaro", "Edward J. Delp"], "year": 2019, "n_citations": 13}
{"id": 2812455, "s2_id": "107e4ea37d2e5364893107a8ce072972c4a10dfb", "title": "Unsupervised Skill Discovery with Bottleneck Option Learning", "abstract": "Having the ability to acquire inherent skills from environments without any external rewards or supervision like humans is an important problem. We propose a novel unsupervised skill discovery method named Information Bottleneck Option Learning (IBOL). On top of the linearization of environments that promotes more various and distant state transitions, IBOL enables the discovery of diverse skills. It provides the abstraction of the skills learned with the information bottleneck framework for the options with improved stability and encouraged disentanglement. We empirically demonstrate that IBOL outperforms multiple state-of-the-art unsupervised skill discovery methods on the information-theoretic evaluations and downstream tasks in MuJoCo environments, including Ant, HalfCheetah, Hopper and D'Kitty.", "venue": "ICML", "authors": ["Jaekyeom  Kim", "Seohong  Park", "Gunhee  Kim"], "year": 2021, "n_citations": 2}
{"id": 2823164, "s2_id": "b105f6632a716a5a925b595d001b1bc19a4755de", "title": "Decentralized Clustering on Compressed Data without Prior Knowledge of the Number of Clusters", "abstract": "In sensor networks, it is not always practical to set up a fusion center. Therefore, there is need for fully decentralized clustering algorithms. Decentralized clustering algorithms should minimize the amount of data exchanged between sensors in order to reduce sensor energy consumption. In this respect, we propose one centralized and one decentralized clustering algorithm that work on compressed data without prior knowledge of the number of clusters. In the standard K-means clustering algorithm, the number of clusters is estimated by repeating the algorithm several times, which dramatically increases the amount of exchanged data, while our algorithm can estimate this number in one run. \nThe proposed clustering algorithms derive from a theoretical framework establishing that, under asymptotic conditions, the cluster centroids are the only fixed-point of a cost function we introduce. This cost function depends on a weight function which we choose as the p-value of a Wald hypothesis test. This p-value measures the plausibility that a given measurement vector belongs to a given cluster. Experimental results show that our two algorithms are competitive in terms of clustering performance with respect to K-means and DB-Scan, while lowering by a factor at least $2$ the amount of data exchanged between sensors.", "venue": "ArXiv", "authors": ["Elsa  Dupraz", "Dominique  Pastor", "Fran\u00e7ois-Xavier  Socheleau"], "year": 2018, "n_citations": 0}
{"id": 2823309, "s2_id": "1add8b23b8e54377742d49dcdc794c5c2f88c62c", "title": "Solution Path Algorithm for Twin Multi-class Support Vector Machine", "abstract": "The twin support vector machine and its extensions have made great achievements in dealing with binary classification problems, however, which is faced with some difficulties such as model selection and solving multi-classification problems quickly. This paper is devoted to the fast regularization parameter tuning algorithm for the twin multi-class support vector machine. A new sample dataset division method is adopted and the Lagrangian multipliers are proved to be piecewise linear with respect to the regularization parameters by combining the linear equations and block matrix theory. Eight kinds of events are defined to seek for the starting event and then the solution path algorithm is designed, which greatly reduces the computational cost. In addition, only few points are combined to complete the initialization and Lagrangian multipliers are proved to be 1 as the regularization parameter tends to infinity. Simulation results based on UCI datasets show that the proposed method can achieve good classification performance with reducing the computational cost of grid search method from exponential level to the constant level.", "venue": "ArXiv", "authors": ["Liuyuan  Chen", "Kanglei  Zhou", "Junchang  Jing", "Haiju  Fan", "Juntao  Li"], "year": 2020, "n_citations": 0}
{"id": 2833390, "s2_id": "25f70f9bfb256546e9f3ac994ed1d50d3b48e23e", "title": "Qd-tree: Learning Data Layouts for Big Data Analytics", "abstract": "Corporations today collect data at an unprecedented and accelerating scale, making the need to run queries on large datasets increasingly important. Technologies such as columnar block-based data organization and compression have become standard practice in most commercial database systems. However, the problem of best assigning records to data blocks on storage is still open. For example, today's systems usually partition data by arrival time into row groups, or range/hash partition the data based on selected fields. For a given workload, however, such techniques are unable to optimize for the important metric of the number of blocks accessed by a query. This metric directly relates to the I/O cost, and therefore performance, of most analytical queries. Further, they are unable to exploit additional available storage to drive this metric down further. In this paper, we propose a new framework called a query-data routing tree, or qd-tree, to address this problem, and propose two algorithms for their construction based on greedy and deep reinforcement learning techniques. Experiments over benchmark and real workloads show that a qd-tree can provide physical speedups of more than an order of magnitude compared to current blocking schemes, and can reach within 2X of the lower bound for data skipping based on selectivity, while providing complete semantic descriptions of created blocks.", "venue": "SIGMOD Conference", "authors": ["Zongheng  Yang", "Badrish  Chandramouli", "Chi  Wang", "Johannes  Gehrke", "Yinan  Li", "Umar Farooq Minhas", "Per-AAke  Larson", "Donald  Kossmann", "Rajeev  Acharya"], "year": 2020, "n_citations": 25}
{"id": 2834689, "s2_id": "901db6dfe1981ee6c566ba65b8954c7228959520", "title": "Adaptive neural network classifier for decoding MEG signals", "abstract": "We introduce two Convolutional Neural Network (CNN) classifiers optimized for inferring brain states from magnetoencephalographic (MEG) measurements. Network design follows a generative model of the electromagnetic (EEG and MEG) brain signals allowing explorative analysis of neural sources informing classification. The proposed networks outperform traditional classifiers as well as more complex neural networks when decoding evoked and induced responses to different stimuli across subjects. Importantly, these models can successfully generalize to new subjects in real-time classification enabling more efficient brain\u2013computer interfaces (BCI).", "venue": "NeuroImage", "authors": ["Ivan  Zubarev", "Rasmus  Zetter", "Hanna-Leena  Halme", "Lauri  Parkkonen"], "year": 2019, "n_citations": 21}
{"id": 2837646, "s2_id": "9050f1cb4de42a524dcc3a927b25cbb23f3e4ee4", "title": "Multiclass Diffuse Interface Models for Semi-supervised Learning on Graphs", "abstract": "We present a graph-based variational algorithm for multiclass classification of high-dimensional data, motivated by total variation techniques. The energy functional is based on a diffuse interface model with a periodic potential. We augment the model by introducing an alternative measure of smoothness that preserves symmetry among the class labels. Through this modification of the standard Laplacian, we construct an efficient multiclass method that allows for sharp transitions between classes. The experimental results demonstrate that our approach is competitive with the state of the art among other graph-based algorithms.", "venue": "ICPRAM", "authors": ["Cristina  Garcia-Cardona", "Arjuna  Flenner", "Allon G. Percus"], "year": 2013, "n_citations": 17}
{"id": 2851532, "s2_id": "0b7b8c5d5e57281f854c2b6a049ba5ca21ffe470", "title": "Improved Adversarial Robustness by Reducing Open Space Risk via Tent Activations", "abstract": "Adversarial examples contain small perturbations that can remain imperceptible to human observers but alter the behavior of even the best performing deep learning models and yield incorrect outputs. Since their discovery, adversarial examples have drawn significant attention in machine learning: researchers try to reveal the reasons for their existence and improve the robustness of machine learning models to adversarial perturbations. The state-of-the-art defense is the computationally expensive and very time consuming adversarial training via projected gradient descent (PGD). We hypothesize that adversarial attacks exploit the open space risk of classic monotonic activation functions. This paper introduces the tent activation function with bounded open space risk and shows that tents make deep learning models more robust to adversarial attacks. We demonstrate on the MNIST dataset that a classifier with tents yields an average accuracy of 91.8% against six white-box adversarial attacks, which is more than 15 percentage points above the state of the art. On the CIFAR-10 dataset, our approach improves the average accuracy against the six white-box adversarial attacks to 73.5% from 41.8% achieved by adversarial training via PGD.", "venue": "ArXiv", "authors": ["Andras  Rozsa", "Terrance E. Boult"], "year": 2019, "n_citations": 9}
{"id": 2852709, "s2_id": "7509c66a666e2e3f14bc8676b969b945ee6e136f", "title": "CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings", "abstract": "Without positional information, attention-based Transformer neural networks are permutation-invariant. Absolute or relative positional embeddings are the most popular ways to feed Transformer models with positional information. Absolute positional embeddings are simple to implement, but suffer from generalization issues when evaluating on sequences longer than seen at training time. Relative positions are more robust to input length change, but are more complex to implement and yield inferior model throughput due to extra computational and memory costs. In this paper, we propose an augmentation-based approach (CAPE) for absolute positional embeddings, which keeps the advantages of both absolute (simplicity and speed) and relative positional embeddings (better generalization). In addition, our empirical evaluation on state-of-the-art models in machine translation, image and speech recognition demonstrates that CAPE leads to better generalization performance as well as increased stability with respect to training hyper-parameters.", "venue": "ArXiv", "authors": ["Tatiana  Likhomanenko", "Qiantong  Xu", "Ronan  Collobert", "Gabriel  Synnaeve", "Alex  Rogozhnikov"], "year": 2021, "n_citations": 4}
{"id": 2854253, "s2_id": "ee894195a8135bd4e189bfb77fe0dc9f844c5e2a", "title": "Human Pose Regression with Residual Log-likelihood Estimation", "abstract": "Heatmap-based methods dominate in the field of human pose estimation by modelling the output distribution through likelihood heatmaps. In contrast, regressionbased methods are more efficient but suffer from inferior performance. In this work, we explore maximum likelihood estimation (MLE) to develop an efficient and effective regression-based method. From the perspective of MLE, adopting different regression losses is making different assumptions about the output density function. A density function closer to the true distribution leads to a better regression performance. In light of this, we propose a novel regression paradigm with Residual Log-likelihood Estimation (RLE) to capture the underlying output distribution. Concretely, RLE learns the change of the distribution instead of the unreferenced underlying distribution to facilitate the training process. With the proposed reparameterization design, our method is compatible with off-theshelf flow models. The proposed method is effective, efficient and flexible. We show its potential in various human pose estimation tasks with comprehensive experiments. Compared to the conventional regression paradigm, regression with RLE bring 12.4 mAP improvement on MSCOCO without any test-time overhead. Moreover, for the first time, especially on multi-person pose estimation, our regression method is superior to the heatmap-based methods. Our code is available at https://github.com/Jeff-sjtu/resloglikelihood-regression.", "venue": "ArXiv", "authors": ["Jiefeng  Li", "Siyuan  Bian", "Ailing  Zeng", "Can  Wang", "Bo  Pang", "Wentao  Liu", "Cewu  Lu"], "year": 2021, "n_citations": 4}
{"id": 2859545, "s2_id": "be7c76e21caa8e3efc47830d39082d93564155f8", "title": "Regularization in neural network optimization via trimmed stochastic gradient descent with noisy label", "abstract": "Regularization is essential for avoiding over-fitting to training data in neural network optimization, leading to better generalization of the trained networks. The label noise provides a strong implicit regularization by replacing the target ground truth labels of training examples by uniform random labels. However, it may also cause undesirable misleading gradients due to the large loss associated with incorrect labels. We propose a first-order optimization method (Label-Noised Trim-SGD) which combines the label noise with the example trimming in order to remove the outliers. The proposed algorithm enables us to impose a large label noise and obtain a better regularization effect than the original methods. The quantitative analysis is performed by comparing the behavior of the label noise, the example trimming, and the proposed algorithm. We also present empirical results that demonstrate the effectiveness of our algorithm using the major benchmarks and the fundamental networks, where our method has successfully outperformed the state-of-the-art optimization methods.", "venue": "ArXiv", "authors": ["Kensuke  Nakamura", "Byung-Woo  Hong"], "year": 2020, "n_citations": 0}
{"id": 2873596, "s2_id": "a23d765860bfb58d68abeb3aa830873ce151cc2e", "title": "Coping with Label Shift via Distributionally Robust Optimisation", "abstract": "The label shift problem refers to the supervised learning setting where the train and test label distributions do not match. Existing work addressing label shift usually assumes access to an \\emph{unlabelled} test sample. This sample may be used to estimate the test label distribution, and to then train a suitably re-weighted classifier. While approaches using this idea have proven effective, their scope is limited as it is not always feasible to access the target domain; further, they require repeated retraining if the model is to be deployed in \\emph{multiple} test environments. Can one instead learn a \\emph{single} classifier that is robust to arbitrary label shifts from a broad family? In this paper, we answer this question by proposing a model that minimises an objective based on distributionally robust optimisation (DRO). We then design and analyse a gradient descent-proximal mirror ascent algorithm tailored for large-scale problems to optimise the proposed objective. %, and establish its convergence. Finally, through experiments on CIFAR-100 and ImageNet, we show that our technique can significantly improve performance over a number of baselines in settings where label shift is present.", "venue": "ICLR", "authors": ["Jingzhao  Zhang", "Aditya  Menon", "Andreas  Veit", "Srinadh  Bhojanapalli", "Sanjiv  Kumar", "Suvrit  Sra"], "year": 2021, "n_citations": 4}
{"id": 2875665, "s2_id": "071100400f16968d16fabb347278d8451216b6ff", "title": "Towards the Unification and Robustness of Perturbation and Gradient Based Explanations", "abstract": "As machine learning black boxes are increasingly being deployed in critical domains such as healthcare and criminal justice, there has been a growing emphasis on developing techniques for explaining these black boxes in a post hoc manner. In this work, we analyze two popular post hoc interpretation techniques: SmoothGrad which is a gradient based method, and a variant of LIME which is a perturbation based method. More specifically, we derive explicit closed form expressions for the explanations output by these two methods and show that they both converge to the same explanation in expectation, i.e., when the number of perturbed samples used by these methods is large. We then leverage this connection to establish other desirable properties, such as robustness, for these techniques. We also derive finite sample complexity bounds for the number of perturbations required for these methods to converge to their expected explanation. Finally, we empirically validate our theory using extensive experimentation on both synthetic and real world datasets.1", "venue": "ICML", "authors": ["Sushant  Agarwal", "Shahin  Jabbari", "Chirag  Agarwal", "Sohini  Upadhyay", "Zhiwei Steven Wu", "Himabindu  Lakkaraju"], "year": 2021, "n_citations": 1}
{"id": 2875778, "s2_id": "84bfdf71b792ffb7319e57dae94b5aa7324298c1", "title": "MODS - A USV-oriented object detection and obstacle segmentation benchmark", "abstract": "Small-sized unmanned surface vehicles (USV) are coastal water devices with a broad range of applications such as environmental control and surveillance. A crucial capability for autonomous operation is obstacle detection for timely reaction and collision avoidance, which has been recently explored in the context of camera-based visual scene interpretation. Owing to curated datasets, substantial advances in scene interpretation have been made in a related field of unmanned ground vehicles. However, the current maritime datasets do not adequately capture the complexity of real-world USV scenes and the evaluation protocols are not standardised, which makes cross-paper comparison of different methods difficult and hiders the progress. To address these issues, we introduce a new obstacle detection benchmark MODS, which considers two major perception tasks: maritime object detection and the more general maritime obstacle segmentation. We present a new diverse maritime evaluation dataset containing approximately 81k stereo images synchronized with an on-board IMU, with over 60k objects annotated. We propose a new obstacle segmentation performance evaluation protocol that reflects the detection accuracy in a way meaningful for practical USV navigation. Seventeen recent state-of-the-art object detection and obstacle segmentation methods are evaluated using the proposed protocol, creating a benchmark to facilitate development of the field.", "venue": "IEEE Transactions on Intelligent Transportation Systems", "authors": ["Borja  Bovcon", "Jon  Muhovic", "Dusko  Vranac", "Dean  Mozetic", "Janez  Pers", "Matej  Kristan"], "year": 2021, "n_citations": 1}
{"id": 2877305, "s2_id": "f8834e65ab6fc45401f80233f2326c4bb6a7021f", "title": "Machine Learning and Deep Learning methods for predictive modelling from Raman spectra in bioprocessing", "abstract": "In chemical processing and bioprocessing, conventional online sensors are limited to measure only basic process variables like pressure and temperature, pH, dissolved O and CO$_2$ and viable cell density (VCD). The concentration of other chemical species is more difficult to measure, as it usually requires an at-line or off-line approach. Such approaches are invasive and slow compared to on-line sensing. It is known that different molecules can be distinguished by their interaction with monochromatic light, producing different profiles for the resulting Raman spectrum, depending on the concentration. Given the availability of reference measurements for the target variable, regression methods can be used to model the relationship between the profile of the Raman spectra and the concentration of the analyte. This work focused on pretreatment methods of Raman spectra for the facilitation of the regression task using Machine Learning and Deep Learning methods, as well as the development of new regression models based on these methods. In the majority of cases, this allowed to outperform conventional Raman models in terms of prediction error and prediction robustness.", "venue": "ArXiv", "authors": ["Semion  Rozov"], "year": 2020, "n_citations": 0}
{"id": 2878503, "s2_id": "c9c6662a9ee9870454f512e34943414a7ed2a1be", "title": "Improving the Detection of Burnt Areas in Remote Sensing using Hyper-features Evolved by M3GP", "abstract": "One problem found when working with satellite images is the radiometric variations across the image and different images. Intending to improve remote sensing models for the classification of burnt areas, we set two objectives. The first is to understand the relationship between feature spaces and the predictive ability of the models, allowing us to explain the differences between learning and generalization when training and testing in different datasets. We find that training on datasets built from more than one image provides models that generalize better. These results are explained by visualizing the dispersion of values on the feature space. The second objective is to evolve hyper-features that improve the performance of different classifiers on a variety of test sets. We find the hyper-features to be beneficial, and obtain the best models with XGBoost, even if the hyper-features are optimized for a different method.", "venue": "2020 IEEE Congress on Evolutionary Computation (CEC)", "authors": ["Joao E. Batista", "Sara  Silva"], "year": 2020, "n_citations": 3}
{"id": 2879230, "s2_id": "4890f2fc74b4cb7da6c4f499c90d4effe86584ca", "title": "Optimistic and Adaptive Lagrangian Hedging", "abstract": "In online learning an algorithm plays against an environment with losses possibly picked by an adversary at each round. The generality of this framework includes problems that are not adversarial, for example offline optimization, or saddle point problems (i.e. min max optimization). However, online algorithms are typically not designed to leverage additional structure present in non-adversarial problems. Recently, slight modifications to well-known online algorithms such as optimism and adaptive step sizes have been used in several domains to accelerate online learning \u2013 recovering optimal rates in offline smooth optimization, and accelerating convergence to saddle points or social welfare in smooth games. In this work we introduce optimism and adaptive stepsizes to Lagrangian hedging, a class of online algorithms that includes regret-matching, and hedge (i.e. multiplicative weights). Our results include: a general general regret bound; a path length regret bound for a fixed smooth loss, applicable to an optimistic variant of regret-matching and regretmatching+; optimistic regret bounds for \u03a6 regret, a framework that includes external, internal, and swap regret; and optimistic bounds for a family of algorithms that includes regret-matching+ as a special case. Introduction Online optimization is a general framework applicable to various problems such as offline optimization, and finding equilibria in games. Typical algorithms only use firstorder information (i.e. a subgradient or gradient), such as online mirror descent (MD) (Nemirovsky and Yudin 1983; Warmuth and Jagota 1997; Beck and Teboulle 2003) which generalizes projected gradient descent (see for example (Orabona 2019)), and follow the regularized leader (FTRL) (Shalev-Shwartz and Singer 2006; Abernethy, Hazan, and Rakhlin 2009; Nesterov 2009). In general, online learning is adversarial, losses may change almost arbitrarily from one time step to the next. However, most problems of interest including offline optimization, and saddle point optimization can be \u201cpre*This work is partially done when Ryan D\u2019Orazio was working at Borealis AI. Copyright \u00a9 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. See Orabona for an excellent historical overview of MD and FTRL. dictable.\u201d That is, the sequence of losses induced by running an online algorithm in these settings has specific structure and can be predictable under the right conditions, like smoothness (i.e. Lipschitz continuous gradient). When losses are predictable a powerful framework is optimistic online learning (Rakhlin and Sridharan 2013a,b; Chiang et al. 2012). Where algorithms are modified to incorporate a guess of the next loss, mt, into their update. Combining optimism with MD and FTRL yields their optimistic counterparts, optimistic mirror descent (OMD), and optimistic follow the regularized leader (OFTRL), respectively. OMD and OFTRL both provide tangible benefits when problems are not quite adversarial. For example, faster convergence to a saddle point on the average (Rakhlin and Sridharan 2013b; Syrgkanis et al. 2015; Farina et al. 2019; Farina, Kroer, and Sandholm 2019); faster convergence to optimal social wellfare in n-player games (Syrgkanis et al. 2015); last iterate convergence in games (Daskalakis and Panageas 2018); acceleration in offline or online optimization (Cutkosky 2019; Mohri and Yang 2016; Joulani et al. 2020; Joulani, Gy\u00f6rgy, and Szepesv\u00e1ri 2017). Interestingly, much of the analysis of optimistic algorithms is black-box. For example, most of the results rely on regret bounds being of a particular form, which is satisfied by both OMD and OFTRL. Naturally, one may ask what other classes of algorithms can be combined with optimism to achieve faster rates in predictable problems? In this paper we extend the idea of optimism to the class of algorithms known as Lagrangian hedging (Gordon 2007). Unfortunately, the regret bounds attained are not consistent with OMD and OFTRL, therefore, immediate theoretical acceleration via the previously mentioned works is not attained. However, our analysis provides interesting regret bounds that should be small given a \u201cgood\u201d guess. And in the case for a smooth fixed loss we show a path length bound for the regret. This result, for example, is applicable to an optimistic varaint of the wellknown regret-matching algorithm when used to train a linear regressor with L1 regularization and the least-squares loss (Schuurmans and Zinkevich 2016). Additionally, our analysis extends beyond the typical regret objectives of MD and FTRL, and includes regret bounds for internal and swap regret (Cesa-Bianchi and Lugosi 2006). To the best of our knowledge, our results provide the first optimistic and adaptive algorithms for minimizing internal regret, with possible applications including finding correlated equilibria in n-player general sum games (Cesa-Bianchi and Lugosi 2006). Background Online Linear Optimization In online convex optimization an algorithm A interacts with an environment for T rounds (Zinkevich 2003). In each round t, A selects an iterate xt within some convex compact set X , afterwhich a convex loss function lt : X \u2192 R chosen by the environment is revealed. Furthermore, A is only allowed to use information from previous rounds. The performance of A after T rounds is measured by its regret R X = T", "venue": "ArXiv", "authors": ["Ryan  D'Orazio", "Ruitong  Huang"], "year": 2021, "n_citations": 2}
{"id": 2879765, "s2_id": "719f9b6f7e0e317709c39b634f27beaf904db199", "title": "On the Expected Complexity of Maxout Networks", "abstract": "Learning with neural networks relies on the complexity of the representable functions, but more importantly, the particular assignment of typical parameters to functions of different complexity. Taking the number of activation regions as a complexity measure, recent works have shown that the practical complexity of deep ReLU networks is often far from the theoretical maximum. In this work we show that this phenomenon also occurs in networks with maxout (multi-argument) activation functions and when considering the decision boundaries in classification tasks. We also show that the parameter space has a multitude of full-dimensional regions with widely different complexity, and obtain nontrivial lower bounds on the expected complexity. Finally, we investigate different parameter initialization procedures and show that they can increase the speed of convergence in training.", "venue": "ArXiv", "authors": ["Hanna  Tseran", "Guido  Mont'ufar"], "year": 2021, "n_citations": 0}
{"id": 2892399, "s2_id": "bd4ef325ef22c37e821c1470bdc9a28262c9a3e3", "title": "Generative and Contrastive Self-Supervised Learning for Graph Anomaly Detection", "abstract": "Anomaly detection from graph data has drawn much attention due to its practical significance in many critical applications including cybersecurity, finance, and social networks. Existing data mining and machine learning methods are either shallow methods that could not effectively capture the complex interdependency of graph data or graph autoencoder methods that could not fully exploit the contextual information as supervision signals for effective anomaly detection. To overcome these challenges, in this paper, we propose a novel method, Self-Supervised Learning for Graph Anomaly Detection (SL-GAD). Our method constructs different contextual subgraphs (views) based on a target node and employs two modules, generative attribute regression and multi-view contrastive learning for anomaly detection. While the generative attribute regression module allows us to capture the anomalies in the attribute space, the multi-view contrastive learning module can exploit richer structure information from multiple subgraphs, thus abling to capture the anomalies in the structure space, mixing of structure, and attribute information. We conduct extensive experiments on six benchmark datasets and the results demonstrate that our method outperforms state-of-the-art methods by a large margin.", "venue": "IEEE Transactions on Knowledge and Data Engineering", "authors": ["Yu  Zheng", "Ming  Jin", "Yixin  Liu", "Lianhua  Chi", "Khoa T. Phan", "Yi-Ping Phoebe Chen"], "year": 2021, "n_citations": 5}
{"id": 2896474, "s2_id": "f662fe85ebc06c310b04baaeb4c42b2efb808d93", "title": "Finding Relevant Points for Nearest-Neighbor Classification", "abstract": "In nearest-neighbor classification problems, a set of d-dimensional training points are given, each with a known classification, and are used to infer unknown classifications of other points by using the same classification as the nearest training point. A training point is relevant if its omission from the training set would change the outcome of some of these inferences. We provide a simple algorithm for thinning a training set down to its subset of relevant points, using as subroutines algorithms for finding the minimum spanning tree of a set of points and for finding the extreme points (convex hull vertices) of a set of points. The time bounds for our algorithm, in any constant dimension d \u2265 3, improve on a previous algorithm for the same problem by Clarkson (FOCS 1994).", "venue": "ArXiv", "authors": ["David  Eppstein"], "year": 2021, "n_citations": 0}
{"id": 2927843, "s2_id": "c3ea1dc14db06c60043a54a86e24ef9985d15f74", "title": "Profiling US Restaurants from Billions of Payment Card Transactions", "abstract": "A payment card (such as debit or credit) is one of the most convenient payment methods for purchasing goods and services. Hundreds of millions of card transactions take place across the globe every day, generating a massive volume of transaction data. The data render a holistic view of cardholder-merchant interactions, containing insights that can benefit various applications, such as payment fraud detection and merchant recommendation. However, utilizing these insights often requires additional information about merchants missing from the data owner\u2019s (i.e., payment company\u2019s) perspective. For example, payment companies do not know the exact type of product a merchant serves. Collecting merchant attributes from external sources for commercial purposes can be expensive. Motivated by this limitation, we aim to infer latent merchant attributes from transaction data. As proof of concept, we concentrate on restaurants and infer the cuisine types of restaurants from transactions. To this end, we present a framework for inferring the cuisine types of restaurants from transaction data. Our proposed framework consists of three steps. In the first step, we generate cuisine labels for a limited number of restaurants via weak supervision. In the second step, we extract a wide variety of statistical features and neural embeddings from the restaurant transactions. In the third step, we use deep neural networks (DNNs) to infer the remaining restaurants\u2019 cuisine types. The proposed framework achieved a 76.2% accuracy in classifying the US restaurants. To the best of our knowledge, this is the first framework to infer the cuisine types of restaurants by analyzing transaction data as the only source.", "venue": "2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)", "authors": ["Himel  Dev", "Hossein  Hamooni"], "year": 2020, "n_citations": 0}
{"id": 2928400, "s2_id": "146b84bdd9b9078f40a2df9b7ded26416771f740", "title": "Inverse Risk-Sensitive Reinforcement Learning", "abstract": "This work addresses the problem of inverse reinforcement learning in Markov decision processes where the decision-making agent is risk-sensitive. In particular, a risk-sensitive reinforcement learning algorithm with convergence guarantees that makes use of coherent risk metrics and models of human decision-making which have their origins in behavioral psychology and economics is presented. The risk-sensitive reinforcement learning algorithm provides the theoretical underpinning for a gradient-based inverse reinforcement learning algorithm that seeks to minimize a loss function defined on the observed behavior. It is shown that the gradient of the loss function with respect to the model parameters is well defined and computable via a contraction map argument. Evaluation of the proposed technique is performed on a Grid World example, a canonical benchmark problem.", "venue": "IEEE Transactions on Automatic Control", "authors": ["Lillian J. Ratliff", "Eric  Mazumdar"], "year": 2020, "n_citations": 12}
{"id": 2931395, "s2_id": "dee708c2325d84d6f833d99bf622e7945d5b1440", "title": "Continuous Learning of Face Attribute Synthesis", "abstract": "The generative adversarial network (GAN) exhibits great superiority in the face attribute synthesis task. However, existing methods have very limited effects on the expansion of new attributes. To overcome the limitations of a single network in new attribute synthesis, a continuous learning method for face attribute synthesis is proposed in this work. First, the feature vector of the input image is extracted and attribute direction regression is performed in the feature space to obtain the axes of different attributes. The feature vector is then linearly guided along the axis so that images with target attributes can be synthesized by the decoder. Finally, to make the network capable of continuous learning, the orthogonal direction modification module is used to extend the newly-added attributes. Experimental results show that the proposed method can endow a single network with the ability to learn attributes continuously, and, as compared to those produced by the current state-of-the-art methods, the synthetic attributes have higher accuracy.", "venue": "2020 25th International Conference on Pattern Recognition (ICPR)", "authors": ["Xin  Ning", "Shaohui  Xu", "Xiaoli  Dong", "Weijun  Li", "Fangzhe  Nan", "Yuanzhou  Yao"], "year": 2021, "n_citations": 1}
{"id": 2931549, "s2_id": "712243f7c6f099a93ad9f62d6e11f19ad68b323c", "title": "Amortized Bayesian model comparison with evidential deep learning", "abstract": "Comparing competing mathematical models of complex processes is a shared goal among many branches of science. The Bayesian probabilistic framework offers a principled way to perform model comparison and extract useful metrics for guiding decisions. However, many interesting models are intractable with standard Bayesian methods, as they lack a closed-form likelihood function or the likelihood is computationally too expensive to evaluate. In this work, we propose a novel method for performing Bayesian model comparison using specialized deep learning architectures. Our method is purely simulation-based and circumvents the step of explicitly fitting all alternative models under consideration to each observed dataset. Moreover, it requires no hand-crafted summary statistics of the data and is designed to amortize the cost of simulation over multiple models, datasets, and dataset sizes. This makes the method especially effective in scenarios where model fit needs to be assessed for a large number of datasets, so that case-based inference is practically infeasible. Finally, we propose a novel way to measure epistemic uncertainty in model comparison problems. We demonstrate the utility of our method on toy examples and simulated data from nontrivial models from cognitive science and single-cell neuroscience. We show that our method achieves excellent results in terms of accuracy, calibration, and efficiency across the examples considered in this work. We argue that our framework can enhance and enrich model-based analysis and inference in many fields dealing with computational models of natural processes. We further argue that the proposed measure of epistemic uncertainty provides a unique proxy to quantify absolute evidence even in a framework which assumes that the true data-generating model is within a finite set of candidate models.", "venue": "IEEE transactions on neural networks and learning systems", "authors": ["Stefan T. Radev", "Marco  D'Alessandro", "Paul-Christian  B\u00fcrkner", "Ulf K. Mertens", "Andreas  Voss", "Ullrich  K\u00f6the"], "year": 2021, "n_citations": 4}
{"id": 2932928, "s2_id": "812013492d86adaa5e6043e9ef30a7123f25ead8", "title": "Improving adversarial robustness of deep neural networks by using semantic information", "abstract": "The vulnerability of deep neural networks (DNNs) to adversarial attack, which is an attack that can mislead state-of-the-art classifiers into making an incorrect classification with high confidence by deliberately perturbing the original inputs, raises concerns about the robustness of DNNs to such attacks. Adversarial training, which is the main heuristic method for improving adversarial robustness and the first line of defense against adversarial attacks, requires many sample-by-sample calculations to increase training size and is usually insufficiently strong for an entire network. This paper provides a new perspective on the issue of adversarial robustness, one that shifts the focus from the network as a whole to the critical part of the region close to the decision boundary corresponding to a given class. From this perspective, we propose a method to generate a single but image-agnostic adversarial perturbation that carries the semantic information implying the directions to the fragile parts on the decision boundary and causes inputs to be misclassified as a specified target. We call the adversarial training based on such perturbations \"region adversarial training\" (RAT), which resembles classical adversarial training but is distinguished in that it reinforces the semantic information missing in the relevant regions. Experimental results on the MNIST and CIFAR-10 datasets show that this approach greatly improves adversarial robustness even using a very small dataset from the training data; moreover, it can defend against FGSM adversarial attacks that have a completely different pattern from the model seen during retraining.", "venue": "Knowl. Based Syst.", "authors": ["Lina  Wang", "Rui  Tang", "Yawei  Yue", "Xingshu  Chen", "Wei  Wang", "Yi  Zhu", "Xuemei  Zeng"], "year": 2021, "n_citations": 3}
{"id": 2939377, "s2_id": "8740f38b80126bf02a87ad4ac08e53598bb09ea4", "title": "Evaluation of the Performance of the Markov Blanket Bayesian Classifier Algorithm", "abstract": "The Markov Blanket Bayesian Classifier is a recently-proposed algorithm for construction of probabilistic classifiers. This paper presents an empirical comparison of the MBBC algorithm with three other Bayesian classifiers: Naive Bayes, Tree-Augmented Naive Bayes and a general Bayesian network. All of these are implemented using the K2 framework of Cooper and Herskovits. The classifiers are compared in terms of their performance (using simple accuracy measures and ROC curves) and speed, on a range of standard benchmark data sets. It is concluded that MBBC is competitive in terms of speed and accuracy with the other algorithms considered.", "venue": "ArXiv", "authors": ["Michael G. Madden"], "year": 2002, "n_citations": 39}
{"id": 2939966, "s2_id": "2b6205113e0c5205f323365af168e0b74c98fe8a", "title": "Auto-Encoding Twin-Bottleneck Hashing", "abstract": "Conventional unsupervised hashing methods usually take advantage of similarity graphs, which are either pre-computed in the high-dimensional space or obtained from random anchor points. On the one hand, existing methods uncouple the procedures of hash function learning and graph construction. On the other hand, graphs empirically built upon original data could introduce biased prior knowledge of data relevance, leading to sub-optimal retrieval performance. In this paper, we tackle the above problems by proposing an efficient and adaptive code-driven graph, which is updated by decoding in the context of an auto-encoder. Specifically, we introduce into our framework twin bottlenecks (i.e., latent variables) that exchange crucial information collaboratively. One bottleneck (i.e., binary codes) conveys the high-level intrinsic data structure captured by the code-driven graph to the other (i.e., continuous variables for low-level detail information), which in turn propagates the updated network feedback for the encoder to learn more discriminative binary codes. The auto-encoding learning objective literally rewards the code-driven graph to learn an optimal encoder. Moreover, the proposed model can be simply optimized by gradient descent without violating the binary constraints. Experiments on benchmarked datasets clearly show the superiority of our framework over the state-of-the-art hashing methods. Our source code can be found at https://github.com/ymcidence/TBH.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Yuming  Shen", "Jie  Qin", "Jiaxin  Chen", "Mengyang  Yu", "Li  Liu", "Fan  Zhu", "Fumin  Shen", "Ling  Shao"], "year": 2020, "n_citations": 22}
{"id": 2940914, "s2_id": "1752d787bf8e08e7da1ec1f2af22f3e98a2ed9a1", "title": "Surrogate Losses in Passive and Active Learning", "abstract": "Active learning is a type of sequential design for supervised machine learning, in which the learning algorithm sequentially requests the labels of selected instances from a large pool of unlabeled data points. The objective is to produce a classifier of relatively low risk, as measured under the 0-1 loss, ideally using fewer label requests than the number of random labeled data points sufficient to achieve the same. This work investigates the potential uses of surrogate loss functions in the context of active learning. Specifically, it presents an active learning algorithm based on an arbitrary classification-calibrated surrogate loss function, along with an analysis of the number of label requests sufficient for the classifier returned by the algorithm to achieve a given risk under the 0-1 loss. Interestingly, these results cannot be obtained by simply optimizing the surrogate risk via active learning to an extent sufficient to provide a guarantee on the 0-1 loss, as is common practice in the analysis of surrogate losses for passive learning. Some of the results have additional implications for the use of surrogate losses in passive learning.", "venue": "Electronic Journal of Statistics", "authors": ["Steve  Hanneke", "Liu  Yang"], "year": 2019, "n_citations": 21}
{"id": 2945334, "s2_id": "71b8e331faa9f8efefab6ca2dbf2133f94df9f72", "title": "Empathy in Bimatrix Games", "abstract": "Although the definition of what empathetic preferences exactly are is still evolving, there is a general consensus in the psychology, science and engineering communities that the evolution toward players' behaviors in interactive decision-making problems will be accompanied by the exploitation of their empathy, sympathy, compassion, antipathy, spitefulness, selfishness, altruism, and self-abnegating states in the payoffs. In this article, we study one-shot bimatrix games from a psychological game theory viewpoint. A new empathetic payoff model is calculated to fit empirical observations and both pure and mixed equilibria are investigated. For a realized empathy structure, the bimatrix game is categorized among four generic class of games. Number of interesting results are derived. A notable level of involvement can be observed in the empathetic one-shot game compared the non-empathetic one and this holds even for games with dominated strategies. Partial altruism can help in breaking symmetry, in reducing payoff-inequality and in selecting social welfare and more efficient outcomes. By contrast, partial spite and self-abnegating may worsen payoff equity. Empathetic evolutionary game dynamics are introduced to capture the resulting empathetic evolutionarily stable strategies under wide range of revision protocols including Brown-von Neumann-Nash, Smith, imitation, replicator, and hybrid dynamics. Finally, mutual support and Berge solution are investigated and their connection with empathetic preferences are established. We show that pure altruism is logically inconsistent, only by balancing it with some partial selfishness does it create a consistent psychology.", "venue": "ArXiv", "authors": ["Brian  Powers", "Michalis  Smyrnakis", "Hamidou  Tembine"], "year": 2017, "n_citations": 2}
{"id": 2946373, "s2_id": "ffcd152f9abb4e769c81cfe39e749f54099a1de0", "title": "Global Convergence of Second-order Dynamics in Two-layer Neural Networks", "abstract": "Recent results have shown that for two-layer fully connected neural networks, gradient flow converges to a global optimum in the infinite width limit, by making a connection between the mean field dynamics and the Wasserstein gradient flow. These results were derived for first-order gradient flow, and a natural question is whether second-order dynamics, i.e., dynamics with momentum, exhibit a similar guarantee. We show that the answer is positive for the heavy ball method. In this case, the resulting integro-PDE is a nonlinear kinetic Fokker Planck equation, and unlike the first-order case, it has no apparent connection with the Wasserstein gradient flow. Instead, we study the variations of a Lyapunov functional along the solution trajectories to characterize the stationary points and to prove convergence. While our results are asymptotic in the mean field limit, numerical simulations indicate that global convergence may already occur for reasonably small networks.", "venue": "ArXiv", "authors": ["Walid  Krichene", "Kenneth F. Caluya", "Abhishek  Halder"], "year": 2020, "n_citations": 4}
{"id": 2950224, "s2_id": "ed81dea951d119d29864e600e9eab7a3e8b7bac7", "title": "Quantifying With Only Positive Training Data", "abstract": "Quantification is the research field that studies the task of counting how many data points belong to each class in an unlabeled sample. Traditionally, researchers in this field assume the availability of training data containing labeled observations for all classes to induce quantification models. Although quantification methods usually estimate counts for every class, we are often interested in those regarding only a target class. In this context, we have proposed a novel setting, known as One-class Quantification (OCQ), where reliable training data is only available for the target class. On the other hand, Positive and Unlabeled Learning (PUL), which is another branch of Machine Learning, has offered solutions that can be applied to OCQ, despite quantification not being the focal point of PUL. In this article, we close the gap between PUL and OCQ and bring both areas together under a unified view. We compare our methods, Passive Aggressive Threshold (PAT) and One Distribution Inside (ODIn), against PUL methods and show that PAT generally is the fastest and most accurate algorithm. Contrary to PUL methods, PAT and ODIn also can induce quantification models that can be replied to quantify different samples of data. We additionally introduce Exhaustive TIcE (ExTIcE), an improved version of the PUL algorithm Tree Induction for c Estimation (TIcE), and show that it quantifies more accurately than PAT and the other algorithms in scenarios where a considerable number of negative observations are identical to positive observations.", "venue": "ArXiv", "authors": ["Denis dos Reis", "Marc'ilio de Souto", "Elaine de Sousa", "Gustavo  Batista"], "year": 2020, "n_citations": 1}
{"id": 2953402, "s2_id": "33fc67c7425c669bac36b4dba7fd427e55d309fe", "title": "Out-of-distribution Detection in Classifiers via Generation", "abstract": "By design, discriminatively trained neural network classifiers produce reliable predictions only for in-distribution samples. For their real-world deployments, detecting out-of-distribution (OOD) samples is essential. Assuming OOD to be outside the closed boundary of in-distribution, typical neural classifiers do not contain the knowledge of this boundary for OOD detection during inference. There have been recent approaches to instill this knowledge in classifiers by explicitly training the classifier with OOD samples close to the in-distribution boundary. However, these generated samples fail to cover the entire in-distribution boundary effectively, thereby resulting in a sub-optimal OOD detector. In this paper, we analyze the feasibility of such approaches by investigating the complexity of producing such \"effective\" OOD samples. We also propose a novel algorithm to generate such samples using a manifold learning network (e.g., variational autoencoder) and then train an n+1 classifier for OOD detection, where the $n+1^{th}$ class represents the OOD samples. We compare our approach against several recent classifier-based OOD detectors on MNIST and Fashion-MNIST datasets. Overall the proposed approach consistently performs better than the others.", "venue": "ArXiv", "authors": ["Sachin  Vernekar", "Ashish  Gaurav", "Vahdat  Abdelzad", "Taylor  Denouden", "Rick  Salay", "Krzysztof  Czarnecki"], "year": 2019, "n_citations": 27}
{"id": 2957913, "s2_id": "11ea19f5953a72493993fde95543b333130261fa", "title": "ZoomCount: A Zooming Mechanism for Crowd Counting in Static Images", "abstract": "This paper proposes a novel approach for crowd counting in low to high density scenarios in static images. Current approaches cannot handle huge crowd diversity well and thus perform poorly in extreme cases, where the crowd density in different regions of an image is either too low or too high, leading to crowd underestimation or overestimation. The proposed solution is based on the observation that detecting and handling such extreme cases in a specialized way leads to better crowd estimation. Additionally, existing methods find it hard to differentiate between the actual crowd and the cluttered background regions, resulting in further count overestimation. To address these issues, we propose a simple yet effective modular approach, where an input image is first subdivided into fixed-size patches and then fed to a four-way classification module labeling each image patch as low, medium, high-dense or no-crowd. This module also provides a count for each label, which is then analyzed via a specifically devised novel decision module to decide whether the image belongs to any of the two extreme cases (very low or very high density) or a normal case. Images, specified as high- or low-density extreme or a normal case, pass through dedicated zooming or normal patch-making blocks respectively before routing to the regressor in the form of fixed-size patches for crowd estimate. Extensive experimental evaluations demonstrate that the proposed approach outperforms the state-of-the-art methods on four benchmarks under most of the evaluation criteria.", "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "authors": ["Usman  Sajid", "Hasan  Sajid", "Hongcheng  Wang", "Guanghui  Wang"], "year": 2020, "n_citations": 17}
{"id": 2959102, "s2_id": "39e4dfa4ec7e2bee44a9c5b940e640eb39c3442f", "title": "An Intersectional Definition of Fairness", "abstract": "We propose differential fairness, a multi-attribute definition of fairness in machine learning which is informed by intersectionality, a critical lens arising from the humanities literature, leveraging connections between differential privacy and legal notions of fairness. We show that our criterion behaves sensibly for any subset of the set of protected attributes, and we prove economic, privacy, and generalization guarantees. We provide a learning algorithm which respects our differential fairness criterion. Experiments on the COMPAS criminal recidivism dataset and census data demonstrate the utility of our methods.", "venue": "2020 IEEE 36th International Conference on Data Engineering (ICDE)", "authors": ["James R. Foulds", "Shimei  Pan"], "year": 2020, "n_citations": 48}
{"id": 2969600, "s2_id": "6341ae08b074d1b39eb689e82db29e8abf39b1fa", "title": "A Low Rank Promoting Prior for Unsupervised Contrastive Learning", "abstract": "Unsupervised learning is just at a tipping point where it could really take off. Among these approaches, contrastive learning has seen tremendous progress and led to state-of-the-art performance. In this paper, we construct a novel probabilistic graphical model that effectively incorporates the low rank promoting prior into the framework of contrastive learning, referred to as LORAC. In contrast to the existing conventional self-supervised approaches that only considers independent learning, our hypothesis explicitly requires that all the samples belonging to the same instance class lie on the same subspace with small dimension. This heuristic poses particular joint learning constraints to reduce the degree of freedom of the problem during the search of the optimal network parameterization. Most importantly, we argue that the low rank prior employed here is not unique, and many different priors can be invoked in a similar probabilistic way, corresponding to different hypotheses about underlying truth behind the contrastive features. Empirical evidences show that the proposed algorithm clearly surpasses the state-of-the-art approaches on multiple benchmarks, including image classification, object detection, instance segmentation and keypoint detection.", "venue": "ArXiv", "authors": ["Yu  Wang", "Jingyang  Lin", "Qi  Cai", "Yingwei  Pan", "Ting  Yao", "Hongyang  Chao", "Tao  Mei"], "year": 2021, "n_citations": 3}
{"id": 2974369, "s2_id": "9014ede9e3503530d1dc0e9680e44d1576d7a71c", "title": "Fast Regression of the Tritium Breeding Ratio in Fusion Reactors", "abstract": "The tritium breeding ratio (TBR) is an essential quantity for the design of modern and next-generation D-T fueled nuclear fusion reactors. Representing the ratio between tritium fuel generated in breeding blankets and fuel consumed during reactor runtime, the TBR depends on reactor geometry and material properties in a complex manner. In this work, we explored the training of surrogate models to produce a cheap but high-quality approximation for a Monte Carlo TBR model in use at the UK Atomic Energy Authority. We investigated possibilities for dimensional reduction of its feature space, reviewed 9 families of surrogate models for potential applicability, and performed hyperparameter optimisation. Here we present the performance and scaling properties of these models, the fastest of which, an artificial neural network, demonstrated R =0.985 and a mean prediction time of 0.898\u03bcs, representing a relative speedup of 8 \u00b7 10 with respect to the expensive MC model. We further present a novel adaptive sampling algorithm, Quality-Adaptive Surrogate Sampling, capable of interfacing with any of the individually studied surrogates. Our preliminary testing on a toy TBR theory has demonstrated the efficacy of this algorithm for accelerating the surrogate modelling process.", "venue": "ArXiv", "authors": ["Petr  M\u00e1nek", "Graham Van Goffrier", "Vignesh  Gopakumar", "Nikolaos  Nikolaou", "Jonathan  Shimwell", "Ingo P. Waldmann"], "year": 2021, "n_citations": 0}
{"id": 2977427, "s2_id": "941b0be328d6eb370121828acff3acf300e0745a", "title": "Coherence Pursuit: Fast, Simple, and Robust Principal Component Analysis", "abstract": "This paper presents a remarkably simple, yet powerful, algorithm termed coherence pursuit (CoP) to robust principal component analysis (PCA). As inliers lie in a low-dimensional subspace and are mostly correlated, an inlier is likely to have strong mutual coherence with a large number of data points. By contrast, outliers either do not admit low-dimensional structures or form small clusters. In either case, an outlier is unlikely to bear strong resemblance to a large number of data points. Given that, CoP sets an outlier apart from an inlier by comparing their coherence with the rest of the data points. The mutual coherences are computed by forming the Gram matrix of the normalized data points. Subsequently, the sought subspace is recovered from the span of the subset of the data points that exhibit strong coherence with the rest of the data. As CoP only involves one simple matrix multiplication, it is significantly faster than the state-of-the-art robust PCA algorithms. We derive analytical performance guarantees for CoP under different models for the distributions of inliers and outliers in both noise-free and noisy settings. CoP is the first robust PCA algorithm that is simultaneously non-iterative, provably robust to both unstructured and structured outliers, and can tolerate a large number of unstructured outliers.", "venue": "IEEE Transactions on Signal Processing", "authors": ["Mostafa  Rahmani", "George  Atia"], "year": 2017, "n_citations": 104}
{"id": 2979110, "s2_id": "32932f6dfef6204d5dbf9759d4e62fdb8554ebaa", "title": "Hyperplane Clustering via Dual Principal Component Pursuit", "abstract": "We extend the theoretical analysis of a recently proposed single subspace learning algorithm, called Dual Principal Component Pursuit (DPCP), to the case where the data are drawn from of a union of hyperplanes. To gain insight into the properties of the $\\ell_1$ non-convex problem associated with DPCP, we develop a geometric analysis of a closely related continuous optimization problem. Then transferring this analysis to the discrete problem, our results state that as long as the hyperplanes are sufficiently separated, the dominant hyperplane is sufficiently dominant and the points are uniformly distributed inside the associated hyperplanes, then the non-convex DPCP problem has a unique global solution, equal to the normal vector of the dominant hyperplane. This suggests the correctness of a sequential hyperplane learning algorithm based on DPCP. A thorough experimental evaluation reveals that hyperplane learning schemes based on DPCP dramatically improve over the state-of-the-art methods for the case of synthetic data, while are competitive to the state-of-the-art in the case of 3D plane clustering for Kinect data.", "venue": "ICML", "authors": ["Manolis C. Tsakiris", "Ren\u00e9  Vidal"], "year": 2017, "n_citations": 25}
{"id": 2994422, "s2_id": "38759a3ab3b6d18ecc2c9ab7991db8b1e81ef501", "title": "Optimistic Policy Iteration for MDPs with Acyclic Transient State Structure", "abstract": "We consider Markov Decision Processes (MDPs) in which every stationary policy induces the same graph structure for the underlying Markov chain and further, the graph has the following property: if we replace each recurrent class by a node, then the resulting graph is acyclic. For such MDPs, we prove the convergence of the stochastic dynamics associated with a version of optimistic policy iteration (OPI), suggested in [1], in which the values associated with all the nodes visited during each iteration of the OPI are updated.", "venue": "ArXiv", "authors": ["Joseph  Lubars", "Anna  Winnicki", "Michael  Livesay", "R.  Srikant"], "year": 2021, "n_citations": 0}
{"id": 2995239, "s2_id": "9299a19eaf9ee81172c7ace8eba43bbcd62fc641", "title": "Bayesian System ID: Optimal management of parameter, model, and measurement uncertainty", "abstract": "We evaluate the robustness of a probabilistic formulation of system identification (ID) to sparse, noisy, and indirect data. Specifically, we compare estimators of future system behavior derived from the Bayesian posterior of a learning problem to several commonly used least squares-based optimization objectives used in system ID. Our comparisons indicate that the log posterior has improved geometric properties compared with the objective function surfaces of traditional methods that include differentially constrained least squares and least squares reconstructions of discrete time steppers like dynamic mode decomposition (DMD). These properties allow it to be both more sensitive to new data and less affected by multiple minima --- overall yielding a more robust approach. Our theoretical results indicate that least squares and regularized least squares methods like dynamic mode decomposition and sparse identification of nonlinear dynamics (SINDy) can be derived from the probabilistic formulation by assuming noiseless measurements. We also analyze the computational complexity of a Gaussian filter-based approximate marginal Markov Chain Monte Carlo scheme that we use to obtain the Bayesian posterior for both linear and nonlinear problems. We then empirically demonstrate that obtaining the marginal posterior of the parameter dynamics and making predictions by extracting optimal estimators (e.g., mean, median, mode) yields orders of magnitude improvement over the aforementioned approaches. We attribute this performance to the fact that the Bayesian approach captures parameter, model, and measurement uncertainties, whereas the other methods typically neglect at least one type of uncertainty.", "venue": "ArXiv", "authors": ["Nicholas  Galioto", "Alex  Gorodetsky"], "year": 2020, "n_citations": 8}
{"id": 3002676, "s2_id": "9561a510d04d4c19a46d232eb293de4054387c82", "title": "Anomaly Detection Under Controlled Sensing Using Actor-Critic Reinforcement Learning", "abstract": "We consider the problem of detecting anomalies among a given set of processes using their noisy binary sensor measurements. The noiseless sensor measurement corresponding to a normal process is 0, and the measurement is 1 if the process is anomalous. The decision-making algorithm is assumed to have no knowledge of the number of anomalous processes. The algorithm is allowed to choose a subset of the sensors at each time instant until the confidence level on the decision exceeds the desired value. Our objective is to design a sequential sensor selection policy that dynamically determines which processes to observe at each time and when to terminate the detection algorithm. The selection policy is designed such that the anomalous processes are detected with the desired confidence level while incurring minimum cost which comprises the delay in detection and the cost of sensing. We cast this problem as a sequential hypothesis testing problem within the framework of Markov decision processes, and solve it using the actor-critic deep reinforcement learning algorithm. This deep neural network-based algorithm offers a low complexity solution with good detection accuracy. We also study the effect of statistical dependence between the processes on the algorithm performance. Through numerical experiments, we show that our algorithm is able to adapt to any unknown statistical dependence pattern of the processes.", "venue": "2020 IEEE 21st International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)", "authors": ["Geethu  Joseph", "M. Cenk Gursoy", "Pramod K. Varshney"], "year": 2020, "n_citations": 3}
{"id": 3014396, "s2_id": "8e44fc1e4ee0ff81040b9beafb6ce5a4ce049c50", "title": "Trajectory Prediction with Latent Belief Energy-Based Model", "abstract": "Human trajectory prediction is critical for autonomous platforms like self-driving cars or social robots. We present a latent belief energy-based model (LB-EBM) for diverse human trajectory forecast. LB-EBM is a probabilistic model with cost function defined in the latent space to account for the movement history and social context. The low-dimensionality of the latent space and the high expressivity of the EBM make it easy for the model to capture the multi-modality of pedestrian trajectory distributions. LB-EBM is learned from expert demonstrations (i.e., human trajectories) projected into the latent space. Sampling from or optimizing the learned LB-EBM yields a belief vector which is used to make a path plan, which then in turn helps to predict a long-range trajectory. The effectiveness of LB-EBM and the two-step approach are supported by strong empirical results. Our model is able to make accurate, multi-modal, and social compliant trajectory predictions and improves over prior state-of-the-arts performance on the Stanford Drone trajectory prediction benchmark by 10.9% and on the ETH-UCY benchmark by 27.6%.", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Bo  Pang", "Tianyang  Zhao", "Xu  Xie", "Ying Nian Wu"], "year": 2021, "n_citations": 7}
{"id": 3017458, "s2_id": "226bf05765f706bc71f604679295d4df0970b0a7", "title": "Reinforced Imitation in Heterogeneous Action Space", "abstract": "Imitation learning is an effective alternative approach to learn a policy when the reward function is sparse. In this paper, we consider a challenging setting where an agent and an expert use different actions from each other. We assume that the agent has access to a sparse reward function and state-only expert observations. We propose a method which gradually balances between the imitation learning cost and the reinforcement learning objective. In addition, this method adapts the agent's policy based on either mimicking expert behavior or maximizing sparse reward. We show, through navigation scenarios, that (i) an agent is able to efficiently leverage sparse rewards to outperform standard state-only imitation learning, (ii) it can learn a policy even when its actions are different from the expert, and (iii) the performance of the agent is not bounded by that of the expert, due to the optimized usage of sparse rewards.", "venue": "ArXiv", "authors": ["Konrad  Zolna", "Negar  Rostamzadeh", "Yoshua  Bengio", "Sungjin  Ahn", "Pedro O. Pinheiro"], "year": 2019, "n_citations": 7}
{"id": 3017622, "s2_id": "d04d18b394288aee4c31f91a65365688863d5e0f", "title": "Efficient K-Shot Learning with Regularized Deep Networks", "abstract": "Feature representations from pre-trained deep neural networks have been known to exhibit excellent generalization and utility across a variety of related tasks. Fine-tuning is by far the simplest and most widely used approach that seeks to exploit and adapt these feature representations to novel tasks with limited data. Despite the effectiveness of fine-tuning, itis often sub-optimal and requires very careful optimization to prevent severe over-fitting to small datasets. The problem of sub-optimality and over-fitting, is due in part to the large number of parameters used in a typical deep convolutional neural network. To address these problems, we propose a simple yet effective regularization method for fine-tuning pre-trained deep networks for the task of k-shot learning. To prevent overfitting, our key strategy is to cluster the model parameters while ensuring intra-cluster similarity and inter-cluster diversity of the parameters, effectively regularizing the dimensionality of the parameter search space. In particular, we identify groups of neurons within each layer of a deep network that shares similar activation patterns. When the network is to be fine-tuned for a classification task using only k examples, we propagate a single gradient to all of the neuron parameters that belong to the same group. The grouping of neurons is non-trivial as neuron activations depend on the distribution of the input data. To efficiently search for optimal groupings conditioned on the input data, we propose a reinforcement learning search strategy using recurrent networks to learn the optimal group assignments for each network layer. Experimental results show that our method can be easily applied to several popular convolutional neural networks and improve upon other state-of-the-art fine-tuning based k-shot learning strategies by more than10%", "venue": "AAAI", "authors": ["Donghyun  Yoo", "Haoqi  Fan", "Vishnu Naresh Boddeti", "Kris M. Kitani"], "year": 2018, "n_citations": 15}
{"id": 3021905, "s2_id": "f678ca5a6bab62f78c26ab9e7f85876c68952173", "title": "Leveraging Motion Priors in Videos for Improving Human Segmentation", "abstract": "Despite many advances in deep-learning based semantic segmentation, performance drop due to distribution mismatch is often encountered in the real world. Recently, a few domain adaptation and active learning approaches have been proposed to mitigate the performance drop. However, very little attention has been made toward leveraging information in videos which are naturally captured in most camera systems. In this work, we propose to leverage \u201cmotion prior\u201d in videos for improving human segmentation in a weakly-supervised active learning setting. By extracting motion information using optical flow in videos, we can extract candidate foreground motion segments (referred to as motion prior) potentially corresponding to human segments. We propose to learn a memory-network-based policy model to select strong candidate segments (referred to as strong motion prior) through reinforcement learning. The selected segments have high precision and are directly used to finetune the model. In a newly collected surveillance camera dataset and a publicly available UrbanStreet dataset, our proposed method improves the performance of human segmentation across multiple scenes and modalities (i.e., RGB to Infrared (IR)). Last but not least, our method is empirically complementary to existing domain adaptation approaches such that additional performance gain is achieved by combining our weakly-supervised active learning approach with domain adaptation approaches.", "venue": "ECCV", "authors": ["Yu-Ting  Chen", "Wen-Yen  Chang", "Hai-Lun  Lu", "Tingfan  Wu", "Min  Sun"], "year": 2018, "n_citations": 2}
{"id": 3022500, "s2_id": "1472c5bb999c663a2ff81aebe071edd18adfc489", "title": "Detecting Covid-19 and Community Acquired Pneumonia Using Chest CT Scan Images With Deep Learning", "abstract": "We propose a two-stage Convolutional Neural Network (CNN) based classification framework for detecting COVID-19 and Community Acquired Pneumonia (CAP) using the chest Computed Tomography (CT) scan images. In the first stage, an infection - COVID-19 or CAP, is detected using a pre-trained DenseNet architecture. Then, in the second stage, a fine-grained three-way classification is done using EfficientNet architecture. The proposed COVID+CAP-CNN framework achieved a slice-level classification accuracy of over 94% at identifying COVID-19 and CAP. Further, the proposed framework has the potential to be an initial screening tool for differential diagnosis of COVID-19 and CAP, achieving a validation accuracy of over 89.3% at the finer three-way COVID-19, CAP, and healthy classification. Within the IEEE ICASSP 2021 Signal Processing Grand Challenge (SPGC) on COVID-19 Diagnosis, our proposed two-stage classification framework achieved an overall accuracy of 90% and sensitivity of .857, .9, and .942 at distinguishing COVID-19, CAP, and normal individuals respectively, to rank first in the evaluation. Code and model weights are available at https://github.com/shubhamchaudhary2015/ct_covid19_cap_cnn", "venue": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Shubham  Chaudhary", "Sadbhawna", "Vinit  Jakhetiya", "Badri N Subudhi", "Ujjwal  Baid", "Sharath Chandra Guntuku"], "year": 2021, "n_citations": 4}
{"id": 3037175, "s2_id": "da6d485feec1d66f295e20cc5ccf380a14ef493a", "title": "Deep Metric Learning using Similarities from Nonlinear Rank Approximations", "abstract": "In recent years, deep metric learning has achieved promising results in learning high dimensional semantic feature embeddings where the spatial relationships of the feature vectors match the visual similarities of the images. Similarity search for images is performed by determining the vectors with the smallest distances to a query vector. However, high retrieval quality does not depend on the actual distances of the feature vectors, but rather on the ranking order of the feature vectors from similar images. In this paper, we introduce a metric learning algorithm that focuses on identifying and modifying those feature vectors that most strongly affect the retrieval quality. We compute normalized approximated ranks and convert them to similarities by applying a nonlinear transfer function. These similarities are used in a newly proposed loss function that better contracts similar and disperses dissimilar samples. Experiments demonstrate significant improvement over existing deep feature embedding methods on the CUB-200-2011, Cars196, and Stanford Online Products data sets for all embedding sizes.", "venue": "2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)", "authors": ["Konstantin  Schall", "Kai Uwe Barthel", "Nico  Hezel", "Klaus  Jung"], "year": 2019, "n_citations": 3}
{"id": 3038709, "s2_id": "f073d1409d59053e9a415c861de80475a8e2a06e", "title": "Recurrent Feedback Improves Recognition of Partially Occluded Objects", "abstract": "Recurrent connectivity in the visual cortex is believed to aid object recognition for challenging conditions such as occlusion. Here we investigate if and how artificial neural networks also benefit from recurrence. We compare architectures composed of bottom-up, lateral and top-down connections and evaluate their performance using two novel stereoscopic occluded object datasets. We find that classification accuracy is significantly higher for recurrent models when compared to feedforward models of matched parametric complexity. Additionally we show that for challenging stimuli, the recurrent feedback is able to correctly revise the initial feedforward guess.", "venue": "ESANN", "authors": ["Markus Roland Ernst", "Jochen  Triesch", "Thomas  Burwick"], "year": 2020, "n_citations": 1}
{"id": 3047545, "s2_id": "cc8ab0d737d8fb1ee904e9085b64261ebd5e9438", "title": "Adaptive Test-Time Augmentation for Low-Power CPU", "abstract": "Convolutional Neural Networks (ConvNets) are trained offline using the few available data and may therefore suffer from substantial accuracy loss when ported on the field, where unseen input patterns received under unpredictable external conditions can mislead the model. Test-Time Augmentation (TTA) techniques aim to alleviate such common side effect at inference-time, first running multiple feed-forward passes on a set of altered versions of the same input sample, and then computing the main outcome through a consensus of the aggregated predictions. Unfortunately, the implementation of TTA on embedded CPUs introduces latency penalties that limit its adoption on edge applications. To tackle this issue, we propose AdapTTA, an adaptive implementation of TTA that controls the number of feed-forward passes dynamically, depending on the complexity of the input. Experimental results on state-of-the-art ConvNets for image classification deployed on a commercial ARM CortexA CPU demonstrate AdapTTA reaches remarkable latency savings, from 1.49\u00d7 to 2.21\u00d7, and hence a higher frame rate compared to static TTA, still preserving the same accuracy gain.", "venue": "ArXiv", "authors": ["Luca  Mocerino", "Roberto G. Rizzo", "Valentino  Peluso", "Andrea  Calimera", "Enrico  Macii"], "year": 2021, "n_citations": 1}
{"id": 3069207, "s2_id": "23f2a20acac59fac220919047cfc09f3853ce713", "title": "CEAI: CCM based Email Authorship Identification Model", "abstract": "Abstract In this paper we present a model for email authorship identification (EAI) by employing a Cluster-based Classification (CCM) technique. Traditionally, stylometric features have been successfully employed in various authorship analysis tasks; we extend the traditional feature set to include some more interesting and effective features for email authorship identification (e.g., the last punctuation mark used in an email, the tendency of an author to use capitalization at the start of an email, or the punctuation after a greeting or farewell). We also included Info Gain feature selection based content features. It is observed that the use of such features in the authorship identification process has a positive impact on the accuracy of the authorship identification task. We performed experiments to justify our arguments and compared the results with other base line models. Experimental results reveal that the proposed CCM-based email authorship identification model, along with the proposed feature set, outperforms the state-of-the-art support vector machine (SVM)-based models, as well as the models proposed by Iqbal et al. (2010, 2013) [1,2] . The proposed model attains an accuracy rate of 94% for 10 authors, 89% for 25 authors, and 81% for 50 authors, respectively on Enron dataset, while 89.5% accuracy has been achieved on authors\u2019 constructed real email dataset. The results on Enron dataset have been achieved on quite a large number of authors as compared to the models proposed by Iqbal et al. [1,2] .", "venue": "ArXiv", "authors": ["Sarwat  Nizamani", "Nasrullah  Memon"], "year": 2013, "n_citations": 20}
{"id": 3069794, "s2_id": "cf6cde1e1778ca6254876a03ce12c061f36cbf87", "title": "The Atari Data Scraper", "abstract": "Reinforcement learning has made great strides in recent years due to the success of methods using deep neural networks. However, such neural networks act as a black box, obscuring the inner workings. While reinforcement learning has the potential to solve unique problems, a lack of trust and understanding of reinforcement learning algorithms could prevent their widespread adoption. Here, we present a library that attaches a \u201cdata scraper\u201d to deep reinforcement learning agents, acting as an observer, and then show how the data collected by the Atari Data Scraper can be used to understand and interpret deep reinforcement learning agents. The code for the Atari Data Scraper can be found here: https: // github. com/ IRLL/ Atari-Data-Scraper .", "venue": "ArXiv", "authors": ["Brittany Davis Pierson", "Justine  Ventura", "Matthew E. Taylor"], "year": 2021, "n_citations": 0}
{"id": 3073750, "s2_id": "ba1fdd717d81b27540cea713ad28ccdc02f96464", "title": "Robust Optimal Transport with Applications in Generative Modeling and Domain Adaptation", "abstract": "Optimal Transport (OT) distances such as Wasserstein have been used in several areas such as GANs and domain adaptation. OT, however, is very sensitive to outliers (samples with large noise) in the data since in its objective function, every sample, including outliers, is weighed similarly due to the marginal constraints. To remedy this issue, robust formulations of OT with unbalanced marginal constraints have previously been proposed. However, employing these methods in deep learning problems such as GANs and domain adaptation is challenging due to the instability of their dual optimization solvers. In this paper, we resolve these issues by deriving a computationally-efficient dual form of the robust OT optimization that is amenable to modern deep learning applications. We demonstrate the effectiveness of our formulation in two applications of GANs and domain adaptation. Our approach can train state-of-the-art GAN models on noisy datasets corrupted with outlier distributions. In particular, our optimization computes weights for training samples reflecting how difficult it is for those samples to be generated in the model. In domain adaptation, our robust OT formulation leads to improved accuracy compared to the standard adversarial adaptation methods. Our code is available at this https URL.", "venue": "NeurIPS", "authors": ["Yogesh  Balaji", "Rama  Chellappa", "Soheil  Feizi"], "year": 2020, "n_citations": 16}
{"id": 3081452, "s2_id": "d09318f21b6885e2b98b299f9c8c96fe53987ee8", "title": "A variational Bayesian spatial interaction model for estimating revenue and demand at business facilities", "abstract": "We study the problem of estimating potential revenue or demand at business facilities and understanding its generating mechanism. This problem arises in different fields such as operation research or urban science, and more generally, it is crucial for businesses\u2019 planning and decision making. We develop a Bayesian spatial interaction model, henceforth BSIM, which provides probabilistic predictions about revenues generated by a particular business location provided their features and the potential customers\u2019 characteristics in a given region. BSIM explicitly accounts for the competition among the competitive facilities through a probability value determined by evaluating a store-specific Gaussian distribution at a given customer location. We propose a scalable variational inference framework that, while being significantly faster than competing Markov Chain Monte Carlo inference schemes, exhibits comparable performances in terms of parameters identification and uncertainty quantification. We demonstrate the benefits of BSIM in various synthetic settings characterised by an increasing number of stores and customers. Finally, we construct a real-world, large spatial dataset for pub activities in London, UK, which includes over 1,500 pubs and 150,000 customer regions. We demonstrate how BSIM outperforms competing approaches on this large dataset in terms of prediction performances while providing results that are both interpretable and consistent with related indicators observed for the London region.", "venue": "ArXiv", "authors": ["Shanaka  Perera", "Virginia  Aglietti", "Theodoros  Damoulas"], "year": 2021, "n_citations": 0}
{"id": 3082048, "s2_id": "cf01479aba42690bac854530cf21f1c56996c97f", "title": "Near optimal sample complexity for matrix and tensor normal models via geodesic convexity", "abstract": "The matrix normal model, the family of Gaussian matrix-variate distributions whose covariance matrix is the Kronecker product of two lower dimensional factors, is frequently used to model matrix-variate data. The tensor normal model generalizes this family to Kronecker products of three or more factors. We study the estimation of the Kronecker factors of the covariance matrix in the matrix and tensor models. We show nonasymptotic bounds for the error achieved by the maximum likelihood estimator (MLE) in several natural metrics. In contrast to existing bounds, our results do not rely on the factors being well-conditioned or sparse. For the matrix normal model, all our bounds are minimax optimal up to logarithmic factors, and for the tensor normal model our bound for the largest factor and overall covariance matrix are minimax optimal up to constant factors provided there are enough samples for any estimator to obtain constant Frobenius error. In the same regimes as our sample complexity bounds, we show that an iterative procedure to compute the MLE known as the flip-flop algorithm converges linearly with high probability. Our main tool is geodesic strong convexity in the geometry on positive-definite matrices induced by the Fisher information metric. This strong convexity is determined by the expansion of certain random quantum channels. We also provide numerical evidence that combining the flip-flop algorithm with a simple shrinkage estimator can improve performance in the undersampled regime.", "venue": "ArXiv", "authors": ["Cole  Franks", "Rafael  Oliveira", "Akshay  Ramachandran", "Michael  Walter"], "year": 2021, "n_citations": 0}
{"id": 3083173, "s2_id": "f33c7fe75f093bdf0f322b8732b15d7ac9d9d730", "title": "Sequential Principal Curves Analysis", "abstract": "This work includes all the technical details of the Sequential Principal Curves Analysis (SPCA) in a single document. SPCA is an unsupervised nonlinear and invertible feature extraction technique. The identified curvilinear features can be interpreted as a set of nonlinear sensors: the response of each sensor is the projection onto the corresponding feature. Moreover, it can be easily tuned for different optimization criteria; e.g. infomax, error minimization, decorrelation; by choosing the right way to measure distances along each curvilinear feature. Even though proposed in [Laparra et al. Neural Comp. 12] and shown to work in multiple modalities in [Laparra and Malo Frontiers Hum. Neuro. 15], the SPCA framework has its original roots in the nonlinear ICA algorithm in [Malo and Gutierrez Network 06]. Later on, the SPCA philosophy for nonlinear generalization of PCA originated substantially faster alternatives at the cost of introducing different constraints in the model. Namely, the Principal Polynomial Analysis (PPA) [Laparra et al. IJNS 14], and the Dimensionality Reduction via Regression (DRR) [Laparra et al. IEEE TGRS 15]. This report illustrates the reasons why we developed such family and is the appropriate technical companion for the missing details in [Laparra et al., NeCo 12, Laparra and Malo, Front.Hum.Neuro. 15]. See also the data, code and examples in the dedicated sites this http URL and this http URL effects.html", "venue": "ArXiv", "authors": ["Valero  Laparra", "Jes\u00fas  Malo"], "year": 2016, "n_citations": 2}
{"id": 3098033, "s2_id": "32cbb3ccfd308fdc0340864356befd4f45aed7a2", "title": "Deep Bayesian Multi-Target Learning for Recommender Systems", "abstract": "With the increasing variety of services that e-commerce platforms provide, criteria for evaluating their success become also increasingly multi-targeting. This work introduces a multi-target optimization framework with Bayesian modeling of the target events, called Deep Bayesian Multi-Target Learning (DBMTL). In this framework, target events are modeled as forming a Bayesian network, in which directed links are parameterized by hidden layers, and learned from training samples. The structure of Bayesian network is determined by model selection. We applied the framework to Taobao live-streaming recommendation, to simultaneously optimize (and strike a balance) on targets including click-through rate, user stay time in live room, purchasing behaviors and interactions. Significant improvement has been observed for the proposed method over other MTL frameworks and the non-MTL model. Our practice shows that with an integrated causality structure, we can effectively make the learning of a target benefit from other targets, creating significant synergy effects that improve all targets. The neural network construction guided by DBMTL fits in with the general probabilistic model connecting features and multiple targets, taking weaker assumption than the other methods discussed in this paper. This theoretical generality brings about practical generalization power over various targets distributions, including sparse targets and continuous-value ones.", "venue": "ArXiv", "authors": ["Qi  Wang", "Zhihui  Ji", "Huasheng  Liu", "Binqiang  Zhao"], "year": 2019, "n_citations": 3}
{"id": 3104736, "s2_id": "0fa13a5ef36168ff3fd08b03fd30f1f935d6a18a", "title": "Methods for Pruning Deep Neural Networks", "abstract": "This paper presents a survey of methods for pruning deep neural networks, from algorithms first proposed for fully connected networks in the 1990s to the recent methods developed for reducing the size of convolutional neural networks. The paper begins by bringing together many different algorithms by categorising them based on the underlying approach used. It then focuses on three categories: methods that use magnitude-based pruning, methods that utilise clustering to identify redundancy, and methods that utilise sensitivity analysis. Some of the key influencing studies within these categories are presented to illuminate the underlying approaches and results achieved. \nMost studies on pruning present results from empirical evaluations, which are distributed in the literature as new architectures, algorithms and data sets have evolved with time. This paper brings together the reported results from some key papers in one place by providing a resource that can be used to quickly compare reported results, and trace studies where specific methods, data sets and architectures have been used.", "venue": "ArXiv", "authors": ["Sunil  Vadera", "Salem  Ameen"], "year": 2020, "n_citations": 1}
{"id": 3104746, "s2_id": "78602bed080785c9de79bedccc56f33a437f0808", "title": "dagger: A Python Framework for Reproducible Machine Learning Experiment Orchestration", "abstract": "Many research directions in machine learning, particularly in deep learning, involve complex, multi-stage experiments, commonly involving state-mutating operations acting on models along multiple paths of execution. Although machine learning frameworks provide clean interfaces for defining model architectures and unbranched flows, burden is often placed on the researcher to track experimental provenance, that is, the state tree that leads to a final model configuration and result in a multi-stage experiment. Originally motivated by analysis reproducibility in the context of neural network pruning research, where multi-stage experiment pipelines are common, we present dagger, a framework to facilitate reproducible and reusable experiment orchestration. We describe the design principles of the framework and example usage.", "venue": "ArXiv", "authors": ["Michela  Paganini", "Jessica Zosa Forde"], "year": 2020, "n_citations": 2}
{"id": 3107402, "s2_id": "92d621a603cda8c32214d70953e180fe5a442f3e", "title": "N2N Learning: Network to Network Compression via Policy Gradient Reinforcement Learning", "abstract": "While bigger and deeper neural network architectures continue to advance the state-of-the-art for many computer vision tasks, real-world adoption of these networks is impeded by hardware and speed constraints. Conventional model compression methods attempt to address this problem by modifying the architecture manually or using pre-defined heuristics. Since the space of all reduced architectures is very large, modifying the architecture of a deep neural network in this way is a difficult task. In this paper, we tackle this issue by introducing a principled method for learning reduced network architectures in a data-driven way using reinforcement learning. Our approach takes a larger `teacher' network as input and outputs a compressed `student' network derived from the `teacher' network. In the first stage of our method, a recurrent policy network aggressively removes layers from the large `teacher' model. In the second stage, another recurrent policy network carefully reduces the size of each remaining layer. The resulting network is then evaluated to obtain a reward -- a score based on the accuracy and compression of the network. Our approach uses this reward signal with policy gradients to train the policies to find a locally optimal student network. Our experiments show that we can achieve compression rates of more than 10x for models such as ResNet-34 while maintaining similar performance to the input `teacher' network. We also present a valuable transfer learning result which shows that policies which are pre-trained on smaller `teacher' networks can be used to rapidly speed up training on larger `teacher' networks.", "venue": "ICLR", "authors": ["Anubhav  Ashok", "Nicholas  Rhinehart", "Fares  Beainy", "Kris M. Kitani"], "year": 2018, "n_citations": 110}
{"id": 3109070, "s2_id": "edbcaf80ad4218fe04e474036484b5543c6f8f49", "title": "Belief Propagation Neural Networks", "abstract": "Learned neural solvers have successfully been used to solve combinatorial optimization and decision problems. More general counting variants of these problems, however, are still largely solved with hand-crafted solvers. To bridge this gap, we introduce belief propagation neural networks (BPNNs), a class of parameterized operators that operate on factor graphs and generalize Belief Propagation (BP). In its strictest form, a BPNN layer (BPNN-D) is a learned iterative operator that provably maintains many of the desirable properties of BP for any choice of the parameters. Empirically, we show that by training BPNN-D learns to perform the task better than the original BP: it converges 1.7x faster on Ising models while providing tighter bounds. On challenging model counting problems, BPNNs compute estimates 100's of times faster than state-of-the-art handcrafted methods, while returning an estimate of comparable quality.", "venue": "NeurIPS", "authors": ["Jonathan  Kuck", "Shuvam  Chakraborty", "Hao  Tang", "Rachel  Luo", "Jiaming  Song", "Ashish  Sabharwal", "Stefano  Ermon"], "year": 2020, "n_citations": 9}
{"id": 3110701, "s2_id": "58215cc1043c036a3386cfa6bc37e974152146c0", "title": "Cross-Entropy Loss and Low-Rank Features Have Responsibility for Adversarial Examples", "abstract": "State-of-the-art neural networks are vulnerable to adversarial examples; they can easily misclassify inputs that are imperceptibly different than their training and test data. In this work, we establish that the use of cross-entropy loss function and the low-rank features of the training data have responsibility for the existence of these inputs. Based on this observation, we suggest that addressing adversarial examples requires rethinking the use of cross-entropy loss function and looking for an alternative that is more suited for minimization with low-rank features. In this direction, we present a training scheme called differential training, which uses a loss function defined on the differences between the features of points from opposite classes. We show that differential training can ensure a large margin between the decision boundary of the neural network and the points in the training dataset. This larger margin increases the amount of perturbation needed to flip the prediction of the classifier and makes it harder to find an adversarial example with small perturbations. We test differential training on a binary classification task with CIFAR-10 dataset and demonstrate that it radically reduces the ratio of images for which an adversarial example could be found -- not only in the training dataset, but in the test dataset as well.", "venue": "ArXiv", "authors": ["Kamil  Nar", "Orhan  Ocal", "S. Shankar Sastry", "Kannan  Ramchandran"], "year": 2019, "n_citations": 26}
{"id": 3120632, "s2_id": "02d8779c388ad2b6b22f471d49944b1dbca5737a", "title": "Re-designing cities with conditional adversarial networks", "abstract": "This paper introduces a conditional generative adversarial network to redesign a street-level image of urban scenes by generating 1) an urban intervention policy, 2) an attention map that localises where intervention is needed, 3) a high-resolution street-level image (1024 X 1024 or 1536 X1536) after implementing the intervention. We also introduce a new dataset that comprises aligned street-level images of before and after urban interventions from real-life scenarios that make this research possible. The introduced method has been trained on different ranges of urban interventions applied to realistic images. The trained model shows strong performance in re-modelling cities, outperforming existing methods that apply image-to-image translation in other domains that is computed in a single GPU. This research opens the door for machine intelligence to play a role in re-thinking and re-designing the different attributes of cities based on adversarial learning, going beyond the mainstream of facial landmarks manipulation or image synthesis from semantic segmentation.", "venue": "ArXiv", "authors": ["Mohamed R. Ibrahim", "James  Haworth", "Nicola  Christie"], "year": 2021, "n_citations": 1}
{"id": 3130970, "s2_id": "38643c2926b10f6f74f122a7037e2cd20d77c0f1", "title": "Supervised Contrastive Learning", "abstract": "Cross entropy is the most widely used loss function for supervised training of image classification models. In this paper, we propose a novel training methodology that consistently outperforms cross entropy on supervised learning tasks across different architectures and data augmentations. We modify the batch contrastive loss, which has recently been shown to be very effective at learning powerful representations in the self-supervised setting. We are thus able to leverage label information more effectively than cross entropy. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. In addition to this, we leverage key ingredients such as large batch sizes and normalized embeddings, which have been shown to benefit self-supervised learning. On both ResNet-50 and ResNet-200, we outperform cross entropy by over 1%, setting a new state of the art number of 78.8% among methods that use AutoAugment data augmentation. The loss also shows clear benefits for robustness to natural corruptions on standard benchmarks on both calibration and accuracy. Compared to cross entropy, our supervised contrastive loss is more stable to hyperparameter settings such as optimizers or data augmentations.", "venue": "NeurIPS", "authors": ["Prannay  Khosla", "Piotr  Teterwak", "Chen  Wang", "Aaron  Sarna", "Yonglong  Tian", "Phillip  Isola", "Aaron  Maschinot", "Ce  Liu", "Dilip  Krishnan"], "year": 2020, "n_citations": 475}
{"id": 3141394, "s2_id": "fb2a1840e61d078e0cb76b5b31374557e6ad1495", "title": "Gaussian Process Meta Few-shot Classifier Learning via Linear Discriminant Laplace Approximation", "abstract": "The meta learning few-shot classification is an emerging problem in machine learning that received enormous attention recently, where the goal is to learn a model that can quickly adapt to a new task with only a few labeled data. We consider the Bayesian Gaussian process (GP) approach, in which we meta-learn the GP prior, and the adaptation to a new task is carried out by the GP predictive model from the posterior inference. We adopt the Laplace posterior approximation, but to circumvent the iterative gradient steps for finding the MAP solution, we introduce a novel linear discriminant analysis (LDA) plugin as a surrogate for the MAP solution. In essence, the MAP solution is approximated by the LDA estimate, but to take the GP prior into account, we adopt the prior-norm adjustment to estimate LDA\u2019s shared variance parameters, which ensures that the adjusted estimate is consistent with the GP prior. This enables closed-form differentiable GP posteriors and predictive distributions, thus allowing fast meta training. We demonstrate considerable improvement over the previous approaches.", "venue": "ArXiv", "authors": ["Minyoung  Kim", "Timothy  Hospedales"], "year": 2021, "n_citations": 0}
{"id": 3142331, "s2_id": "32f0c95cee39eba143452d6a0fe93283575257e6", "title": "Generative Adversarial Networks for Extreme Learned Image Compression", "abstract": "We present a learned image compression system based on GANs, operating at extremely low bitrates. Our proposed framework combines an encoder, decoder/generator and a multi-scale discriminator, which we train jointly for a generative learned compression objective. The model synthesizes details it cannot afford to store, obtaining visually pleasing results at bitrates where previous methods fail and show strong artifacts. Furthermore, if a semantic label map of the original image is available, our method can fully synthesize unimportant regions in the decoded image such as streets and trees from the label map, proportionally reducing the storage cost. A user study confirms that for low bitrates, our approach is preferred to state-of-the-art methods, even when they use more than double the bits.", "venue": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)", "authors": ["Eirikur  Agustsson", "Michael  Tschannen", "Fabian  Mentzer", "Radu  Timofte", "Luc Van Gool"], "year": 2019, "n_citations": 251}
{"id": 3166633, "s2_id": "e6ed2eae6d810deb0dd00b2bdedf07252dedd51b", "title": "A Review of Deep Learning with Special Emphasis on Architectures, Applications and Recent Trends", "abstract": "Deep learning has taken over - both in problems beyond the realm of traditional, hand-crafted machine learning paradigms as well as in capturing the imagination of the practitioner sitting on top of petabytes of data. While the public perception about the efficacy of deep neural architectures in complex pattern recognition tasks grows, sequentially up-to-date primers on the current state of affairs must follow. In this review, we seek to present a refresher of the many different stacked, connectionist networks that make up the deep learning architectures followed by automatic architecture optimization protocols using multi-agent approaches. Further, since guaranteeing system uptime is fast becoming an indispensable asset across multiple industrial modalities, we include an investigative section on testing neural networks for fault detection and subsequent mitigation. This is followed by an exploratory survey of several application areas where deep learning has emerged as a game-changing technology - be it anomalous behavior detection in financial applications or financial time-series forecasting, predictive and prescriptive analytics, medical imaging, natural language processing or power systems research. The thrust of this review is on outlining emerging areas of application-oriented research within the deep learning community as well as to provide a handy reference to researchers seeking to embrace deep learning in their work for what it is: statistical pattern recognizers with unparalleled hierarchical structure learning capacity with the ability to scale with information.", "venue": "ArXiv", "authors": ["Saptarshi  Sengupta", "Sanchita  Basak", "Pallabi  Saikia", "Sayak  Paul", "Vasilios  Tsalavoutis", "Frederick Ditliac Atiah", "Vadlamani  Ravi", "Richard Alan Peters"], "year": 2019, "n_citations": 41}
{"id": 3174113, "s2_id": "1a2f7473af170bc77fe51e8c55c251f4a9cf3473", "title": "Analysing Soccer Games with Clustering and Conceptors", "abstract": "We present a new approach for identifying situations and behaviours, which we call \"moves\", from soccer games in the 2D simulation league. Being able to identify key situations and behaviours are useful capabilities for analysing soccer matches, anticipating opponent behaviours to aid selection of appropriate tactics, and also as a prerequisite for automatic learning of behaviours and policies. To support a wide set of strategies, our goal is to identify situations from data, in an unsupervised way without making use of pre-defined soccer specific concepts such as \"pass\" or \"dribble\". The recurrent neural networks we use in our approach act as a high-dimensional projection of the recent history of a situation on the field. Similar situations, i.e., with similar histories, are found by clustering of network states. The same networks are also used to learn so-called conceptors, that are lower-dimensional manifolds that describe trajectories through a high-dimensional state space that enable situation-specific predictions from the same neural network. With the proposed approach, we can segment games into sequences of situations that are learnt in an unsupervised way, and learn conceptors that are useful for the prediction of the near future of the respective situation.", "venue": "RoboCup", "authors": ["Olivia  Michael", "Oliver  Obst", "Falk  Schmidsberger", "Frieder  Stolzenburg"], "year": 2017, "n_citations": 8}
{"id": 3178594, "s2_id": "ca36821dc536ca492feadbb738625a3d82408834", "title": "Towards a Unified Information-Theoretic Framework for Generalization", "abstract": "In this work, we investigate the expressiveness of the \u201cconditional mutual information\u201d (CMI) framework of Steinke and Zakynthinou [1] and the prospect of using it to provide a unified framework for proving generalization bounds in the realizable setting. We first demonstrate that one can use this framework to express non-trivial (but sub-optimal) bounds for any learning algorithm that outputs hypotheses from a class of bounded VC dimension. We then explore two directions of strengthening this bound: (i) Can the CMI framework express optimal ti l a ti l bounds for VC classes? (ii) Can the CMI framework be used to analyze algorithms whose output hypothesis space is unrestricted t i t r s r e c e t i t r r (i.e. has an unbounded VC dimension)? With respect to Item (i) we prove that the CMI framework yields the optimal bound on the expected risk of Support Vector Machines (SVMs) for learning halfspaces. This result is an application of our general result showing that stable compression schemes [2] of size k have uniformly bounded CMI of order O(k). We further show that an inherent limitation of proper learning of VC classes contradicts the existence of a proper learner with constant CMI, and it implies a negative resolution to an open problem of Steinke and Zakynthinou [3]. We further study the CMI of empirical risk minimizers (ERMs) of classH and show that it is possible to output all consistent classifiers (version space) with bounded CMI if and only if H has a bounded star number [4]. With respect to Item (ii) we prove a general reduction showing that \u201cleave-one-out\u201d analysis is expressible via the CMI framework. As a corollary we investigate the CMI of the one-inclusion-graph algorithm proposed by Haussler et al. [5]. More generally, we show that the CMI framework is universal in the sense that for every consistent algorithm and data distribution, the expected risk vanishes as the number of samples diverges if and only if its evaluated CMI has sublinear growth with the number of samples.", "venue": "ArXiv", "authors": ["Mahdi  Haghifam", "Gintare Karolina Dziugaite", "Shay  Moran", "Daniel M. Roy"], "year": 2021, "n_citations": 0}
{"id": 3182705, "s2_id": "f7abae7cd31d7ab6695934097976d7122282f57a", "title": "Approximate Gradient Coding with Optimal Decoding", "abstract": "In distributed optimization problems, a technique called gradient coding, which involves replicating data points, has been used to mitigate the effect of straggling machines. Recent work has studied approximate gradient coding, which concerns coding schemes where the replication factor of the data is too low to recover the full gradient exactly. Our work is motivated by the challenge of creating approximate gradient coding schemes that simultaneously work well in both the adversarial and stochastic models. To that end, we introduce novel approximate gradient codes based on expander graphs, in which each machine receives exactly two blocks of data points. We analyze the decoding error both in the random and adversarial straggler setting, when optimal decoding coefficients are used. We show that in the random setting, our schemes achieve an error to the gradient that decays exponentially in the replication factor. In the adversarial setting, the error is nearly a factor of two smaller than any existing code with similar performance in the random setting. We show convergence bounds both in the random and adversarial setting for gradient descent under standard assumptions using our codes. In the random setting, our convergence rate improves upon block-box bounds. In the adversarial setting, we show that gradient descent can converge down to a noise floor that scales linearly with the adversarial error to the gradient. We demonstrate empirically that our schemes achieve near-optimal error in the random setting and converge faster than algorithms which do not use the optimal decoding coefficients.", "venue": "2021 IEEE International Symposium on Information Theory (ISIT)", "authors": ["Margalit  Glasgow", "Mary  Wootters"], "year": 2021, "n_citations": 0}
{"id": 3183673, "s2_id": "1e47d5f0fb35a9e19df0a1e4d697e71eaa00f224", "title": "On the Privacy Risks of Model Explanations", "abstract": "Privacy and transparency are two key foundations of trustworthy machine learning. Model explanations offer insights into a model's decisions on input data, whereas privacy is primarily concerned with protecting information about the training data. We analyze connections between model explanations and the leakage of sensitive information about the model's training set. We investigate the privacy risks of feature-based model explanations using membership inference attacks: quantifying how much model predictions plus their explanations leak information about the presence of a datapoint in the training set of a model. We extensively evaluate membership inference attacks based on feature-based model explanations, over a variety of datasets. We show that backpropagation-based explanations can leak a significant amount of information about individual training datapoints. This is because they reveal statistical information about the decision boundaries of the model about an input, which can reveal its membership. We also empirically investigate the trade-off between privacy and explanation quality, by studying the perturbation-based model explanations.", "venue": "AIES", "authors": ["Reza  Shokri", "Martin  Strobel", "Yair  Zick"], "year": 2021, "n_citations": 20}
{"id": 3185251, "s2_id": "85285109cc3204e925bf7fdc32fadcbc96bd50b9", "title": "Multiscale Hierarchical Convolutional Networks", "abstract": "Deep neural network algorithms are difficult to analyze because they lack structure allowing to understand the properties of underlying transforms and invariants. Multiscale hierarchical convolutional networks are structured deep convolutional networks where layers are indexed by progressively higher dimensional attributes, which are learned from training data. Each new layer is computed with multidimensional convolutions along spatial and attribute variables. We introduce an efficient implementation of such networks where the dimensionality is progressively reduced by averaging intermediate layers along attribute indices. Hierarchical networks are tested on CIFAR image data bases where they obtain comparable precisions to state of the art networks, with much fewer parameters. We study some properties of the attributes learned from these databases.", "venue": "ArXiv", "authors": ["J\u00f6rn-Henrik  Jacobsen", "Edouard  Oyallon", "St\u00e9phane  Mallat", "Arnold W. M. Smeulders"], "year": 2017, "n_citations": 14}
{"id": 3187438, "s2_id": "9301b04a76a03344b5e2ccb2ccfae6aa2d99e487", "title": "Semantic Interpolation in Implicit Models", "abstract": "In implicit models, one often interpolates between sampled points in latent space. As we show in this paper, care needs to be taken to match-up the distributional assumptions on code vectors with the geometry of the interpolating paths. Otherwise, typical assumptions about the quality and semantics of in-between points may not be justified. Based on our analysis we propose to modify the prior code distribution to put significantly more probability mass closer to the origin. As a result, linear interpolation paths are not only shortest paths, but they are also guaranteed to pass through high-density regions, irrespective of the dimensionality of the latent space. Experiments on standard benchmark image datasets demonstrate clear visual improvements in the quality of the generated samples and exhibit more meaningful interpolation paths.", "venue": "ICLR", "authors": ["Yannic  Kilcher", "Aur\u00e9lien  Lucchi", "Thomas  Hofmann"], "year": 2018, "n_citations": 15}
{"id": 3193974, "s2_id": "cc614a5983fa44b84350466724f435f9837d05ce", "title": "HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism", "abstract": "Multi-agent reinforcement learning often suffers from the exponentially larger action space caused by a large number of agents. In this paper, we propose a novel value decomposition framework HAVEN based on hierarchical reinforcement learning for the fully cooperative multi-agent problems. In order to address instabilities that arise from the concurrent optimization of high-level and low-level policies and another concurrent optimization of agents, we introduce the dual coordination mechanism of inter-layer strategies and inter-agent strategies. HAVEN does not require domain knowledge and pretraining at all, and can be applied to any value decomposition variants. Our method is demonstrated to achieve superior results to many baselines on StarCraft II micromanagement tasks and offers an efficient solution to multi-agent hierarchical reinforcement learning in fully cooperative scenarios. In the last few years there has been a growing interest in multi-agent reinforcement learning (MARL), which plays an vital role in various tasks such as traffic control (Kuyer et al. 2008), recommendation systems (Choi et al. 2018) and game AI (Vinyals et al. 2019). Most of the multi-agent reinforcement learning algorithms follow the paradigm known as centralized training with decentralized execution (CTDE), which means each agent can use all available information during training but only make decisions on the basis of its own observation. According to this principles, MARL algorithms can be divided into several categories including ones based on centralized critics and decentralized actors (Lowe et al. 2017; Foerster et al. 2018; Iqbal and Sha 2019), communication (Sukhbaatar, Szlam, and Fergus 2016; Foerster et al. 2016; Peng et al. 2017), and value decomposition (Sunehag et al. 2018; Rashid et al. 2018; Son et al. 2019). In some cooperation scenarios, the value decomposition methods can significantly alleviate the credit assignment problem. Several value decomposition variants have been proposed and achieved far-reaching performance improvements recently. However, most of the previous studies on multi-agent cooperative tasks do not take the hierarchical decomposition into account. For example, as the central nervous system, the brain often controls the lower level nervous system instead of directly controlling the muscles to complete specific actions. The hierarchical structure can decompose the action space exponentially related to the number of agents, thereby reducing computational complexity. Besides, the advantage of the hierarchical approach is its better interpretability. Hierarchical reinforcement learning (HRL) is realized based on the idea that decompose the complex tasks into some simpler subtasks. Traditional hierarchical reinforcement learning methods include hierarchical abstraction machine (HAM) (Parr and Russell 1997), MAXQ (Dietterich 2000), option (Sutton, Precup, and Singh 1999; Precup and Sutton 2000) and feudal neural networks (Dayan and Hinton 1992). With the recent development of deep learning, HRL has gradually gradually developed into two main branches: subgoal-based methods (Vezhnevets et al. 2017; Nachum et al. 2018) and option-based methods (Bacon, Harb, and Precup 2017; Harb et al. 2018). And both of them has been utilized in many single-agent applications. However, HRL may not be practical in all situations. For example: it is difficult to generate subgoals by subgoal-based methods; in option-based approach one option often degenerates into a single primitive action; the setup of intrinsic reward requires domain knowledge; and the concurrent optimization of high-level and low-level policies can easily lead to unstable training process and difficult convergence. In this paper, we propose a new framework for the multiagent cooperation problems that can be modelled by DecPOMDPs, HierArchical Value dEcompositioN (HAVEN), a hierarchically structured method combined with the value decomposition methods. HAVEN constructs a two-layer strategy, and uses the advantage function of the high-level policy as part of the intrinsic reward of the low-level policy. In this way, the simultaneous optimization of high-level and low-level policies are guaranteed, which alleviates the training instability that was key limitation of the previous HRL work. There is also no need to pretrain the low-level policies. Simultaneously, because the action space of the high-level policies is preset with maintaining the generality, the training process of the entire framework does not require domain knowledge. Besides, it is worth mentioning that HAVEN can be extended to any value decomposition variant. In summary, HAVEN is an end-to-end and knowledge-free framework. Our contributions include three aspects: \u2022 We presents the HAVEN framework that builds a dual coordination mechanism of inter-level and inter-agent to solve the Dec-POMDP problems. ar X iv :2 11 0. 07 24 6v 1 [ cs .M A ] 1 4 O ct 2 02 1 \u2022 Through visualizing the decision-making process, we proved that the decision space is implicitly divided into multiple subspaces by high-level strategies of HAVEN. \u2022 Empirical evaluations in the StarCraft II micromanagement testbed also demonstrate that our method significantly outperforms previous algorithms.", "venue": "ArXiv", "authors": ["Zhiwei  Xu", "Yunpeng  Bai", "Bin  Zhang", "Dapeng  Li", "Guoliang  Fan"], "year": 2021, "n_citations": 0}
{"id": 3197123, "s2_id": "59026ef1a7390b3606ee6699cc9c45612e7ad577", "title": "Structure Parameter Optimized Kernel Based Online Prediction with a Generalized Optimization Strategy for Nonstationary Time Series", "abstract": "In this paper, sparsification techniques aided online prediction algorithms in a reproducing kernel Hilbert space are studied for nonstationary time series. The online prediction algorithms as usual consist of the selection of kernel structure parameters and the kernel weight vector updating. For structure parameters, the kernel dictionary is selected by some sparsification techniques with online selective modeling criteria, and moreover the kernel covariance matrix is intermittently optimized in the light of the covariance matrix adaptation evolution strategy (CMA-ES). Optimizing the real symmetric covariance matrix can not only improve the kernel structure\u2019s flexibility by the cross relatedness of the input variables, but also partly alleviate the prediction uncertainty caused by the kernel dictionary selection for nonstationary time series. In order to sufficiently capture the underlying dynamic characteristics in prediction-error time series, a generalized optimization strategy is designed to construct the kernel dictionary sequentially in multiple kernel connection modes. The generalized optimization strategy provides a more self-contained way to construct the entire kernel connections, which enhances the ability to adaptively track the changing dynamic characteristics. Numerical simulations have demonstrated that the proposed approach has superior prediction performance for nonstationary time series.", "venue": "ArXiv", "authors": ["Jinhua  Guo", "Hao  Chen", "Jingxin  Zhang", "Sheng  Chen"], "year": 2021, "n_citations": 0}
{"id": 3198542, "s2_id": "fba05a989d2e13ec5f633e9723e54376d61db692", "title": "Multilevel Initialization for Layer-Parallel Deep Neural Network Training", "abstract": "This paper investigates multilevel initialization strategies for training very deep neural networks with a layer-parallel multigrid solver. The scheme is based on the continuous interpretation of the training problem as a problem of optimal control, in which neural networks are represented as discretizations of time-dependent ordinary differential equations. A key goal is to develop a method able to intelligently initialize the network parameters for the very deep networks enabled by scalable layer-parallel training. To do this, we apply a refinement strategy across the time domain, that is equivalent to refining in the layer dimension. The resulting refinements create deep networks, with good initializations for the network parameters coming from the coarser trained networks. We investigate the effectiveness of such multilevel \"nested iteration\" strategies for network training, showing supporting numerical evidence of reduced run time for equivalent accuracy. In addition, we study whether the initialization strategies provide a regularizing effect on the overall training process and reduce sensitivity to hyperparameters and randomness in initial network parameters.", "venue": "ArXiv", "authors": ["Eric C. Cyr", "Stefanie  G\u00fcnther", "Jacob B. Schroder"], "year": 2019, "n_citations": 5}
{"id": 3214441, "s2_id": "6de980fd6c50d0f764e6e3f2c2d19250c32ca4b9", "title": "A Secure Learning Control Strategy via Dynamic Camouflaging for Unknown Dynamical Systems under Attacks", "abstract": "This paper presents a secure reinforcement learning (RL) based control method for unknown linear time-invariant cyber-physical systems (CPSs) that are subjected to compositional attacks such as eavesdropping and covert attack. We consider the attack scenario where the attacker learns about the dynamic model during the exploration phase of the learning conducted by the designer to learn a linear quadratic regulator (LQR), and thereafter, use such information to conduct a covert attack on the dynamic system, which we refer to as doubly learning-based control and attack (DLCA) framework. We propose a dynamic camouflaging based attack-resilient reinforcement learning (ARRL) algorithm which can learn the desired optimal controller for the dynamic system, and at the same time, can inject sufficient misinformation in the estimation of system dynamics by the attacker. The algorithm is accompanied by theoretical guarantees and extensive numerical experiments on a consensus multi-agent system and on a benchmark power grid model.", "venue": "ArXiv", "authors": ["Sayak  Mukherjee", "Veronica  Adetola"], "year": 2021, "n_citations": 0}
{"id": 3234139, "s2_id": "35a5824d5dafbc392fdd7edd0ee774a56f9df6d3", "title": "Encrypted statistical machine learning: new privacy preserving methods", "abstract": "We present two new statistical machine learning methods designed to learn on fully homomorphic encrypted (FHE) data. The introduction of FHE schemes following Gentry (2009) opens up the prospect of privacy preserving statistical machine learning analysis and modelling of encrypted data without compromising security constraints. We propose tailored algorithms for applying extremely random forests, involving a new cryptographic stochastic fraction estimator, and na\\\"{i}ve Bayes, involving a semi-parametric model for the class decision boundary, and show how they can be used to learn and predict from encrypted data. We demonstrate that these techniques perform competitively on a variety of classification data sets and provide detailed information about the computational practicalities of these and other FHE methods.", "venue": "ArXiv", "authors": ["Louis J. M. Aslett", "Pedro M. Esperan\u00e7a", "Chris C. Holmes"], "year": 2015, "n_citations": 48}
{"id": 3235213, "s2_id": "fb470ef2fe032607ebb8b3337f8e79b4588733f8", "title": "A Semi-Supervised Machine Learning Approach to Detecting Recurrent Metastatic Breast Cancer Cases Using Linked Cancer Registry and Electronic Medical Record Data", "abstract": "Objectives: Most cancer data sources lack information on metastatic recurrence. Electronic medical records (EMRs) and population-based cancer registries contain complementary information on cancer treatment and outcomes, yet are rarely used synergistically. To enable detection of metastatic breast cancer (MBC), we applied a semi-supervised machine learning framework to linked EMR-California Cancer Registry (CCR) data. Materials and Methods: We studied 11,459 female patients treated at Stanford Health Care who received an incident breast cancer diagnosis from 2000-2014. The dataset consisted of structured data and unstructured free-text clinical notes from EMR, linked to CCR, a component of the Surveillance, Epidemiology and End Results (SEER) database. We extracted information on metastatic disease from patient notes to infer a class label and then trained a regularized logistic regression model for MBC classification. We evaluated model performance on a gold standard set of set of 146 patients. Results: There are 495 patients with de novo stage IV MBC, 1,374 patients initially diagnosed with Stage 0-III disease had recurrent MBC, and 9,590 had no evidence of metastatis. The median follow-up time is 96.3 months (mean 97.8, standard deviation 46.7). The best-performing model incorporated both EMR and CCR features. The area under the receiver-operating characteristic curve=0.925 [95% confidence interval: 0.880-0.969], sensitivity=0.861, specificity=0.878 and overall accuracy=0.870. Discussion and Conclusion: A framework for MBC case detection combining EMR and CCR data achieved good sensitivity, specificity and discrimination without requiring expert-labeled examples. This approach enables population-based research on how patients die from cancer and may identify novel predictors of cancer recurrence.", "venue": "ArXiv", "authors": ["Albee Y. Ling", "Allison W. Kurian", "Jennifer L. Caswell-Jin", "George W. Sledge", "Nigam H. Shah", "Suzanne R. Tamang"], "year": 2019, "n_citations": 3}
{"id": 3245568, "s2_id": "db5c4cc2f42cbbd08483c13f4ef47f7e724904e1", "title": "Robust subgroup discovery", "abstract": "We introduce the problem of robust subgroup discovery, i.e., finding a set of interpretable descriptions of subsets that 1) stand out with respect to one or more target attributes, 2) are statistically robust, and 3) non-redundant. Many attempts have been made to mine either locally robust subgroups or to tackle the pattern explosion, but we are the first to address both challenges at the same time from a global modelling perspective. First, we formulate the broad model class of subgroup lists, i.e., ordered sets of subgroups, for univariate and multivariate targets that can consist of nominal or numeric variables, and that includes traditional top-1 subgroup discovery in its definition. This novel model class allows us to formalise the problem of optimal robust subgroup discovery using the Minimum Description Length (MDL) principle, where we resort to optimal Normalised Maximum Likelihood and Bayesian encodings for nominal and numeric targets, respectively. Second, as finding optimal subgroup lists is NP-hard, we propose SSD++, a greedy heuristic that finds good subgroup lists and guarantees that the most significant subgroup found according to the MDL criterion is added in each iteration, which is shown to be equivalent to a Bayesian one-sample proportions, multinomial, or t-test between the subgroup and dataset marginal target distributions plus a multiple hypothesis testing penalty. We empirically show on 54 datasets Hugo Manuel Proen\u00e7a LIACS, Niels Bohrweg 1, 2333 CA Leiden, Netherlands E-mail: h.manuel.proenca@liacs.leidenuniv.nl Peter Gr\u00fcnwald CWI, Science Park 123, 1098 XG Amsterdam E-mail: peter.grunwald@cwi.nl Thomas B\u00e4ck LIACS, Niels Bohrweg 1, 2333 CA Leiden, Netherlands E-mail: t.h.w.baeck@liacs.leidenuniv.nl Matthijs van Leeuwen LIACS, Niels Bohrweg 1, 2333 CA Leiden, Netherlands E-mail: m.van.leeuwen@liacs.leidenuniv.nl ar X iv :2 10 3. 13 68 6v 2 [ cs .L G ] 2 8 N ov 2 02 1 2 Hugo M. Proen\u00e7a et al. that SSD++ outperforms previous subgroup set discovery methods in terms of quality and subgroup list size.", "venue": "ArXiv", "authors": ["Hugo Manuel Proen\u00e7a", "Thomas  B\u00e4ck", "Matthijs van Leeuwen"], "year": 2021, "n_citations": 1}
{"id": 3249657, "s2_id": "1f4dc42971044d409aab379e49ea7ad23fb3aa6a", "title": "How Do Classifiers Induce Agents to Invest Effort Strategically?", "abstract": "Algorithms are often used to produce decision-making rules that classify or evaluate individuals. When these individuals have incentives to be classified a certain way, they may behave strategically to influence their outcomes. We develop a model for how strategic agents can invest effort in order to change the outcomes they receive, and we give a tight characterization of when such agents can be incentivized to invest specified forms of effort into improving their outcomes as opposed to \"gaming\" the classifier. We show that whenever any \"reasonable\" mechanism can do so, a simple linear mechanism suffices.", "venue": "EC", "authors": ["Jon M. Kleinberg", "Manish  Raghavan"], "year": 2019, "n_citations": 64}
{"id": 3260832, "s2_id": "363a8e20ff8ca662466df802a510a6b974a90893", "title": "Pre-interpolation loss behaviour in neural networks", "abstract": "When training neural networks as classifiers, it is common to observe an increase in average test loss while still maintaining or improving the overall classification accuracy on the same dataset. In spite of the ubiquity of this phenomenon, it has not been well studied and is often dismissively attributed to an increase in borderline correct classifications. We present an empirical investigation that shows how this phenomenon is actually a result of the differential manner by which test samples are processed. In essence: test loss does not increase overall, but only for a small minority of samples. Large representational capacities allow losses to decrease for the vast majority of test samples at the cost of extreme increases for others. This effect seems to be mainly caused by increased parameter values relating to the correctly processed sample features. Our findings contribute to the practical understanding of a common behaviour of deep neural networks. We also discuss the implications of this work for network optimisation and generalisation.", "venue": "ArXiv", "authors": ["Arthur E. W. Venter", "Marthinus W. Theunissen", "Marelie H. Davel"], "year": 2021, "n_citations": 0}
{"id": 3262631, "s2_id": "0421a6a269b31827429290a4afebffc384a5e76c", "title": "Imitation Learning of Factored Multi-agent Reactive Models", "abstract": "We apply recent advances in deep generative modeling to the task of imitation learning from biological agents. Specifically, we apply variations of the variational recurrent neural network model to a multi-agent setting where we learn policies of individual uncoordinated agents acting based on their perceptual inputs and their hidden belief state. We learn stochastic policies for these agents directly from observational data, without constructing a reward function. An inference network learned jointly with the policy allows for efficient inference over the agent's belief state given a sequence of its current perceptual inputs and the prior actions it performed, which lets us extrapolate observed sequences of behavior into the future while maintaining uncertainty estimates over future trajectories. We test our approach on a dataset of flies interacting in a 2D environment, where we demonstrate better predictive performance than existing approaches which learn deterministic policies with recurrent neural networks. We further show that the uncertainty estimates over future trajectories we obtain are well calibrated, which makes them useful for a variety of downstream processing tasks.", "venue": "ArXiv", "authors": ["Michael  Teng", "Tuan Anh Le", "Adam  Scibior", "Frank  Wood"], "year": 2019, "n_citations": 1}
{"id": 3278726, "s2_id": "def0bf85248be140f431e5074d7cd2c3c92c2e6e", "title": "Large-Scale Methods for Distributionally Robust Optimization", "abstract": "We propose and analyze algorithms for distributionally robust optimization of convex losses with conditional value at risk (CVaR) and $\\chi^2$ divergence uncertainty sets. We prove that our algorithms require a number of gradient evaluations independent of training set size and number of parameters, making them suitable for large-scale applications. For $\\chi^2$ uncertainty sets these are the first such guarantees in the literature, and for CVaR our guarantees scale linearly in the uncertainty level rather than quadratically as in previous work. We also provide lower bounds proving the worst-case optimality of our algorithms for CVaR and a penalized version of the $\\chi^2$ problem. Our primary technical contributions are novel bounds on the bias of batch robust risk estimation and the variance of a multilevel Monte Carlo gradient estimator due to [Blanchet & Glynn, 2015]. Experiments on MNIST and ImageNet confirm the theoretical scaling of our algorithms, which are 9--36 times more efficient than full-batch methods.", "venue": "NeurIPS", "authors": ["Daniel  Levy", "Yair  Carmon", "John C. Duchi", "Aaron  Sidford"], "year": 2020, "n_citations": 23}
{"id": 3284036, "s2_id": "efd7186461c6333b113635fef80e6d965b075114", "title": "Batched Bandits with Crowd Externalities", "abstract": "In Batched Multi-Armed Bandits (BMAB), the policy is not allowed to be updated at each time step. Usually, the setting asserts a maximum number of allowed policy updates and the algorithm schedules them so that to minimize the expected regret. In this paper, we describe a novel setting for BMAB, with the following twist: the timing of the policy update is not controlled by the BMAB algorithm, but instead the amount of data received during each batch, called crowd, is influenced by the past selection of arms. We first design a near-optimal policy with approximate knowledge of the parameters that we prove to have a regret in O( \u221a ln x x + )wherex is the size of the crowd and is the parameter error. Next, we implement a UCBinspired algorithm that guarantees an additional regret in O ( max(K lnT, \u221a T lnT ) ) , where K is the number of arms and T is the horizon.", "venue": "ArXiv", "authors": ["Romain  Laroche", "Othmane  Safsafi", "Raphael  Feraud", "Nicolas  Broutin"], "year": 2021, "n_citations": 0}
{"id": 3288050, "s2_id": "60f8091e65c1e9d6b1473ecf9842d57478836773", "title": "Collaborative Filtering with User-Item Co-Autoregressive Models", "abstract": "Deep neural networks have shown promise in collaborative filtering (CF). However, existing neural approaches are either user-based or item-based, which cannot leverage all the underlying information explicitly. We propose CF-UIcA, a neural co-autoregressive model for CF tasks, which exploits the structural correlation in the domains of both users and items. The co-autoregression allows extra desired properties to be incorporated for different tasks. Furthermore, we develop an efficient stochastic learning algorithm to handle large scale datasets. We evaluate CF-UIcA on two popular benchmarks: MovieLens 1M and Netflix, and achieve state-of-the-art performance in both rating prediction and top-N recommendation tasks, which demonstrates the effectiveness of CF-UIcA.", "venue": "AAAI", "authors": ["Chao  Du", "Chongxuan  Li", "Yin  Zheng", "Jun  Zhu", "Cailiang  Liu", "Hanning  Zhou", "Bo  Zhang"], "year": 2018, "n_citations": 18}
{"id": 3290969, "s2_id": "e5ce416a687660ecd6fb9039c5296615e17d680e", "title": "GrowSpace: Learning How to Shape Plants", "abstract": "Plants are dynamic systems that are integral to our existence and survival. Plants face environment changes and adapt over time to their surrounding conditions. We argue that plant responses to an environmental stimulus are a good example of a real-world problem that can be approached within a reinforcement learning (RL) framework. With the objective of controlling a plant by moving the light source, we propose GrowSpace, as a new RL benchmark. The back-end of the simulator is implemented using the Space Colonisation Algorithm, a plant growing model based on competition for space. Compared to video game RL environments, this simulator addresses a real-world problem and serves as a test bed to visualize plant growth and movement in a faster way than physical experiments. GrowSpace is composed of a suite of challenges that tackle several problems such as control, multi-stagelearning, fairness and multi-objective learning. We provide agent baselines alongside case studies to demonstrate the difficulty of the proposed benchmark.", "venue": "ArXiv", "authors": ["Yasmeen  Hitti", "Ionelia  Buzatu", "Manuel Del Verme", "Mark  Lefsrud", "Florian  Golemo", "Audrey  Durand"], "year": 2021, "n_citations": 0}
{"id": 3292248, "s2_id": "e41d0faebcf9c92d907cdfb36905b37de642dfb4", "title": "Spatiotemporal Ground Reaction Force Analysis using Convolutional Neural Networks to Analyze Parkinsonian Gait", "abstract": "Parkinson\u2019s disease (PD) is a non-curable disease that commonly found among elders that greatly reduce their quality of life. PD primarily affects the gait pattern and slowly changes the walking gait from the normality to disability. The early diagnosing of PD is important for treatments and gait pattern analysis is used as a technique to diagnose PD. The present paper has identified the raw spatiotemporal ground reaction force (GRF) as a key parameter to identify the changes in human gait patterns associated with PD. The changes in GRF are identified using a convolutional neural network through pre-processing, conversion, recognition, and performance evaluation. The proposed algorithm is capable of identifying the severity of the PD and distinguishing the parkinsonian gait from the healthy gait. The technique has shown a 97% of accuracy in automatic decision-making process.", "venue": "ArXiv", "authors": ["Musthaq  Ahamed", "P.D.S.H.  Gunawardane", "Nimali T. Medagedara"], "year": 2021, "n_citations": 0}
{"id": 3292724, "s2_id": "1a22f5495f6d005166fba0d42a91a0c0451206dd", "title": "The intriguing role of module criticality in the generalization of deep networks", "abstract": "We study the phenomenon that some modules of deep neural networks (DNNs) are more \\emph{critical} than others. Meaning that rewinding their parameter values back to initialization, while keeping other modules fixed at the trained parameters, results in a large drop in the network's performance. Our analysis reveals interesting properties of the loss landscape which leads us to propose a complexity measure, called {\\em module criticality}, based on the shape of the valleys that connects the initial and final values of the module parameters. We formulate how generalization relates to the module criticality, and show that this measure is able to explain the superior generalization performance of some architectures over others, whereas earlier measures fail to do so.", "venue": "ICLR", "authors": ["Niladri S. Chatterji", "Behnam  Neyshabur", "Hanie  Sedghi"], "year": 2020, "n_citations": 20}
{"id": 3299791, "s2_id": "af3b940a174611e010720505d672e283f29716ed", "title": "Beyond the One Step Greedy Approach in Reinforcement Learning", "abstract": "The famous Policy Iteration algorithm alternates between policy improvement and policy evaluation. Implementations of this algorithm with several variants of the latter evaluation stage, e.g, $n$-step and trace-based returns, have been analyzed in previous works. However, the case of multiple-step lookahead policy improvement, despite the recent increase in empirical evidence of its strength, has to our knowledge not been carefully analyzed yet. In this work, we introduce the first such analysis. Namely, we formulate variants of multiple-step policy improvement, derive new algorithms using these definitions and prove their convergence. Moreover, we show that recent prominent Reinforcement Learning algorithms are, in fact, instances of our framework. We thus shed light on their empirical success and give a recipe for deriving new algorithms for future study.", "venue": "ICML", "authors": ["Yonathan  Efroni", "Gal  Dalal", "Bruno  Scherrer", "Shie  Mannor"], "year": 2018, "n_citations": 25}
{"id": 3318722, "s2_id": "b673b8fed476bb7fc3729c2dd541914c897caeb0", "title": "Identifying Helpful Sentences in Product Reviews", "abstract": "In recent years online shopping has gained momentum and became an important venue for customers wishing to save time and simplify their shopping process. A key advantage of shopping online is the ability to read what other customers are saying about products of interest. In this work, we aim to maintain this advantage in situations where extreme brevity is needed, for example, when shopping by voice. We suggest a novel task of extracting a single representative helpful sentence from a set of reviews for a given product. The selected sentence should meet two conditions: first, it should be helpful for a purchase decision and second, the opinion it expresses should be supported by multiple reviewers. This task is closely related to the task of Multi Document Summarization in the product reviews domain but differs in its objective and its level of conciseness. We collect a dataset in English of sentence helpfulness scores via crowd-sourcing and demonstrate its reliability despite the inherent subjectivity involved. Next, we describe a complete model that extracts representative helpful sentences with positive and negative sentiment towards the product and demonstrate that it outperforms several baselines.", "venue": "NAACL", "authors": ["Iftah  Gamzu", "Hila  Gonen", "Gilad  Kutiel", "Ran  Levy", "Eugene  Agichtein"], "year": 2021, "n_citations": 1}
{"id": 3319219, "s2_id": "afa36d8c4d3c4cebc61beab9dfeafaad2a26e20d", "title": "Image deblurring based on lightweight multi-information fusion network", "abstract": "Recently, deep learning based image deblurring has been well developed. However, exploiting the detailed image features in a deep learning framework always requires a mass of parameters, which inevitably makes the network suffer from high computational burden. To solve this problem, we propose a lightweight multiinformation fusion network (LMFN) for image deblurring. The proposed LMFN is designed as an encoder-decoder architecture. In the encoding stage, the image feature is reduced to various smallscale spaces for multi-scale information extraction and fusion without a large amount of information loss. Then, a distillation network is used in the decoding stage, which allows the network benefit the most from residual learning while remaining sufficiently lightweight. Meanwhile, an information fusion strategy between distillation modules and feature channels is also carried out by attention mechanism. Through fusing different information in the proposed approach, our network can achieve state-of-the-art image deblurring result with smaller number of parameters and outperforms existing methods in model complexity.", "venue": "ICIP 2021", "authors": ["Yanni  Zhang", "Yiming  Liu", "Qiang  Li", "Miao  Qi", "Dahong  Xu", "Jun  Kong", "Jianzhong  Wang"], "year": 2021, "n_citations": 0}
{"id": 3326412, "s2_id": "c8b509be29721ee6b12c880b4d97ed6b60bad217", "title": "Generative Moment Matching Networks", "abstract": "We consider the problem of learning deep generative models from data. We formulate a method that generates an independent sample via a single feedforward pass through a multilayer perceptron, as in the recently proposed generative adversarial networks (Goodfellow et al., 2014). Training a generative adversarial network, however, requires careful optimization of a difficult minimax program. Instead, we utilize a technique from statistical hypothesis testing known as maximum mean discrepancy (MMD), which leads to a simple objective that can be interpreted as matching all orders of statistics between a dataset and samples from the model, and can be trained by backpropagation. We further boost the performance of this approach by combining our generative network with an auto-encoder network, using MMD to learn to generate codes that can then be decoded to produce samples. We show that the combination of these techniques yields excellent generative models compared to baseline approaches as measured on MNIST and the Toronto Face Database.", "venue": "ICML", "authors": ["Yujia  Li", "Kevin  Swersky", "Richard S. Zemel"], "year": 2015, "n_citations": 606}
{"id": 3334562, "s2_id": "b01cea7ea01e5103fc07132fa8389a54a75fb35c", "title": "Using Eigencentrality to Estimate Joint, Conditional and Marginal Probabilities from Mixed-Variable Data: Method and Applications", "abstract": "The ability to estimate joint, conditional and marginal probability distributions over some set of variables is of great utility for many common machine learning tasks. However, estimating these distributions can be challenging, particularly in the case of data containing a mix of discrete and continuous variables. This paper presents a non-parametric method for estimating these distributions directly from a dataset. The data are first represented as a graph consisting of object nodes and attribute value nodes. Depending on the distribution to be estimated, an appropriate eigenvector equation is then constructed. This equation is then solved to find the corresponding stationary distribution of the graph, from which the required distributions can then be estimated and sampled from. The paper demonstrates how the method can be applied to many common machine learning tasks including classification, regression, missing value imputation, outlier detection, random vector generation, and clustering.", "venue": "ArXiv", "authors": ["Andrew  Skabar"], "year": 2018, "n_citations": 0}
{"id": 3339442, "s2_id": "ed9acc61319c2aad04ce25c3bc348b955296bed3", "title": "Efficient Representation of Low-Dimensional Manifolds using Deep Networks", "abstract": "We consider the ability of deep neural networks to represent data that lies near a low-dimensional manifold in a high-dimensional space. We show that deep networks can efficiently extract the intrinsic, low-dimensional coordinates of such data. We first show that the first two layers of a deep network can exactly embed points lying on a monotonic chain, a special type of piecewise linear manifold, mapping them to a low-dimensional Euclidean space. Remarkably, the network can do this using an almost optimal number of parameters. We also show that this network projects nearby points onto the manifold and then embeds them with little error. We then extend these results to more general manifolds.", "venue": "ICLR", "authors": ["Ronen  Basri", "David W. Jacobs"], "year": 2017, "n_citations": 30}
{"id": 3362716, "s2_id": "44e57cb0167e299d9429e3d6d19370fb975ce3e6", "title": "A Scalable Framework for Trajectory Prediction", "abstract": "Trajectory prediction (TP) is of great importance for a wide range of location-based applications in intelligent transport systems, such as location-based advertising, route planning, traffic management, and early warning systems. In the last few years, the widespread use of GPS navigation systems and wireless communication technology enabled vehicles has resulted in huge volumes of trajectory data. The task of utilizing these data employing spatio-temporal techniques for TP in an efficient and accurate manner is an ongoing research problem. Existing TP approaches are limited to the short-term predictions. Moreover, they cannot handle a large volume of trajectory data for long-term prediction. To address these limitations, we propose a scalable clustering and Markov chain-based hybrid framework, called Traj-clusiVAT-based TP, for both short- and long-term TPs, which can handle a large number of overlapping trajectories in a dense road network. Traj-clusiVAT can also determine the number of clusters, which represent different movement behaviors in input trajectory data. In our experiments, we compare our proposed approach with a mixed Markov model-based scheme and a trajectory clustering, NETSCAN-based TP method for both short- and long-term TPs. We performed our experiments on two real, vehicle trajectory datasets, including a large-scale trajectory dataset consisting of 3.28 million trajectories obtained from 15 061 taxis in Singapore over a period of one month. The experimental results on two real trajectory datasets show that our proposed approach outperforms the existing approaches in terms of both short- and long-term prediction performances, based on the prediction accuracy and distance error (in km).", "venue": "IEEE Transactions on Intelligent Transportation Systems", "authors": ["Punit  Rathore", "Dheeraj  Kumar", "Sutharshan  Rajasegarar", "Marimuthu  Palaniswami", "James C. Bezdek"], "year": 2019, "n_citations": 24}
{"id": 3364734, "s2_id": "ea8048d190afec36c83714dd757797827b369f91", "title": "Mining Coronavirus (COVID-19) Posts in Social Media", "abstract": "World Health Organization (WHO) characterized the novel coronavirus (COVID-19) as a global pandemic on March 11th, 2020. Before this and in late January, more specifically on January 27th, while the majority of the infection cases were still reported in China and a few cruise ships, we began crawling social media user postings using the Twitter search API. Our goal was to leverage machine learning and linguistic tools to better understand the impact of the outbreak in China. Unlike our initial expectation to monitor a local outbreak, COVID-19 rapidly spread across the globe. In this short article we report the preliminary results of our study on automatically detecting the positive reports of COVID-19 from social media user postings using state-of-the-art machine learning models.", "venue": "ArXiv", "authors": ["Negin  Karisani", "Payam  Karisani"], "year": 2020, "n_citations": 17}
{"id": 3367550, "s2_id": "31f10a6f602bef0306ac37322f84f6163c8a8ecb", "title": "CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning", "abstract": "We develop an algorithm that can detect pneumonia from chest X-rays at a level exceeding practicing radiologists. Our algorithm, CheXNet, is a 121-layer convolutional neural network trained on ChestX-ray14, currently the largest publicly available chest X-ray dataset, containing over 100,000 frontal-view X-ray images with 14 diseases. Four practicing academic radiologists annotate a test set, on which we compare the performance of CheXNet to that of radiologists. We find that CheXNet exceeds average radiologist performance on the F1 metric. We extend CheXNet to detect all 14 diseases in ChestX-ray14 and achieve state of the art results on all 14 diseases.", "venue": "ArXiv", "authors": ["Pranav  Rajpurkar", "Jeremy  Irvin", "Kaylie  Zhu", "Brandon  Yang", "Hershel  Mehta", "Tony  Duan", "Daisy Yi Ding", "Aarti  Bagul", "Curtis P. Langlotz", "Katie S. Shpanskaya", "Matthew P. Lungren", "Andrew Y. Ng"], "year": 2017, "n_citations": 1315}
{"id": 3371492, "s2_id": "6c4274c70034083215f97086d18f6b515fcd04f4", "title": "Framework for Inferring Following Strategies from Time Series of Movement Data", "abstract": "How do groups of individuals achieve consensus in movement decisions? Do individuals follow their friends, the one predetermined leader, or whomever just happens to be nearby? To address these questions computationally, we formalize Coordination Strategy Inference Problem. In this setting, a group of multiple individuals moves in a coordinated manner toward a target path. Each individual uses a specific strategy to follow others (e.g., nearest neighbors, pre-defined leaders, and preferred friends). Given a set of time series that includes coordinated movement and a set of candidate strategies as inputs, we provide the first methodology (to the best of our knowledge) to infer whether each individual uses local-agreement system or dictatorship-like strategy to achieve movement coordination at the group level. We evaluate and demonstrate the performance of the proposed framework by predicting directions of movement of an individual in a group in both simulated datasets as well as in two real-world datasets: a school of fish and a troop of baboons. Moreover, since there is no prior methodology for inferring individual-level strategies, we compare our framework with the state-of-the-art approach for the task of classification of group-level-coordination models. Results show that our approach is highly accurate in inferring correct strategies in simulated datasets even in complicated mixed strategy settings, which no existing method can infer. In the task of classification of group-level-coordination models, our framework performs better than the state-of-the-art approach in all datasets. Animal data experiments show that fish, as expected, follow their neighbors, while baboons have a preference to follow specific individuals. Our methodology generalizes to arbitrary time series data of real numbers, beyond movement data.", "venue": "ACM Trans. Knowl. Discov. Data", "authors": ["Chainarong  Amornbunchornvej", "Tanya  Berger-Wolf"], "year": 2020, "n_citations": 2}
{"id": 3373377, "s2_id": "f780650b18759bf2bd92d01ccfbe7a2b683bc19b", "title": "Polynomial-Time Algorithms for Multiple-Arm Identification with Full-Bandit Feedback", "abstract": "We study the problem of stochastic multiple-arm identification, where an agent sequentially explores a size-k subset of arms (also known as a super arm) from given n arms and tries to identify the best super arm. Most work so far has considered the semi-bandit setting, where the agent can observe the reward of each pulled arm or assumed each arm can be queried at each round. However, in real-world applications, it is costly or sometimes impossible to observe a reward of individual arms. In this study, we tackle the full-bandit setting, where only a noisy observation of the total sum of a super arm is given at each pull. Although our problem can be regarded as an instance of the best arm identification in linear bandits, a naive approach based on linear bandits is computationally infeasible since the number of super arms K is exponential. To cope with this problem, we first design a polynomial-time approximation algorithm for a 0-1 quadratic programming problem arising in confidence ellipsoid maximization. Based on our approximation algorithm, we propose a bandit algorithm whose computation time is O(log K), thereby achieving an exponential speedup over linear bandit algorithms. We provide a sample complexity upper bound that is still worst-case optimal. Finally, we conduct experiments on large-scale data sets with more than 1010 super arms, demonstrating the superiority of our algorithms in terms of both the computation time and the sample complexity.", "venue": "Neural Computation", "authors": ["Yuko  Kuroki", "Liyuan  Xu", "Atsushi  Miyauchi", "Junya  Honda", "Masashi  Sugiyama"], "year": 2020, "n_citations": 11}
{"id": 3375606, "s2_id": "e3efb45c140ad80b1a0a6a6089f2a94e91583e9a", "title": "MeshfreeFlowNet: A Physics-Constrained Deep Continuous Space-Time Super-Resolution Framework", "abstract": "We propose MeshfreeFlowNet, a novel deep learning-based super-resolution framework to generate continuous (grid-free) spatio-temporal solutions from the low-resolution inputs. While being computationally efficient, MeshfreeFlowNet accurately recovers the fine-scale quantities of interest. MeshfreeFlowNet allows for: (i) the output to be sampled at all spatio-temporal resolutions, (ii) a set of Partial Differential Equation (PDE) constraints to be imposed, and (iii) training on fixed-size inputs on arbitrarily sized spatio-temporal domains owing to its fully convolutional encoder. We empirically study the performance of MeshfreeFlowNet on the task of super-resolution of turbulent flows in the Rayleigh-Benard convection problem. Across a diverse set of evaluation metrics, we show that MeshfreeFlowNet significantly outperforms existing baselines. Furthermore, we provide a large scale implementation of MeshfreeFlowNet and show that it efficiently scales across large clusters, achieving 96.80% scaling efficiency on up to 128 GPUs and a training time of less than 4 minutes.", "venue": "SC", "authors": ["Chiyu Max Jiang", "Soheil  Esmaeilzadeh", "Kamyar  Azizzadenesheli", "Karthik  Kashinath", "Mustafa  Mustafa", "Hamdi A. Tchelepi", "Philip  Marcus", "Prabhat", "Anima  Anandkumar"], "year": 2020, "n_citations": 23}
{"id": 3375893, "s2_id": "c1cd3ef5bd9439de1f138ab5200a2c9cecf362af", "title": "Physical Side-Channel Attacks on Embedded Neural Networks: A Survey", "abstract": "During the last decade, Deep Neural Networks (DNN) have progressively been integrated on all types of platforms, from data centers to embedded systems including low-power processors and, recently, FPGAs. Neural Networks (NN) are expected to become ubiquitous in IoT systems by transforming all sorts of real-world applications, including applications in the safety-critical and security-sensitive domains. However, the underlying hardware security vulnerabilities of embedded NN implementations remain unaddressed. In particular, embedded DNN implementations are vulnerable to Side-Channel Analysis (SCA) attacks, which are especially important in the IoT and edge computing contexts where an attacker can usually gain physical access to the targeted device. A research field has therefore emerged and is rapidly growing in terms of the use of SCA including timing, electromagnetic attacks and power attacks to target NN embedded implementations. Since 2018, research papers have shown that SCA enables an attacker to recover inference models architectures and parameters, to expose industrial IP and endangers data confidentiality and privacy. Without a complete review of this emerging field in the literature so far, this paper surveys state-of-the-art physical SCA attacks relative to the implementation of embedded DNNs on micro-controllers and FPGAs in order to provide a thorough analysis on the current landscape. It provides a taxonomy and a detailed classification of current attacks. It first discusses mitigation techniques and then provides insights for future research leads.", "venue": "Applied Sciences", "authors": ["Maria M\u00e9ndez Real", "Rub\u00e9n  Salvador"], "year": 2021, "n_citations": 0}
{"id": 3382993, "s2_id": "2c6f83b417e127130703b5b81e42899e0ae3693e", "title": "Comparing Rewinding and Fine-tuning in Neural Network Pruning", "abstract": "Many neural network pruning algorithms proceed in three steps: train the network to completion, remove unwanted structure to compress the network, and retrain the remaining structure to recover lost accuracy. The standard retraining technique, fine-tuning, trains the unpruned weights from their final trained values using a small fixed learning rate. In this paper, we compare fine-tuning to alternative retraining techniques. Weight rewinding (as proposed by Frankle et al., (2019)), rewinds unpruned weights to their values from earlier in training and retrains them from there using the original training schedule. Learning rate rewinding (which we propose) trains the unpruned weights from their final values using the same learning rate schedule as weight rewinding. Both rewinding techniques outperform fine-tuning, forming the basis of a network-agnostic pruning algorithm that matches the accuracy and compression ratios of several more network-specific state-of-the-art techniques.", "venue": "ICLR", "authors": ["Alex  Renda", "Jonathan  Frankle", "Michael  Carbin"], "year": 2020, "n_citations": 124}
{"id": 3407330, "s2_id": "bc41762eac59dbada40bac457b02af1cc02ca920", "title": "Graph Neural Networks to Predict Customer Satisfaction Following Interactions with a Corporate Call Center", "abstract": "Customer satisfaction is an important factor in creating and maintaining long-term relationships with customers. Near real-time identification of potentially dissatisfied customers following phone calls can provide organizations the opportunity to take meaningful interventions and to foster ongoing customer satisfaction and loyalty. This work describes a fully operational system we have developed at a large US company for predicting customer satisfaction following incoming phone calls. The system takes as an input speech-to-text transcriptions of calls and predicts call satisfaction reported by customers on post-call surveys (scale from 1 to 10). Because of its ordinal, subjective, and often highly-skewed nature, predicting survey scores is not a trivial task and presents several modeling challenges. We introduce a graph neural network (GNN) approach that takes into account the comparative nature of the problem by considering the relative scores among batches, instead of only pairs of calls when training. This approach produces more accurate predictions than previous approaches including standard regression and classification models that directly fit the survey scores with call data. Our proposed approach can be easily generalized to other customer satisfaction prediction problems.", "venue": "ArXiv", "authors": ["Teja  Kanchinadam", "Zihang  Meng", "Joseph  Bockhorst", "Vikas  Singh", "Glenn  Fung"], "year": 2021, "n_citations": 0}
{"id": 3408098, "s2_id": "1ef315032a8c6c32ecb6741c1f90598616f18d68", "title": "SISA: Securing Images by Selective Alteration", "abstract": "With an increase in mobile and camera devices\u2019 popularity, digital content in the form of images has increased drastically. As personal life is being continuously documented in pictures, the risk of losing it to eavesdroppers is a matter of grave concern. Secondary storage is the most preferred medium for the storage of personal and other images. Our work is concerned with the security of such images. While encryption is the best way to ensure image security, full encryption and decryption is a computationally-intensive process. Moreover, as cameras are getting better every day, image quality, and thus, the pixel density has increased considerably. The increased pixel density makes encryption and decryption more expensive. We, therefore, delve into selective encryption and selective blurring based on the region of interest. Instead of encrypting or blurring the entire photograph, we only encode selected regions of the image. We present a comparative analysis of the partial and full encryption of the photos. This kind of encoding will help us lower the encryption overhead without compromising security. The applications utilizing this technique will become more usable due to the reduction in the decryption time. Additionally, blurred images being more readable than encrypted ones, allowed us to define the level of security. We leverage the machine learning algorithms like Mask-RCNN (Region-based convolutional neural network) and YOLO (You Only Look Once) to select the region of interest. These algorithms have set new benchmarks for object recognition. We develop an end to end system to demonstrate our idea of selective encryption.", "venue": "ArXiv", "authors": ["Prutha  Gaherwar", "Shraddha  Joshi", "Raviraj  Joshi", "Rahul  Khengare"], "year": 2021, "n_citations": 0}
{"id": 3413271, "s2_id": "37278f60ce066f4a2ba2f4665c892c5e95a721f2", "title": "Explainable AI: current status and future directions", "abstract": "Explainable Artificial Intelligence (XAI) is an emerging area of research in the field of Artificial Intelligence (AI). XAI can explain how AI obtained a particular solution (e.g., classification or object detection) and can also answer other \"wh\" questions. This explainability is not possible in traditional AI. Explainablity is essential for critical applications, such as defence, health care, law and order, and autonomous driving vehicles, etc, where the know how is required for trust and transparency. A number of XAI techniques so far have been purposed for such applications. This paper provides an overview of these techniques from a multimedia (i.e., text, image, audio, and video) point of view. Advantages and shortcomings of these techniques have been discussed, and pointers to some future directions have also been provided. INDEX TERMS Explainable Artificial Intelligence (XAI), Explainability, Interpretable Artificial Intelligence.", "venue": "ArXiv", "authors": ["Prashant  Gohel", "Priyanka  Singh", "Manoranjan  Mohanty"], "year": 2021, "n_citations": 0}
{"id": 3435212, "s2_id": "91bf4e7a6be0c20a1e33ecc5b6f75453f5c20b1e", "title": "Deep convolutional generative adversarial networks for traffic data imputation encoding time series as images", "abstract": "Sufficient high-quality traffic data are a crucial component of various Intelligent Transportation System (ITS) applications and research related to congestion prediction, speed prediction, incident detection, and other traffic operation tasks. Nonetheless, missing traffic data are a common issue in sensor data which is inevitable due to several reasons, such as malfunctioning, poor maintenance or calibration, and intermittent communications. Such missing data issues often make data analysis and decision-making complicated and challenging. In this study, we have developed a generative adversarial network (GAN) based traffic sensor data imputation framework (TSDIGAN) to efficiently reconstruct the missing data by generating realistic synthetic data. In recent years, GANs have shown impressive success in image data generation. However, generating traffic data by taking advantage of GAN based modeling is a challenging task, since traffic data have strong time dependency. To address this problem, we propose a novel time-dependent encoding method called the Gramian Angular Summation Field (GASF) that converts the problem of traffic time-series data generation into that of image generation. We have evaluated and tested our proposed model using the benchmark dataset provided by Caltrans Performance Management Systems (PeMS). This study shows that the proposed model can significantly improve the traffic data imputation accuracy in terms of Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) compared to state-of-the-art models on the benchmark dataset. Further, the model achieves reasonably high accuracy in imputation tasks even under a very high missing data rate ($>$ 50\\%), which shows the robustness and efficiency of the proposed model.", "venue": "International Journal of Transportation Science and Technology", "authors": ["Tongge  Huang", "Pranamesh  Chakraborty", "Anuj  Sharma"], "year": 2021, "n_citations": 1}
{"id": 3436474, "s2_id": "5f392561552741d9e6aba1951bc7663e3698d417", "title": "The Platform Design Problem", "abstract": "On-line firms deploy suites of software platforms, where each platform is designed to interact with users during a certain activity, such as browsing, chatting, socializing, emailing, driving, etc. The economic and incentive structure of this exchange, as well as its algorithmic nature, have not been explored to our knowledge; we initiate their study in this paper. We model this interaction as a Stackelberg game between a Designer and one or more Agents. We model an Agent as a Markov chain whose states are activities; we assume that the Agent's utility is a linear function of the steady-state distribution of this chain. The Designer may design a platform for each of these activities/states; if a platform is adopted by the Agent, the transition probabilities of the Markov chain are affected, and so is the objective of the Agent. The Designer's utility is a linear function of the steady state probabilities of the accessible states (that is, the ones for which the platform has been adopted), minus the development cost of the platforms. The underlying optimization problem of the Agent -- that is, how to choose the states for which to adopt the platform -- is an MDP. If this MDP has a simple yet plausible structure (the transition probabilities from one state to another only depend on the target state and the recurrent probability of the current state) the Agent's problem can be solved by a greedy algorithm. The Designer's optimization problem (designing a custom suite for the Agent so as to optimize, through the Agent's optimum reaction, the Designer's revenue), while NP-hard, has an FPTAS. These results generalize, under mild additional assumptions, from a single Agent to a distribution of Agents with finite support. The Designer's optimization problem has abysmal \"price of robustness\", suggesting that learning the parameters of the problem is crucial for the Designer.", "venue": "ArXiv", "authors": ["Christos  Papadimitriou", "Kiran  Vodrahalli", "Mihalis  Yannakakis"], "year": 2020, "n_citations": 0}
{"id": 3438325, "s2_id": "65926a0e95437bc1c986954478b3f8ff017ea609", "title": "Model Explanations under Calibration", "abstract": "Explaining and interpreting the decisions of recommender systems are becoming extremely relevant both, for improving predictive performance, and providing valid explanations to users. While most of the recent interest has focused on providing local explanations, there has been a much lower emphasis on studying the effects of model dynamics and its impact on explanation. In this paper, we perform a focused study on the impact of model interpretability in the context of calibration. Specifically, we address the challenges of both over-confident and under-confident predictions with interpretability using attention distribution. Our results indicate that the means of using attention distributions for interpretability are highly unstable for un-calibrated models. Our empirical analysis on the stability of attention distribution raises questions on the utility of attention for explainability.", "venue": "ArXiv", "authors": ["Rishabh  Jain", "Pranava  Madhyastha"], "year": 2019, "n_citations": 1}
{"id": 3443450, "s2_id": "1074b3790f801695566b53e081040acfb404a7c8", "title": "Multi-Label Learning with Deep Forest", "abstract": "In multi-label learning, each instance is associated with multiple labels and the crucial task is how to leverage label correlations in building models. Deep neural network methods usually jointly embed the feature and label information into a latent space to exploit label correlations. However, the success of these methods highly depends on the precise choice of model depth. Deep forest is a recent deep learning framework based on tree model ensembles, which does not rely on backpropagation. We consider the advantages of deep forest models are very appropriate for solving multi-label problems. Therefore we design the Multi-Label Deep Forest (MLDF) method with two mechanisms: measure-aware feature reuse and measure-aware layer growth. The measure-aware feature reuse mechanism reuses the good representation in the previous layer guided by confidence. The measure-aware layer growth mechanism ensures MLDF gradually increase the model complexity by performance measure. MLDF handles two challenging problems at the same time: one is restricting the model complexity to ease the overfitting issue; another is optimizing the performance measure on user's demand since there are many different measures in the multi-label evaluation. Experiments show that our proposal not only beats the compared methods over six measures on benchmark datasets but also enjoys label correlation discovery and other desired properties in multi-label learning.", "venue": "ECAI", "authors": ["Liang  Yang", "Xi-Zhu  Wu", "Yuan  Jiang", "Zhi-Hua  Zhou"], "year": 2020, "n_citations": 10}
{"id": 3445651, "s2_id": "a4a6edb8768fc519e0b7edcc3bb1301b89771d49", "title": "Representation Edit Distance as a Measure of Novelty", "abstract": "Adaptation to novelty is viewed as learning to change and augment existing skills to confront unfamiliar situations. In this paper, we propose that the amount of editing of an effective representation (the Representation Edit Distance or RED) used in a set of skill programs in an agent\u2019s mental model is a measure of difficulty for adaptation to novelty. The RED is an intuitive approximation to the change in information content in bit strings measured by comparing pre-novelty and postnovelty skill programs. We also present some notional examples of how to use RED for predicting difficulty. 1 Framework for adaptation to novelty", "venue": "ArXiv", "authors": ["Joshua  Alspector"], "year": 2021, "n_citations": 0}
{"id": 3451605, "s2_id": "9d3772a8472e6c6c6569607b3738c708eee16032", "title": "Supervised Discrete Hashing With Relaxation", "abstract": "Data-dependent hashing has recently attracted attention due to being able to support efficient retrieval and storage of high-dimensional data, such as documents, images, and videos. In this paper, we propose a novel learning-based hashing method called \u201csupervised discrete hashing with relaxation\u201d (SDHR) based on \u201csupervised discrete hashing\u201d (SDH). SDH uses ordinary least squares regression and traditional zero-one matrix encoding of class label information as the regression target (code words), thus fixing the regression target. In SDHR, the regression target is instead optimized. The optimized regression target matrix satisfies a large margin constraint for correct classification of each example. Compared with SDH, which uses the traditional zero-one matrix, SDHR utilizes the learned regression target matrix and, therefore, more accurately measures the classification error of the regression model and is more flexible. As expected, SDHR generally outperforms SDH. Experimental results on two large-scale image data sets (CIFAR-10 and MNIST) and a large-scale and challenging face data set (FRGC) demonstrate the effectiveness and efficiency of SDHR.", "venue": "IEEE Transactions on Neural Networks and Learning Systems", "authors": ["Jie  Gui", "Tongliang  Liu", "Zhenan  Sun", "Dacheng  Tao", "Tieniu  Tan"], "year": 2018, "n_citations": 51}
{"id": 3455380, "s2_id": "bd3e810e61657c4aadf35cef7a9bb6abc4e78689", "title": "Adaptive Partial Scanning Transmission Electron Microscopy with Reinforcement Learning", "abstract": "Compressed sensing is applied to scanning transmission electron microscopy to decrease electron dose and scan time. However, established methods use static sampling strategies that do not adapt to samples. We have extended recurrent deterministic policy gradients to train deep LSTMs and differentiable neural computers to adaptively sample scan path segments. Recurrent agents cooperate with a convolutional generator to complete partial scans. We show that our approach outperforms established algorithms based on spiral scans, and we expect our results to be generalizable to other scan systems. Source code, pretrained models and training data is available at this https URL.", "venue": "Machine Learning: Science and Technology", "authors": ["Jeffrey M. Ede"], "year": 2021, "n_citations": 2}
{"id": 3458333, "s2_id": "b48473b2ba2c953da2aa8f3c0d91feef976d7946", "title": "Learning offline: memory replay in biological and artificial reinforcement learning", "abstract": "Learning to act in an environment to maximise rewards is among the brain's key functions. This process has often been conceptualised within the framework of reinforcement learning, which has also gained prominence in machine learning and artificial intelligence (AI) as a way to optimise decision making. A common aspect of both biological and machine reinforcement learning is the reactivation of previously experienced episodes, referred to as replay. Replay is important for memory consolidation in biological neural networks and is key to stabilising learning in deep neural networks. Here, we review recent developments concerning the functional roles of replay in the fields of neuroscience and AI. Complementary progress suggests how replay might support learning processes, including generalisation and continual learning, affording opportunities to transfer knowledge across the two fields to advance the understanding of biological and artificial learning and memory.", "venue": "Trends in Neurosciences", "authors": ["Emma L. Roscow", "Raymond  Chua", "Rui Ponte Costa", "Matt W. Jones", "Nathan  Lepora"], "year": 2021, "n_citations": 3}
{"id": 3477205, "s2_id": "47b54e3e965ab4fb003ebb8057d7b12afb106de1", "title": "Generative Adversarial Networks for Bitcoin Data Augmentation", "abstract": "In Bitcoin entity classification, results are strongly conditioned by the ground-truth dataset, especially when applying supervised machine learning approaches. However, these ground-truth datasets are frequently affected by significant class imbalance as generally they contain much more information regarding legal services (Exchange, Gambling), than regarding services that may be related to illicit activities (Mixer, Service). Class imbalance increases the complexity of applying machine learning techniques and reduces the quality of classification results, especially for underrepresented, but critical classes.In this paper, we propose to address this problem by using Generative Adversarial Networks (GANs) for Bitcoin data augmentation as GANs recently have shown promising results in the domain of image classification. However, there is no \u201cone-fits-all\u201d GAN solution that works for every scenario. In fact, setting GAN training parameters is non-trivial and heavily affects the quality of the generated synthetic data. We therefore evaluate how GAN parameters such as the optimization function, the size of the dataset and the chosen batch size affect GAN implementation for one underrepresented entity class (Mining Pool) and demonstrate how a \u201cgood\u201d GAN configuration can be obtained that achieves high similarity between synthetically generated and real Bitcoin address data. To the best of our knowledge, this is the first study presenting GANs as a valid tool for generating synthetic address data for data augmentation in Bitcoin entity classification.", "venue": "2020 2nd Conference on Blockchain Research & Applications for Innovative Networks and Services (BRAINS)", "authors": ["Francesco  Zola", "Jan Lukas Bruse", "Xabier Etxeberria Barrio", "Mikel  Galar", "Raul Orduna Urrutia"], "year": 2020, "n_citations": 0}
{"id": 3480394, "s2_id": "a290824efa4ec2839d9b97fe52814ea865a661bd", "title": "Pseudo-Encoded Stochastic Variational Inference", "abstract": "Posterior inference in directed graphical models is commonly done using a probabilistic encoder (a.k.a inference model) conditioned on the input. Often this inference model is trained jointly with the probabilistic decoder (a.k.a generator model). If probabilistic encoder encounters complexities during training (e.g. suboptimal complxity or parameterization), then learning reaches a suboptimal objective; a phenomena commonly called inference suboptimality. In Variational Inference (VI), optimizing the ELBo using Stochastic Variational Inference (SVI) can eliminate the inference suboptimality (as demonstrated in this paper), however, this solution comes at a substantial computational cost when inference needs to be done on new data points. Essentially, a long sequential chain of gradient updates is required to fully optimize approximate posteriors. In this paper, we present an approach called Pseudo-Encoded Stochastic Variational Inference (PE-SVI), to reduce the inference complexity of SVI during test time. Our approach relies on finding a suitable initial start point for gradient operations, which naturally reduces the required gradient steps. Furthermore, this initialization allows for adopting larger step sizes (compared to random initialization used in SVI), which further reduces the inference time complexity. PE-SVI reaches the same ELBo objective as SVI using less than one percent of required steps, on average.", "venue": "ArXiv", "authors": ["Amir  Zadeh", "Smon  Hessner", "Yao-Chong  Lim", "Louis-Phlippe  Morency"], "year": 2019, "n_citations": 0}
{"id": 3487440, "s2_id": "9ea36f68f36d39d4901897d8c7b22bd392017bdc", "title": "Practical Multi-fidelity Bayesian Optimization for Hyperparameter Tuning", "abstract": "Bayesian optimization is popular for optimizing time-consuming black-box objectives. Nonetheless, for hyperparameter tuning in deep neural networks, the time required to evaluate the validation error for even a few hyperparameter settings remains a bottleneck. Multi-fidelity optimization promises relief using cheaper proxies to such objectives --- for example, validation error for a network trained using a subset of the training points or fewer iterations than required for convergence. We propose a highly flexible and practical approach to multi-fidelity Bayesian optimization, focused on efficiently optimizing hyperparameters for iteratively trained supervised learning models. We introduce a new acquisition function, the trace-aware knowledge-gradient, which efficiently leverages both multiple continuous fidelity controls and trace observations --- values of the objective at a sequence of fidelities, available when varying fidelity using training iterations. We provide a provably convergent method for optimizing our acquisition function and show it outperforms state-of-the-art alternatives for hyperparameter tuning of deep neural networks and large-scale kernel learning.", "venue": "UAI", "authors": ["Jian  Wu", "Saul  Toscano-Palmerin", "Peter I. Frazier", "Andrew Gordon Wilson"], "year": 2019, "n_citations": 45}
{"id": 3503662, "s2_id": "29d22a4939e3497d5a9b6a3e1c47584854a46000", "title": "Spatio-Temporal Graph Scattering Transform", "abstract": "Although spatio-temporal graph neural networks have achieved great empirical success in handling multiple correlated time series, they may be impractical in some real-world scenarios due to a lack of sufficient high-quality training data. Furthermore, spatio-temporal graph neural networks lack theoretical interpretation. To address these issues, we put forth a novel mathematically designed framework to analyze spatio-temporal data. Our proposed spatio-temporal graph scattering transform (ST-GST) extends traditional scattering transforms to the spatio-temporal domain. It performs iterative applications of spatio-temporal graph wavelets and nonlinear activation functions, which can be viewed as a forward pass of spatio-temporal graph convolutional networks without training. Since all the filter coefficients in ST-GST are mathematically designed, it is promising for the real-world scenarios with limited training data, and also allows for a theoretical analysis, which shows that the proposed ST-GST is stable to small perturbations of input signals and structures. Finally, our experiments show that i) ST-GST outperforms spatio-temporal graph convolutional networks by an increase of 35% in accuracy for MSR Action3D dataset; ii) it is better and computationally more efficient to design the transform based on separable spatio-temporal graphs than the joint ones; and iii) the nonlinearity in ST-GST is critical to empirical performance.", "venue": "ICLR", "authors": ["Chao  Pan", "Siheng  Chen", "Antonio  Ortega"], "year": 2021, "n_citations": 2}
{"id": 3507952, "s2_id": "64421cbac57e607d5e522d762129e4c8439df0cb", "title": "SONG: Self-Organizing Neural Graphs", "abstract": "Recent years have seen a surge in research on deep interpretable neural networks with decision trees as one of the most commonly incorporated tools. There are at least three advantages of using decision trees over logistic regression classification models: they are easy to interpret since they are based on binary decisions, they can make decisions faster, and they provide a hierarchy of classes. However, one of the well-known drawbacks of decision trees, as compared to decision graphs, is that decision trees cannot reuse the decision nodes. Nevertheless, decision graphs were not commonly used in deep learning due to the lack of efficient gradient-based training techniques. In this paper, we fill this gap and provide a general paradigm based on Markov processes, which allows for efficient training of the special type of decision graphs, which we call Self-Organizing Neural Graphs (SONG). We provide an extensive theoretical study of SONG, complemented by experiments conducted on Letter, Connect4, MNIST, CIFAR, and TinyImageNet datasets, showing that our method performs on par or better than existing decision models.", "venue": "ArXiv", "authors": ["Lukasz  Struski", "Tomasz  Danel", "Marek  'Smieja", "Jacek  Tabor", "Bartosz  Zieli'nski"], "year": 2021, "n_citations": 0}
{"id": 3526140, "s2_id": "9936f70be81d7458473d819d6231f84ff585870d", "title": "Fuzzy k-Nearest Neighbors with monotonicity constraints: Moving towards the robustness of monotonic noise", "abstract": "This paper proposes a new model based on Fuzzy k-Nearest Neighbors for classification with monotonic constraints, Monotonic Fuzzy k-NN (MonFkNN). Real-life data-sets often do not comply with monotonic constraints due to class noise. MonFkNN incorporates a new calculation of fuzzy memberships, which increases robustness against monotonic noise without the need for relabeling. Our proposal has been designed to be adaptable to the different needs of the problem being tackled. In several experimental studies, we show significant improvements in accuracy while matching the best degree of monotonicity obtained by comparable methods. We also show that MonFkNN empirically achieves improved performance compared with Monotonic k-NN in the presence of large amounts of class noise.", "venue": "Neurocomputing", "authors": ["Sergio  Gonz'alez", "Salvador  Garc'ia", "Sheng-Tun  Li", "Robert  John", "Francisco  Herrera"], "year": 2021, "n_citations": 3}
{"id": 3534255, "s2_id": "fcca8ad57cdcf11b802e015c85631ae3b67553f7", "title": "On the exact relationship between the denoising function and the data distribution", "abstract": "We prove an exact relationship between the optimal denoising function and the data distribution in the case of additive Gaussian noise, showing that denoising implicitly models the structure of data allowing it to be exploited in the unsupervised learning of representations. This result generalizes a known relationship [2], which is valid only in the limit of small corruption noise.", "venue": "ArXiv", "authors": ["Heikki  Arponen", "Matti  Herranen", "Harri  Valpola"], "year": 2017, "n_citations": 3}
{"id": 3535229, "s2_id": "658993ad3d9903ddc91eabb9a3507199c58c124e", "title": "Emphatic Algorithms for Deep Reinforcement Learning", "abstract": "Off-policy learning allows us to learn about possible policies of behavior from experience generated by a different behavior policy. Temporal difference (TD) learning algorithms can become unstable when combined with function approximation and off-policy sampling\u2014this is known as the \u201cdeadly triad\u201d. Emphatic temporal difference (ETD(\u03bb)) algorithm ensures convergence in the linear case by appropriately weighting the TD(\u03bb) updates. In this paper, we extend the use of emphatic methods to deep reinforcement learning agents. We show that naively adapting ETD(\u03bb) to popular deep reinforcement learning algorithms, which use forward view multi-step returns, results in poor performance. We then derive new emphatic algorithms for use in the context of such algorithms, and we demonstrate that they provide noticeable benefits in small problems designed to highlight the instability of TD methods. Finally, we observed improved performance when applying these algorithms at scale on classic Atari games from the Arcade Learning Environment. Off-policy learning, whereby an agent learns from behavior that differs from its current policy, affords an agent opportunities to accumulate rich knowledge (Degris & Modayil, 2012) by learning about the effect of different policies of behaviors. This can also be extended to learn about different goals, e.g., by learning general value functions (Sutton et al., 2011) for cumulants that differ from the main task reward. Unfortunately, it is well known that reinforcement learning algorithms (Sutton & Barto, 2018) can become unstable when combining function approximation, off-policy learning, and bootstrapping (Tsitsiklis & Van Roy, 1997)\u2014for this reason such combination is referred to as the deadly triad (Sutton & Barto, 2018; van Hasselt et al., 2018). DeepMind, London, UK. Amii, Department of Computing Science, University of Alberta. Correspondence to: Ray Jiang <rayjiang@google.com>. Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s). Many reinforcement learning (RL) agents learn off-policy to some extent, to learn about the greedy policy while exploring (Watkins, 1989), to make predictions about policies simultaneously (Sutton et al., 2011; Zahavy et al., 2020; Jaderberg et al., 2017), to improve sample complexity via experience replay (Lin, 1992; Mnih et al., 2015), or even just to correct for the latency introduced by distributed computation (Espeholt et al., 2018). Since these algorithms make use of bootstrapping and function approximation, they may suffer from deadly triad symptoms of \u201csoft divergence\u201d and slow convergence (van Hasselt et al., 2018). The ETD(\u03bb) algorithm (Sutton et al., 2016) ensures convergence with linear function approximation (Yu, 2015) by weighting the updates of TD(\u03bb) (in the backward view, with eligibility traces). However, combining eligibility traces and deep neural networks can be challenging (Sutton, 1987)1, and thus widely used deep RL systems instead typically use n-step forward view methods. Overall, none of the existing solutions to the deadly triad (Sutton et al., 2009; 2016) have become standard practice in deep RL. In this paper, we extend the emphatic method to multi-step deep RL learning targets, including an off-policy value-learning method known as \u2018V-trace\u2019 (Espeholt et al., 2018) that is often used in actor-critic systems. The structure of this paper is the following. Sec. 1 explains the background on forward view learning targets and ETD(\u03bb). Next we adapt ETD(\u03bb) to the forward view in Sec. 2.1, and derive a new multi-step emphatic trace for n-step TD in Sec. 2.2. We discuss further algorithmic considerations in Sec. 2.3, including extensions for variance reduction, for the V-trace value learning target and for the actor critic learning algorithms. Empirically, we provide an in-depth comparison of their qualitative properties on small diagnostic MDPs in Sec. 3. Finally, we demonstrate that combining emphatic trace with deep neural networks can improve performance on classic Atari video games in Sec. 4, reporting the highest score to date for an RL agent without experience replay in the 200M frames data regime: 497% median human normalized score across 57 games, improved from the baseline performance of 403%. See van Hasselt et al. (2021) for recent developments. Emphatic Algorithms for Deep Reinforcement Learning", "venue": "ICML", "authors": ["Ray  Jiang", "Tom  Zahavy", "Zhongwen  Xu", "Adam  White", "Matteo  Hessel", "Charles  Blundell", "Hado van Hasselt"], "year": 2021, "n_citations": 2}
{"id": 3549360, "s2_id": "de9e7d6319b26c0d9f0da20c79403e9b9367fff4", "title": "BERT as a Teacher: Contextual Embeddings for Sequence-Level Reward", "abstract": "Measuring the quality of a generated sequence against a set of references is a central problem in many learning frameworks, be it to compute a score, to assign a reward, or to perform discrimination. Despite great advances in model architectures, metrics that scale independently of the number of references are still based on n-gram estimates. We show that the underlying operations, counting words and comparing counts, can be lifted to embedding words and comparing embeddings. An in-depth analysis of BERT embeddings shows empirically that contextual embeddings can be employed to capture the required dependencies while maintaining the necessary scalability through appropriate pruning and smoothing techniques. We cast unconditional generation as a reinforcement learning problem and show that our reward function indeed provides a more effective learning signal than n-gram reward in this challenging setting.", "venue": "ArXiv", "authors": ["Florian  Schmidt", "Thomas  Hofmann"], "year": 2020, "n_citations": 4}
{"id": 3560188, "s2_id": "a0304d3c4dfa8cd4c48bf7cae82c6c31ba4b957e", "title": "Surveillance of COVID-19 Pandemic using Hidden Markov Model", "abstract": "COVID-19 pandemic has brought the whole world to a stand-still over the last few months. In particular the pace at which pandemic has spread has taken everybody off-guard. The Governments across the world have responded by imposing lock-downs, stopping/restricting travel and mandating social distancing. On the positive side there is wide availability of information on active cases, recoveries and deaths collected daily across regions. However, what has been particularly challenging is to track the spread of the disease by asymptomatic carriers termed as super-spreaders. In this paper we look at applying Hidden Markov Model to get a better assessment of extent of spread. The outcome of such analysis can be useful to Governments to design the required interventions/responses in a calibrated manner. The data we have chosen to analyze pertains to Indian scenario.", "venue": "ArXiv", "authors": ["Shreekanth M. Prabhu", "Natarajan  Subramanyam"], "year": 2020, "n_citations": 2}
{"id": 3564826, "s2_id": "b610d3d3c374cfc5aeb021b218195ff15713a3a3", "title": "RPN: A Residual Pooling Network for Efficient Federated Learning", "abstract": "Federated learning is a distributed machine learning framework which enables different parties to collaboratively train a model while protecting data privacy and security. Due to model complexity, network unreliability and connection in-stability, communication cost has became a major bottleneck for applying federated learning to real-world applications. Current existing strategies are either need to manual setting for hyperparameters, or break up the original process into multiple steps, which make it hard to realize end-to-end implementation. In this paper, we propose a novel compression strategy called Residual Pooling Network (RPN). Our experiments show that RPN not only reduce data transmission effectively, but also achieve almost the same performance as compared to standard federated learning. Our new approach performs as an end-to-end procedure, which should be readily applied to all CNN-based model training scenarios for improvement of communication efficiency, and hence make it easy to deploy in real-world application without much human intervention.", "venue": "ECAI", "authors": ["Anbu  Huang", "Yuanyuan  Chen", "Yang  Liu", "Tianjian  Chen", "Qiang  Yang"], "year": 2020, "n_citations": 2}
{"id": 3572410, "s2_id": "3e465fef2e077d1a1eb110aea0b98e3d7a1f3abb", "title": "Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study of COVID-19 Infodemic", "abstract": "The spreading of COVID-19 misinformation over social media already draws the attention of many researchers. According to Google Scholar, about 26000 COVID-19 related misinformation studies have been published to date. Most of these studies focus on 1) detection and/or 2) analysing the characteristics of COVID-19 related misinformation. However, the study of the social behaviours related to misinformation is often neglected. In this paper, we introduce a fine-grained annotated misinformation tweets dataset including social behaviours annotation (e.g. comment or question to the misinformation). The dataset not only allows social behaviours analysis but is also suitable for both an evidence-based or non-evidence-based misinformation classification task. In addition, we introduce \u2019leave claim out\u2019 validation in our experiments and demonstrate that misinformation classification performance could be significantly different when applying to real-world unseen misinformation.", "venue": "ArXiv", "authors": ["Ye  Jiang", "Xingyi  Song", "Carolina  Scarton", "Ahmet  Aker", "Kalina  Bontcheva"], "year": 2021, "n_citations": 1}
{"id": 3596893, "s2_id": "533fb9cb19d26d97b6588b9fd573a0f3498505b3", "title": "Incremental knowledge base construction using DeepDive", "abstract": "Populating a database with information from unstructured sources\u2014also known as knowledge base construction (KBC)\u2014is a long-standing problem in industry and research that encompasses problems of extraction, cleaning, and integration. In this work, we describe DeepDive, a system that combines database and machine learning ideas to help develop KBC systems, and we present techniques to make the KBC process more efficient. We observe that the KBC process is iterative, and we develop techniques to incrementally produce inference results for KBC systems. We propose two methods for incremental inference, based, respectively, on sampling and variational techniques. We also study the trade-off space of these methods and develop a simple rule-based optimizer. DeepDive includes all of these contributions, and we evaluate DeepDive on five KBC systems, showing that it can speed up KBC inference tasks by up to two orders of magnitude with negligible impact on quality.", "venue": "The VLDB Journal", "authors": ["Christopher De Sa", "Alexander  Ratner", "Christopher  R\u00e9", "Jaeho  Shin", "Feiran  Wang", "Sen  Wu", "Ce  Zhang"], "year": 2016, "n_citations": 189}
{"id": 3598978, "s2_id": "dfa2fe00291a69d5fe982a6d980f35a8e58b0de6", "title": "MiME: Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare", "abstract": "Deep learning models exhibit state-of-the-art performance for many predictive healthcare tasks using electronic health records (EHR) data, but these models typically require training data volume that exceeds the capacity of most healthcare systems. External resources such as medical ontologies are used to bridge the data volume constraint, but this approach is often not directly applicable or useful because of inconsistencies with terminology. To solve the data insufficiency challenge, we leverage the inherent multilevel structure of EHR data and, in particular, the encoded relationships among medical codes. We propose Multilevel Medical Embedding (MiME) which learns the multilevel embedding of EHR data while jointly performing auxiliary prediction tasks that rely on this inherent EHR structure without the need for external labels. We conducted two prediction tasks, heart failure prediction and sequential disease prediction, where MiME outperformed baseline methods in diverse evaluation settings. In particular, MiME consistently outperformed all baselines when predicting heart failure on datasets of different volumes, especially demonstrating the greatest performance improvement (15% relative gain in PR-AUC over the best baseline) on the smallest dataset, demonstrating its ability to effectively model the multilevel structure of EHR data.", "venue": "NeurIPS", "authors": ["Edward  Choi", "Cao  Xiao", "Walter F. Stewart", "Jimeng  Sun"], "year": 2018, "n_citations": 113}
{"id": 3603974, "s2_id": "fe8fc7a86b064e85d9726a0b4b1749afcee908cf", "title": "An Information-Theoretic Framework for Identifying Age-Related Genes Using Human Dermal Fibroblast Transcriptome Data", "abstract": "Investigation of age-related genes is of great importance for multiple purposes, for instance, improving our understanding of the mechanism of ageing, increasing life expectancy, age prediction, and other healthcare applications. In this work, starting with a set of 27,142 genes, we develop an information-theoretic framework for identifying genes that are associated with aging by applying unsupervised and semisupervised learning techniques on human dermal fibroblast gene expression data. First, we use unsupervised learning and apply information-theoretic measures to identify key features for effective representation of gene expression values in the transcriptome data. Using the identified features, we perform clustering on the data. Finally, we apply semi-supervised learning on the clusters using different distance measures to identify novel genes that are potentially associated with aging. Performance assessment for both unsupervised and semi-supervised methods show the effectiveness of the framework.", "venue": "ArXiv", "authors": ["Salman  Mohamadi", "Donald  Adjeroh"], "year": 2021, "n_citations": 0}
{"id": 3608122, "s2_id": "669a6f4d4f196d91a77ee01f30fbb9011470cad7", "title": "An Encoding Framework With Brain Inner State for Natural Image Identification", "abstract": "Neural encoding and decoding, which aim to characterize the relationship between stimuli and brain activities, have emerged as an important area in cognitive neuroscience. Traditional encoding models, which focus on feature extraction and mapping, consider the brain as an input\u2013output mapper without inner states. In this article, inspired by the fact that the human brain acts like a state machine, we proposed a novel encoding framework that combines information from both the external world and the inner state to predict brain activity. The framework comprises two parts: 1) forward encoding model that deals with visual stimuli and 2) inner state model that captures influence from intrinsic connections in the brain. The forward model can be any traditional encoding model, making the framework flexible. The inner state model is a linear model to utilize information in the prediction residuals of the forward model. The proposed encoding framework achieved much better performance on natural image identification than forward-only models, with a maximum identification accuracy of 100%. The identification accuracy decreased slightly with the data set size increasing, but remained relatively stable with different identification methods. The results confirm that the new encoding framework is effective and robust when used for brain decoding.", "venue": "IEEE Transactions on Cognitive and Developmental Systems", "authors": ["Hao  Wu", "Ziyu  Zhu", "Jiayi  Wang", "Nanning  Zheng", "Badong  Chen"], "year": 2021, "n_citations": 0}
{"id": 3614299, "s2_id": "a6f8acee1f0c1f044bf898a92558e647e4bbad0f", "title": "Mixed Strategy Game Model Against Data Poisoning Attacks", "abstract": "In this paper we use game theory to model poisoning attack scenarios. We prove the non-existence of pure strategy Nash Equilibrium in the attacker and defender game. We then propose a mixed extension of our game model and an algorithm to approximate the Nash Equilibrium strategy for the defender. We then demonstrate the effectiveness of the mixed defence strategy generated by the algorithm, in an experiment.", "venue": "2019 49th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)", "authors": ["Yifan  Ou", "Reza  Samavi"], "year": 2019, "n_citations": 2}
{"id": 3632701, "s2_id": "85209a1dd0fb0335a1b3549c9abcddf4d2352081", "title": "Reinforcement Learning for General LTL Objectives Is Intractable", "abstract": "In recent years, researchers have made significant progress in devising reinforcement-learning algorithms for optimizing linear temporal logic (LTL) objectives and LTL-like objectives. Despite these advancements, there are fundamental limitations to how well this problem can be solved that previous studies have alluded to but, to our knowledge, have not examined in depth. In this paper, we address theoretically the hardness of learning with general LTL objectives. We formalize the problem under the probably approximately correct learning in Markov decision processes (PAC-MDP) framework, a standard framework for measuring sample complexity in reinforcement learning. In this formalization, we prove that the optimal policy for any LTL formula is PAC-MDPlearnable only if the formula is in the most limited class in the LTL hierarchy, consisting of only finite-horizon-decidable properties. Practically, our result implies that it is impossible for a reinforcement-learning algorithm to obtain a PACMDP guarantee on the performance of its learned policy after finitely many interactions with an unconstrained environment for non-finite-horizon-decidable LTL objectives.", "venue": "ArXiv", "authors": ["Cambridge  Yang", "Michael  Littman", "Michael  Carbin"], "year": 2021, "n_citations": 0}
{"id": 3634095, "s2_id": "15daf08191360a1f14c1ebaf4585f13a0fe0ccff", "title": "Asymmetric Graph Representation Learning", "abstract": "Despite the enormous success of graph neural networks (GNNs), most existing GNNs can only be applicable to undirected graphs where relationships among connected nodes are two-way symmetric (i.e., information can be passed back and forth). However, there is a vast amount of applications where the information flow is asymmetric, leading to directed graphs where information can only be passed in one direction. For example, a directed edge indicates that the information can only be conveyed forwardly from the start node to the end node, but not backwardly. To accommodate such an asymmetric structure of directed graphs within the framework of GNNs, we propose a simple yet remarkably effective framework for directed graph analysis to incorporate such one-way information passing. We define an incoming embedding and an outgoing embedding for each node to model its sending and receiving features respectively. We further develop two steps in our directed GNN model with the first one to aggregate/update the incoming features of nodes and the second one to aggregate/update the outgoing features. By imposing the two roles for each node, the likelihood of a directed edge can be calculated based on the outgoing embedding of the start node and the incoming embedding of the end node. The loglikelihood of all edges plays a natural role of regularization for the proposed model, which can alleviate the oversmoothing problem of the deep GNNs. Extensive experiments on multiple real-world directed graphs demonstrate outstanding performances of the proposed model in both node-level and graph-level tasks.", "venue": "ArXiv", "authors": ["Zhuo  Tan", "Bin  Liu", "Guosheng  Yin"], "year": 2021, "n_citations": 0}
{"id": 3638394, "s2_id": "6042883a898e33dcc56cc84885fafad139ed1de3", "title": "Machine Identification of High Impact Research through Text and Image Analysis", "abstract": "The volume of academic paper submissions and publications is growing at an ever increasing rate. While this flood of research promises progress in various fields, the sheer volume of output inherently increases the amount of noise. We present a system to automatically separate papers with a high from those with a low likelihood of gaining citations as a means to quickly find high impact, high quality research. Our system uses both a visual classifier, useful for surmising a document's overall appearance, and a text classifier, for making content-informed decisions. Current work in the field focuses on small datasets composed of papers from individual conferences. Attempts to use similar techniques on larger datasets generally only considers excerpts of the documents such as the abstract, potentially throwing away valuable data. We rectify these issues by providing a dataset composed of PDF documents and citation counts spanning a decade of output within two separate academic domains: computer science and medicine. This new dataset allows us to expand on current work in the field by generalizing across time and academic domain. Moreover, we explore inter-domain prediction models - evaluating a classifier's performance on a domain it was not trained on - to shed further insight on this important problem.", "venue": "2017 IEEE Third International Conference on Multimedia Big Data (BigMM)", "authors": ["Marko  Stamenovic", "Sam  Schick", "Jiebo  Luo"], "year": 2017, "n_citations": 2}
{"id": 3640293, "s2_id": "d6f06d2a07fcb9429c0b3b7b97e71e77e2f8bd6b", "title": "Algorithmic Concept-based Explainable Reasoning", "abstract": "Recent research on graph neural network (GNN) models successfully applied GNNs to classical graph algorithms and combinatorial optimisation problems. This has numerous benefits, such as allowing applications of algorithms when preconditions are not satisfied, or reusing learned models when sufficient training data is not available or can\u2019t be generated. Unfortunately, a key hindrance of these approaches is their lack of explainability, since GNNs are black-box models that cannot be interpreted directly. In this work, we address this limitation by applying existing work on concept-based explanations to GNN models. We introduce conceptbottleneck GNNs, which rely on a modification to the GNN readout mechanism. Using three case studies we demonstrate that: (i) our proposed model is capable of accurately learning concepts and extracting propositional formulas based on the learned concepts for each target class; (ii) our concept-based GNN models achieve comparative performance with state-of-the-art models; (iii) we can derive global graph concepts, without explicitly providing any supervision on graph-level concepts.", "venue": "ArXiv", "authors": ["Dobrik  Georgiev", "Pietro  Barbiero", "Dmitry  Kazhdan", "Petar  Velivckovi'c", "Pietro  Lio"], "year": 2021, "n_citations": 0}
{"id": 3641284, "s2_id": "6a33350790e3b39ee16effe6f6573690cc0ead7e", "title": "Bayesian Treatment of Incomplete Discrete Data applied to Mutual Information and Feature Selection", "abstract": "Given the joint chances of a pair of random variables one can compute quantities of interest, like the mutual information. The Bayesian treatment of unknown chances involves computing, from a second order prior distribution and the data likelihood, a posterior distribution of the chances. A common treatment of incomplete data is to assume ignorability and determine the chances by the expectation maximization (EM) algorithm. The two different methods above are well established but typically separated. This paper joins the two approaches in the case of Dirichlet priors, and derives efficient approximations for the mean, mode and the (co)variance of the chances and the mutual information. Furthermore, we prove the unimodality of the posterior distribution, whence the important property of convergence of EM to the global maximum in the chosen framework. These results are applied to the problem of selecting features for incremental learning and naive Bayes classification. A fast filter based on the distribution of mutual information is shown to outperform the traditional filter based on empirical mutual information on a number of incomplete real data sets.", "venue": "KI", "authors": ["Marcus  Hutter", "Marco  Zaffalon"], "year": 2003, "n_citations": 3}
{"id": 3646438, "s2_id": "dbde7dfa6cae81df8ac19ef500c42db96c3d1edd", "title": "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation", "abstract": "Neural Machine Translation (NMT) is an end-to-end learning approach for automated translation, with the potential to overcome many of the weaknesses of conventional phrase-based translation systems. Unfortunately, NMT systems are known to be computationally expensive both in training and in translation inference. Also, most NMT systems have difficulty with rare words. These issues have hindered NMT's use in practical deployments and services, where both accuracy and speed are essential. In this work, we present GNMT, Google's Neural Machine Translation system, which attempts to address many of these issues. Our model consists of a deep LSTM network with 8 encoder and 8 decoder layers using attention and residual connections. To improve parallelism and therefore decrease training time, our attention mechanism connects the bottom layer of the decoder to the top layer of the encoder. To accelerate the final translation speed, we employ low-precision arithmetic during inference computations. To improve handling of rare words, we divide words into a limited set of common sub-word units (\"wordpieces\") for both input and output. This method provides a good balance between the flexibility of \"character\"-delimited models and the efficiency of \"word\"-delimited models, naturally handles translation of rare words, and ultimately improves the overall accuracy of the system. Our beam search technique employs a length-normalization procedure and uses a coverage penalty, which encourages generation of an output sentence that is most likely to cover all the words in the source sentence. On the WMT'14 English-to-French and English-to-German benchmarks, GNMT achieves competitive results to state-of-the-art. Using a human side-by-side evaluation on a set of isolated simple sentences, it reduces translation errors by an average of 60% compared to Google's phrase-based production system.", "venue": "ArXiv", "authors": ["Yonghui  Wu", "Mike  Schuster", "Zhifeng  Chen", "Quoc V. Le", "Mohammad  Norouzi", "Wolfgang  Macherey", "Maxim  Krikun", "Yuan  Cao", "Qin  Gao", "Klaus  Macherey", "Jeff  Klingner", "Apurva  Shah", "Melvin  Johnson", "Xiaobing  Liu", "Lukasz  Kaiser", "Stephan  Gouws", "Yoshikiyo  Kato", "Taku  Kudo", "Hideto  Kazawa", "Keith  Stevens", "George  Kurian", "Nishant  Patil", "Wei  Wang", "Cliff  Young", "Jason  Smith", "Jason  Riesa", "Alex  Rudnick", "Oriol  Vinyals", "Gregory S. Corrado", "Macduff  Hughes", "Jeffrey  Dean"], "year": 2016, "n_citations": 4198}
{"id": 3652413, "s2_id": "a40a162bf864bc29eada2483a782fecb6d816227", "title": "Semi-supervised deep learning for high-dimensional uncertainty quantification", "abstract": "Conventional uncertainty quantification methods usually lacks the capability of dealing with high-dimensional problems due to the curse of dimensionality. This paper presents a semi-supervised learning framework for dimension reduction and reliability analysis. An autoencoder is first adopted for mapping the high-dimensional space into a low-dimensional latent space, which contains a distinguishable failure surface. Then a deep feedforward neural network (DFN) is utilized to learn the mapping relationship and reconstruct the latent space, while the Gaussian process (GP) modeling technique is used to build the surrogate model of the transformed limit state function. During the training process of the DFN, the discrepancy between the actual and reconstructed latent space is minimized through semi-supervised learning for ensuring the accuracy. Both labeled and unlabeled samples are utilized for defining the loss function of the DFN. Evolutionary algorithm is adopted to train the DFN, then the Monte Carlo simulation method is used for uncertainty quantification and reliability analysis based on the proposed framework. The effectiveness is demonstrated through a mathematical example.", "venue": "DAC 2020", "authors": ["Zequn  Wang", "Mingyang  Li"], "year": 2020, "n_citations": 0}
{"id": 3657765, "s2_id": "49df015b8e349e37c189c5acad88cbf236ea488b", "title": "Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning", "abstract": "This paper initiates the theoretical study of policy finetuning towards bridging the gap between (sample-efficient) online RL and offline RL. In this problem, the online RL learner has additional access to a \u201creference policy\u201d \u03bc close to the optimal policy \u03c0? in a certain sense. We first design a sharp offline reduction algorithm\u2014which simply executes \u03bc and runs offline policy optimization on the collected dataset\u2014that finds an \u03b5 near-optimal policy within \u00d5(HSC/\u03b5) episodes, where C is the single-policy concentrability coefficient between \u03bc and \u03c0?. This offline result is the first that matches the sample complexity lower bound in this setting, and resolves a recent open question in offline RL. We then establish an \u03a9(HSmin{C, A}/\u03b5) sample complexity lower bound for any policy finetuning algorithm, including those that can adaptively explore the environment. This implies that\u2014 perhaps surprisingly\u2014the optimal policy finetuning algorithm is either offline reduction or a purely online RL algorithm that does not use \u03bc. Finally, we design a new hybrid offline/online algorithm for policy finetuning that achieves better sample complexity than both vanilla offline reduction and purely online RL algorithms, in a relaxed setting where \u03bc only satisfies concentrability partially up to a certain time step. Overall, our results offer a quantitative understanding on the benefit of a good reference policy, and make a step towards bridging offline and online RL.", "venue": "ArXiv", "authors": ["Tengyang  Xie", "Nan  Jiang", "Huan  Wang", "Caiming  Xiong", "Yu  Bai"], "year": 2021, "n_citations": 5}
{"id": 3659596, "s2_id": "6a5e0c5063cceb8321c0ddf8117586b04ba8b291", "title": "Community Detection and Improved Detectability in Multiplex Networks", "abstract": "We investigate the widely encountered problem of detecting communities in multiplex networks, such as social networks, with an unknown arbitrary heterogeneous structure. To improve detectability, we propose a generative model that leverages the multiplicity of a single community in multiple layers, with no prior assumption on the relation of communities among different layers. Our model relies on a novel idea of incorporating a large set of generic localized community label constraints across the layers, in conjunction with the celebrated Stochastic Block Model (SBM) in each layer. Accordingly, we build a probabilistic graphical model over the entire multiplex network by treating the constraints as Bayesian priors. We mathematically prove that these constraints/priors promote existence of identical communities across layers without introducing further correlation between individual communities. The constraints are further tailored to render a sparse graphical model and the numerically efficient Belief Propagation algorithm is subsequently employed. We further demonstrate by numerical experiments that in the presence of consistent communities between different layers, consistent communities are matched, and the detectability is improved over a single layer. We compare our model with a \u201ccorrelated model\u201d which exploits the prior knowledge of community correlation between layers. Similar detectability improvement is obtained under such a correlation, even though our model relies on much milder assumptions than the correlated model. Our model even shows a better detection performance over a certain correlation and signal to noise ratio (SNR) range. In the absence of community correlation, the correlation model naturally fails, while ours maintains its performance.", "venue": "IEEE Transactions on Network Science and Engineering", "authors": ["Yuming  Huang", "Ashkan  Panahi", "Hamid  Krim", "Liyi  Dai"], "year": 2020, "n_citations": 7}
{"id": 3666609, "s2_id": "b86b850b8546fb1d9625e9a19c4119684273c537", "title": "Autonomous discovery of battery electrolytes with robotic experimentation and machine-learning", "abstract": "\n \n \n Innovations in batteries take years to formulate, requiring extensive experimentation during the design and optimization phases. We approach the design of a battery electrolyte as\na black-box optimization problem. We report here the discovery of a novel battery electrolyte by a robotic electrolyte experiment guided by machine-learning software. Motivated\nby the recent trend toward super-concentrated aqueous electrolytes for high-performance\nbatteries, we utilize Dragonfly - a Bayesian machine-learning software package - to search\nmixtures of commonly used lithium and sodium salts for super-concentrated aqueous electrolytes with wide electrochemical stability windows. Dragonfly autonomously managed the\nrobotic test-stand, recommending electrolyte designs to test and receiving experimental feed-\nback in real time. Within 40 hours of continuous experimentation, Dragonfly discovered a\nnovel, high-performing aqueous sodium electrolyte that a human-guided design process may\nhave missed. This result demonstrates the possibility of integrating robotics with machine-learning to rapidly and autonomously discover novel battery materials.", "venue": "ArXiv", "authors": ["Adarsh  Dave", "Jared  Mitchell", "Kirthevasan  Kandasamy", "Sven  Burke", "Biswajit  Paria", "Barnabas  Poczos", "Jay  Whitacre", "Venkatasubramanian  Viswanathan"], "year": 2020, "n_citations": 14}
{"id": 3667767, "s2_id": "d037b1666dea95be5f40b075ff1676b6fa23121f", "title": "Divergence-Based Motivation for Online EM and Combining Hidden Variable Models", "abstract": "Expectation-Maximization (EM) is a prominent approach for parameter estimation of hidden (aka latent) variable models. Given the full batch of data, EM forms an upper-bound of the negative log-likelihood of the model at each iteration and updates to the minimizer of this upper-bound. We first provide a \"model level\" interpretation of the EM upper-bound as sum of relative entropy divergences to a set of singleton models, induced by the set of observations. Our alternative motivation unifies the \"observation level\" and the \"model level\" view of the EM. As a result, we formulate an online version of the EM algorithm by adding an analogous inertia term which corresponds to the relative entropy divergence to the old model. Our motivation is more widely applicable than the previous approaches and leads to simple online updates for mixture of exponential distributions, hidden Markov models, and the first known online update for Kalman filters. Additionally, the finite sample form of the inertia term lets us derive online updates when there is no closed-form solution. Finally, we extend the analysis to the distributed setting where we motivate a systematic way of combining multiple hidden variable models. Experimentally, we validate the results on synthetic as well as real-world datasets.", "venue": "UAI", "authors": ["Ehsan  Amid", "Manfred K. Warmuth"], "year": 2020, "n_citations": 3}
{"id": 3671974, "s2_id": "af85fa6837eac0a72f6ce22cd83643748ed7508f", "title": "XAI Handbook: Towards a Unified Framework for Explainable AI", "abstract": "The field of explainable AI (XAI) has quickly become a thriving and prolific community. However, a silent, recurrent and acknowledged issue in this area is the lack of consensus regarding its terminology. In particular, each new contribution seems to rely on its own (and often intuitive) version of terms like \"explanation\" and \"interpretation\". Such disarray encumbers the consolidation of advances in the field towards the fulfillment of scientific and regulatory demands e.g., when comparing methods or establishing their compliance w.r.t. biases and fairness constraints. We propose a theoretical framework that not only provides concrete definitions for these terms, but it also outlines all steps necessary to produce explanations and interpretations. The framework also allows for existing contributions to be re-contextualized such that their scope can be measured, thus making them comparable to other methods. We show that this framework is compliant with desiderata on explanations, on interpretability and on evaluation metrics. We present a use-case showing how the framework can be used to compare LIME, SHAP and MDNet, establishing their advantages and shortcomings. Finally, we discuss relevant trends in XAI as well as recommendations for future work, all from the standpoint of our framework.", "venue": "2021 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)", "authors": ["Sebastian  Palacio", "Adriano  Lucieri", "Mohsin  Munir", "Jorn  Hees", "Sheraz  Ahmed", "Andreas  Dengel"], "year": 2021, "n_citations": 0}
{"id": 3672328, "s2_id": "e8d5aff1ac52a60d6d598d3fc8621735536eeba2", "title": "Distance Metric Learning for Graph Structured Data", "abstract": "Graphs are versatile tools for representing structured data. Therefore, a variety of machine learning methods have been studied for graph data analysis. Although many of those learning methods depend on the measurement of differences between input graphs, defining an appropriate distance metric for a graph remains a controversial issue. Hence, we propose a supervised distance metric learning method for the graph classification problem. Our method, named interpretable graph metric learning (IGML), learns discriminative metrics in a subgraph-based feature space, which has a strong graph representation capability. By introducing a sparsity-inducing penalty on a weight of each subgraph, IGML can identify a small number of important subgraphs that can provide insight about the given classification task. Since our formulation has a large number of optimization variables, an efficient algorithm is also proposed by using pruning techniques based on safe screening and working set selection methods. An important property of IGML is that the optimality of the solution is guaranteed because the problem is formulated as a convex problem and our pruning strategies only discard unnecessary subgraphs. Further, we show that IGML is also applicable to other structured data such as item-set and sequence data, and that it can incorporate vertex-label similarity by using a transportation-based subgraph feature. We empirically evaluate the computational efficiency and classification performance on several benchmark datasets and show some illustrative examples demonstrating that IGML identifies important subgraphs from a given graph dataset.", "venue": "Mach. Learn.", "authors": ["Tomoki  Yoshida", "Ichiro  Takeuchi", "Masayuki  Karasuyama"], "year": 2021, "n_citations": 2}
{"id": 3675659, "s2_id": "c4e962869cdf8744791450aca9474677569574b6", "title": "Learning to Select Base Classes for Few-Shot Classification", "abstract": "Few-shot learning has attracted intensive research attention in recent years. Many methods have been proposed to generalize a model learned from provided base classes to novel classes, but no previous work studies how to select base classes, or even whether different base classes will result in different generalization performance of the learned model. In this paper, we utilize a simple yet effective measure, the Similarity Ratio, as an indicator for the generalization performance of a few-shot model. We then formulate the base class selection problem as a submodular optimization problem over Similarity Ratio. We further provide theoretical analysis on the optimization lower bound of different optimization methods, which could be used to identify the most appropriate algorithm for different experimental settings. The extensive experiments on ImageNet, Caltech256 and CUB-200-2011 demonstrate that our proposed method is effective in selecting a better base dataset.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Linjun  Zhou", "Peng  Cui", "Xu  Jia", "Shiqiang  Yang", "Qi  Tian"], "year": 2020, "n_citations": 11}
{"id": 3689879, "s2_id": "6e4bccf768dba72150034fd5359d2539ca220f68", "title": "Domain Constraint Approximation based Semi Supervision", "abstract": "Deep learning for supervised learning has achieved astonishing performance in various machine learning applications. However, annotated data is expensive and rare. In practice, only a small portion of data samples are annotated. Pseudo-ensembling-based approaches have achieved state-of-the-art results in computer vision related tasks. However, it still relies on the quality of an initial model built by labeled data. Less labeled data may degrade model performance a lot. Domain constraint is another way regularize the posterior but has some limitation. In this paper, we proposed a fuzzy domain-constraint-based framework which loses the requirement of traditional constraint learning and enhances the model quality for semi supervision. Simulations results show the effectiveness of our design.", "venue": "ArXiv", "authors": ["Yifu  Wu", "Jin  Wei", "Rigoberto  Roche'"], "year": 2019, "n_citations": 0}
{"id": 3691784, "s2_id": "c9fd57acd55b0ae9473a4e918b72d38fc6296b9e", "title": "Continual Learning of Generative Models with Limited Data: From Wasserstein-1 Barycenter to Adaptive Coalescence", "abstract": "Learning generative models is challenging for a network edge node with limited data and computing power. Since tasks in similar environments share model similarity, it is plausible to leverage pre-trained generative models from the cloud or other edge nodes. Appealing to optimal transport theory tailored towards Wasserstein-1 generative adversarial networks (WGAN), this study aims to develop a framework which systematically optimizes continual learning of generative models using local data at the edge node while exploiting adaptive coalescence of pre-trained generative models. Specifically, by treating the knowledge transfer from other nodes as Wasserstein balls centered around their pre-trained models, continual learning of generative models is cast as a constrained optimization problem, which is further reduced to a Wasserstein-1 barycenter problem. A two-stage approach is devised accordingly: 1) The barycenters among the pre-trained models are computed offline, where displacement interpolation is used as the theoretic foundation for finding adaptive barycenters via a \u201crecursive\u201d WGAN configuration; 2) the barycenter computed offline is used as meta-model initialization for continual learning and then fast adaptation is carried out to find the generative model using the local samples at the target edge node. Finally, a weight ternarization method, based on joint optimization of weights and threshold for quantization, is developed to compress the generative model further.", "venue": "ArXiv", "authors": ["Mehmet  Dedeoglu", "Sen  Lin", "Zhaofeng  Zhang", "Junshan  Zhang"], "year": 2021, "n_citations": 0}
{"id": 3705076, "s2_id": "5a998e48d440740d403ea891e586e2dc14e175b6", "title": "Efficient end-to-end learning for quantizable representations", "abstract": "Embedding representation learning via neural networks is at the core foundation of modern similarity based search. While much effort has been put in developing algorithms for learning binary hamming code representations for search efficiency, this still requires a linear scan of the entire dataset per each query and trades off the search accuracy through binarization. To this end, we consider the problem of directly learning a quantizable embedding representation and the sparse binary hash code end-to-end which can be used to construct an efficient hash table not only providing significant search reduction in the number of data but also achieving the state of the art search accuracy outperforming previous state of the art deep metric learning methods. We also show that finding the optimal sparse binary hash code in a mini-batch can be computed exactly in polynomial time by solving a minimum cost flow problem. Our results on Cifar-100 and on ImageNet datasets show the state of the art search accuracy in precision@k and NMI metrics while providing up to 98X and 478X search speedup respectively over exhaustive linear search. The source code is available at this https URL", "venue": "ICML", "authors": ["Yeonwoo  Jeong", "Hyun Oh Song"], "year": 2018, "n_citations": 7}
{"id": 3723384, "s2_id": "cc05edfa486d33554b645d96c763a7bb4c285f36", "title": "Bond Default Prediction with Text Embeddings, Undersampling and Deep Learning", "abstract": "The special and important problems of default prediction for municipal bonds are addressed using a combination of text embeddings from a pre-trained transformer network, a fully connected neural network, and synthetic oversampling. The combination of these techniques provides significant improvement in performance over human estimates, linear models, and boosted ensemble models, on data with extreme imbalance. Less than 0.2% of municipal bonds default, but our technique predicts 9 out of 10 defaults at the time of issue, without using bond ratings, at a cost of false positives on less than 0.1% non-defaulting bonds. The results hold the promise of reducing the cost of capital for local public goods, which are vital for society, and bring techniques previously used in personal credit and public equities (or national fixed income), as well as the current generation of embedding techniques, to sub-sovereign credit decisions.", "venue": "ArXiv", "authors": ["Luke  Jordan"], "year": 2021, "n_citations": 0}
{"id": 3737960, "s2_id": "ae4580fd859934472cf3794ba595045d4dee1624", "title": "Solving differential equations with unknown constitutive relations as recurrent neural networks", "abstract": "We solve a system of ordinary differential equations with an unknown functional form of a sink (reaction rate) term. We assume that the measurements (time series) of state variables are partially available, and we use recurrent neural network to \"learn\" the reaction rate from this data. This is achieved by including a discretized ordinary differential equations as part of a recurrent neural network training problem. We extend TensorFlow's recurrent neural network architecture to create a simple but scalable and effective solver for the unknown functions, and apply it to a fedbatch bioreactor simulation problem. Use of techniques from recent deep learning literature enables training of functions with behavior manifesting over thousands of time steps. Our networks are structurally similar to recurrent neural networks, but differences in design and function require modifications to the conventional wisdom about training such networks.", "venue": "ArXiv", "authors": ["Tobias  Hagge", "Panos  Stinis", "Enoch  Yeung", "Alexandre M. Tartakovsky"], "year": 2017, "n_citations": 13}
{"id": 3745554, "s2_id": "14ccc04f63e273f36b1c8c2c51c65cada4be60e3", "title": "Classification of Diabetic Retinopathy Severity in Fundus Images with DenseNet121 and ResNet50", "abstract": "In this work, deep learning algorithms are used to classify fundus images in terms of diabetic retinopathy severity. Six different combinations of two model architectures, the Dense Convolutional Network-121 and the Residual Neural Network-50 and three image types, RGB, Green, and High Contrast, were tested to find the highest performing combination. We achieved an average validation loss of 0.17 and a max validation accuracy of 85 percent. By testing out multiple combinations, certain combinations of parameters performed better than others, though minimal variance was found overall. Green filtration was shown to perform the poorest, while amplified contrast appeared to have a negligible effect in comparison to RGB analysis. ResNet50 proved to be less of a robust model as opposed to DenseNet121.", "venue": "ArXiv", "authors": ["Jonathan  Zhang", "Bowen  Xie", "Xin  Wu", "Rahul  Ram", "David  Liang"], "year": 2021, "n_citations": 0}
{"id": 3756402, "s2_id": "196cdc1f86749418f928bab241cc79ec7c14ce53", "title": "Softmax Gradient Tampering: Decoupling the Backward Pass for Improved Fitting", "abstract": "We introduce Softmax Gradient Tampering, a technique for modifying the gradients in the backward pass of neural networks in order to enhance their accuracy. Our approach transforms the predicted probability values using a powerbased probability transformation and then recomputes the gradients in the backward pass. This modification results in a smoother gradient profile, which we demonstrate empirically and theoretically. We do a grid search for the transform parameters on residual networks. We demonstrate that modifying the softmax gradients in ConvNets may result in increased training accuracy, thus increasing the fit across the training data and maximally utilizing the learning capacity of neural networks. We get better test metrics and lower generalization gaps when combined with regularization techniques such as label smoothing. Softmax gradient tampering improves ResNet-50\u2019s test accuracy by 0.52% over the baseline on the ImageNet dataset. Our approach is very generic and may be used across a wide range of different network architectures and datasets.", "venue": "ArXiv", "authors": ["Bishshoy  Das", "Milton  Mondal", "Brejesh  Lall", "Shiv Dutt Joshi", "Sumantra Dutta Roy"], "year": 2021, "n_citations": 0}
{"id": 3758839, "s2_id": "c4f758fcba09ad23140e2c566edb3f40de5d6bd9", "title": "The MeSH-gram Neural Network Model: Extending Word Embedding Vectors with MeSH Concepts for UMLS Semantic Similarity and Relatedness in the Biomedical Domain", "abstract": "Eliciting semantic similarity between concepts in the biomedical domain remains a challenging task. Recent approaches founded on embedding vectors have gained in popularity as they risen to efficiently capture semantic relationships The underlying idea is that two words that have close meaning gather similar contexts. In this study, we propose a new neural network model named MeSH-gram which relies on a straighforward approach that extends the skip-gram neural network model by considering MeSH (Medical Subject Headings) descriptors instead words. Trained on publicly available corpus PubMed MEDLINE, MeSH-gram is evaluated on reference standards manually annotated for semantic similarity. MeSH-gram is first compared to skip-gram with vectors of size 300 and at several windows contexts. A deeper comparison is performed with tewenty existing models. All the obtained results of Spearman's rank correlations between human scores and computed similarities show that MeSH-gram outperforms the skip-gram model, and is comparable to the best methods but that need more computation and external resources.", "venue": "ArXiv", "authors": ["Sa\u00efd  Abdedda\u00efm", "Sylvestre  Vimard", "Lina Fatima Soualmia"], "year": 2018, "n_citations": 5}
{"id": 3769873, "s2_id": "6893fed92bd40ac080f2a1679d8c2790c313b46e", "title": "A Review of Intelligent Practices for Irrigation Prediction", "abstract": "Population growth and increasing droughts are creating unprecedented strain on the continued availability of water resources. Since irrigation is a major consumer of fresh water, wastage of resources in this sector could have strong consequences. To address this issue, irrigation water management and prediction techniques need to be employed effectively and should be able to account for the variabilities present in the environment. The different techniques surveyed in this paper can be classified into two categories: computational and statistical. Computational methods deal with scientific correlations between physical parameters whereas statistical methods involve specific prediction algorithms that can be used to automate the process of irrigation water prediction. These algorithms interpret semantic relationships between the various parameters of temperature, pressure, evapotranspiration etc. and store them as numerical precomputed entities specific to the conditions and the area used as the data for the training corpus used to train it. We focus on reviewing the computational methods used to determine Evapotranspiration and its implications. We compare the efficiencies of different data mining and machine learning methods implemented in this area, such as Logistic Regression, Decision Tress Classifier, SysFor, Support Vector Machine(SVM), Fuzzy Logic techniques, Artifical Neural Networks(ANNs) and various hybrids of Genetic Algorithms (GA) applied to irrigation prediction. We also recommend a possible technique for the same based on its superior results in other such time series analysis tasks.", "venue": "ArXiv", "authors": ["Hans  Krupakar", "Akshay  Jayakumar", "G  Dhivya"], "year": 2016, "n_citations": 3}
{"id": 3775821, "s2_id": "9c47facec14c8e64f37559f5997df2d9ed3a1d38", "title": "Embedding Physics to Learn Spatiotemporal Dynamics from Sparse Data", "abstract": "Modeling nonlinear spatiotemporal dynamical systems has primarily relied on partial differential equations (PDEs) that are typically derived from first principles. However, the explicit formulation of PDEs for many underexplored processes, such as climate systems, biochemical reaction and epidemiology, remains uncertain or partially unknown, where very sparse measurement data is yet available. To tackle this challenge, we propose a novel deep learning architecture that forcibly embedded known physics knowledge in a residual-recurrent \u03a0-block network, to facilitate the learning of the spatiotemporal dynamics in a data-driven manner. The coercive embedding mechanism of physics, fundamentally different from physics-informed neural networks based on loss penalty, ensures the network to rigorously obey given physics. Numerical experiments demonstrate that the resulting learning paradigm that embeds physics possesses remarkable accuracy, robustness, interpretability and generalizability for learning spatiotemporal dynamics.", "venue": "ArXiv", "authors": ["Chengping  Rao", "Hao  Sun", "Yang  Liu"], "year": 2021, "n_citations": 1}
{"id": 3786779, "s2_id": "c2e4f1f96268c77ad57b2e77cc3d3595f4865798", "title": "Training Stable Graph Neural Networks Through Constrained Learning", "abstract": "Graph Neural Networks (GNN) rely on graph convolutions to learn features from network data. GNNs are stable to different types of perturbations of the underlying graph, a property that they inherit from graph filters. In this paper we leverage the stability property of GNNs as a typing point in order to seek for representations that are stable within a distribution. We propose a novel constrained learning approach by imposing a constraint on the stability condition of the GNN within a perturbation of choice. We showcase our framework in real world data, corroborating that we are able to obtain more stable representations while not compromising the overall accuracy of the predictor.", "venue": "ArXiv", "authors": ["Juan  Cervino", "Luana  Ruiz", "Alejandro  Ribeiro"], "year": 2021, "n_citations": 1}
{"id": 3786938, "s2_id": "3a8bd738ef5176132b8e83dc0ceb7c7847530ab6", "title": "Finding trainable sparse networks through Neural Tangent Transfer", "abstract": "Deep neural networks have dramatically transformed machine learning, but their memory and energy demands are substantial. The requirements of real biological neural networks are rather modest in comparison, and one feature that might underlie this austerity is their sparse connectivity. In deep learning, trainable sparse networks that perform well on a specific task are usually constructed using label-dependent pruning criteria. In this article, we introduce Neural Tangent Transfer, a method that instead finds trainable sparse networks in a label-free manner. Specifically, we find sparse networks whose training dynamics, as characterized by the neural tangent kernel, mimic those of dense networks in function space. Finally, we evaluate our label-agnostic approach on several standard classification tasks and show that the resulting sparse networks achieve higher classification performance while converging faster.", "venue": "ICML", "authors": ["Tianlin  Liu", "Friedemann  Zenke"], "year": 2020, "n_citations": 5}
{"id": 3788832, "s2_id": "d89de19619220a55e0fa46385149e43e59952046", "title": "Complex Network Construction for Interactive Image Segmentation Using Particle Competition and Cooperation: A New Approach", "abstract": "In the interactive image segmentation task, the Particle Competition and Cooperation (PCC) model is fed with a complex network, which is built from the input image. In the network construction phase, a weight vector is needed to define the importance of each element in the feature set, which consists of color and location information of the corresponding pixels, thus demanding a specialist\u2019s intervention. The present paper proposes the elimination of the weight vector through modifications in the network construction phase. The proposed model and the reference model, without the use of a weight vector, were compared using 151 images extracted from the Grabcut dataset, the PASCAL VOC dataset and the Alpha matting dataset. Each model was applied 30 times to each image to obtain an error average. These simulations resulted in an error rate of only 0.49% when classifying pixels with the proposed model while the reference model had an error rate of 3.14%. The proposed method also presented less error variation in the diversity of the evaluated images, when compared to the reference model.", "venue": "ICCSA", "authors": ["Jefferson Antonio Ribeiro Passerini", "Fabricio Aparecido Breve"], "year": 2020, "n_citations": 0}
{"id": 3792077, "s2_id": "890079c13dfa2812c0be9c63050a9de74767b3b0", "title": "Adaptive Signal Variances: CNN Initialization Through Modern Architectures", "abstract": "Deep convolutional neural networks (CNN) have achieved the unwavering confidence in its performance on image processing tasks. The CNN architecture constitutes a variety of different types of layers including the convolution layer and the max-pooling layer. CNN practitioners widely understand the fact that the stability of learning depends on how to initialize the model parameters in each layer. Nowadays, no one doubts that the de facto standard scheme for initialization is the so-called Kaiming initialization that has been developed by He et al. The Kaiming scheme was derived from a much simpler model than the currently used CNN structure having evolved since the emergence of the Kaiming scheme. The Kaiming model consists only of the convolution and fully connected layers, ignoring the max-pooling layer and the global average pooling layer. In this study, we derived the initialization scheme again not from the simplified Kaiming model, but precisely from the modern CNN architectures, and empirically investigated how the new initialization method performs compared to the de facto standard ones that are widely used today.", "venue": "ICIP 2021", "authors": ["Takahiko  Henmi", "Esmeraldo Ronnie Rey Zara", "Yoshihiro  Hirohashi", "Tsuyoshi  Kato"], "year": 2020, "n_citations": 0}
{"id": 3795739, "s2_id": "762549d0bb2c60d5f4bb358a19edfc0452ae6039", "title": "What is important about the No Free Lunch theorems?", "abstract": "The No Free Lunch theorems prove that under a uniform distribution over induction problems (search problems or learning problems), all induction algorithms perform equally. As I discuss in this chapter, the importance of the theorems arises by using them to analyze scenarios involving {non-uniform} distributions, and to compare different algorithms, without any assumption about the distribution over problems at all. In particular, the theorems prove that {anti}-cross-validation (choosing among a set of candidate algorithms based on which has {worst} out-of-sample behavior) performs as well as cross-validation, unless one makes an assumption -- which has never been formalized -- about how the distribution over induction problems, on the one hand, is related to the set of algorithms one is choosing among using (anti-)cross validation, on the other. In addition, they establish strong caveats concerning the significance of the many results in the literature which establish the strength of a particular algorithm without assuming a particular distribution. They also motivate a ``dictionary'' between supervised learning and improve blackbox optimization, which allows one to ``translate'' techniques from supervised learning into the domain of blackbox optimization, thereby strengthening blackbox optimization algorithms. In addition to these topics, I also briefly discuss their implications for philosophy of science.", "venue": "ArXiv", "authors": ["David H. Wolpert"], "year": 2020, "n_citations": 4}
{"id": 3797844, "s2_id": "aba478b7a3c65114ec57d450833988a69c647918", "title": "Learning under selective labels in the presence of expert consistency", "abstract": "We explore the problem of learning under selective labels in the context of algorithm-assisted decision making. Selective labels is a pervasive selection bias problem that arises when historical decision making blinds us to the true outcome for certain instances. Examples of this are common in many applications, ranging from predicting recidivism using pre-trial release data to diagnosing patients. In this paper we discuss why selective labels often cannot be effectively tackled by standard methods for adjusting for sample selection bias, even if there are no unobservables. We propose a data augmentation approach that can be used to either leverage expert consistency to mitigate the partial blindness that results from selective labels, or to empirically validate whether learning under such framework may lead to unreliable models prone to systemic discrimination.", "venue": "ArXiv", "authors": ["Maria  De-Arteaga", "Artur  Dubrawski", "Alexandra  Chouldechova"], "year": 2018, "n_citations": 17}
{"id": 3809348, "s2_id": "26877c7dabc4b7f1cb2d6f09a0b98ce2cccc5419", "title": "The association problem in wireless networks: a Policy Gradient Reinforcement Learning approach", "abstract": "The purpose of this paper is to develop a self-optimized association algorithm based on PGRL (Policy Gradient Reinforcement Learning), which is both scalable, stable and robust. The term robust means that performance degradation in the learning phase should be forbidden or limited to predefined thresholds. The algorithm is model-free (as opposed to Value Iteration) and robust (as opposed to Q-Learning). The association problem is modeled as a Markov Decision Process (MDP). The policy space is parameterized. The parameterized family of policies is then used as expert knowledge for the PGRL. The PGRL converges towards a local optimum and the average cost decreases monotonically during the learning process. The properties of the solution make it a good candidate for practical implementation. Furthermore, the robustness property allows to use the PGRL algorithm in an \"always-on\" learning mode.", "venue": "ArXiv", "authors": ["Richard  Combes", "Ilham El Bouloumi", "St\u00e9phane  S\u00e9n\u00e9cal", "Zwi  Altman"], "year": 2013, "n_citations": 2}
{"id": 3811566, "s2_id": "1b548d2a629326930930f806ae8e9a88823070f8", "title": "Human-Robot Collaboration via Deep Reinforcement Learning of Real-World Interactions", "abstract": "We present a robotic setup for real-world testing and evaluation of human-robot and human-human collaborative learning. Leveraging the sample-efficiency of the Soft Actor-Critic algorithm, we have implemented a robotic platform able to learn a non-trivial collaborative task with a human partner, without pre-training in simulation, and using only 30 minutes of real-world interactions. This enables us to study Human-Robot and Human-Human collaborative learning through real-world interactions. We present preliminary results, showing that state-of-the-art deep learning methods can take human-robot collaborative learning a step closer to that of humans interacting with each other.", "venue": "ArXiv", "authors": ["Jonas  Tjomsland", "Ali  Shafti", "A. Aldo Faisal"], "year": 2019, "n_citations": 1}
{"id": 3812014, "s2_id": "2a78862ca731737a082221028402bddf32a0d299", "title": "Exact Recovery of Clusters in Finite Metric Spaces Using Oracle Queries", "abstract": "We investigate the problem of exact cluster recovery using oracle queries. Previous results show that clusters in Euclidean spaces that are convex and separated with a margin can be reconstructed exactly using only O(log n) same-cluster queries, where n is the number of input points. In this work, we study this problem in the more challenging non-convex setting. We introduce a structural characterization of clusters, called (\u03b2, \u03b3)-convexity, that can be applied to any finite set of points equipped with a metric (or even a semimetric, as the triangle inequality is not needed). Using (\u03b2, \u03b3)-convexity, we can translate natural density properties of clusters (which include, for instance, clusters that are strongly non-convex in R) into a graph-theoretic notion of convexity. By exploiting this convexity notion, we design a deterministic algorithm that recovers (\u03b2, \u03b3)-convex clusters using O(k log n+k(6/\u03b2\u03b3)) same-cluster queries, where k is the number of clusters and dens(X) is the density dimension of the semimetric. We show that an exponential dependence on the density dimension is necessary, and we also show that, if we are allowed to makeO(k +k log n) additional queries to a \u201ccluster separation\u201d oracle, then we can recover clusters that have different and arbitrary scales, even when the scale of each cluster is unknown.", "venue": "COLT", "authors": ["Marco  Bressan", "Nicolo  Cesa-Bianchi", "Silvio  Lattanzi", "Andrea  Paudice"], "year": 2021, "n_citations": 3}
{"id": 3814411, "s2_id": "aef22f9681ac458e6fef7dc6cdb89723702923e7", "title": "Single-Training Collaborative Object Detectors Adaptive to Bandwidth and Computation", "abstract": "In the past few years, mobile deep-learning deployment progressed by leaps and bounds, but solutions still struggle to accommodate its severe and fluctuating operational restrictions, which include bandwidth, latency, computation, and energy. In this work, we help to bridge that gap, introducing the first configurable solution for object detection that manages the triple communication-computationaccuracy trade-off with a single set of weights. Our solution shows state-of-the-art results on COCO\u20132017, adding only a minor penalty on the base EfficientDet-D2 architecture. Our design is robust to the choice of base architecture and compressor and should adapt well for future architectures.", "venue": "ArXiv", "authors": ["Juliano S. Assine", "J. C. S. Santos Filho", "Eduardo  Valle"], "year": 2021, "n_citations": 1}
{"id": 3816099, "s2_id": "0ea5daff8b27a855a92e8334899c4b62c2334e6e", "title": "Distributed stochastic optimization for deep learning (thesis)", "abstract": "We study the problem of how to distribute the training of large-scale deep learning models in the parallel computing environment. We propose a new distributed stochastic optimization method called Elastic Averaging SGD (EASGD). We analyze the convergence rate of the EASGD method in the synchronous scenario and compare its stability condition with the existing ADMM method in the round-robin scheme. An asynchronous and momentum variant of the EASGD method is applied to train deep convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Our approach accelerates the training and furthermore achieves better test accuracy. It also requires a much smaller amount of communication than other common baseline approaches such as the DOWNPOUR method. \nWe then investigate the limit in speedup of the initial and the asymptotic phase of the mini-batch SGD, the momentum SGD, and the EASGD methods. We find that the spread of the input data distribution has a big impact on their initial convergence rate and stability region. We also find a surprising connection between the momentum SGD and the EASGD method with a negative moving average rate. A non-convex case is also studied to understand when EASGD can get trapped by a saddle point. \nFinally, we scale up the EASGD method by using a tree structured network topology. We show empirically its advantage and challenge. We also establish a connection between the EASGD and the DOWNPOUR method with the classical Jacobi and the Gauss-Seidel method, thus unifying a class of distributed stochastic optimization methods.", "venue": "ArXiv", "authors": ["Sixin  Zhang"], "year": 2016, "n_citations": 3}
{"id": 3817428, "s2_id": "2c5c50d9b0b9d0bed9d2027d3be72374e21c0c9a", "title": "Towards Deep Industrial Transfer Learning for Anomaly Detection on Time Series Data", "abstract": "Deep learning promises performant anomaly detection on time-variant datasets, but greatly suffers from low availability of suitable training datasets and frequently changing tasks. Deep transfer learning offers mitigation by letting algorithms built upon previous knowledge from different tasks or locations. In this article, a modular deep learning algorithm for anomaly detection on time series datasets is presented that allows for an easy integration of such transfer learning capabilities. It is thoroughly tested on a dataset from a discrete manufacturing process in order to prove its fundamental adequacy towards deep industrial transfer learning - the transfer of knowledge in industrial applications' special environment.", "venue": "2021 26th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA )", "authors": ["Benjamin  Maschler", "Tim  Knodel", "Michael  Weyrich"], "year": 2021, "n_citations": 0}
{"id": 3824228, "s2_id": "f8127c708b94a0ebb52eb4c07421e6add8a9fdbe", "title": "A Probabilistic Representation of DNNs: Bridging Mutual Information and Generalization", "abstract": "Recently, Mutual Information (MI) has attracted attention in bounding the generalization error of Deep Neural Networks (DNNs). However, it is intractable to accurately estimate the MI in DNNs, thus most previous works have to relax the MI bound, which in turn weakens the information theoretic explanation for generalization. To address the limitation, this paper introduces a probabilistic representation of DNNs for accurately estimating the MI. Leveraging the proposed MI estimator, we validate the information theoretic explanation for generalization, and derive a tighter generalization bound than the state-of-the-art relaxations.", "venue": "ArXiv", "authors": ["Xinjie  Lan", "Kenneth  Barner"], "year": 2021, "n_citations": 0}
{"id": 3826569, "s2_id": "033a418872cac4b58c3da4bedf87b4c921bf5526", "title": "Fast Hybrid Cascade for Voxel-based 3D Object Classification", "abstract": "Voxel-based 3D object classification has been frequently studied in recent years. The previous methods often directly convert the classic 2D convolution into a 3D form applied to an object with binary voxel representation. In this paper, we investigate the reason why binary voxel representation is not very suitable for 3D convolution and how to simultaneously improve the performance both in accuracy and speed. We show that by giving each voxel a signed distance value, the accuracy will gain about 30% promotion compared with binary voxel representation using a two-layer fully connected network. We then propose a fast fully connected and convolution hybrid cascade network for voxel-based 3D object classification. This threestage cascade network can divide 3D models into three categories: easy, moderate and hard. Consequently, the mean inference time (0.3ms) can speedup about 5x and 2x compared with the state-of-the-art point cloud and voxel based methods respectively, while achieving the highest accuracy in the latter category of methods (92%). Experiments with ModelNet andMNIST verify the performance of the proposed hybrid cascade network.", "venue": "ArXiv", "authors": ["Hui  Cao", "Jie  Wang", "Yuqi  Liu", "Siyu  Zhang", "Shen  Cai"], "year": 2020, "n_citations": 0}
{"id": 3831514, "s2_id": "b82d167bcbf7ffadf327bd53bba16fa8b51db284", "title": "Towards Efficiently Evaluating the Robustness of Deep Neural Networks in IoT Systems: A GAN-based Method", "abstract": "Intelligent Internet of Things (IoT) systems based on deep neural networks (DNNs) have been widely deployed in the real world. However, DNNs are found to be vulnerable to adversarial examples, which raises people\u2019s concerns about intelligent IoT systems\u2019 reliability and security. Testing and evaluating the robustness of IoT systems becomes necessary and essential. Recently various attacks and strategies have been proposed, but the efficiency problem remains unsolved properly. Existing methods are either computationally extensive or timeconsuming, which is not applicable in practice. In this paper, we propose a novel framework called Attack-Inspired GAN (AI-GAN) to generate adversarial examples conditionally. Once trained, it can generate adversarial perturbations efficiently given input images and target classes. We apply AI-GAN on different datasets in white-box settings, black-box settings and targeted models protected by state-of-the-art defenses. Through extensive experiments, AI-GAN achieves high attack success rates, outperforming existing methods, and reduces generation time significantly. Moreover, for the first time, AI-GAN successfully scales to complex datasets e.g., CIFAR-100 and ImageNet, with about 90% success rates among all classes.", "venue": "IEEE Internet of Things Journal", "authors": ["Tao  Bai", "Jun  Zhao", "Jinlin  Zhu", "Shoudong  Han", "Jiefeng  Chen", "Bo  Li", "Alex  Kot"], "year": 2021, "n_citations": 0}
{"id": 3832256, "s2_id": "c9d3958d236d81f0b3c5e5ffef5cbf472744112a", "title": "Learning Deep Architectures for Interaction Prediction in Structure-based Virtual Screening", "abstract": "We introduce a deep learning architecture for structure-based virtual screening that generates fixed-sized fingerprints of proteins and small molecules by applying learnable atom convolution and softmax operations to each compound separately. These fingerprints are further transformed non-linearly, their inner-product is calculated and used to predict the binding potential. Moreover, we show that widely used benchmark datasets may be insufficient for testing structure-based virtual screening methods that utilize machine learning. Therefore, we introduce a new benchmark dataset, which we constructed based on DUD-E and PDBBind databases.", "venue": "ArXiv", "authors": ["Adam  Gonczarek", "Jakub M. Tomczak", "Szymon  Zareba", "Joanna  Kaczmar", "Piotr  Dabrowski", "Michal J. Walczak"], "year": 2016, "n_citations": 46}
{"id": 3838964, "s2_id": "20f9be018bd9c842523fb8e207920c57f4dd7d78", "title": "Conformal testing in a binary model situation", "abstract": "Conformal testing is a way of testing the IID assumption based on conformal prediction. The topic of this note is computational evaluation of the performance of conformal testing in a model situation in which IID binary observations generated from a Bernoulli distribution are followed by IID binary observations generated from another Bernoulli distribution, with the parameters of the distributions and changepoint unknown. Existing conformal test martingales can be used for this task and work well in simple cases, but their efficiency can be improved greatly.", "venue": "ArXiv", "authors": ["Vladimir  Vovk"], "year": 2021, "n_citations": 5}
{"id": 3852836, "s2_id": "f1fd9611e3fa41ba50b570f14386165b7cbc6f79", "title": "Safety-Oriented Pedestrian Motion and Scene Occupancy Forecasting", "abstract": "In this paper, we address the important problem in self-driving of forecasting multi-pedestrian motion and their shared scene occupancy map, critical for safe navigation. Our contributions are two-fold. First, we advocate for predicting both the individual motions as well as the scene occupancy map in order to effectively deal with missing detections caused by postprocessing, e.g. confidence thresholding and non-maximum suppression. Second, we propose a Scene-Actor Graph Neural Network (SA-GNN) which preserves the relative spatial information of pedestrians via 2D convolution, and captures the interactions among pedestrians within the same scene, including those that have not been detected, via message passing. On two large-scale real-world datasets, nuScenes and ATG4D, we showcase that our scene-occupancy predictions are more accurate and better calibrated than those from state-of-the-art motion forecasting methods, while also matching their performance in pedestrian motion forecasting metrics.", "venue": "ArXiv", "authors": ["Katie  Luo", "Sergio  Casas", "Renjie  Liao", "Xinchen  Yan", "Yuwen  Xiong", "Wenyuan  Zeng", "Raquel  Urtasun"], "year": 2021, "n_citations": 1}
{"id": 3872359, "s2_id": "4c29342faf58ca042fb57c4ad049ce99448b6cf7", "title": "Adversarial Examples in Deep Learning for Multivariate Time Series Regression", "abstract": "Multivariate time series (MTS) regression tasks are common in many real-world data mining applications including finance, cybersecurity, energy, healthcare, prognostics, and many others. Due to the tremendous success of deep learning (DL) algorithms in various domains including image recognition and computer vision, researchers started adopting these techniques for solving MTS data mining problems, many of which are targeted for safety-critical and cost-critical applications. Unfortunately, DL algorithms are known for their susceptibility to adversarial examples which makes the DL regression models for MTS forecasting also vulnerable to those attacks. To the best of our knowledge, no previous work has explored the vulnerability of DL MTS regression models to adversarial time series examples, which is an important step, specifically when the forecasting from such models is used in safety-critical and cost-critical applications. In this work, we leverage existing adversarial attack generation techniques from the image classification domain and craft adversarial multivariate time series examples for three state-of-the-art deep learning regression models, specifically Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU). We evaluate our study using Google stock and household power consumption dataset. The obtained results show that all the evaluated DL regression models are vulnerable to adversarial attacks, transferable, and thus can lead to catastrophic consequences in safety-critical and cost-critical domains, such as energy and finance.", "venue": "2020 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)", "authors": ["Gautam Raj Mode", "Khaza Anuarul Hoque"], "year": 2020, "n_citations": 6}
{"id": 3873768, "s2_id": "4b2afc0cddb0672478fc76c1f9cd50f5b1582d87", "title": "CQ-VAE: Coordinate Quantized VAE for Uncertainty Estimation with Application to Disk Shape Analysis from Lumbar Spine MRI Images", "abstract": "Ambiguity is inevitable in medical images, which often results in different image interpretations (e.g. object boundaries or segmentation maps) from different human experts. Thus, a model that learns the ambiguity and outputs a probability distribution of the target, would be valuable for medical applications to assess the uncertainty of diagnosis. In this paper, we propose a powerful generative model to learn a representation of ambiguity and to generate probabilistic outputs. Our model, named Coordinate Quantization Variational Autoencoder (CQ-VAE) employs a discrete latent space with an internal discrete probability distribution by quantizing the coordinates of a continuous latent space. As a result, the output distribution from CQ-VAE is discrete. During training, Gumbel-Softmax sampling is used to enable backpropagation through the discrete latent space. A matching algorithm is used to establish the correspondence between model-generated samples and \"ground-truth\" samples, which makes a trade-off between the ability to generate new samples and the ability to represent training samples. Besides these probabilistic components to generate possible outputs, our model has a deterministic path to output the best estimation. We demonstrated our method on a lumbar disk image dataset, and the results show that our CQ-VAE can learn lumbar disk shape variation and uncertainty.", "venue": "2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)", "authors": ["Linchen  Qian", "Jiasong  Chen", "Timur  Urakov", "Weiyong  Gu", "Liang  Liang"], "year": 2020, "n_citations": 1}
{"id": 3878180, "s2_id": "b1949b1d42519a62b086c683df243479fc6fdbba", "title": "Adversarial Augmentation Policy Search for Domain and Cross-Lingual Generalization in Reading Comprehension", "abstract": "Reading comprehension models often overfit to nuances of training datasets and fail at adversarial evaluation. Training with adversarially augmented dataset improves robustness against those adversarial attacks but hurts generalization of the models. In this work, we present several effective adversaries and automated data augmentation policy search methods with the goal of making reading comprehension models more robust to adversarial evaluation, but also improving generalization to the source domain as well as new domains and languages. We first propose three new methods for generating QA adversaries, that introduce multiple points of confusion within the context, show dependence on insertion location of the distractor, and reveal the compounding effect of mixing adversarial strategies with syntactic and semantic paraphrasing methods. Next, we find that augmenting the training datasets with uniformly sampled adversaries improves robustness to the adversarial attacks but leads to decline in performance on the original unaugmented dataset. We address this issue via RL and more efficient Bayesian policy search methods for automatically learning the best augmentation policy combinations of the transformation probability for each adversary in a large search space. Using these learned policies, we show that adversarial training can lead to significant improvements in in-domain, out-of-domain, and cross-lingual (German, Russian, Turkish) generalization.", "venue": "FINDINGS", "authors": ["Adyasha  Maharana", "Mohit  Bansal"], "year": 2020, "n_citations": 5}
{"id": 3885836, "s2_id": "e7f2dc1c52dfce9c29f879808c7a6a601845d7bc", "title": "Compressing GANs using Knowledge Distillation", "abstract": "Generative Adversarial Networks (GANs) have been used in several machine learning tasks such as domain transfer, super resolution, and synthetic data generation. State-of-the-art GANs often use tens of millions of parameters, making them expensive to deploy for applications in low SWAP (size, weight, and power) hardware, such as mobile devices, and for applications with real time capabilities. There has been no work found to reduce the number of parameters used in GANs. Therefore, we propose a method to compress GANs using knowledge distillation techniques, in which a smaller \"student\" GAN learns to mimic a larger \"teacher\" GAN. We show that the distillation methods used on MNIST, CIFAR-10, and Celeb-A datasets can compress teacher GANs at ratios of 1669:1, 58:1, and 87:1, respectively, while retaining the quality of the generated image. From our experiments, we observe a qualitative limit for GAN's compression. Moreover, we observe that, with a fixed parameter budget, compressed GANs outperform GANs trained using standard training methods. We conjecture that this is partially owing to the optimization landscape of over-parameterized GANs which allows efficient training using alternating gradient descent. Thus, training an over-parameterized GAN followed by our proposed compression scheme provides a high quality generative model with a small number of parameters.", "venue": "ArXiv", "authors": ["Angeline  Aguinaldo", "Ping-Yeh  Chiang", "Alexander  Gain", "Ameya  Patil", "Kolten  Pearson", "Soheil  Feizi"], "year": 2019, "n_citations": 37}
{"id": 3889124, "s2_id": "69ed87322418a7501765b66573840c5d1fa29f3d", "title": "Learning Interaction-Aware Trajectory Predictions for Decentralized Multi-Robot Motion Planning in Dynamic Environments", "abstract": "This letter presents a data-driven decentralized trajectory optimization approach for multi-robot motion planning in dynamic environments. When navigating in a shared space, each robot needs accurate motion predictions of neighboring robots to achieve predictive collision avoidance. These motion predictions can be obtained among robots by sharing their future planned trajectories with each other via communication. However, such communication may not be available nor reliable in practice. In this letter, we introduce a novel trajectory prediction model based on recurrent neural networks (RNN) that can learn multi-robot motion behaviors from demonstrated trajectories generated using a centralized sequential planner. The learned model can run efficiently online for each robot and provide interaction-aware trajectory predictions of its neighbors based on observations of their history states. We then incorporate the trajectory prediction model into a decentralized model predictive control (MPC) framework for multi-robot collision avoidance. Simulation results show that our decentralized approach can achieve a comparable level of performance to a centralized planner while being communication-free and scalable to a large number of robots. We also validate our approach with a team of quadrotors in real-world experiments.", "venue": "IEEE Robotics and Automation Letters", "authors": ["Hai  Zhu", "Francisco Martinez Claramunt", "Bruno  Brito", "Javier  Alonso-Mora"], "year": 2021, "n_citations": 2}
{"id": 3894623, "s2_id": "785d454eab4020c736fe96f91f8ff59800823308", "title": "A Study on the Manifestation of Trust in Speech", "abstract": "Research has shown that trust is an essential aspect of human-computer interaction directly determining the degree to which the person is willing to use a system. An automatic prediction of the level of trust that a user has on a certain system could be used to attempt to correct potential distrust by having the system take relevant actions like, for example, apologizing or explaining its decisions. In this work, we explore the feasibility of automatically detecting the level of trust that a user has on a virtual assistant (VA) based on their speech. Since, to our knowledge, no public databases were available to study the effect of trust in speech, we developed a novel protocol for collecting speech data from subjects induced to have different degrees of trust in the skills of a VA. The protocol consists of an interactive session where the subject is asked to respond to a series of factual questions with the help of a virtual assistant. In order to induce subjects to either trust or distrust the VA\u2019s skills, they are first informed that the VA was previously rated by other users as being either good or bad; subsequently, the VA answers the Lara and Leonardo contributed equally to the paper. Lara focused on the design, implementation and deployment of the data collection protocol as well as data curation. Pablo and Lara worked on the analysis of the collected database. Leonardo worked on the machine learning approaches, experimentation and analysis of results. Silvina helped design the data collection protocol. Jazmin helped with data curation. Agust\u0301\u0131n and Luciana directed the work, with hands-on contributions in the design of the protocol, the code, the machine learning approaches and the experiments. Preprint submitted to Computer Science and Language February 19, 2021 ar X iv :2 10 2. 09 37 0v 1 [ cs .H C ] 9 F eb 2 02 1 subjects\u2019 questions consistently to its alleged abilities. All interactions are speech-based, with subjects and VAs communicating verbally, which allows the recording of speech produced under different trust conditions. Using this protocol, we collected a speech corpus in Argentine Spanish. We show clear evidence that the protocol effectively succeeded in influencing subjects into the desired mental state of either trusting or distrusting the agent\u2019s skills, and present results of a perceptual study of the degree of trust performed by expert listeners. Finally, we found that the subject\u2019s speech can be used to detect which type of VA they were using, which could be considered a proxy for the user\u2019s trust toward the VA\u2019s abilities, with an accuracy up to 76%, compared to a random baseline of 50%. These results are obtained using features that have been previously found useful for detecting speech directed to infants and non-native speakers. The collected speech dataset is publicly available for research use.", "venue": "ArXiv", "authors": ["Lara  Gauder", "Leonardo  Pepino", "Pablo  Riera", "Silvina  Brussino", "Jazm'in  Vidal", "Agust'in  Gravano", "Luciana  Ferrer"], "year": 2021, "n_citations": 0}
{"id": 3896363, "s2_id": "3f0f1dfbecd0779f0cfea5de97dfdecefefb3259", "title": "UCSL : A Machine Learning Expectation-Maximization framework for Unsupervised Clustering driven by Supervised Learning", "abstract": "Subtype Discovery consists in finding interpretable and consistent subparts of a dataset, which are also relevant to a certain supervised task. From a mathematical point of view, this can be defined as a clustering task driven by supervised learning in order to uncover subgroups in line with the supervised prediction. In this paper, we propose a general Expectation-Maximization ensemble framework entitled UCSL (Unsupervised Clustering driven by Supervised Learning). Our method is generic, it can integrate any clustering method and can be driven by both binary classification and regression. We propose to construct a non-linear model by merging multiple linear estimators, one per cluster. Each hyperplane is estimated so that it correctly discriminates or predict only one cluster. We use SVC or Logistic Regression for classification and SVR for regression. Furthermore, to perform cluster analysis within a more suitable space, we also propose a dimension-reduction algorithm that projects the data onto an orthonormal space relevant to the supervised task. We analyze the robustness and generalization capability of our algorithm using synthetic and experimental datasets. In particular, we validate its ability to identify suitable consistent sub-types by conducting a psychiatric-diseases cluster analysis with known ground-truth labels. The gain of the proposed method over previous state-of-theart techniques is about +1.9 points in terms of balanced accuracy. Finally, we make codes and examples available in a scikit-learn-compatible Python package. https://github.com/neurospin-projects/2021 rlouiset ucsl/", "venue": "ECML/PKDD", "authors": ["Robin  Louiset", "Pietro  Gori", "Benoit  Dufumier", "Josselin  Houenou", "Antoine  Grigis", "Edouard  Duchesnay"], "year": 2021, "n_citations": 0}
{"id": 3914234, "s2_id": "e090a0597b4e9df5f9b28c0cb6a91d71280dc4f8", "title": "Network Flow Algorithms for Structured Sparsity", "abstract": "We consider a class of learning problems that involve a structured sparsity-inducing norm defined as the sum of l\u221e-norms over groups of variables. Whereas a lot of effort has been put in developing fast optimization methods when the groups are disjoint or embedded in a specific hierarchical structure, we address here the case of general overlapping groups. To this end, we show that the corresponding optimization problem is related to network flow optimization. More precisely, the proximal problem associated with the norm we consider is dual to a quadratic min-cost flow problem. We propose an efficient procedure which computes its solution exactly in polynomial time. Our algorithm scales up to millions of variables, and opens up a whole new range of applications for structured sparse models. We present several experiments on image and video data, demonstrating the applicability and scalability of our approach for various problems.", "venue": "NIPS", "authors": ["Julien  Mairal", "Rodolphe  Jenatton", "Guillaume  Obozinski", "Francis R. Bach"], "year": 2010, "n_citations": 160}
{"id": 3921477, "s2_id": "7214ccfb116b2d81aa310d2b523370a404192b8b", "title": "A Deep Learning Based Ternary Task Classification System Using Gramian Angular Summation Field in fNIRS Neuroimaging Data", "abstract": "Functional near-infrared spectroscopy (fNIRS) is a non-invasive, economical method used to study its blood flow pattern. These patterns can be used to classify tasks a subject is performing. Currently, most of the classification systems use simple machine learning solutions for the classification of tasks. These conventional machine learning methods, which are easier to implement and interpret, usually suffer from low accuracy and undergo a complex preprocessing phase before network training. The proposed method converts the raw fNIRS time series data into an image using Gramian Angular Summation Field. A Deep Convolutional Neural Network (CNN) based architecture is then used for task classification, including mental arithmetic, motor imagery, and idle state. Further, this method can eliminate the feature selection stage, which affects the traditional classifiers' performance. This system obtained 87.14% average classification accuracy higher than any other method for the dataset.", "venue": "2020 IEEE International Conference on E-health Networking, Application & Services (HEALTHCOM)", "authors": ["Sajila D. Wickramaratne", "Md Shaad Mahmud"], "year": 2021, "n_citations": 2}
{"id": 3942017, "s2_id": "a3c4a6e9bec19d246f6090127c2ed10e9b09e066", "title": "Forecasting Black Sigatoka Infection Risks with Latent Neural ODEs", "abstract": "Black Sigatoka disease severely decreases global banana production, and climate change aggravates the problem by altering fungal species distributions. Due to the heavy financial burden of managing this infectious disease, farmers in developing countries face significant banana crop losses. Though scientists have produced mathematical models of infectious diseases, adapting these models to incorporate climate effects is difficult. We present MR. NODE (Multiple predictoR Neural ODE), a neural network that models the dynamics of black Sigatoka infection learnt directly from data via Neural Ordinary Differential Equations. Our method encodes external predictor factors into the latent space in addition to the variable that we infer, and it can also predict the infection risk at an arbitrary point in time. Empirically, we demonstrate on historical climate data that our method has superior generalization performance on time points up to one month in the future and unseen irregularities. We believe that our method can be a useful tool to control the spread of black Sigatoka.", "venue": "ArXiv", "authors": ["Yuchen  Wang", "Matthieu Chan Chee", "Ziyad  Edher", "Minh Duc Hoang", "Shion  Fujimori", "Sornnujah  Kathirgamanathan", "Jesse  Bettencourt"], "year": 2020, "n_citations": 1}
{"id": 3943477, "s2_id": "b59b84de622467a12b136e051057277c96625f1b", "title": "Efficient Methods for Structured Nonconvex-Nonconcave Min-Max Optimization", "abstract": "The use of min-max optimization in adversarial training of deep neural network classifiers and training of generative adversarial networks has motivated the study of nonconvex-nonconcave optimization objectives, which frequently arise in these applications. Unfortunately, recent results have established that even approximate first-order stationary points of such objectives are intractable, even under smoothness conditions, motivating the study of min-max objectives with additional structure. We introduce a new class of structured nonconvex-nonconcave min-max optimization problems, proposing a generalization of the extragradient algorithm which provably converges to a stationary point. The algorithm applies not only to Euclidean spaces, but also to general $\\ell_p$-normed finite-dimensional real vector spaces. We also discuss its stability under stochastic oracles and provide bounds on its sample complexity. Our iteration complexity and sample complexity bounds either match or improve the best known bounds for the same or less general nonconvex-nonconcave settings, such as those that satisfy variational coherence or in which a weak solution to the associated variational inequality problem is assumed to exist.", "venue": "AISTATS", "authors": ["Jelena  Diakonikolas", "Constantinos  Daskalakis", "Michael I. Jordan"], "year": 2021, "n_citations": 21}
{"id": 3956392, "s2_id": "f7e0f0d051eb9cef1042ae9027422909a63bfee9", "title": "From Dark Matter to Galaxies with Convolutional Networks", "abstract": "Cosmological surveys aim at answering fundamental questions about our Universe, including the nature of dark matter or the reason of unexpected accelerated expansion of the Universe. In order to answer these questions, two important ingredients are needed: 1) data from observations and 2) a theoretical model that allows fast comparison between observation and theory. Most of the cosmological surveys observe galaxies, which are very difficult to model theoretically due to the complicated physics involved in their formation and evolution; modeling realistic galaxies over cosmological volumes requires running computationally expensive hydrodynamic simulations that can cost millions of CPU hours. In this paper, we propose to use deep learning to establish a mapping between the 3D galaxy distribution in hydrodynamic simulations and its underlying dark matter distribution. One of the major challenges in this pursuit is the very high sparsity in the predicted galaxy distribution. To this end, we develop a two-phase convolutional neural network architecture to generate fast galaxy catalogues, and compare our results against a standard cosmological technique. We find that our proposed approach either outperforms or is competitive with traditional cosmological techniques. Compared to the common methods used in cosmology, our approach also provides a nice trade-off between time-consumption (comparable to fastest benchmark in the literature) and the quality and accuracy of the predicted simulation. In combination with current and upcoming data from cosmological observations, our method has the potential to answer fundamental questions about our Universe with the highest accuracy.", "venue": "ArXiv", "authors": ["Xinyue  Zhang", "Yanfang  Wang", "Wei  Zhang", "Yueqiu  Sun", "Siyu  He", "Gabriella  Contardo", "Francisco  Villaescusa-Navarro", "Shirley  Ho"], "year": 2019, "n_citations": 23}
{"id": 3958869, "s2_id": "0132b16590fc162de272fe153f773008bc118eba", "title": "Causally Driven Incremental Multi Touch Attribution Using a Recurrent Neural Network", "abstract": "This paper describes a practical system for Multi Touch Attribution (MTA) for use by a publisher of digital ads. We developed this system for JD.com, an eCommerce company, which is also a publisher of digital ads in China. The approach has two steps. The first step (\u00e2\u20ac\u0153response modeling\u00e2\u20ac ) fits a user-level model for purchase of a product as a function of the user\u00e2\u20ac\u2122s exposure to ads. The second (\u00e2\u20ac\u0153credit allocation\u00e2\u20ac ) uses the fitted model to allocate the incremental part of the observed purchase due to advertising, to the ads the user is exposed to over the previous T days. To implement step one, we train a Recurrent Neural Network (RNN) on user-level conversion and exposure data. The RNN has the advantage of flexibly handling the sequential dependence in the data in a semi-parametric way. The specific RNN formulation we implement captures the impact of advertising intensity, timing, competition, and user-heterogeneity, which are known to be relevant to ad-response. To implement step two, we compute Shapley Values, which have the advantage of having axiomatic foundations and satisfying fairness considerations. The specific formulation of the Shapley Value we implement respects incrementality by allocating the overall incremental improvement in conversion to the exposed ads, while handling the sequence-dependence of exposures on the observed outcomes. The system is under production at JD.com, and scales to handle the high dimensionality of the problem on the platform (attribution of the orders of about 300M users, for roughly 160K brands, across 200+ ad-types, served about 80B ad-impressions over a typical 15-day period).", "venue": "ArXiv", "authors": ["Ruihuan  Du", "Yu  Zhong", "Harikesh S. Nair", "Bo  Cui", "Ruyang  Shou"], "year": 2019, "n_citations": 10}
{"id": 3967008, "s2_id": "e4b7902bee9af53cc7a2445f31338b75bb5ba052", "title": "Exploiting Cross-Lingual Subword Similarities in Low-Resource Document Classification", "abstract": "Text classification must sometimes be applied in a low-resource language with no labeled training data. However, training data may be available in a related language. We investigate whether character-level knowledge transfer from a related language helps text classification. We present a cross-lingual document classification framework (CACO) that exploits cross-lingual subword similarity by jointly training a character-based embedder and a word-based classifier. The embedder derives vector representations for input words from their written forms, and the classifier makes predictions based on the word vectors. We use a joint character representation for both the source language and the target language, which allows the embedder to generalize knowledge about source language words to target language words with similar forms. We propose a multi-task objective that can further improve the model if additional cross-lingual or monolingual resources are available. Experiments confirm that character-level knowledge transfer is more data-efficient than word-level transfer between related languages.", "venue": "AAAI", "authors": ["Mozhi  Zhang", "Yoshinari  Fujinuma", "Jordan L. Boyd-Graber"], "year": 2020, "n_citations": 7}
{"id": 3967232, "s2_id": "4d6c4c861dac14dbb72444f2a1fe367ce83012d2", "title": "ByzShield: An Efficient and Robust System for Distributed Training", "abstract": "Training of large scale models on distributed clusters is a critical component of the machine learning pipeline. However, this training can easily be made to fail if some workers behave in an adversarial (Byzantine) fashion whereby they return arbitrary results to the parameter server (PS). A plethora of existing papers consider a variety of attack models and propose robust aggregation and/or computational redundancy to alleviate the effects of these attacks. In this work we consider an omniscient attack model where the adversary has full knowledge about the gradient computation assignments of the workers and can choose to attack (up to) any q out of n worker nodes to induce maximal damage. Our redundancy-based method ByzShield leverages the properties of bipartite expander graphs for the assignment of tasks to workers; this helps to effectively mitigate the effect of the Byzantine behavior. Specifically, we demonstrate an upper bound on the worst case fraction of corrupted gradients based on the eigenvalues of our constructions which are based on mutually orthogonal Latin squares and Ramanujan graphs. Our numerical experiments indicate over a 36% reduction on average in the fraction of corrupted gradients compared to the state of the art. Likewise, our experiments on training followed by image classification on the CIFAR-10 dataset show that ByzShield has on average a 20% advantage in accuracy under the most sophisticated attacks. ByzShield also tolerates a much larger fraction of adversarial nodes compared to prior work.", "venue": "ArXiv", "authors": ["Konstantinos  Konstantinidis", "Aditya  Ramamoorthy"], "year": 2020, "n_citations": 3}
{"id": 3968742, "s2_id": "4f95c2668bd061a557c597e45b2575766bcd7aec", "title": "Optimal Recovery from Inaccurate Data in Hilbert Spaces: Regularize, but what of the Parameter?", "abstract": "In Optimal Recovery, the task of learning a function from observational data is tackled deterministically by adopting a worst-case perspective tied to an explicit model assumption made on the functions to be learned. Working in the framework of Hilbert spaces, this article considers a model assumption based on approximability. It also incorporates observational inaccuracies modeled via additive errors bounded in `2. Earlier works have demonstrated that regularization provide algorithms that are optimal in this situation, but did not fully identify the desired hyperparameter. This article fills the gap in both a local scenario and a global scenario. In the local scenario, which amounts to the determination of Chebyshev centers, the semidefinite recipe of Beck and Eldar (legitimately valid in the complex setting only) is complemented by a more direct approach, with the proviso that the observational functionals have orthonormal representers. In the said approach, the desired parameter is the solution to an equation that can be resolved via standard methods. In the global scenario, where linear algorithms rule, the parameter elusive in the works of Micchelli et al. is found as the byproduct of a semidefinite program. Additionally and quite surprisingly, in case of observational functionals with orthonormal representers, it is established that any regularization parameter is optimal.", "venue": "ArXiv", "authors": ["Simon  Foucart", "Chunyang  Liao"], "year": 2021, "n_citations": 0}
{"id": 3971739, "s2_id": "7c38e16b011f6ca62de733e098b5233200bd39ff", "title": "Tensor Clustering with Planted Structures: Statistical Optimality and Computational Limits", "abstract": "This paper studies the statistical and computational limits of high-order clustering with planted structures. We focus on two clustering models, constant high-order clustering (CHC) and rank-one higher-order clustering (ROHC), and study the methods and theory for testing whether a cluster exists (detection) and identifying the support of cluster (recovery). \nSpecifically, we identify the sharp boundaries of signal-to-noise ratio for which CHC and ROHC detection/recovery are statistically possible. We also develop the tight computational thresholds: when the signal-to-noise ratio is below these thresholds, we prove that polynomial-time algorithms cannot solve these problems under the computational hardness conjectures of hypergraphic planted clique (HPC) detection and hypergraphic planted dense subgraph (HPDS) recovery. We also propose polynomial-time tensor algorithms that achieve reliable detection and recovery when the signal-to-noise ratio is above these thresholds. Both sparsity and tensor structures yield the computational barriers in high-order tensor clustering. The interplay between them results in significant differences between high-order tensor clustering and matrix clustering in literature in aspects of statistical and computational phase transition diagrams, algorithmic approaches, hardness conjecture, and proof techniques. To our best knowledge, we are the first to give a thorough characterization of the statistical and computational trade-off for such a double computational-barrier problem. Finally, we provide evidence for the computational hardness conjectures of HPC detection and HPDS recovery.", "venue": "ArXiv", "authors": ["Yuetian  Luo", "Anru R. Zhang"], "year": 2020, "n_citations": 20}
{"id": 3984997, "s2_id": "a7da2f44aa205b9b99d8c04d3dfa51c2840b6605", "title": "Stolen Memories: Leveraging Model Memorization for Calibrated White-Box Membership Inference", "abstract": "Membership inference (MI) attacks exploit the fact that machine learning algorithms sometimes leak information about their training data through the learned model. In this work, we study membership inference in the white-box setting in order to exploit the internals of a model, which have not been effectively utilized by previous work. Leveraging new insights about how overfitting occurs in deep neural networks, we show how a model's idiosyncratic use of features can provide evidence for membership to white-box attackers---even when the model's black-box behavior appears to generalize well---and demonstrate that this attack outperforms prior black-box methods. Taking the position that an effective attack should have the ability to provide confident positive inferences, we find that previous attacks do not often provide a meaningful basis for confidently inferring membership, whereas our attack can be effectively calibrated for high precision. Finally, we examine popular defenses against MI attacks, finding that (1) smaller generalization error is not sufficient to prevent attacks on real models, and (2) while small-$\\epsilon$-differential privacy reduces the attack's effectiveness, this often comes at a significant cost to the model's accuracy; and for larger $\\epsilon$ that are sometimes used in practice (e.g., $\\epsilon=16$), the attack can achieve nearly the same accuracy as on the unprotected model.", "venue": "USENIX Security Symposium", "authors": ["Klas  Leino", "Matt  Fredrikson"], "year": 2020, "n_citations": 65}
{"id": 3986498, "s2_id": "b8dd8a835bb7411ad3c82a307961778943b342ad", "title": "DLTPy: Deep Learning Type Inference of Python Function Signatures using Natural Language Context", "abstract": "Due to the rise of machine learning, Python is an increasingly popular programming language. Python, however, is dynamically typed. Dynamic typing has shown to have drawbacks when a project grows, while at the same time it improves developer productivity. To have the benefits of static typing, combined with high developer productivity, types need to be inferred. In this paper, we present DLTPy: a deep learning type inference solution for the prediction of types in function signatures based on the natural language context (identifier names, comments and return expressions) of a function. We found that DLTPy is effective and has a top-3 F1-score of 91.6%. This means that in most of the cases the correct type is within the top-3 predictions. We conclude that natural language contained in comments and return expressions are beneficial to predicting types more accurately. DLTPy does not significantly outperform or underperform the previous work NL2Type for Javascript, but does show that similar prediction is possible for Python.", "venue": "ArXiv", "authors": ["Casper  Boone", "Niels de Bruin", "Arjan  Langerak", "Fabian  Stelmach"], "year": 2019, "n_citations": 3}
{"id": 3999653, "s2_id": "13b66921f396996a7ab2b463c002342b4ce0c546", "title": "Improving the Certified Robustness of Neural Networks via Consistency Regularization", "abstract": "A range of defense methods have been proposed to improve the robustness of neural networks on adversarial examples, among which provable defense methods have been demonstrated to be effective to train neural networks that are certifiably robust to the attacker. However, most of these provable defense methods treat all examples equally during training process, which ignore the inconsistent constraint of certified robustness between correctly classified (natural) and misclassified examples. In this paper, we explore this inconsistency caused by misclassified examples and add a novel consistency regularization term to make better use of the misclassified examples. Specifically, we identified that the certified robustness of network can be significantly improved if the constraint of certified robustness on misclassified examples and correctly classified examples is consistent. Motivated by this discovery, we design a new defense regularization term called Misclassification Aware Adversarial Regularization (MAAR), which constrains the output probability distributions of all examples in the certified region of the misclassified example. Experimental results show that our proposed MAAR achieves the best certified robustness and comparable accuracy on CIFAR-10 and MNIST datasets in comparison with several state-of-the-art methods.", "venue": "ArXiv", "authors": ["Mengting  Xu", "Tao  Zhang", "Zhongnian  Li", "Wei  Shao", "Daoqiang  Zhang"], "year": 2020, "n_citations": 0}
{"id": 4010793, "s2_id": "717163ebaa910fed65a1ad6c2516137fcadb6434", "title": "STOI-Net: A Deep Learning based Non-Intrusive Speech Intelligibility Assessment Model", "abstract": "The calculation of most objective speech intelligibility assessment metrics requires clean speech as a reference. Such a requirement may limit the applicability of these metrics in real-world scenarios. To overcome this limitation, we propose a deep learning-based non-intrusive speech intelligibility assessment model, namely STOI-Net. The input and output of STOI-Net are speech spectral features and predicted STOI scores, respectively. The model is formed by the combination of a convolutional neural network and bidirectional long short-term memory (CNNBLSTM) architecture with a multiplicative attention mechanism. Experimental results show that the STOI score estimated by STOI-Net has a good correlation with the actual STOI score when tested with noisy and enhanced speech utterances. The correlation values are 0.97 and 0.83, respectively, for the seen test condition (the test speakers and noise types are involved in the training set) and the unseen test condition (the test speakers and noise types are not involved in the training set). The results confirm the capability of STOI-Net to accurately predict the STOI scores without referring to clean speech.", "venue": "2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)", "authors": ["Ryandhimas E. Zezario", "Szu-Wei  Fu", "Chiou-Shann  Fuh", "Yu  Tsao", "Hsin-Min  Wang"], "year": 2020, "n_citations": 6}
{"id": 4016615, "s2_id": "2483231624f15c40dc6178ac99a5c25fc8c5c5de", "title": "Hierarchical Character Tagger for Short Text Spelling Error Correction", "abstract": "State-of-the-art approaches to spelling error correction problem include Transformer-based Seq2Seq models, which require large training sets and suffer from slow inference time; and sequence labeling models based on Transformer encoders like BERT, which involve token-level label space and therefore a large pre-defined vocabulary dictionary. In this paper we present a Hierarchical Character Tagger model, or HCTagger, for short text spelling error correction. We use a pre-trained language model at the character level as a text encoder, and then predict character-level edits to transform the original text into its error-free form with a much smaller label space. For decoding, we propose a hierarchical multi-task approach to alleviate the issue of long-tail label distribution without introducing extra model parameters. Experiments on two public misspelling correction datasets demonstrate that HCTagger is an accurate and much faster approach than many existing models.", "venue": "WNUT", "authors": ["Mengyi  Gao", "Canran  Xu", "Peng  Shi"], "year": 2021, "n_citations": 0}
{"id": 4024688, "s2_id": "0927c7eba740953117ddf3e35ca65dd446955c65", "title": "A statistical model for tensor PCA", "abstract": "We consider the Principal Component Analysis problem for large tensors of arbitrary order $k$ under a single-spike (or rank-one plus noise) model. On the one hand, we use information theory, and recent results in probability theory, to establish necessary and sufficient conditions under which the principal component can be estimated using unbounded computational resources. It turns out that this is possible as soon as the signal-to-noise ratio $\\beta$ becomes larger than $C\\sqrt{k\\log k}$ (and in particular $\\beta$ can remain bounded as the problem dimensions increase). \nOn the other hand, we analyze several polynomial-time estimation algorithms, based on tensor unfolding, power iteration and message passing ideas from graphical models. We show that, unless the signal-to-noise ratio diverges in the system dimensions, none of these approaches succeeds. This is possibly related to a fundamental limitation of computationally tractable estimators for this problem. \nWe discuss various initializations for tensor power iteration, and show that a tractable initialization based on the spectrum of the matricized tensor outperforms significantly baseline methods, statistically and computationally. Finally, we consider the case in which additional side information is available about the unknown signal. We characterize the amount of side information that allows the iterative algorithms to converge to a good estimate.", "venue": "NIPS", "authors": ["Emile  Richard", "Andrea  Montanari"], "year": 2014, "n_citations": 171}
{"id": 4040059, "s2_id": "b8fcabcd72e41713bb23ffab8efdb52777d3f0c1", "title": "Teaching deep learning causal effects improves predictive performance", "abstract": "Causal inference is a powerful statistical methodology for explanatory analysis and individualized treatment effect (ITE) estimation, a prominent causal inference task that has become a fundamental research problem. ITE estimation, when performed naively, tends to produce biased estimates. To obtain unbiased estimates, counterfactual information is needed, which is not directly observable from data. Based on mature domain knowledge, reliable traditional methods to estimate ITE exist. In recent years, neural networks have been widely used in clinical studies. Specifically, recurrent neural networks (RNN) have been applied to temporal Electronic Health Records (EHR) data analysis. However, RNNs are not guaranteed to automatically discover causal knowledge, correctly estimate counterfactual information, and thus correctly estimate the ITE. This lack of correct ITE estimates can hinder the performance of the model. In this work we study whether RNNs can be guided to correctly incorporate ITE-related knowledge and whether this improves predictive performance. Specifically, we first describe a Causal-Temporal Structure for temporal EHR data; then based on this structure, we estimate sequential ITE along the timeline, using sequential Propensity Score Matching (PSM); and finally, we propose a knowledge-guided neural network methodology to incorporate estimated ITE. We demonstrate on real-world and synthetic data (where the actual ITEs are known) that the proposed methodology can significantly improve the prediction performance of RNN.", "venue": "ArXiv", "authors": ["Jia  Li", "Xiaowei  Jia", "Haoyu  Yang", "Vipin  Kumar", "Michael  Steinbach", "Gyorgy  Simon"], "year": 2020, "n_citations": 2}
{"id": 4048652, "s2_id": "7638e53f81602ba793a50763508ae1d5b254edb4", "title": "Meteorological and human mobility data on predicting COVID-19 cases by a novel hybrid decomposition method with anomaly detection analysis: A case study in the capitals of Brazil", "abstract": "\n In 2020, Brazil was the leading country in COVID-19 cases in Latin America, and capital cities were the most severely affected by the outbreak. Climates vary in Brazil due to the territorial extension of the country, its relief, geography, and other factors. Since the most common COVID-19 symptoms are related to the respiratory system, many researchers have studied the correlation between the number of COVID-19 cases with meteorological variables like temperature, humidity, rainfall, etc. Also, due to its high transmission rate, some researchers have analyzed the impact of human mobility on the dynamics of COVID-19 transmission. There is a dearth of literature that considers these two variables when predicting the spread of COVID-19 cases. In this paper, we analyzed the correlation between the number of COVID-19 cases and human mobility, and meteorological data in Brazilian capitals. We found that the correlation between such variables depends on the regions where the cities are located. We employed the variables with a significant correlation with COVID-19 cases to predict the number of COVID-19 infections in all Brazilian capitals and proposed a prediction method combining the Ensemble Empirical Mode Decomposition (EEMD) method with the Autoregressive Integrated Moving Average Exogenous inputs (ARIMAX) method, which we called EEMD-ARIMAX. After analyzing the results poor predictions were further investigated using a signal processing-based anomaly detection method. Computational tests showed that EEMD-ARIMAX achieved a forecast 26.73% better than ARIMAX. Moreover, an improvement of 30.69% in the average root mean squared error (RMSE) was noticed when applying the EEMD-ARIMAX method to the data normalized after the anomaly detection.\n", "venue": "Expert Systems with Applications", "authors": ["Tiago Tiburcio da Silva", "Rodrigo  Francisquini", "Mari\u00e1 C. V. Nascimento"], "year": 2021, "n_citations": 3}
{"id": 4052326, "s2_id": "c05934549edf9cd27ca9695717771e100bcecad3", "title": "Functional Mixture Discriminant Analysis with hidden process regression for curve classification", "abstract": "In this paper, we study the modeling and the classification of functional data presenting regime changes over time. We propose a new model-based functional mixture discriminant analysis approach based on a specific hidden process regression model that governs the regime changes over time. Our approach is particularly adapted to handle the problem of complex-shaped classes of curves, where each class is potentially composed of several sub-classes, and to deal with the regime changes within each homogeneous sub-class. The proposed model explicitly integrates the heterogeneity of each class of curves via a mixture model formulation, and the regime changes within each sub-class through a hidden logistic process. Each class of complex-shaped curves is modeled by a finite number of homogeneous clusters, each of them being decomposed into several regimes. The model parameters of each class are learned by maximizing the observed-data log-likelihood by using a dedicated expectation-maximization (EM) algorithm. Comparisons are performed with alternative curve classification approaches, including functional linear discriminant analysis and functional mixture discriminant analysis with polynomial regression mixtures and spline regression mixtures. Results obtained on simulated data and real data show that the proposed approach outperforms the alternative approaches in terms of discrimination, and significantly improves the curves approximation.", "venue": "ESANN", "authors": ["Faicel  Chamroukhi", "Herv\u00e9  Glotin", "Allou  Sam\u00e9"], "year": 2012, "n_citations": 15}
{"id": 4056129, "s2_id": "c2929349db20144b2a0332477699e5a2f26dc91b", "title": "Combinatorial optimization and reasoning with graph neural networks", "abstract": "Combinatorial optimization is a well-established area in operations research and computer science. Until recently, its methods have mostly focused on solving problem instances in isolation, ignoring the fact that they often stem from related data distributions in practice. However, recent years have seen a surge of interest in using machine learning, especially graph neural networks, as a key building block for combinatorial tasks, either directly as solvers or by enhancing the former. This paper presents a conceptual review of recent key advancements in this emerging field, aiming at researchers in both optimization and machine learning.", "venue": "IJCAI", "authors": ["Quentin  Cappart", "Didier  Ch\u00e9telat", "Elias Boutros Khalil", "Andrea  Lodi", "Christopher  Morris", "Petar  Velickovic"], "year": 2021, "n_citations": 26}
{"id": 4057407, "s2_id": "767a6054796e2e6c1de453afab0e05e55aadf825", "title": "Learning Continuous Image Representation with Local Implicit Image Function", "abstract": "How to represent an image? While the visual world is presented in a continuous manner, machines store and see the images in a discrete way with 2D arrays of pixels. In this paper, we seek to learn a continuous representation for images. Inspired by the recent progress in 3D reconstruction with implicit neural representation, we propose Local Implicit Image Function (LIIF), which takes an image coordinate and the 2D deep features around the coordinate as inputs, predicts the RGB value at a given coordinate as an output. Since the coordinates are continuous, LIIF can be presented in arbitrary resolution. To generate the continuous representation for images, we train an encoder with LIIF representation via a self-supervised task with superresolution. The learned continuous representation can be presented in arbitrary resolution even extrapolate to \u00d730 higher resolution, where the training tasks are not provided. We further show that LIIF representation builds a bridge between discrete and continuous representation in 2D, it naturally supports the learning tasks with size-varied image ground-truths and significantly outperforms the method with resizing the ground-truths. Our project page with code is at https://yinboc.github.io/liif/.", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Yinbo  Chen", "Sifei  Liu", "Xiaolong  Wang"], "year": 2021, "n_citations": 50}
{"id": 4076286, "s2_id": "a4a09fadf38dd65daf98cf5d06d5b69f24546b0b", "title": "Non-Parametric Transformation Networks", "abstract": "ConvNets have been very effective in many applications where it is required to learn invariances to within-class nuisance transformations. However, through their architecture, ConvNets only enforce invariance to translation. In this paper, we introduce a new class of convolutional architectures called Non-Parametric Transformation Networks (NPTNs) which can learn general invariances and symmetries directly from data. NPTNs are a direct and natural generalization of ConvNets and can be optimized directly using gradient descent. They make no assumption regarding structure of the invariances present in the data and in that aspect are very flexible and powerful. We also model ConvNets and NPTNs under a unified framework called Transformation Networks which establishes the natural connection between the two. We demonstrate the efficacy of NPTNs on natural data such as MNIST and CIFAR 10 where it outperforms ConvNet baselines with the same number of parameters. We show it is effective in learning invariances unknown apriori directly from data from scratch. Finally, we apply NPTNs to Capsule Networks and show that they enable them to perform even better.", "venue": "AAAI 2019", "authors": ["Dipan K. Pal", "Marios  Savvides"], "year": 2018, "n_citations": 4}
{"id": 4087197, "s2_id": "90e4bb1c41039da4d77dd677d50b59f11e75bcff", "title": "Learning to Detect: A Data-driven Approach for Network Intrusion Detection", "abstract": "With massive data being generated daily and the ever-increasing interconnectivity of the world\u2019s Internet infrastructures, a machine learning based intrusion detection system (IDS) has become a vital component to protect our economic and national security. In this paper, we perform a comprehensive study on NSL-KDD, a network traffic dataset, by visualizing patterns and employing different learning-based models to detect cyber attacks. Unlike previous shallow learning and deep learning models that use the single learning model approach for intrusion detection, we adopt a hierarchy strategy, in which the intrusion and normal behavior are classified firstly, and then the specific types of attacks are classified. We demonstrate the advantage of the unsupervised representation learning model in binary intrusion detection tasks. Besides, we alleviate the data imbalance problem with SVM-SMOTE oversampling technique in 4-class classification and further demonstrate the effectiveness and the drawback of the oversampling mechanism with a deep neural network as a base model.", "venue": "ArXiv", "authors": ["Zachary  Tauscher", "Yushan  Jiang", "Kai  Zhang", "Jian  Wang", "Houbing  Song"], "year": 2021, "n_citations": 0}
{"id": 4091467, "s2_id": "2047511f992d748e1b750ea3ea9f5f9c045f7d63", "title": "Distributed estimation of the inverse Hessian by determinantal averaging", "abstract": "In distributed optimization and distributed numerical linear algebra, we often encounter an inversion bias: if we want to compute a quantity that depends on the inverse of a sum of distributed matrices, then the sum of the inverses does not equal the inverse of the sum. An example of this occurs in distributed Newton's method, where we wish to compute (or implicitly work with) the inverse Hessian multiplied by the gradient. In this case, locally computed estimates are biased, and so taking a uniform average will not recover the correct solution. To address this, we propose determinantal averaging, a new approach for correcting the inversion bias. This approach involves reweighting the local estimates of the Newton's step proportionally to the determinant of the local Hessian estimate, and then averaging them together to obtain an improved global estimate. This method provides the first known distributed Newton step that is asymptotically consistent, i.e., it recovers the exact step in the limit as the number of distributed partitions grows to infinity. To show this, we develop new expectation identities and moment bounds for the determinant and adjugate of a random matrix. Determinantal averaging can be applied not only to Newton's method, but to computing any quantity that is a linear tranformation of a matrix inverse, e.g., taking a trace of the inverse covariance matrix, which is used in data uncertainty quantification.", "venue": "NeurIPS", "authors": ["Michal  Derezinski", "Michael W. Mahoney"], "year": 2019, "n_citations": 13}
{"id": 4095902, "s2_id": "8ea36d6c25e1e76c406d915ec79767698f268c14", "title": "Impossibility Results for Grammar-Compressed Linear Algebra", "abstract": "To handle vast amounts of data, it is natural and popular to compress vectors and matrices. When we compress a vector from size $N$ down to size $n \\ll N$, it certainly makes it easier to store and transmit efficiently, but does it also make it easier to process? \nIn this paper we consider lossless compression schemes, and ask if we can run our computations on the compressed data as efficiently as if the original data was that small. That is, if an operation has time complexity $T(\\rm{inputsize})$, can we perform it on the compressed representation in time $T(n)$ rather than $T(N)$? We consider the most basic linear algebra operations: inner product, matrix-vector multiplication, and matrix multiplication. In particular, given two compressed vectors, can we compute their inner product in time $O(n)$? Or perhaps we must decompress first and then multiply, spending $\\Omega(N)$ time? \nThe answer depends on the compression scheme. While for simple ones such as Run-Length-Encoding (RLE) the inner product can be done in $O(n)$ time, we prove that this is impossible for compressions from a richer class: essentially $n^2$ or even larger runtimes are needed in the worst case (under complexity assumptions). This is the class of grammar-compressions containing most popular methods such as the Lempel-Ziv family. These schemes are more compressing than the simple RLE, but alas, we prove that performing computations on them is much harder.", "venue": "NeurIPS", "authors": ["Amir  Abboud", "Arturs  Backurs", "Karl  Bringmann", "Marvin  K\u00fcnnemann"], "year": 2020, "n_citations": 1}
{"id": 4099604, "s2_id": "fd83cd664bf667ef97a76bc4c9bb47a06f898769", "title": "Duality-Induced Regularizer for Tensor Factorization Based Knowledge Graph Completion", "abstract": "Tensor factorization based models have shown great power in knowledge graph completion (KGC). However, their performance usually suffers from the overfitting problem seriously. This motivates various regularizers---such as the squared Frobenius norm and tensor nuclear norm regularizers---while the limited applicability significantly limits their practical usage. To address this challenge, we propose a novel regularizer---namely, DUality-induced RegulArizer (DURA)---which is not only effective in improving the performance of existing models but widely applicable to various methods. The major novelty of DURA is based on the observation that, for an existing tensor factorization based KGC model (primal), there is often another distance based KGC model (dual) closely associated with it. Experiments show that DURA yields consistent and significant improvements on benchmarks.", "venue": "NeurIPS", "authors": ["Zhanqiu  Zhang", "Jianyu  Cai", "Jie  Wang"], "year": 2020, "n_citations": 8}
{"id": 4102025, "s2_id": "1908bd5541a52965309fc5d3e22364daaf19c43e", "title": "Sharp Restricted Isometry Bounds for the Inexistence of Spurious Local Minima in Nonconvex Matrix Recovery", "abstract": "Nonconvex matrix recovery is known to contain no spurious local minima under a restricted isometry property (RIP) with a sufficiently small RIP constant $\\delta$. If $\\delta$ is too large, however, then counterexamples containing spurious local minima are known to exist. In this paper, we introduce a proof technique that is capable of establishing sharp thresholds on $\\delta$ to guarantee the inexistence of spurious local minima. Using the technique, we prove that in the case of a rank-1 ground truth, an RIP constant of $\\delta<1/2$ is both necessary and sufficient for exact recovery from any arbitrary initial point (such as a random point). We also prove a local recovery result: given an initial point $x_{0}$ satisfying $f(x_{0})\\le(1-\\delta)^{2}f(0)$, any descent algorithm that converges to second-order optimality guarantees exact recovery.", "venue": "J. Mach. Learn. Res.", "authors": ["Richard Y. Zhang", "Somayeh  Sojoudi", "Javad  Lavaei"], "year": 2019, "n_citations": 31}
{"id": 4102693, "s2_id": "e0e8a3b6c6f1521d222ebf71bfa53f9f8dd75312", "title": "Learning robot activities from first-person human videos using convolutional future regression", "abstract": "We design a new approach that allows robot learning of new activities from unlabeled human example videos. Given videos of humans executing the same activity from a human's viewpoint (i.e., first-person videos), our objective is to make the robot learn the temporal structure of the activity as its future regression network, and learn to transfer such model for its own motor execution. We present a new deep learning model: We extend the state-of-the-art convolutional object detection network for the representation/estimation of human hands in training videos, and newly introduce the concept of using a fully convolutional network to regress (i.e., predict) the intermediate scene representation corresponding to the future frame (e.g., 1\u20132 seconds later). Combining these allows direct prediction of future locations of human hands and objects, which enables the robot to infer the motor control plan using our manipulation network. We experimentally confirm that our approach makes learning of robot activities from unlabeled human interaction videos possible, and demonstrate that our robot is able to execute the learned collaborative activities in real-time directly based on its camera input.", "venue": "2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "authors": ["Jangwon  Lee", "Michael S. Ryoo"], "year": 2017, "n_citations": 29}
{"id": 4109431, "s2_id": "bc29909786f996bfe783c116ff2a2df090ce0fb1", "title": "U-Det: A Modified U-Net architecture with bidirectional feature network for lung nodule segmentation", "abstract": "Early diagnosis and analysis of lung cancer involve a precise and efficient lung nodule segmentation in computed tomography (CT) images. However, the anonymous shapes, visual features, and surroundings of the nodule in the CT image pose a challenging problem to the robust segmentation of the lung nodules. This article proposes U-Det, a resource-efficient model architecture, which is an end to end deep learning approach to solve the task at hand. It incorporates a Bi-FPN (bidirectional feature network) between the encoder and decoder. Furthermore, it uses Mish activation function and class weights of masks to enhance segmentation efficiency. The proposed model is extensively trained and evaluated on the publicly available LUNA-16 dataset consisting of 1186 lung nodules. The U-Det architecture outperforms the existing U-Net model with the Dice similarity coefficient (DSC) of 82.82% and achieves results comparable to human experts.", "venue": "ArXiv", "authors": ["Nikhil Varma Keetha", "P  SamsonAnoshBabu", "Chandra Sekhara Rao Annavarapu"], "year": 2020, "n_citations": 7}
{"id": 4111427, "s2_id": "fa66d51611d7a309522ea855da847cc54516a56e", "title": "Bayesian optimization for modular black-box systems with switching costs", "abstract": "Most existing black-box optimization methods assume that all variables in the system being optimized have equal cost and can change freely at each iteration. However, in many real world systems, inputs are passed through a sequence of different operations or modules, making variables in earlier stages of processing more costly to update. Such structure imposes a cost on switching variables in early parts of a data processing pipeline. In this work, we propose a new algorithm for switch cost-aware optimization called Lazy Modular Bayesian Optimization (LaMBO). This method efficiently identifies the global optimum while minimizing cost through a passive change of variables in early modules. The method is theoretical grounded and achieves vanishing regret when augmented with switching cost. We apply LaMBO to multiple synthetic functions and a three-stage image segmentation pipeline used in a neuroscience application, where we obtain promising improvements over prevailing cost-aware Bayesian optimization algorithms. Our results demonstrate that LaMBO is an effective strategy for black-box optimization that is capable of minimizing switching costs in modular systems.", "venue": "UAI", "authors": ["Chi-Heng  Lin", "Joseph D. Miano", "Eva L. Dyer"], "year": 2021, "n_citations": 0}
{"id": 4114125, "s2_id": "0c1cb3ce072e0b593ddce096be5520a05e65c75e", "title": "Variance-reduced Language Pretraining via a Mask Proposal Network", "abstract": "Self-supervised learning, a.k.a., pretraining, is important in natural language processing. Most of the pretraining methods first randomly mask some positions in a sentence and then train a model to recover the tokens at the masked positions. In such a way, the model can be trained without human labeling, and the massive data can be used with billion parameters. Therefore, the optimization efficiency becomes critical. In this paper, we tackle the problem from the view of gradient variance reduction. In particular, we first propose a principled gradient variance decomposition theorem, which shows that the variance of the stochastic gradient of the language pretraining can be naturally decomposed into two terms: the variance that arises from the sample of data in a batch, and the variance that arises from the sampling of the mask. The second term is the key difference between selfsupervised learning and supervised learning, which makes the pretraining slower. In order to reduce the variance of the second part, we leverage the importance sampling strategy, which aims at sampling the masks according to a proposal distribution instead of the uniform distribution. It can be shown that if the proposal distribution is proportional to the gradient norm, the variance of the sampling is reduced. To improve efficiency, we introduced a MAsk Proposal Network (MAPNet), which approximates the optimal mask proposal distribution and is trained end-to-end along with the model. According to the experimental result, our model converges much faster and achieves higher performance than the baseline BERT model.", "venue": "ArXiv", "authors": ["Liang  Chen", "Tianyuan  Zhang", "Di  He", "Guolin  Ke", "Liwei  Wang", "Tie-Yan  Liu"], "year": 2020, "n_citations": 6}
{"id": 4121169, "s2_id": "ee85229d8872bb46305c4e081d6cb3182544d213", "title": "The Wilderness Area Data Set: Adapting the Covertype data set for unsupervised learning", "abstract": "Benchmark data sets are of vital importance in machine learning research, as indicated by the number of repositories that exist to make them publicly available. Although many of these are usable in the stream mining context as well, it is less obvious which data sets can be used to evaluate data stream clustering algorithms. We note that the classic Covertype data set's size makes it attractive for use in stream mining but unfortunately it is specifically designed for classification. Here we detail the process of transforming the Covertype data set into one amenable for unsupervised learning, which we call the Wilderness Area data set. Our quantitative analysis allows us to conclude that the Wilderness Area data set is more appropriate for unsupervised learning than the original Covertype data set.", "venue": "ArXiv", "authors": ["Richard Hugh Moulton", "Jakub  Zgraja"], "year": 2019, "n_citations": 1}
{"id": 4165162, "s2_id": "fee092ff8e5bf4af48e2763406bf59a793ec69f0", "title": "Online Reinforcement Learning in Stochastic Games", "abstract": "We study online reinforcement learning in average-reward stochastic games (SGs). An SG models a two-player zero-sum game in a Markov environment, where state transitions and one-step payoffs are determined simultaneously by a learner and an adversary. We propose the UCSG algorithm that achieves a sublinear regret compared to the game value when competing with an arbitrary opponent. This result improves previous ones under the same setting. The regret bound has a dependency on the diameter, which is an intrinsic value related to the mixing property of SGs. If we let the opponent play an optimistic best response to the learner, UCSG finds an $\\varepsilon$-maximin stationary policy with a sample complexity of $\\tilde{\\mathcal{O}}\\left(\\text{poly}(1/\\varepsilon)\\right)$, where $\\varepsilon$ is the gap to the best policy.", "venue": "NIPS", "authors": ["Chen-Yu  Wei", "Yi-Te  Hong", "Chi-Jen  Lu"], "year": 2017, "n_citations": 59}
{"id": 4166224, "s2_id": "8f21e8a7442a21b87859215aacc67f11ee5ce100", "title": "Sampled Softmax with Random Fourier Features", "abstract": "The computational cost of training with softmax cross entropy loss grows linearly with the number of classes. For the settings where a large number of classes are involved, a common method to speed up training is to sample a subset of classes and utilize an estimate of the loss gradient based on these classes, known as the sampled softmax method. However, the sampled softmax provides a biased estimate of the gradient unless the samples are drawn from the exact softmax distribution, which is again expensive to compute. Therefore, a widely employed practical approach involves sampling from a simpler distribution in the hope of approximating the exact softmax distribution. In this paper, we develop the first theoretical understanding of the role that different sampling distributions play in determining the quality of sampled softmax. Motivated by our analysis and the work on kernel-based sampling, we propose the Random Fourier Softmax (RF-softmax) method that utilizes the powerful Random Fourier Features to enable more efficient and accurate sampling from an approximate softmax distribution. We show that RF-softmax leads to low bias in estimation in terms of both the full softmax distribution and the full softmax gradient. Furthermore, the cost of RF-softmax scales only logarithmically with the number of classes.", "venue": "NeurIPS", "authors": ["Ankit Singh Rawat", "Jiecao  Chen", "Felix  Yu", "Ananda Theertha Suresh", "Sanjiv  Kumar"], "year": 2019, "n_citations": 31}
{"id": 4167928, "s2_id": "c36d5b0aeb6f7ff7d83b4fbc3b136f6918a40ed0", "title": "Using Neural Networks for Relation Extraction from Biomedical Literature", "abstract": "Using different sources of information to support automated extracting of relations between biomedical concepts contributes to the development of our understanding of biological systems. The primary comprehensive source of these relations is biomedical literature. Several relation extraction approaches have been proposed to identify relations between concepts in biomedical literature, namely, using neural networks algorithms. The use of multichannel architectures composed of multiple data representations, as in deep neural networks, is leading to state-of-the-art results. The right combination of data representations can eventually lead us to even higher evaluation scores in relation extraction tasks. Thus, biomedical ontologies play a fundamental role by providing semantic and ancestry information about an entity. The incorporation of biomedical ontologies has already been proved to enhance previous state-of-the-art results.", "venue": "Artificial Neural Networks, 3rd Edition", "authors": ["Diana  Sousa", "Andre  Lamurias", "Francisco M. Couto"], "year": 2021, "n_citations": 6}
{"id": 4168148, "s2_id": "73d094743380350b19e854fb98eeba0dd8c94e6e", "title": "Risk-Averse Action Selection Using Extreme Value Theory Estimates of the CVaR", "abstract": "The Conditional Value-at-Risk (CVaR) is a useful risk measure in machine learning, finance, insurance, energy, etc. When the CVaR confidence parameter is very high, estimation by sample averaging exhibits high variance due to the limited number of samples above the corresponding threshold. To mitigate this problem, we present an estimation procedure for the CVaR that combines extreme value theory and a recently introduced method of automated threshold selection by Bader et al. (2018). Under appropriate conditions, we estimate the tail risk using a generalized Pareto distribution. We compare empirically this estimation procedure with the naive method of sample averaging, and show an improvement in accuracy for some specific cases. We also show how the estimation procedure can be used in reinforcement learning by applying our method to the multi-armed bandit problem where the goal is to avoid catastrophic risk.", "venue": "ArXiv", "authors": ["Dylan  Troop", "Fr'ed'eric  Godin", "Jia Yuan Yu"], "year": 2019, "n_citations": 1}
{"id": 4179067, "s2_id": "e5a19aa0f71e71d017044aac3b8b3df669942542", "title": "On the Stability Analysis of Deep Neural Network Representations of an Optimal State Feedback", "abstract": "Recent works have shown that the optimal state feedback for deterministic, nonlinear autonomous systems can be approximated by deep neural networks. In this article, we consider the stability of nonlinear systems controlled by such a network representation of the optimal feedback. First, we show that principal methods from stability theory readily applies. We then propose a novel method based on differential algebra techniques to study the robustness of a nominal trajectory with respect to perturbations of the initial conditions. It is, to the best of our knowledge, the first time that differential algebraic techniques are shown to allow for the high-order analysis of motion stability for a nonlinear system in general and for a neurocontrolled system in particular. We exemplify the proposed method in the 2-D case of the optimal control of a quadcopter and demonstrate it for different neural network architectures.", "venue": "IEEE Transactions on Aerospace and Electronic Systems", "authors": ["Dario  Izzo", "Dharmesh  Tailor", "Thomas  Vasileiou"], "year": 2021, "n_citations": 5}
{"id": 4181744, "s2_id": "a07278f84658128f0345c3ef16ea544c002567b8", "title": "Neural ODE with Temporal Convolution and Time Delay Neural Networks for Small-Footprint Keyword Spotting", "abstract": "In this paper, we propose neural network models based on the neural ordinary differential equation (NODE) for small-footprint keyword spotting (KWS). We present techniques to apply NODE to KWS that make it possible to adopt Batch Normalization to NODE-based network and to reduce the number of computations during inference. Finally, we show that the number of model parameters of the proposed model is smaller by 68% than that of the conventional KWS model.", "venue": "ArXiv", "authors": ["Hiroshi  Fuketa", "Yukinori  Morita"], "year": 2020, "n_citations": 1}
{"id": 4193075, "s2_id": "78b6b65f041fda8db64baeac39067ee7552a31a6", "title": "Sequential Bayesian Detection of Spike Activities From Fluorescence Observations", "abstract": "Extracting and detecting spike activities from the fluorescence observations is an important step in understanding how neuron systems work. The main challenge lies in the combined ambient noise with fluctuated baseline, which contaminates the observations, thereby deteriorating the reliability of spike detection. This may be even worse in the face of the nonlinear biological process, the coupling interactions between spikes and baseline, and the unknown critical parameters of an underlying model, in which erroneous estimations of parameters will affect the detection of spikes causing further error propagation. The state-of-the-art MLSpike is premised on static parameter inference on spike events and ignores sequential spike nonlinear interactions. In this paper, we propose a random finite set (RFS) based Bayesian inference approach, which encapsulates the dynamics of sequential spikes, fluctuated baseline, and unknown model parameters. Specifically, the cardinal probability of RFS is able to distinguish latent spike behaviours (e.g., spike or non-spike). Our results demonstrate that the proposed scheme can gain an extra 12% detection accuracy in comparison with the state-of-the-art MLSpike method.", "venue": "IEEE Transactions on Molecular, Biological and Multi-Scale Communications", "authors": ["Zhuangkun  Wei", "Bin  Li", "Weisi  Guo", "Wenxiu  Hu", "Chenglin  Zhao"], "year": 2019, "n_citations": 1}
{"id": 4203083, "s2_id": "7694aae9766d5f1fe74d900cd82aee898cb6e8e9", "title": "How to Train BERT with an Academic Budget", "abstract": "While large language models \u00e0 la BERT are used ubiquitously in NLP, pretraining them is considered a luxury that only a few wellfunded industry labs can afford. How can one train such models with a more modest budget? We present a recipe for pretraining a masked language model in 24 hours, using only 8 low-range 12GB GPUs. We demonstrate that through a combination of software optimizations, design choices, and hyperparameter tuning, it is possible to produce models that are competitive with BERTBASE on GLUE tasks at a fraction of the original pretraining cost.", "venue": "EMNLP", "authors": ["Peter  Izsak", "Moshe  Berchansky", "Omer  Levy"], "year": 2021, "n_citations": 4}
{"id": 4205633, "s2_id": "e48f4ef212c5205c79ec1db1b4ff307d2c8b58b0", "title": "NILM as a regression versus classification problem: the importance of thresholding", "abstract": "Non-Intrusive Load Monitoring (NILM) aims to predict the status or consumption of domestic appliances in a household only by knowing the aggregated power load. NILM can be formulated as regression problem or most often as a classification problem. Most datasets gathered by smart meters allow to define naturally a regression problem, but the corresponding classification problem is a derived one, since it requires a conversion from the power signal to the status of each device by a thresholding method. We treat three different thresholding methods to perform this task, discussing their differences on various devices from the UK-DALE dataset. We analyze the performance of deep learning state-of-the-art architectures on both the regression and classification problems, introducing criteria to select the most convenient thresholding method.", "venue": "ArXiv", "authors": ["Daniel  Precioso", "David  G\u00f3mez-Ullate"], "year": 2020, "n_citations": 0}
{"id": 4207050, "s2_id": "6f72e07c99073797c0ad8ea9c91987eef1009197", "title": "MOrdReD: Memory-based Ordinal Regression Deep Neural Networks for Time Series Forecasting", "abstract": "Time series forecasting is ubiquitous in the modern world. Applications range from health care to astronomy, include climate modelling, financial trading and monitoring of critical engineering equipment. To offer value over this range of activities we must have models that not only provide accurate forecasts but that also quantify and adjust their uncertainty over time. Furthermore, such models must allow for multimodal, non-Gaussian behaviour that arises regularly in applied settings. In this work, we propose a novel, end-to-end deep learning method for time series forecasting. Crucially, our model allows the principled assessment of predictive uncertainty as well as providing rich information regarding multiple modes of future data values. Our approach not only provides an excellent predictive forecast, shadowing true future values, but also allows us to infer valuable information, such as the predictive distribution of the occurrence of critical events of interest, accurately and reliably even over long time horizons. We find the method outperforms other state-of-the-art algorithms, such as Gaussian Processes.", "venue": "ArXiv", "authors": ["Bernardo P\u00e9rez Orozco", "Gabriele  Abbati", "Stephen J. Roberts"], "year": 2018, "n_citations": 10}
{"id": 4212228, "s2_id": "3392b27174352499358fccff91a715c02a27af07", "title": "PIVETed-Granite: Computational Phenotypes through Constrained Tensor Factorization", "abstract": "It has been recently shown that sparse, nonnegative tensor factorization of multi-modal electronic health record data is a promising approach to high-throughput computational phenotyping. However, such approaches typically do not leverage available domain knowledge while extracting the phenotypes; hence, some of the suggested phenotypes may not map well to clinical concepts or may be very similar to other suggested phenotypes. To address these issues, we present a novel, automatic approach called PIVETed-Granite that mines existing biomedical literature (PubMed) to obtain cannot-link constraints that are then used as side-information during a tensor-factorization based computational phenotyping process. The resulting improvements are clearly observed in experiments using a large dataset from VUMC to identify phenotypes for hypertensive patients.", "venue": "ArXiv", "authors": ["Jette  Henderson", "Bradley  Malin", "Joyce C. Ho", "Joydeep  Ghosh"], "year": 2018, "n_citations": 1}
{"id": 4216956, "s2_id": "6105fc6d1058cd883037ed89f42332c56eef8160", "title": "Decentralized Deep Learning with Arbitrary Communication Compression", "abstract": "Decentralized training of deep learning models is a key element for enabling data privacy and on-device learning over networks, as well as for efficient scaling to large compute clusters. As current approaches suffer from limited bandwidth of the network, we propose the use of communication compression in the decentralized training context. We show that Choco-SGD $-$ recently introduced and analyzed for strongly-convex objectives only $-$ converges under arbitrary high compression ratio on general non-convex functions at the rate $O\\bigl(1/\\sqrt{nT}\\bigr)$ where $T$ denotes the number of iterations and $n$ the number of workers. The algorithm achieves linear speedup in the number of workers and supports higher compression than previous state-of-the art methods. We demonstrate the practical performance of the algorithm in two key scenarios: the training of deep learning models (i) over distributed user devices, connected by a social network and (ii) in a datacenter (outperforming all-reduce time-wise).", "venue": "ICLR", "authors": ["Anastasia  Koloskova", "Tao  Lin", "Sebastian U. Stich", "Martin  Jaggi"], "year": 2020, "n_citations": 85}
{"id": 4218730, "s2_id": "01970acfa658b4ec151ae398999cfbdf777a3fb5", "title": "Unconfused ultraconservative multiclass algorithms", "abstract": "We tackle the problem of learning linear classifiers from noisy datasets in a multiclass setting. The two-class version of this problem was studied a few years ago where the proposed approaches to combat the noise revolve around a Perceptron learning scheme fed with peculiar examples computed through a weighted average of points from the noisy training set. We propose to build upon these approaches and we introduce a new algorithm called Unconfused Multiclass additive Algorithm (UMA) which may be seen as a generalization to the multiclass setting of the previous approaches. In order to characterize the noise we use the confusion matrix as a multiclass extension of the classification noise studied in the aforementioned literature. Theoretically well-founded, UMA furthermore displays very good empirical noise robustness, as evidenced by numerical simulations conducted on both synthetic and real data.", "venue": "Machine Learning", "authors": ["Ugo  Louche", "Liva  Ralaivola"], "year": 2015, "n_citations": 2}
{"id": 4229008, "s2_id": "c4f63a7de9288bc6b87296114cecf1e420a1806b", "title": "Counterfactual Prediction with Deep Instrumental Variables Networks", "abstract": "We are in the middle of a remarkable rise in the use and capability of artificial intelligence. Much of this growth has been fueled by the success of deep learning architectures: models that map from observables to outputs via multiple layers of latent representations. These deep learning algorithms are effective tools for unstructured prediction, and they can be combined in AI systems to solve complex automated reasoning problems. This paper provides a recipe for combining ML algorithms to solve for causal effects in the presence of instrumental variables -- sources of treatment randomization that are conditionally independent from the response. We show that a flexible IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose loss function involves integration over the conditional treatment distribution. This Deep IV framework imposes some specific structure on the stochastic gradient descent routine used for training, but it is general enough that we can take advantage of off-the-shelf ML capabilities and avoid extensive algorithm customization. We outline how to obtain out-of-sample causal validation in order to avoid over-fit. We also introduce schemes for both Bayesian and frequentist inference: the former via a novel adaptation of dropout training, and the latter via a data splitting routine.", "venue": "ArXiv", "authors": ["Jason S. Hartford", "Greg  Lewis", "Kevin  Leyton-Brown", "Matt  Taddy"], "year": 2016, "n_citations": 38}
{"id": 4243128, "s2_id": "f5ca30ccf6222431c271c2c8672b842916806bbc", "title": "Time Series Cluster Kernel for Learning Similarities between Multivariate Time Series with Missing Data", "abstract": "Abstract Similarity-based approaches represent a promising direction for time series analysis. However, many such methods rely on parameter tuning, and some have shortcomings if the time series are multivariate (MTS), due to dependencies between attributes, or the time series contain missing data. In this paper, we address these challenges within the powerful context of kernel methods by proposing the robust time series cluster kernel (TCK). The approach taken leverages the missing data handling properties of Gaussian mixture models (GMM) augmented with informative prior distributions. An ensemble learning approach is exploited to ensure robustness to parameters by combining the clustering results of many GMM to form the final kernel. We evaluate the TCK on synthetic and real data and compare to other state-of-the-art techniques. The experimental results demonstrate that the TCK is robust to parameter choices, provides competitive results for MTS without missing data and outstanding results for missing data.", "venue": "Pattern Recognit.", "authors": ["Karl \u00d8yvind Mikalsen", "Filippo Maria Bianchi", "Cristina  Soguero-Ru\u00edz", "Robert  Jenssen"], "year": 2018, "n_citations": 67}
{"id": 4249349, "s2_id": "18a1713062a2294d1f006926b6cf702fb839a99a", "title": "Elastic Net based Feature Ranking and Selection", "abstract": "Feature selection is important in data representation and intelligent diagnosis. Elastic net is one of the most widely used feature selectors. However, the features selected are dependant on the training data, and their weights dedicated for regularized regression are irrelevant to their importance if used for feature ranking, that degrades the model interpretability and extension. In this study, an intuitive idea is put at the end of multiple times of data splitting and elastic net based feature selection. It concerns the frequency of selected features and uses the frequency as an indicator of feature importance. After features are sorted according to their frequency, linear support vector machine performs the classification in an incremental manner. At last, a compact subset of discriminative features is selected by comparing the prediction performance. Experimental results on breast cancer data sets (BCDR-F03, WDBC, GSE 10810, and GSE 15852) suggest that the proposed framework achieves competitive or superior performance to elastic net and with consistent selection of fewer features. How to further enhance its consistency on high-dimension small-sample-size data sets should be paid more attention in our future work. The proposed framework is \u2217Corresponding author Email address: yushaodemia@163.com (Shaode Yu) Preprint submitted to ABC January 1, 2021 ar X iv :2 01 2. 14 98 2v 1 [ cs .L G ] 3 0 D ec 2 02 0 accessible online (https://github.com/NicoYuCN/elasticnetFR).", "venue": "ArXiv", "authors": ["Shaode  Yu", "Haobo  Chen", "Hang  Yu", "Zhicheng  Zhang", "Xiaokun  Liang", "Wenjian  Qin", "Yaoqin  Xie", "Ping  Shi"], "year": 2020, "n_citations": 0}
{"id": 4254751, "s2_id": "1ae1088dbf511b652866dbf750ea207409bf589e", "title": "Faster Maximum Feasible Subsystem Solutions for Dense Constraint Matrices", "abstract": "Finding the largest cardinality feasible subset of an infeasible set of linear constraints is the Maximum Feasible Subsystem problem (MAX FS). Solving this problem is crucial in a wide range of applications such as machine learning and compressive sensing. Although MAX FS is NP-hard, useful heuristic algorithms exist, but these can be slow for large problems. We extend the existing heuristics for the case of dense constraint matrices to greatly increase their speed while preserving or improving solution quality. We test the extended algorithms on two applications that have dense constraint matrices: binary classification, and sparse recovery in compressive sensing. In both cases, speed is greatly increased with no loss of accuracy.", "venue": "Computers & Operations Research", "authors": ["Fereshteh Fakhar Firouzeh", "John W. Chinneck", "Sreeraman  Rajan"], "year": 2021, "n_citations": 0}
{"id": 4256185, "s2_id": "b70f1eb15cc7d67448e1ee66931a4382042fe9b4", "title": "Diagnostic Image Quality Assessment and Classification in Medical Imaging: Opportunities and Challenges", "abstract": "Magnetic Resonance Imaging (MRI) suffers from several artifacts, the most common of which are motion artifacts. These artifacts often yield images that are of non-diagnostic quality. To detect such artifacts, images are prospectively evaluated by experts for their diagnostic quality, which necessitates patient-revisits and rescans whenever non-diagnostic quality scans are encountered. This motivates the need to develop an automated framework capable of accessing medical image quality and detecting diagnostic and non-diagnostic images. In this paper, we explore several convolutional neural network-based frameworks for medical image quality assessment and investigate several challenges therein.", "venue": "2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)", "authors": ["Jeffrey  Ma", "Ukash  Nakarmi", "Cedric Yue Sik Kin", "Christopher  Sandino", "Joseph Y. Cheng", "Ali B. Syed", "Peter  Wei", "John M. Pauly", "Shreyas  Vasanawala"], "year": 2020, "n_citations": 3}
{"id": 4283980, "s2_id": "e31b682a55e0bcf022b85c0a793c2ab5c51de2a0", "title": "Progressive transfer learning for low frequency data prediction in full waveform inversion", "abstract": "To effectively overcome the cycle-skipping issue in full-waveform inversion (FWI), we have developed a deep neural network (DNN) approach to predict the absent low-frequency (LF) components by exploiting the hidden physical relation connecting the LF and high-frequency (HF) data. To efficiently solve this challenging nonlinear regression problem, two novel strategies are proposed to design the DNN architecture and to optimize the learning process: (1)\u00a0the dual data feed structure and (2)\u00a0progressive transfer learning. With the dual data feed structure, not only the HF data, but also the corresponding beat tone data, are fed into the DNN to relieve the burden of feature extraction. The second strategy, progressive transfer learning, enables us to train the DNN using a single evolving training data set. Within the framework of progressive transfer learning, the training data set continuously evolves in an iterative manner by gradually retrieving the subsurface information through the physics-based inversion module, progressively enhancing the prediction accuracy of the DNN and propelling the inversion process out of the local minima. The synthetic numerical experiments suggest that, without any a priori geologic information, the LF data predicted by the progressive transfer learning are sufficiently accurate for an FWI engine to produce reliable subsurface velocity models free of cycle-skipping artifacts.", "venue": "GEOPHYSICS", "authors": ["Wenyi  Hu", "Yuchen  Jin", "Xuqing  Wu", "Jiefu  Chen"], "year": 2021, "n_citations": 6}
{"id": 4294633, "s2_id": "c2dc7ac4929c01cbe0dac38b5765b3762bf8f784", "title": "Multi-Gradient Descent for Multi-Objective Recommender Systems", "abstract": "Recommender systems need to mirror the complexity of the environment they are applied in. The more we know about what might benefit the user, the more objectives the recommender system has. In addition there may be multiple stakeholders - sellers, buyers, shareholders - in addition to legal and ethical constraints. Simultaneously optimizing for a multitude of objectives, correlated and not correlated, having the same scale or not, has proven difficult so far. \nWe introduce a stochastic multi-gradient descent approach to recommender systems (MGDRec) to solve this problem. We show that this exceeds state-of-the-art methods in traditional objective mixtures, like revenue and recall. Not only that, but through gradient normalization we can combine fundamentally different objectives, having diverse scales, into a single coherent framework. We show that uncorrelated objectives, like the proportion of quality products, can be improved alongside accuracy. Through the use of stochasticity, we avoid the pitfalls of calculating full gradients and provide a clear setting for its applicability.", "venue": "ArXiv", "authors": ["Nikola  Milojkovi\u0107", "Diego  Antognini", "Giancarlo  Bergamin", "Boi  Faltings", "Claudiu  Musat"], "year": 2020, "n_citations": 18}
{"id": 4296070, "s2_id": "d8da8b3db325be6060a8445154356397d2f177b0", "title": "Error Control and Loss Functions for the Deep Learning Inversion of Borehole Resistivity Measurements", "abstract": "Deep learning (DL) is a numerical method that approximates functions. Recently, its use has become attractive for the simulation and inversion of multiple problems in computational mechanics, including the inversion of borehole logging measurements for oil and gas applications. In this context, DL methods exhibit two key attractive features: a) once trained, they enable to solve an inverse problem in a fraction of a second, which is convenient for borehole geosteering operations as well as in other real-time inversion applications. b) DL methods exhibit a superior capability for approximating highly-complex functions across different areas of knowledge. Nevertheless, as it occurs with most numerical methods, DL also relies on expert design decisions that are problem specific to achieve reliable and robust results. Herein, we investigate two key aspects of deep neural networks (DNNs) when applied to the inversion of borehole resistivity measurements: error control and adequate selection of the loss function. As we illustrate via theoretical considerations and extensive numerical experiments, these interrelated aspects are critical to recover accurate inversion results.", "venue": "ArXiv", "authors": ["M.  Shahriari", "D.  Pardo", "J. A. Rivera", "C.  Torres-Verd'in", "A.  Picon", "J. Del Ser", "S.  Ossand'on", "V. M. Calo"], "year": 2020, "n_citations": 7}
{"id": 4304811, "s2_id": "efd3b8c16beeeb0add830e539d849b338f1d7fc4", "title": "Partition and Code: learning how to compress graphs", "abstract": "Can we use machine learning to compress graph data? The absence of ordering in graphs poses a significant challenge to conventional compression algorithms, limiting their attainable gains as well as their ability to discover relevant patterns. On the other hand, most graph compression approaches rely on domain-dependent handcrafted representations and cannot adapt to different underlying graph distributions. This work aims to establish the necessary principles a lossless graph compression method should follow to approach the entropy storage lower bound. Instead of making rigid assumptions about the graph distribution, we formulate the compressor as a probabilistic model that can be learned from data and generalise to unseen instances. Our \u201cPartition and Code\u201d framework entails three steps: first, a partitioning algorithm decomposes the graph into elementary structures, then these are mapped to the elements of a small dictionary on which we learn a probability distribution, and finally, an entropy encoder translates the representation into bits. All three steps are parametric and can be trained with gradient descent. We theoretically compare the compression quality of several graph encodings and prove, under mild conditions, a total ordering of their expected description lengths. Moreover, we show that, under the same conditions, PnC achieves compression gains w.r.t. the baselines that grow either linearly or quadratically with the number of vertices. Our algorithms are quantitatively evaluated on diverse real-world networks obtaining significant performance improvements with respect to different families of non-parametric and parametric graph compressors. .", "venue": "ArXiv", "authors": ["Giorgos  Bouritsas", "Andreas  Loukas", "Nikolaos  Karalias", "Michael M. Bronstein"], "year": 2021, "n_citations": 2}
{"id": 4306804, "s2_id": "363f5fc91e73c8834844df681e017a8fe88803ff", "title": "On a Bernoulli Autoregression Framework for Link Discovery and Prediction", "abstract": "We present a dynamic prediction framework for binary sequences that is based on a Bernoulli generalization of the auto-regressive process. Our approach lends itself easily to variants of the standard link prediction problem for a sequence of time dependent networks. Focusing on this dynamic network link prediction/recommendation task, we propose a novel problem that exploits additional information via a much larger sequence of auxiliary networks and has important real-world relevance. To allow discovery of links that do not exist in the available data, our model estimation framework introduces a regularization term that presents a trade-off between the conventional link prediction and this discovery task. In contrast to existing work our stochastic gradient based estimation approach is highly efficient and can scale to networks with millions of nodes. We show extensive empirical results on both actual product-usage based time dependent networks and also present results on a Reddit based data set of time dependent sentiment sequences.", "venue": "ArXiv", "authors": ["Xiaohan  Yan", "Avleen S. Bijral"], "year": 2020, "n_citations": 0}
{"id": 4308586, "s2_id": "f4b434c3ab979ecdd71bbed894b34de77590c6dd", "title": "Adversarial Risk and the Dangers of Evaluating Against Weak Attacks", "abstract": "This paper investigates recently proposed approaches for defending against adversarial examples and evaluating adversarial robustness. The existence of adversarial examples in trained neural networks reflects the fact that expected risk alone does not capture the model's performance against worst-case inputs. We motivate the use of adversarial risk as an objective, although it cannot easily be computed exactly. We then frame commonly used attacks and evaluation metrics as defining a tractable surrogate objective to the true adversarial risk. This suggests that models may be obscured to adversaries, by optimizing this surrogate rather than the true adversarial risk. We demonstrate that this is a significant problem in practice by repurposing gradient-free optimization techniques into adversarial attacks, which we use to decrease the accuracy of several recently proposed defenses to near zero. Our hope is that our formulations and results will help researchers to develop more powerful defenses.", "venue": "ICML", "authors": ["Jonathan  Uesato", "Brendan  O'Donoghue", "A\u00e4ron van den Oord", "Pushmeet  Kohli"], "year": 2018, "n_citations": 341}
{"id": 4309130, "s2_id": "9c51af4f811f7dc196d8d64e44f68ab7a8a0cf89", "title": "Reinforcement learning for adaptive routing", "abstract": "Reinforcement learning means learning a policy-a mapping of observations into actions-based on feedback from the environment. The learning can be viewed as browsing a set of policies while evaluating them by trial through interaction with the environment. We present an application of a gradient ascent algorithm for reinforcement learning to a complex domain of packet routing in network communication and compare the performance of this algorithm to other routing methods on a benchmark problem.", "venue": "Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No.02CH37290)", "authors": ["Leonid  Peshkin", "Virginia  Savova"], "year": 2002, "n_citations": 107}
{"id": 4309563, "s2_id": "0a5bcd1c9e88ec6b2fcf4699a8a0a93547bd07b2", "title": "Courteous Autonomous Cars", "abstract": "Typically, autonomous cars optimize for a combination of safety, efficiency, and driving quality. But as we get better at this optimization, we start seeing behavior go from too conservative to too aggressive. The car's behavior exposes the incentives we provide in its cost function. In this work, we argue for cars that are not optimizing a purely selfish cost, but also try to be courteous to other interactive drivers. We formalize courtesy as a term in the objective that measures the increase in another driver's cost induced by the autonomous car's behavior. Such a courtesy term enables the robot car to be aware of possible irrationality of the human behavior, and plan accordingly. We analyze the effect of courtesy in a variety of scenarios. We find, for example, that courteous robot cars leave more space when merging in front of a human driver. Moreover, we find that such a courtesy term can help explain real human driver behavior on the NGSIM dataset.", "venue": "2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "authors": ["Liting  Sun", "Wei  Zhan", "Masayoshi  Tomizuka", "Anca D. Dragan"], "year": 2018, "n_citations": 33}
{"id": 4311540, "s2_id": "8c4d12f51d219e9f006ff7d74c101eb588b55f60", "title": "Study of Robust Adaptive Beamforming Based on Low-Complexity DFT Spatial Sampling", "abstract": "In this paper, a novel and robust algorithm is proposed for adaptive beamforming based on the idea of reconstructing the autocorrelation sequence (ACS) of a random process from a set of measured data. This is obtained from the first column and the first row of the sample covariance matrix (SCM) after averaging along its diagonals. Then, the power spectrum of the correlation sequence is estimated using the discrete Fourier transform (DFT). The DFT coefficients corresponding to the angles within the noise-plus-interference region are used to reconstruct the noise-plus-interference covariance matrix (NPICM), while the desired signal covariance matrix (DSCM) is estimated by identifying and removing the noise-plusinterference component from the SCM. In particular, the spatial power spectrum of the estimated received signal is utilized to compute the correlation sequence corresponding to the noiseplus-interference in which the dominant DFT coefficient of the noise-plus-interference is captured. A key advantage of the proposed adaptive beamforming is that only little prior information is required. Specifically, an imprecise knowledge of the array geometry and of the angular sectors in which the interferences are located is needed. Simulation results demonstrate that compared with previous reconstruction-based beamformers, the proposed approach can achieve better overall performance in the case of multiple mismatches over a very large range of input signal-tonoise ratios.", "venue": "ArXiv", "authors": ["Saeed  Mohammadzadeh", "Vitor H. Nascimento", "Rodrigo C. de Lamare", "\u00d6sman  K\u00fckrer"], "year": 2021, "n_citations": 0}
{"id": 4318227, "s2_id": "4e61388aa51eaecfc073ba8e9a5db890e70b6ead", "title": "HCMS at SemEval-2020 Task 9: A Neural Approach to Sentiment Analysis for Code-Mixed Texts", "abstract": "Problems involving code-mixed language are often plagued by a lack of resources and an absence of materials to perform sophisticated transfer learning with. In this paper we describe our submission to the Sentimix Hindi-English task involving sentiment classification of code-mixed texts, and with an F1 score of 67.1%, we demonstrate that simple convolution and attention may well produce reasonable results.", "venue": "SEMEVAL", "authors": ["Aditya  Srivastava", "V. Harsha Vardhan"], "year": 2020, "n_citations": 3}
{"id": 4320064, "s2_id": "c8067ed833c3a4f3047aebf98dc82ec625b6e0c6", "title": "Image Translation for Medical Image Generation - Ischemic Stroke Lesions", "abstract": "Deep learning-based automated disease detection and segmentation algorithms promise to accelerate and improve many clinical processes. However, such algorithms require vast amounts of annotated training data, which are typically not available in a medical context, e.g., due to data privacy concerns, legal obstructions, and non-uniform data formats. Synthetic databases of annotated pathologies could provide the required amounts of training data. Here, we demonstrate with the example of ischemic stroke that a significant improvement in lesion segmentation is feasible using deep learning-based data augmentation. To this end, we train different image-to-image translation models to synthesize diffusion-weighted magnetic resonance images (DWIs) of brain volumes with and without stroke lesions from semantic segmentation maps. In addition, we train a generative adversarial network to generate synthetic lesion masks. Subsequently, we combine these two components to build a large database of synthetic stroke DWIs. The performance of the various generative models is evaluated using a U-Net which is trained to segment stroke lesions on a clinical test set. We compare the results to human expert inter-reader scores. For the model with the best performance, we report a maximum Dice score of 82.6\\%, which significantly outperforms the model trained on the clinical images alone (74.8\\%), and also the inter-reader Dice score of two human readers of 76.9\\%. Moreover, we show that for a very limited database of only 10 or 50 clinical cases, synthetic data can be used to pre-train the segmentation algorithms, which ultimately yields an improvement by a factor of as high as 8 compared to a setting where no synthetic data is used.", "venue": "ArXiv", "authors": ["Moritz  Platscher", "Jonathan  Zopes", "Christian  Federau"], "year": 2020, "n_citations": 0}
{"id": 4334607, "s2_id": "c1243acc6a98733f872617f9aec3208dddac3a20", "title": "Weak Supervision for Fake News Detection via Reinforcement Learning", "abstract": "Today social media has become the primary source for news. Via social media platforms, fake news travel at unprecedented speeds, reach global audiences and put users and communities at great risk. Therefore, it is extremely important to detect fake news as early as possible. Recently, deep learning based approaches have shown improved performance in fake news detection. However, the training of such models requires a large amount of labeled data, but manual annotation is time-consuming and expensive. Moreover, due to the dynamic nature of news, annotated samples may become outdated quickly and cannot represent the news articles on newly emerged events. Therefore, how to obtain fresh and high-quality labeled samples is the major challenge in employing deep learning models for fake news detection. In order to tackle this challenge, we propose a reinforced weakly-supervised fake news detection framework, i.e., WeFEND, which can leverage users' reports as weak supervision to enlarge the amount of training data for fake news detection. The proposed framework consists of three main components: the annotator, the reinforced selector and the fake news detector. The annotator can automatically assign weak labels for unlabeled news based on users' reports. The reinforced selector using reinforcement learning techniques chooses high-quality samples from the weakly labeled data and filters out those low-quality ones that may degrade the detector's prediction performance. The fake news detector aims to identify fake news based on the news content. We tested the proposed framework on a large collection of news articles published via WeChat official accounts and associated user reports. Extensive experiments on this dataset show that the proposed WeFEND model achieves the best performance compared with the state-of-the-art methods.", "venue": "AAAI", "authors": ["Yaqing  Wang", "Weifeng  Yang", "Fenglong  Ma", "Jin  Xu", "Bin  Zhong", "Qiang  Deng", "Jing  Gao"], "year": 2020, "n_citations": 34}
{"id": 4335455, "s2_id": "5788dc6baf25ec6e8e2783aede8676635316a277", "title": "Simultaneous super-resolution and motion artifact removal in diffusion-weighted MRI using unsupervised deep learning", "abstract": "Diffusion-weighted MRI is nowadays performed routinely due to its prognostic ability, yet the quality of the scans are often unsatisfactory which can subsequently hamper the clinical utility. To overcome the limitations, here we propose a fully unsupervised quality enhancement scheme, which boosts the resolution and removes the motion artifact simultaneously. This process is done by first training the network using optimal transport driven cycleGAN with stochastic degradation block which learns to remove aliasing artifacts and enhance the resolution, then using the trained network in the test stage by utilizing bootstrap subsampling and aggregation for motion artifact suppression. We further show that we can control the trade-off between the amount of artifact correction and resolution by controlling the bootstrap subsampling ratio at the inference stage. To the best of our knowledge, the proposed method is the first to tackle super-resolution and motion artifact correction simultaneously in the context of MRI using unsupervised learning. We demonstrate the efficiency of our method by applying it to both quantitative evaluation using simulation study, and to in vivo diffusion-weighted MR scans, which shows that our method is superior to the current state-of-the-art methods. The proposed method is flexible in that it can be applied to various quality enhancement schemes in other types of MR scans, and also directly to the quality enhancement of apparent diffusion coefficient maps. \u00a9 2021", "venue": "ArXiv", "authors": ["Hyungjin  Chung", "Jaehyun  Kim", "Jeong Hee Yoon", "Jeong Min Lee", "Jong Chul Ye"], "year": 2021, "n_citations": 2}
{"id": 4337093, "s2_id": "a47ef545d002c1daaf596ed048afbf152ba037f2", "title": "Fast and Accurate Quantized Camera Scene Detection on Smartphones, Mobile AI 2021 Challenge: Report", "abstract": "Camera scene detection is among the most popular computer vision problem on smartphones. While many custom solutions were developed for this task by phone vendors, none of the designed models were available publicly up until now. To address this problem, we introduce the first Mobile AI challenge, where the target is to develop quantized deep learning-based camera scene classification solutions that can demonstrate a real-time performance on smartphones and IoT platforms. For this, the participants were provided with a large-scale CamSDD dataset consisting of more than 11K images belonging to the 30 most important scene categories. The runtime of all models was evaluated on the popular Apple Bionic A11 platform that can be found in many iOS devices. The proposed solutions are fully compatible with all major mobile AI accelerators and can demonstrate more than 100-200 FPS on the majority of recent smartphone platforms while achieving a top-3 accuracy of more than 98%. A detailed description of all models developed in the challenge is provided in this paper.", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "authors": ["Andrey  Ignatov", "Grigory  Malivenko", "Radu  Timofte", "Sheng  Chen", "Xin  Xia", "Zhaoyan  Liu", "Yuwei  Zhang", "Feng  Zhu", "Jiashi  Li", "Xuefeng  Xiao", "Yuan  Tian", "Xinglong  Wu", "Christos  Kyrkou", "Yixin  Chen", "Zexin  Zhang", "Yunbo  Peng", "Yue  Lin", "Saikat  Dutta", "Sourya Dipta Das", "Nisarg A. Shah", "Himanshu  Kumar", "Chao  Ge", "Pei-Lin  Wu", "Jin-Hua  Du", "Andrew  Batutin", "Juan Pablo Federico", "Konrad  Lyda", "Levon  Khojoyan", "Abhishek  Thanki", "Sayak  Paul", "Shahid  Siddiqui"], "year": 2021, "n_citations": 6}
{"id": 4341199, "s2_id": "f3f1c2bc4cfb4c86c418ea312cacefaf6db0065e", "title": "Training GANs with Stronger Augmentations via Contrastive Discriminator", "abstract": "Recent works in Generative Adversarial Networks (GANs) are actively revisiting various data augmentation techniques as an effective way to prevent discriminator overfitting. It is still unclear, however, that which augmentations could actually improve GANs, and in particular, how to apply a wider range of augmentations in training. In this paper, we propose a novel way to address these questions by incorporating a recent contrastive representation learning scheme into the GAN discriminator, coined ContraD. This \u201cfusion\u201d enables the discriminators to work with much stronger augmentations without increasing their training instability, thereby preventing the discriminator overfitting issue in GANs more effectively. Even better, we observe that the contrastive learning itself also benefits from our GAN training, i.e., by maintaining discriminative features between real and fake samples, suggesting a strong coherence between the two worlds: good contrastive representations are also good for GAN discriminators, and vice versa. Our experimental results show that GANs with ContraD consistently improve FID and IS compared to other recent techniques incorporating data augmentations, still maintaining highly discriminative features in the discriminator in terms of the linear evaluation. Finally, as a byproduct, we also show that our GANs trained in an unsupervised manner (without labels) can induce many conditional generative models via a simple latent sampling, leveraging the learned features of ContraD. Code is available at https://github.com/jh-jeong/ContraD.", "venue": "ICLR", "authors": ["Jongheon  Jeong", "Jinwoo  Shin"], "year": 2021, "n_citations": 9}
{"id": 4343701, "s2_id": "cb117e1cfa6a410b397f1e32dce3c54b3295a055", "title": "A Bayesian Perspective on Training Speed and Model Selection", "abstract": "We take a Bayesian perspective to illustrate a connection between training speed and the marginal likelihood in linear models. This provides two major insights: first, that a measure of a model's training speed can be used to estimate its marginal likelihood. Second, that this measure, under certain conditions, predicts the relative weighting of models in linear model combinations trained to minimize a regression loss. We verify our results in model selection tasks for linear models and for the infinite-width limit of deep neural networks. We further provide encouraging empirical evidence that the intuition developed in these settings also holds for deep neural networks trained with stochastic gradient descent. Our results suggest a promising new direction towards explaining why neural networks trained with stochastic gradient descent are biased towards functions that generalize well.", "venue": "NeurIPS", "authors": ["Clare  Lyle", "Lisa  Schut", "Binxin  Ru", "Yarin  Gal", "Mark van der Wilk"], "year": 2020, "n_citations": 10}
{"id": 4346870, "s2_id": "8e2de063a19df803dd22e5fca2912f43e6fea75b", "title": "Designing Machine Learning Pipeline Toolkit for AutoML Surrogate Modeling Optimization", "abstract": "The pipeline optimization problem in machine learning requires simultaneous optimization of pipeline structures and parameter adaptation of their elements. Having an elegant way to express these structures can help lessen the complexity in the management and analysis of their performances together with the different choices of optimization strategies. With these issues in mind, we created the AutoMLPipeline (AMLP) toolkit which facilitates the creation and evaluation of complex machine learning pipeline structures using simple expressions. We use AMLP to find optimal pipeline signatures, datamine them, and use these datamined features to speed-up learning and prediction. We formulated a two-stage pipeline optimization with surrogate modeling in AMLP which outperforms other AutoML approaches with a 4-hour time budget in less than 5 minutes of AMLP computation time.", "venue": "ArXiv", "authors": ["Paulito P. Palmes", "Akihiro  Kishimoto", "Radu  Marinescu", "Parikshit  Ram", "Elizabeth  Daly"], "year": 2021, "n_citations": 0}
{"id": 4354212, "s2_id": "215d1f46697054a710f062e1fca6c4a2fcc18a2a", "title": "A deep convolutional neural network for COVID-19 detection using chest X-rays", "abstract": "Purpose We present image classifiers based on Dense Convolutional Networks and transfer learning to classify chest X-ray images according to three labels: COVID-19, pneumonia, and normal. Methods We fine-tuned neural networks pretrained on ImageNet and applied a twice transfer learning approach, using NIH ChestX-ray14 dataset as an intermediate step. We also suggested a novelty called output neuron keeping, which changes the twice transfer learning technique. In order to clarify the modus operandi of the models, we used Layer-wise Relevance Propagation (LRP) to generate heatmaps. Results We were able to reach test accuracy of 100% on our test dataset. Twice transfer learning and output neuron keeping showed promising results improving performances, mainly in the beginning of the training process. Although LRP revealed that words on the X-rays can influence the networks\u2019 predictions, we discovered this had only a very small effect on accuracy. Conclusion Although clinical studies and larger datasets are still needed to further ensure good generalization, the state-of-the-art performances we achieved show that, with the help of artificial intelligence, chest X-rays can become a cheap and accurate auxiliary method for COVID-19 diagnosis. Heatmaps generated by LRP improve the interpretability of the deep neural networks and indicate an analytical path for future research on diagnosis. Twice transfer learning with output neuron keeping improved DNN performance.", "venue": "Research on Biomedical Engineering", "authors": ["Pedro R. A. S. Bassi", "Romis  Attux"], "year": 2021, "n_citations": 42}
{"id": 4355798, "s2_id": "1be1766a0a92e353f7e314b440c6ee55458ebb32", "title": "Machine Learning Methods for Shark Detection", "abstract": "This essay reviews human observer-based methods employed in shark spotting in Muizenberg Beach. It investigates Machine Learning methods for automated shark detection with the aim of enhancing human observation. A questionnaire and interview were used to collect information about shark spotting, the motivation of the actual Shark Spotter program and its limitations. We have defined a list of desirable properties for our model and chosen the adequate mathematical techniques. The preliminary results of the research show that we can expect to extract useful information from shark images despite the geometric transformations that sharks perform, its features do not change. To conclude, we have partially implemented our model; the remaining implementation requires dataset.", "venue": "ArXiv", "authors": ["Jordan F. Masakuna"], "year": 2019, "n_citations": 0}
{"id": 4361242, "s2_id": "c0ff3bd5fc32d4fdd5a1138fd9b470f3b2ab059d", "title": "Embedding Words as Distributions with a Bayesian Skip-gram Model", "abstract": "We introduce a method for embedding words as probability densities in a low-dimensional space. Rather than assuming that a word embedding is fixed across the entire text collection, as in standard word embedding methods, in our Bayesian model we generate it from a word-specific prior density for each occurrence of a given word. Intuitively, for each word, the prior density encodes the distribution of its potential \u2018meanings\u2019. These prior densities are conceptually similar to Gaussian embeddings of \u0117wcitevilnis2014word. Interestingly, unlike the Gaussian embeddings, we can also obtain context-specific densities: they encode uncertainty about the sense of a word given its context and correspond to the approximate posterior distributions within our model. The context-dependent densities have many potential applications: for example, we show that they can be directly used in the lexical substitution task. We describe an effective estimation method based on the variational autoencoding framework. We demonstrate the effectiveness of our embedding technique on a range of standard benchmarks.", "venue": "COLING", "authors": ["Arthur  Brazinskas", "Serhii  Havrylov", "Ivan  Titov"], "year": 2018, "n_citations": 24}
{"id": 4370136, "s2_id": "7d1ce34de0cbeff136339f2baaa6cc3e9f8e77d2", "title": "Automatic Discovery of Privacy\u2013Utility Pareto Fronts", "abstract": "Abstract Differential privacy is a mathematical framework for privacy-preserving data analysis. Changing the hyperparameters of a differentially private algorithm allows one to trade off privacy and utility in a principled way. Quantifying this trade-off in advance is essential to decision-makers tasked with deciding how much privacy can be provided in a particular application while maintaining acceptable utility. Analytical utility guarantees offer a rigorous tool to reason about this tradeoff, but are generally only available for relatively simple problems. For more complex tasks, such as training neural networks under differential privacy, the utility achieved by a given algorithm can only be measured empirically. This paper presents a Bayesian optimization methodology for efficiently characterizing the privacy\u2013 utility trade-off of any differentially private algorithm using only empirical measurements of its utility. The versatility of our method is illustrated on a number of machine learning tasks involving multiple models, optimizers, and datasets.", "venue": "Proc. Priv. Enhancing Technol.", "authors": ["Brendan  Avent", "Javier  Gonz\u00e1lez", "Tom  Diethe", "Andrei  Paleyes", "Borja  Balle"], "year": 2020, "n_citations": 11}
{"id": 4379196, "s2_id": "7941fb3c0a50921baf0de5ddc439992680b42586", "title": "Q-FIT: The Quantifiable Feature Importance Technique for Explainable Machine Learning", "abstract": "We introduce a novel framework to quantify the importance of each input feature for model explainability. A user of our framework can choose between two modes: (a) global explanation: providing feature importance globally across all the data points; and (b) local explanation: providing feature importance locally for each individual data point. The core idea of our method comes from utilizing the Dirichlet distribution to define a distribution over the importance of input features. This particular distribution is useful in ranking the importance of the input features as a sample from this distribution is a probability vector (i.e., the vector components sum to 1), Thus, the ranking uncovered by our framework which provides a \\textit{quantifiable explanation} of how significant each input feature is to a model's output. This quantifiable explainability differentiates our method from existing feature-selection methods, which simply determine whether a feature is relevant or not. Furthermore, a distribution over the explanation allows to define a closed-form divergence to measure the similarity between learned feature importance under different models. We use this divergence to study how the feature importance trade-offs with essential notions in modern machine learning, such as privacy and fairness. We show the effectiveness of our method on a variety of synthetic and real datasets, taking into account both tabular and image datasets.", "venue": "ArXiv", "authors": ["Kamil  Adamczewski", "Frederik  Harder", "Mijung  Park"], "year": 2020, "n_citations": 0}
{"id": 4380567, "s2_id": "af3bfa53ac27e0f28fb5d08599a4471e1ecb43cb", "title": "G-SMOTE: A GMM-based synthetic minority oversampling technique for imbalanced learning", "abstract": "Imbalanced Learning is an important learning algorithm for the classification models, which have enjoyed much popularity on many applications. Typically, imbalanced learning algorithms can be partitioned into two types, i.e., data level approaches and algorithm level approaches. In this paper, the focus is to develop a robust synthetic minority oversampling technique which falls the umbrella of data level approaches. On one hand, we proposed a method to generate synthetic samples in a high dimensional feature space, instead of a linear sampling space. On the other hand, in the proposed imbalanced learning framework, Gaussian Mixture Model is employed to distinguish the outliers from minority class instances and filter out the synthetic majority class instances. Last and more importantly, an adaptive optimization method is proposed to optimize these parameters in sampling process. By doing so, an effectiveness and efficiency imbalanced learning framework is developed.", "venue": "ArXiv", "authors": ["Tianlun  Zhang", "Xi  Yang"], "year": 2018, "n_citations": 4}
{"id": 4381278, "s2_id": "583c09064b7eff09947e9bd863914a0b166f1400", "title": "Image-Audio Encoding to Improve C2 Decision-Making in Multi-Domain Environment", "abstract": "The military is investigating methods to improve communication and agility in its multi-domain operations (MDO). Nascent popularity of Internet of Things (IoT) has gained traction in public and government domains. Its usage in MDO may revolutionize future battleelds and may enable strategic advantage. While this technology o ers leverage to military capabilities, it comes with challenges where one is the uncertainty and associated risk. A key question is how can these uncertainties be addressed. Recently published studies proposed information camou age to transform information from one data domain to another. As this is comparatively a new approach, we investigate challenges of such transformations and how these associated uncertainties can be detected and addressed, speci cally unknown-unknowns to improve decision-making.", "venue": "ArXiv", "authors": ["Piyush K. Sharma", "Adrienne  Raglin"], "year": 2021, "n_citations": 3}
{"id": 4392268, "s2_id": "af5a134e26abad218657ba3930b8e16058092016", "title": "Geometric Methods for Robust Data Analysis in High Dimension", "abstract": "Machine learning and data analysis now finds both scientific and industrial application in biology, chemistry, geology, medicine, and physics. These applications rely on large quantities of data gathered from automated sensors and user input. Furthermore, the dimensionality of many datasets is extreme: more details are being gathered about single user interactions or sensor readings. All of these applications encounter problems with a common theme: use observed data to make inferences about the world. Our work obtains the first provably efficient algorithms for Independent Component Analysis (ICA) in the presence of heavy-tailed data. The main tool in this result is the centroid body (a well-known topic in convex geometry), along with optimization and random walks for sampling from a convex body. This is the first algorithmic use of the centroid body and it is of independent theoretical interest, since it effectively replaces the estimation of covariance from samples, and is more generally accessible. \nThis reduction relies on a non-linear transformation of samples from such an intersection of halfspaces (i.e. a simplex) to samples which are approximately from a linearly transformed product distribution. Through this transformation of samples, which can be done efficiently, one can then use an ICA algorithm to recover the vertices of the intersection of halfspaces. \nFinally, we again use ICA as an algorithmic primitive to construct an efficient solution to the widely-studied problem of learning the parameters of a Gaussian mixture model. Our algorithm again transforms samples from a Gaussian mixture model into samples which fit into the ICA model and, when processed by an ICA algorithm, result in recovery of the mixture parameters. Our algorithm is effective even when the number of Gaussians in the mixture grows polynomially with the ambient dimension", "venue": "ArXiv", "authors": ["Joseph  Anderson"], "year": 2017, "n_citations": 0}
{"id": 4392810, "s2_id": "b25a30451518d372817967a72e125d638c85379e", "title": "On the Fairness of Disentangled Representations", "abstract": "Recently there has been a significant interest in learning disentangled representations, as they promise increased interpretability, generalization to unseen scenarios and faster learning on downstream tasks. In this paper, we investigate the usefulness of different notions of disentanglement for improving the fairness of downstream prediction tasks based on representations. We consider the setting where the goal is to predict a target variable based on the learned representation of high-dimensional observations (such as images) that depend on both the target variable and an \\emph{unobserved} sensitive variable. We show that in this setting both the optimal and empirical predictions can be unfair, even if the target variable and the sensitive variable are independent. Analyzing the representations of more than \\num{12600} trained state-of-the-art disentangled models, we observe that several disentanglement scores are consistently correlated with increased fairness, suggesting that disentanglement may be a useful property to encourage fairness when sensitive variables are not observed.", "venue": "NeurIPS", "authors": ["Francesco  Locatello", "Gabriele  Abbati", "Tom  Rainforth", "Stefan  Bauer", "Bernhard  Sch\u00f6lkopf", "Olivier  Bachem"], "year": 2019, "n_citations": 103}
{"id": 4405464, "s2_id": "64a85b9e330315364739766bf170c11b4889dc68", "title": "DL-PDE: Deep-learning based data-driven discovery of partial differential equations from discrete and noisy data", "abstract": "In recent years, data-driven methods have been developed to learn dynamical systems and partial differential equations (PDE). The goal of such work is discovering unknown physics and the corresponding equations. However, prior to achieving this goal, major challenges remain to be resolved, including learning PDE under noisy data and limited discrete data. To overcome these challenges, in this work, a deep-learning based data-driven method, called DL-PDE, is developed to discover the governing PDEs of underlying physical processes. The DL-PDE method combines deep learning via neural networks and data-driven discovery of PDE via sparse regressions. In the DL-PDE, a neural network is first trained, and then a large amount of meta-data is generated, and the required derivatives are calculated by automatic differentiation. Finally, the form of PDE is discovered by sparse regression. The proposed method is tested with physical processes, governed by groundwater flow equation, convection-diffusion equation, Burgers equation and Korteweg-de Vries (KdV) equation, for proof-of-concept and applications in real-world engineering settings. The proposed method achieves satisfactory results when data are noisy and limited.", "venue": "ArXiv", "authors": ["Hao  Xu", "Haibin  Chang", "Dongxiao  Zhang"], "year": 2019, "n_citations": 22}
{"id": 4414260, "s2_id": "11a8d27509e5ddda23f554e1a937c87668aaa6ae", "title": "Deep Neural Network inference with reduced word length", "abstract": "Deep neural networks (DNN) are powerful models for many pattern recognition tasks, yet their high computational complexity and memory requirement limit them to applications on high-performance computing platforms. In this paper, we propose a new method to evaluate DNNs trained with 32bit floating point (float32) accuracy using only low precision integer arithmetics in combination with binary shift and clipping operations. Because hardware implementation of these operations is much simpler than high precision floating point calculation, our method can be used for an efficient DNN inference on dedicated hardware. In experiments on MNIST, we demonstrate that DNNs trained with float32 can be evaluated using a combination of 2bit integer arithmetics and a few float32 calculations in each layer or only 3bit integer arithmetics in combination with binary shift and clipping without significant performance degradation.", "venue": "ArXiv", "authors": ["Lukas  Mauch", "Bin  Yang"], "year": 2018, "n_citations": 0}
{"id": 4435865, "s2_id": "7e6dc618d5c0c01cbc7dacd7a58112939b980a63", "title": "A Variance Reduced Stochastic Newton Method", "abstract": "Quasi-Newton methods are widely used in practise for convex loss minimization problems. These methods exhibit good empirical performance on a wide variety of tasks and enjoy super-linear convergence to the optimal solution. For large-scale learning problems, stochastic Quasi-Newton methods have been recently proposed. However, these typically only achieve sub-linear convergence rates and have not been shown to consistently perform well in practice since noisy Hessian approximations can exacerbate the effect of high-variance stochastic gradient estimates. In this work we propose Vite, a novel stochastic Quasi-Newton algorithm that uses an existing first-order technique to reduce this variance. Without exploiting the specific form of the approximate Hessian, we show that Vite reaches the optimum at a geometric rate with a constant step-size when dealing with smooth strongly convex functions. Empirically, we demonstrate improvements over existing stochastic Quasi-Newton and variance reduced stochastic gradient methods.", "venue": "ArXiv", "authors": ["Aur\u00e9lien  Lucchi", "Brian  McWilliams", "Thomas  Hofmann"], "year": 2015, "n_citations": 32}
{"id": 4449565, "s2_id": "20e1d1b185b538f6d6df50e32fb15169c830beb8", "title": "Deep Neural Network-Based Respiratory Pathology Classification Using Cough Sounds", "abstract": "Intelligent systems are transforming the world, as well as our healthcare system. We propose a deep learning-based cough sound classification model that can distinguish between children with healthy versus pathological coughs such as asthma, upper respiratory tract infection (URTI), and lower respiratory tract infection (LRTI). To train a deep neural network model, we collected a new dataset of cough sounds, labelled with a clinician\u2019s diagnosis. The chosen model is a bidirectional long\u2013short-term memory network (BiLSTM) based on Mel-Frequency Cepstral Coefficients (MFCCs) features. The resulting trained model when trained for classifying two classes of coughs\u2014healthy or pathology (in general or belonging to a specific respiratory pathology)\u2014reaches accuracy exceeding 84% when classifying the cough to the label provided by the physicians\u2019 diagnosis. To classify the subject\u2019s respiratory pathology condition, results of multiple cough epochs per subject were combined. The resulting prediction accuracy exceeds 91% for all three respiratory pathologies. However, when the model is trained to classify and discriminate among four classes of coughs, overall accuracy dropped: one class of pathological coughs is often misclassified as the other. However, if one considers the healthy cough classified as healthy and pathological cough classified to have some kind of pathology, then the overall accuracy of the four-class model is above 84%. A longitudinal study of MFCC feature space when comparing pathological and recovered coughs collected from the same subjects revealed the fact that pathological coughs, irrespective of the underlying conditions, occupy the same feature space making it harder to differentiate only using MFCC features.", "venue": "Sensors", "authors": ["T  BalamuraliB", "Hwan Ing Hee", "Saumitra  Kapoor", "Oon Hoe Teoh", "Sung Shin Teng", "Khai Pin Lee", "Dorien  Herremans", "Jer Ming Chen"], "year": 2021, "n_citations": 0}
{"id": 4454198, "s2_id": "bc9293bcee13cae5cff8a088f4038c4236decd42", "title": "A Multimodal Anomaly Detector for Robot-Assisted Feeding Using an LSTM-Based Variational Autoencoder", "abstract": "The detection of anomalous executions is valuable for reducing potential hazards in assistive manipulation. Multimodal sensory signals can be helpful for detecting a wide range of anomalies. However, the fusion of high-dimensional and heterogeneous modalities is a challenging problem for model-based anomaly detection. We introduce a long short-term memory-based variational autoencoder (LSTM-VAE) that fuses signals and reconstructs their expected distribution by introducing a progress-based varying prior. Our LSTM-VAE-based detector reports an anomaly when a reconstruction-based anomaly score is higher than a state-based threshold. For evaluations with 1555 robot-assisted feeding executions, including 12 representative types of anomalies, our detector had a higher area under the receiver operating characteristic curve of 0.8710 than 5 other baseline detectors from the literature. We also show the variational autoencoding and state-based thresholding are effective in detecting anomalies from 17 raw sensory signals without significant feature engineering effort.", "venue": "IEEE Robotics and Automation Letters", "authors": ["Daehyung  Park", "Yuuna  Hoshi", "Charles C. Kemp"], "year": 2018, "n_citations": 168}
{"id": 4456803, "s2_id": "7e9ff94476f41041c75e253e84f487db00e9c861", "title": "Long Range Arena: A Benchmark for Efficient Transformers", "abstract": "Transformers do not scale very well to long sequence lengths largely because of quadratic self-attention complexity. In the recent months, a wide spectrum of efficient, fast Transformers have been proposed to tackle this problem, more often than not claiming superior or comparable model quality to vanilla Transformer models. To this date, there is no well-established consensus on how to evaluate this class of models. Moreover, inconsistent benchmarking on a wide spectrum of tasks and datasets makes it difficult to assess relative model quality amongst many models. This paper proposes a systematic and unified benchmark, LRA, specifically focused on evaluating model quality under long-context scenarios. Our benchmark is a suite of tasks consisting of sequences ranging from $1K$ to $16K$ tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. We systematically evaluate ten well-established long-range Transformer models (Reformers, Linformers, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on our newly proposed benchmark suite. LRA paves the way towards better understanding this class of efficient Transformer models, facilitates more research in this direction, and presents new challenging tasks to tackle. Our benchmark code will be released at this https URL.", "venue": "ICLR", "authors": ["Yi  Tay", "Mostafa  Dehghani", "Samira  Abnar", "Yikang  Shen", "Dara  Bahri", "Philip  Pham", "Jinfeng  Rao", "Liu  Yang", "Sebastian  Ruder", "Donald  Metzler"], "year": 2021, "n_citations": 112}
{"id": 4456886, "s2_id": "a5fe578a6b9f51ce19263676e6395421fedc6d2d", "title": "Residual Gated Graph ConvNets", "abstract": "Graph-structured data such as social networks, functional brain networks, gene regulatory networks, communications networks have brought the interest in generalizing deep learning techniques to graph domains. In this paper, we are interested to design neural networks for graphs with variable length in order to solve learning problems such as vertex classification, graph classification, graph regression, and graph generative tasks. Most existing works have focused on recurrent neural networks (RNNs) to learn meaningful representations of graphs, and more recently new convolutional neural networks (ConvNets) have been introduced. In this work, we want to compare rigorously these two fundamental families of architectures to solve graph learning tasks. We review existing graph RNN and ConvNet architectures, and propose natural extension of LSTM and ConvNet to graphs with arbitrary size. Then, we design a set of analytically controlled experiments on two basic graph problems, i.e. subgraph matching and graph clustering, to test the different architectures. Numerical results show that the proposed graph ConvNets are 3-17% more accurate and 1.5-4x faster than graph RNNs. Graph ConvNets are also 36% more accurate than variational (non-learning) techniques. Finally, the most effective graph ConvNet architecture uses gated edges and residuality. Residuality plays an essential role to learn multi-layer architectures as they provide a 10% gain of performance.", "venue": "ArXiv", "authors": ["Xavier  Bresson", "Thomas  Laurent"], "year": 2017, "n_citations": 111}
{"id": 4466926, "s2_id": "d5fe2f56e1f18240475e0a2fa2423706c0b43d78", "title": "Multipartite Pooling for Deep Convolutional Neural Networks", "abstract": "We propose a novel pooling strategy that learns how to adaptively rank deep convolutional features for selecting more informative representations. To this end, we exploit discriminative analysis to project the features onto a space spanned by the number of classes in the dataset under study. This maps the notion of labels in the feature space into instances in the projected space. We employ these projected distances as a measure to rank the existing features with respect to their specific discriminant power for each individual class. We then apply multipartite ranking to score the separability of the instances and aggregate one-versus-all scores to compute an overall distinction score for each feature. For the pooling, we pick features with the highest scores in a pooling window instead of maximum, average or stochastic random assignments. Our experiments on various benchmarks confirm that the proposed strategy of multipartite pooling is highly beneficial to consistently improve the performance of deep convolutional networks via better generalization of the trained models for the test-time data.", "venue": "ArXiv", "authors": ["Arash  Shahriari", "Fatih Murat Porikli"], "year": 2017, "n_citations": 3}
{"id": 4468987, "s2_id": "a00da61f23420b3af96c6549a6db3644109f4111", "title": "Matrix Completion under Low-Rank Missing Mechanism", "abstract": "Matrix completion is a modern missing data problem where both the missing structure and the underlying parameter are high dimensional. Although missing structure is a key component to any missing data problems, existing matrix completion methods often assume a simple uniform missing mechanism. In this work, we study matrix completion from corrupted data under a novel low-rank missing mechanism. The probability matrix of observation is estimated via a high dimensional low-rank matrix estimation procedure, and further used to complete the target matrix via inverse probabilities weighting. Due to both high dimensional and extreme (i.e., very small) nature of the true probability matrix, the effect of inverse probability weighting requires careful study. We derive optimal asymptotic convergence rates of the proposed estimators for both the observation probabilities and the target matrix.", "venue": "ArXiv", "authors": ["Xiaojun  Mao", "Raymond K. W. Wong", "Song Xi Chen"], "year": 2018, "n_citations": 2}
{"id": 4472848, "s2_id": "25384b0b3a92b2544b6a294d2a535d378174a2b5", "title": "Leveraging Automated Machine Learning for Text Classification: Evaluation of AutoML Tools and Comparison with Human Performance", "abstract": "Recently, Automated Machine Learning (AutoML) has registered increasing success with respect to tabular data. However, the question arises whether AutoML can also be applied effectively to text classification tasks. This work compares four AutoML tools on 13 different popular datasets, including Kaggle competitions, and opposes human performance. The results show that the AutoML tools perform better than the machine learning community in 4 out of 13 tasks and that two stand out.", "venue": "ICAART", "authors": ["Matthias  Blohm", "Marc  Hanussek", "Maximilien  Kintz"], "year": 2021, "n_citations": 6}
{"id": 4481524, "s2_id": "699f4c8cbff14d82a26d85bc5b61e7dc4e2aca86", "title": "Contrastive learning, multi-view redundancy, and linear models", "abstract": "Self-supervised learning is an empirically successful approach to unsupervised learning based on creating artificial supervised learning problems. A popular self-supervised approach to representation learning is contrastive learning, which leverages naturally occurring pairs of similar and dissimilar data points, or multiple views of the same data. This work provides a theoretical analysis of contrastive learning in the multi-view setting, where two views of each datum are available. The main result is that linear functions of the learned representations are nearly optimal on downstream prediction tasks whenever the two views provide redundant information about the label.", "venue": "ALT", "authors": ["Christopher  Tosh", "Akshay  Krishnamurthy", "Daniel  Hsu"], "year": 2021, "n_citations": 29}
{"id": 4484475, "s2_id": "17583773f884b6fe93febaf77d6e1179c4fb92a7", "title": "HOI Analysis: Integrating and Decomposing Human-Object Interaction", "abstract": "Human-Object Interaction (HOI) consists of human, object and implicit interaction/verb. Different from previous methods that directly map pixels to HOI semantics, we propose a novel perspective for HOI learning in an analytical manner. In analogy to Harmonic Analysis, whose goal is to study how to represent the signals with the superposition of basic waves, we propose the HOI Analysis. We argue that coherent HOI can be decomposed into isolated human and object. Meanwhile, isolated human and object can also be integrated into coherent HOI again. Moreover, transformations between human-object pairs with the same HOI can also be easier approached with integration and decomposition. As a result, the implicit verb will be represented in the transformation function space. In light of this, we propose an Integration-Decomposition Network (IDN) to implement the above transformations and achieve state-of-the-art performance on widely-used HOI detection benchmarks. Code is available at this https URL.", "venue": "NeurIPS", "authors": ["Yonglu  Li", "Xinpeng  Liu", "Xiaoqian  Wu", "Yizhuo  Li", "Cewu  Lu"], "year": 2020, "n_citations": 11}
{"id": 4486928, "s2_id": "c0dc4b964a612112f1ba2ed8f6a24db70c355914", "title": "Invariant learning based multi-stage identification for Lithium-ion battery performance degradation", "abstract": "By informing accurate performance (e.g., capacity), health state management plays a significant role in safeguarding battery and its powered system. While most current approaches are primary based on data-driven methods, lacking in-depth analysis of battery performance degradation mechanism may discount their performances. To fill in the research gap about data-driven battery performance degradation analysis, an invariant-learning based method is proposed to investigate whether the battery performance degradation follows a fixed behavior. First, to unfold the hidden dynamics of cycling battery data, measurements are reconstructed in phase subspace. Next, a novel multi-stage division strategy is put forward to judge the existent of multiple degradation behaviors. Then the whole aging procedure is sequentially divided into several segments, among which cycling data with consistent degradation speed are assigned in the same stage. Simulations on a well-know benchmark verify the efficacy of the proposed multi-stages identification strategy. The proposed method not only enables insights into degradation mechanism from data perspective, but also will be helpful to related topics, such as stage of health.", "venue": "IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society", "authors": ["Yan  Qin", "Chau  Yuen", "Stefan  Adams"], "year": 2020, "n_citations": 2}
{"id": 4487340, "s2_id": "c4f6f1a94f0d8028c80be57c9942adfca3dd58bd", "title": "Personalization of Deep Learning", "abstract": "We discuss training techniques, objectives and metrics toward personalization of deep learning models. In machine learning, personalization addresses the goal of a trained model to target a particular individual by optimizing one or more performance metrics, while conforming to certain constraints. To personalize, we investigate three methods of ``curriculum learning`` and two approaches for data grouping, i.e., augmenting the data of an individual by adding similar data identified with an auto-encoder. We show that both ``curriculuum learning'' and ``personalized'' data augmentation lead to improved performance on data of an individual. Mostly, this comes at the cost of reduced performance on a more general, broader dataset.", "venue": "iDSC'19", "authors": ["Johannes  Schneider", "Michail  Vlachos"], "year": 2019, "n_citations": 5}
{"id": 4506384, "s2_id": "efd926a008ffb74acb515db60679583480041cf7", "title": "A New Confidence Interval for the Mean of a Bounded Random Variable", "abstract": "We present a new method for constructing a confidence interval for the mean of a bounded random variable from samples of the random variable. We conjecture that the confidence interval has guaranteed coverage, i.e., that it contains the mean with high probability for all distributions on a bounded interval, for all samples sizes, and for all confidence levels. This new method provides confidence intervals that are competitive with those produced using Student's t-statistic, but does not rely on normality assumptions. In particular, its only requirement is that the distribution be bounded on a known finite interval.", "venue": "ArXiv", "authors": ["Erik G. Learned-Miller", "Philip S. Thomas"], "year": 2019, "n_citations": 2}
{"id": 4512184, "s2_id": "dfdaf6a8da9f747c1f55be247573cd1f56ba51da", "title": "Parsimonious Mahalanobis kernel for the classification of high dimensional data", "abstract": "The classification of high dimensional data with kernel methods is considered in this paper. Exploiting the emptiness property of high dimensional spaces, a kernel based on the Mahalanobis distance is proposed. The computation of the Mahalanobis distance requires the inversion of a covariance matrix. In high dimensional spaces, the estimated covariance matrix is ill-conditioned and its inversion is unstable or impossible. Using a parsimonious statistical model, namely the High Dimensional Discriminant Analysis model, the specific signal and noise subspaces are estimated for each considered class making the inverse of the class specific covariance matrix explicit and stable, leading to the definition of a parsimonious Mahalanobis kernel. A SVM based framework is used for selecting the hyperparameters of the parsimonious Mahalanobis kernel by optimizing the so-called radius-margin bound. Experimental results on three high dimensional data sets show that the proposed kernel is suitable for classifying high dimensional data, providing better classification accuracies than the conventional Gaussian kernel.", "venue": "Pattern Recognit.", "authors": ["Mathieu  Fauvel", "Jocelyn  Chanussot", "Jon Atli Benediktsson", "Alberto  Villa"], "year": 2013, "n_citations": 26}
{"id": 4513826, "s2_id": "c4319a237396171dbd4af7ac9c533b3146466f28", "title": "An Equivalence between the Lasso and Support Vector Machines", "abstract": "We investigate the relation of two fundamental tools in machine learning and signal processing, that is the support vector machine (SVM) for classification, and the Lasso technique used in regression. We show that the resulting optimization problems are equivalent, in the following sense. Given any instance of an $\\ell_2$-loss soft-margin (or hard-margin) SVM, we construct a Lasso instance having the same optimal solutions, and vice versa. \nAs a consequence, many existing optimization algorithms for both SVMs and Lasso can also be applied to the respective other problem instances. Also, the equivalence allows for many known theoretical insights for SVM and Lasso to be translated between the two settings. One such implication gives a simple kernelized version of the Lasso, analogous to the kernels used in the SVM setting. Another consequence is that the sparsity of a Lasso solution is equal to the number of support vectors for the corresponding SVM instance, and that one can use screening rules to prune the set of support vectors. Furthermore, we can relate sublinear time algorithms for the two problems, and give a new such algorithm variant for the Lasso. We also study the regularization paths for both methods.", "venue": "ArXiv", "authors": ["Martin  Jaggi"], "year": 2013, "n_citations": 44}
{"id": 4518447, "s2_id": "c2a8d73fdcf8c09d9174cdbd0c105ed3ab153b3c", "title": "Upsampling Artifacts in Neural Audio Synthesis", "abstract": "A number of recent advances in neural audio synthesis rely on up-sampling layers, which can introduce undesired artifacts. In computer vision, upsampling artifacts have been studied and are known as checkerboard artifacts (due to their characteristic visual pattern). However, their effect has been overlooked so far in audio processing. Here, we address this gap by studying this problem from the audio signal processing perspective. We first show that the main sources of upsampling artifacts are: (i) the tonal and filtering artifacts introduced by problematic upsampling operators, and (ii) the spectral replicas that emerge while upsampling. We then compare different upsampling layers, showing that nearest neighbor upsamplers can be an alternative to the problematic (but state-of-the-art) transposed and subpixel convolutions which are prone to introduce tonal artifacts.", "venue": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Jordi  Pons", "Santiago  Pascual", "Giulio  Cengarle", "Joan  Serra"], "year": 2021, "n_citations": 8}
{"id": 4519412, "s2_id": "bf4e487dff232354128e5855a5e52caf3e6b20a3", "title": "Height Estimation of Children under Five Years using Depth Images", "abstract": "Malnutrition is a global health crisis and is a leading cause of death among children under 5 years. Detecting malnutrition requires anthropometric measurements of weight, height, and middle-upper arm circumference. However, measuring them accurately is a challenge, especially in the global south, due to limited resources. In this work, we propose a CNN-based approach to estimate the height of standing children under 5 years from depth images collected using a smartphone. According to the SMART Methodology Manual, the acceptable accuracy for height is less than 1.4 cm. On training our deep learning model on 87131 depth images, our model achieved a mean absolute error of 1.64% on 57064 test images. For 70.3% test images, we estimated height accurately within the acceptable 1.4 cm range. Thus, our proposed solution can accurately detect stunting (low height-for-age) in standing children below 5 years of age.", "venue": "2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)", "authors": ["Anusua  Trivedi", "Mohit  Jain", "Nikhil Kumar Gupta", "Markus  Hinsche", "Prashant  Singh", "Markus  Matiaschek", "Tristan  Behrens", "Mirco  Militeri", "Cameron  Birge", "Shivangi  Kaushik", "Archisman  Mohapatra", "Rita  Chatterjee", "Rahul  Dodhia", "Juan Lavista Ferres"], "year": 2021, "n_citations": 0}
{"id": 4533595, "s2_id": "905057c2ce305c9d888ff3fda78ef3fd6ce9f60f", "title": "Semi-Supervised Nonlinear Distance Metric Learning via Forests of Max-Margin Cluster Hierarchies", "abstract": "Metric learning is a key problem for many data mining and machine learning applications, and has long been dominated by Mahalanobis methods. Recent advances in nonlinear metric learning have demonstrated the potential power of non-Mahalanobis distance functions, particularly tree-based functions. We propose a novel nonlinear metric learning method that uses an iterative, hierarchical variant of semi-supervised max-margin clustering to construct a forest of cluster hierarchies, where each individual hierarchy can be interpreted as a weak metric over the data. By introducing randomness during hierarchy training and combining the output of many of the resulting semi-random weak hierarchy metrics, we can obtain a powerful and robust nonlinear metric model. This method has two primary contributions: first, it is semi-supervised, incorporating information from both constrained and unconstrained points. Second, we take a relaxed approach to constraint satisfaction, allowing the method to satisfy different subsets of the constraints at different levels of the hierarchy rather than attempting to simultaneously satisfy all of them. This leads to a more robust learning algorithm. We compare our method to a number of state-of-the-art benchmarks on $k$-nearest neighbor classification, large-scale image retrieval and semi-supervised clustering problems, and find that our algorithm yields results comparable or superior to the state-of-the-art.", "venue": "IEEE Transactions on Knowledge and Data Engineering", "authors": ["David M. Johnson", "Caiming  Xiong", "Jason J. Corso"], "year": 2016, "n_citations": 20}
{"id": 4550304, "s2_id": "3e09c4a07e1f0289812f72ecaa9223815e4ea9bd", "title": "ModelWizard: Toward Interactive Model Construction", "abstract": "Data scientists engage in model construction to discover machine learning models that well explain a dataset, in terms of predictiveness, understandability and generalization across domains. Questions such as \"what if we model common cause Z\" and \"what if Y's dependence on X reverses\" inspire many candidate models to consider and compare, yet current tools emphasize constructing a final model all at once. \nTo more naturally reflect exploration when debating numerous models, we propose an interactive model construction framework grounded in composable operations. Primitive operations capture core steps refining data and model that, when verified, form an inductive basis to prove model validity. Derived, composite operations enable advanced model families, both generic and specialized, abstracted away from low-level details. \nWe prototype our envisioned framework in ModelWizard, a domain-specific language embedded in F# to construct Tabular models. We enumerate language design and demonstrate its use through several applications, emphasizing how language may facilitate creation of complex models. To future engineers designing data science languages and tools, we offer ModelWizard's design as a new model construction paradigm, speeding discovery of our universe's structure.", "venue": "ArXiv", "authors": ["Dylan  Hutchison"], "year": 2016, "n_citations": 2}
{"id": 4553873, "s2_id": "f244f207f4576bd639f4e276b791b92b58d6bb16", "title": "Learning network structures from contagion", "abstract": "In 2014, Amin, Heidari, and Kearns proved that tree networks can be learned by observing only the infected set of vertices of the contagion process under the independent cascade model, in both the active and passive query models. They also showed empirically that simple extensions of their algorithms work on sparse networks. In this work, we focus on the active model. We prove that a simple modification of Amin et al.'s algorithm works on more general classes of networks, namely (i) networks with large girth and low path growth rate, and (ii) networks with bounded degree. This also provides partial theoretical explanation for Amin et al.'s experiments on sparse networks. This work considers the contagion process under the independent cascading model.The focus is on networks with large girth and low path growth rate.If the seed sets can be chosen with queries, this type of networks can be learned.This generalizes the result of Amin, Heidari and Kearns (2014) on tree networks.Under the same model, networks with bounded degree can also be learned.", "venue": "Inf. Process. Lett.", "authors": ["Adisak  Supeesun", "Jittat  Fakcharoenphol"], "year": 2017, "n_citations": 2}
{"id": 4566550, "s2_id": "78caecf402cdd7f64ba4fc135981d337df1f718a", "title": "Multiple Support Recovery Using Very Few Measurements Per Sample", "abstract": "In the problem of multiple support recovery, we are given access to linear measurements of multiple sparse samples in $\\mathbb{R}^{d}$. These samples can be partitioned into $\\ell$ groups, with samples having the same support belonging to the same group. For a given budget of $m$ measurements per sample, the goal is to recover the $\\ell$ underlying supports, in the absence of the knowledge of group labels. We study this problem with a focus on the measurement-constrained regime where $m$ is smaller than the support size $k$ of each sample. We design a two-step procedure that estimates the union of the underlying supports first, and then uses a spectral algorithm to estimate the individual supports. Our proposed estimator can recover the supports with $m < k$ measurements per sample, from $\\tilde{O}(k^{4}\\ell^{4}/m^{4})$ samples. Our guarantees hold for a general, generative model assumption on the samples and measurement matrices.", "venue": "2021 IEEE International Symposium on Information Theory (ISIT)", "authors": ["Lekshmi  Ramesh", "Chandra R. Murthy", "Himanshu  Tyagi"], "year": 2021, "n_citations": 0}
{"id": 4567807, "s2_id": "82553e1153f6e1fa6966e3f5baa201dc9e336f27", "title": "Identifying Linear Models in Multi-Resolution Population Data Using Minimum Description Length Principle to Predict Household Income", "abstract": "One shirt size cannot fit everybody, while we cannot make a unique shirt that fits perfectly for everyone because of resource limitations. This analogy is true for policy making as well. Policy makers cannot make a single policy to solve all problems for all regions because each region has its own unique issue. At the other extreme, policy makers also cannot make a policy for each small village due to resource limitations. Would it be better if we can find a set of largest regions such that the population of each region within this set has common issues and we can make a single policy for them? In this work, we propose a framework using regression analysis and Minimum Description Length (MDL) to find a set of largest areas that have common indicators, which can be used to predict household incomes efficiently. Given a set of household features, and a multi-resolution partition that represents administrative divisions, our framework reports a set C* of largest subdivisions that have a common predictive model for population-income prediction. We formalize the problem of finding C* and propose an algorithm that can find C* correctly. We use both simulation datasets as well as a real-world dataset of Thailand\u2019s population household information to demonstrate our framework performance and application. The results show that our framework performance is better than the baseline methods. Moreover, we demonstrate that the results of our method can be used to find indicators of income prediction for many areas in Thailand. By adjusting these indicator values via policies, we expect people in these areas to gain more incomes. Hence, the policy makers will be able to make policies by using these indicators in our results as a guideline to solve low-income issues. Our framework can be used to support policy makers in making policies regarding any other dependent variable beyond income in order to combat poverty and other issues. We provide the R package, MRReg, which is the implementation of our framework in the R language. The MRReg package comes with a documentation for anyone who is interested in analyzing linear regression on multi-resolution population data.", "venue": "ACM Trans. Knowl. Discov. Data", "authors": ["Chainarong  Amornbunchornvej", "Navaporn  Surasvadi", "Anon  Plangprasopchok", "Suttipong  Thajchayapong"], "year": 2021, "n_citations": 3}
{"id": 4574142, "s2_id": "20a10367df3c6cab9090392fdf1ea8d42b245570", "title": "Sharp Analysis of a Simple Model for Random Forests", "abstract": "Random forests have become an important tool for improving accuracy in regression and classification problems since their inception by Leo Breiman in 2001. In this paper, we revisit a historically important random forest model originally proposed by Breiman in 2004 and later studied by G\\'erard Biau in 2012, where a feature is selected at random and the splits occurs at the midpoint of the node along the chosen feature. If the regression function is Lipschitz and depends only on a small subset of $ S $ out of $ d $ features, we show that, given access to $ n $ observations and properly tuned split probabilities, the mean-squared prediction error is $ O((n(\\log n)^{(S-1)/2})^{-\\frac{1}{S\\log2+1}}) $. This positively answers an outstanding question of Biau about whether the rate of convergence for this random forest model could be improved. Furthermore, by a refined analysis of the approximation and estimation errors for linear models, we show that this rate cannot be improved in general. Finally, we generalize our analysis and improve extant prediction error bounds for another random forest model in which each tree is constructed from subsampled data and the splits are performed at the empirical median along a chosen feature.", "venue": "AISTATS", "authors": ["Jason M. Klusowski"], "year": 2021, "n_citations": 8}
{"id": 4583264, "s2_id": "72d48e0e708a3075c6c572b776fc93fb22d5f253", "title": "Zero-Shot Personalized Speech Enhancement Through Speaker-Informed Model Selection", "abstract": "This paper presents a novel zero-shot learning approach towards personalized speech enhancement through the use of a sparsely active ensemble model. Optimizing speech denoising systems towards a particular test-time speaker can improve performance and reduce run-time complexity. However, test-time model adaptation may be challenging if collecting data from the test-time speaker is not possible. To this end, we propose using an ensemble model wherein each specialist module denoises noisy utterances from a distinct partition of training set speakers. The gating module inexpensively estimates test-time speaker characteristics in the form of an embedding vector and selects the most appropriate specialist module for denoising the test signal. Grouping the training set speakers into non-overlapping semantically similar groups is non-trivial and ill-defined. To do this, we first train a Siamese network using noisy speech pairs to maximize or minimize the similarity of its output vectors depending on whether the utterances derive from the same speaker or not. Next, we perform k-means clustering on the latent space formed by the averaged embedding vectors per training set speaker. In this way, we designate speaker groups and train specialist modules optimized around partitions of the complete training set. Our experiments show that ensemble models made up of low-capacity specialists can outperform high-capacity generalist models with greater efficiency and improved adaptation towards unseen test-time speakers.", "venue": "2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)", "authors": ["Aswin  Sivaraman", "Minje  Kim"], "year": 2021, "n_citations": 0}
{"id": 4597410, "s2_id": "b611636f3cfe7b9aa41a606bec1d9fa72e1359ae", "title": "ATOMO: Communication-efficient Learning via Atomic Sparsification", "abstract": "Distributed model training suffers from communication overheads due to frequent gradient updates transmitted between compute nodes. To mitigate these overheads, several studies propose the use of sparsified stochastic gradients. We argue that these are facets of a general sparsification method that can operate on any possible atomic decomposition. Notable examples include element-wise, singular value, and Fourier decompositions. We present ATOMO, a general framework for atomic sparsification of stochastic gradients. Given a gradient, an atomic decomposition, and a sparsity budget, ATOMO gives a random unbiased sparsification of the atoms minimizing variance. We show that methods such as QSGD and TernGrad are special cases of ATOMO and show that sparsifiying gradients in their singular value decomposition (SVD), rather than the coordinate-wise one, can lead to significantly faster distributed training.", "venue": "NeurIPS", "authors": ["Hongyi  Wang", "Scott  Sievert", "Shengchao  Liu", "Zachary B. Charles", "Dimitris S. Papailiopoulos", "Stephen  Wright"], "year": 2018, "n_citations": 169}
{"id": 4604063, "s2_id": "98109740948652595939d69fc797517dd7e009a3", "title": "From things' modeling language (ThingML) to things' machine learning (ThingML2)", "abstract": "In this paper, we illustrate how to enhance an existing state-of-the-art modeling language and tool for the Internet of Things (IoT), called ThingML, to support machine learning on the modeling level. To this aim, we extend the Domain-Specific Language (DSL) of ThingML, as well as its code generation framework. Our DSL allows one to define things, which are in charge of carrying out data analytics. Further, our code generators can automatically produce the complete implementation in Java and Python. The generated Python code is responsible for data analytics and employs APIs of machine learning libraries, such as Keras, Tensorflow and Scikit Learn. Our prototype is available as open source software on Github.", "venue": "MODELS Companion", "authors": ["Armin  Moin", "Stephan  R\u00f6ssler", "Marouane  Sayih", "Stephan  G\u00fcnnemann"], "year": 2020, "n_citations": 7}
{"id": 4604722, "s2_id": "78b78a06d62ec7a234081e39ab9ad71e38ab5b1f", "title": "Deep Time Series Models for Scarce Data", "abstract": "Abstract Time series data have grown at an explosive rate in numerous domains and have stimulated a surge of time series modeling research. A comprehensive comparison of different time series models, for a considered data analytics task, provides useful guidance on model selection for data analytics practitioners. Data scarcity is a universal issue that occurs in a vast range of data analytics problems, due to the high costs associated with collecting, generating and labeling data as well as some data quality issues such as missing data. In this paper, we focus on the temporal classification/regression problem that attempts to build a mathematical mapping from multivariate time series inputs to a discrete class label or a real-valued response variable. For this specific problem, we identify two types of scarce data: scarce data with small samples and scarce data with sparsely and irregularly observed time series covariates. Observing that all existing works are incapable of utilizing the sparse time series inputs for proper modeling building, we propose a model called sparse functional multilayer perceptron (SFMLP) for handling the sparsity in the time series covariates. The effectiveness of the proposed SFMLP under each of the two types of data scarcity, in comparison with the conventional deep sequential learning models (e.g., Recurrent Neural Network, and Long Short-Term Memory), is investigated through mathematical arguments and numerical experiments 1 .", "venue": "Neurocomputing", "authors": ["Qiyao  Wang", "Ahmed  Farahat", "Chetan  Gupta", "Shuai  Zheng"], "year": 2021, "n_citations": 1}
{"id": 4615163, "s2_id": "5f76631d8fbd4293a28aa4d0e4bbcabe2079e364", "title": "FuzzerGym: A Competitive Framework for Fuzzing and Learning", "abstract": "Fuzzing is a commonly used technique designed to test software by automatically crafting program inputs. Currently, the most successful fuzzing algorithms emphasize simple, low-overhead strategies with the ability to efficiently monitor program state during execution. Through compile-time instrumentation, these approaches have access to numerous aspects of program state including coverage, data flow, and heterogeneous fault detection and classification. However, existing approaches utilize blind random mutation strategies when generating test inputs. We present a different approach that uses this state information to optimize mutation operators using reinforcement learning (RL). By integrating OpenAI Gym with libFuzzer we are able to simultaneously leverage advancements in reinforcement learning as well as fuzzing to achieve deeper coverage across several varied benchmarks. Our technique connects the rich, efficient program monitors provided by LLVM Santizers with a deep neural net to learn mutation selection strategies directly from the input data. The cross-language, asynchronous architecture we developed enables us to apply any OpenAI Gym compatible deep reinforcement learning algorithm to any fuzzing problem with minimal slowdown.", "venue": "ArXiv", "authors": ["William  Drozd", "Michael D. Wagner"], "year": 2018, "n_citations": 16}
{"id": 4617891, "s2_id": "ba2e183e2ccb2f55f0cad2f5401975b0b348aad6", "title": "A deep learning classifier for local ancestry inference", "abstract": "Local ancestry inference (LAI) identifies the ancestry of each segment of an individual's genome and is an important step in medical and population genetic studies of diverse cohorts. Several techniques have been used for LAI, including Hidden Markov Models and Random Forests. Here, we formulate the LAI task as an image segmentation problem and develop a new LAI tool using a deep convolutional neural network with an encoder-decoder architecture. We train our model using complete genome sequences from 982 unadmixed individuals from each of five continental ancestry groups, and we evaluate it using simulated admixed data derived from an additional 279 individuals selected from the same populations. We show that our model is able to learn admixture as a zero-shot task, yielding ancestry assignments that are nearly as accurate as those from the existing gold standard tool, RFMix.", "venue": "ArXiv", "authors": ["Matthew  Aguirre", "Jan  Sokol", "Guhan  Venkataraman", "Alexander  Ioannidis"], "year": 2020, "n_citations": 0}
{"id": 4624643, "s2_id": "085f657d684c50eff68fb3067ad006784e2fad21", "title": "Analyzing the Performance of Smart Industry 4.0 Applications on Cloud Computing Systems", "abstract": "Cloud-based Deep Neural Network (DNN) applications that make latency-sensitive inference are becoming an indispensable part of Industry 4.0. Due to the multi-tenancy and resource heterogeneity, both inherent to the cloud computing environments, the inference time of DNN-based applications are stochastic. Such stochasticity, if not captured, can potentially lead to low Quality of Service (QoS) or even a disaster in critical sectors, such as Oil and Gas industry. To make Industry 4.0 robust, solution architects and researchers need to understand the behavior of DNN-based applications and capture the stochasticity exists in their inference times. Accordingly, in this study, we provide a descriptive analysis of the inference time from two perspectives. First, we perform an application-centric analysis and statistically model the execution time of four categorically different DNN applications on both Amazon and Chameleon clouds. Second, we take a resource-centric approach and analyze a rate-based metric in form of Million Instruction Per Second (MIPS) for heterogeneous machines in the cloud. This non-parametric modeling, achieved via Jackknife and Bootstrap re-sampling methods, provides the confidence interval of MIPS for heterogeneous cloud machines. The findings of this research can be helpful for researchers and cloud solution architects to develop solutions that are robust against the stochastic nature of the inference time of DNN applications in the cloud and can offer a higher QoS to their users and avoid unintended outcomes.", "venue": "2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems (HPCC/SmartCity/DSS)", "authors": ["Razin Farhan Hussain", "Alireza  Pakravan", "Mohsen Amini Salehi"], "year": 2020, "n_citations": 0}
{"id": 4625119, "s2_id": "87d0c65af9ccb1054afbf125e4ee8dbf3dcbfab1", "title": "Learning Diverse Policies in MOBA Games via Macro-Goals", "abstract": "Recently, many researchers have made successful progress in building the AI systems for MOBA-game-playing with deep reinforcement learning, such as on Dota 2 and Honor of Kings. Even though these AI systems have achieved or even exceeded human-level performance, they still suffer from the lack of policy diversity. In this paper, we propose a novel Macro-Goals Guided framework, called MGG, to learn diverse policies in MOBA games. MGG abstracts strategies as macro-goals from human demonstrations and trains a Meta-Controller to predict these macro-goals. To enhance policy diversity, MGG samples macro-goals from the Meta-Controller prediction and guides the training process towards these goals. Experimental results on the typical MOBA game Honor of Kings demonstrate that MGG can execute diverse policies in different matches and lineups, and also outperform the state-of-the-art methods over 102 heroes.", "venue": "ArXiv", "authors": ["Yiming  Gao", "Bei  Shi", "Xueying  Du", "Liang  Wang", "Guangwei  Chen", "Zhenjie  Lian", "Fuhao  Qiu", "Guoan  Han", "Weixuan  Wang", "Deheng  Ye", "Qiang  Fu", "Wei  Yang", "Lanxiao  Huang"], "year": 2021, "n_citations": 0}
{"id": 4645038, "s2_id": "94744a831b83ae5c584ad77e52756cb3913cc6f2", "title": "A Close Look at Deep Learning with Small Data", "abstract": "In this work, we perform a wide variety of experiments with different deep learning architectures on datasets of limited size. According to our study, we show that model complexity is a critical factor when only a few samples per class are available. Differently from the literature, we show that in some configurations, the state of the art can be improved using low complexity models. For instance, in problems with scarce training samples and without data augmentation, low-complexity convolutional neural networks perform comparably well or better than state-of-the-art architectures. Moreover, we show that even standard data augmentation can boost recognition performance by large margins. This result suggests the development of more complex data generation/augmentation pipelines for cases when data is limited. Finally, we show that dropout, a widely used regularization technique, maintains its role as a good regularizer even when data is scarce. Our findings are empirically validated on the sub-sampled versions of popular CIFAR-10, Fashion-MNIST and, SVHN benchmarks.", "venue": "2020 25th International Conference on Pattern Recognition (ICPR)", "authors": ["L.  Brigato", "L.  Iocchi"], "year": 2021, "n_citations": 12}
{"id": 4646027, "s2_id": "d84ed05ab860b75f9e6b28e717abf4bc12da03d7", "title": "Explanation-Based Human Debugging of NLP Models: A Survey", "abstract": "Debugging a machine learning model is hard since the bug usually involves the training data and the learning process. This becomes even harder for an opaque deep learning model if we have no clue about how the model actually works. In this survey, we review papers that exploit explanations to enable humans to give feedback and debug NLP models. We call this problem explanation-based human debugging (EBHD). In particular, we categorize and discuss existing work along three dimensions of EBHD (the bug context, the workflow, and the experimental setting), compile findings on how EBHD components affect the feedback providers, and highlight open problems that could be future research directions.", "venue": "ArXiv", "authors": ["Piyawat  Lertvittayakumjorn", "Francesca  Toni"], "year": 2021, "n_citations": 7}
{"id": 4646661, "s2_id": "de25e177b99a9ab064d16afd506c93dd0220a910", "title": "Performance Boundary Identification for the Evaluation of Automated Vehicles using Gaussian Process Classification", "abstract": "Safety is an essential aspect in the facilitation of automated vehicle deployment. Current testing practices are not enough, and going beyond them leads to infeasible testing requirements, such as needing to drive billions of kilometres on public roads. Automated vehicles are exposed to an indefinite number of scenarios. Handling of the most challenging scenarios should be tested, which leads to the question of how such corner cases can be determined. We propose an approach to identify the performance boundary, where these corner cases are located, using Gaussian Process Classification. We also demonstrate the classification on an exemplary traffic jam approach scenario, showing that it is feasible and would lead to more efficient testing practices.", "venue": "2019 IEEE Intelligent Transportation Systems Conference (ITSC)", "authors": ["Felix  Batsch", "Alireza  Daneshkhah", "Madeline  Cheah", "Stratis  Kanarachos", "Anthony  Baxendale"], "year": 2019, "n_citations": 3}
{"id": 4673901, "s2_id": "00e3cd4085e845fe7b95e323f8f058011b10dbe4", "title": "Inferring User Preferences by Probabilistic Logical Reasoning over Social Networks", "abstract": "We propose a framework for inferring the latent attitudes or preferences of users by performing probabilistic first-order logical reasoning over the social network graph. Our method answers questions about Twitter users like {\\em Does this user like sushi?} or {\\em Is this user a New York Knicks fan?} by building a probabilistic model that reasons over user attributes (the user's location or gender) and the social network (the user's friends and spouse), via inferences like homophily (I am more likely to like sushi if spouse or friends like sushi, I am more likely to like the Knicks if I live in New York). The algorithm uses distant supervision, semi-supervised data harvesting and vector space models to extract user attributes (e.g. spouse, education, location) and preferences (likes and dislikes) from text. The extracted propositions are then fed into a probabilistic reasoner (we investigate both Markov Logic and Probabilistic Soft Logic). Our experiments show that probabilistic logical reasoning significantly improves the performance on attribute and relation extraction, and also achieves an F-score of 0.791 at predicting a users likes or dislikes, significantly better than two strong baselines.", "venue": "ArXiv", "authors": ["Jiwei  Li", "Alan  Ritter", "Daniel  Jurafsky"], "year": 2014, "n_citations": 15}
{"id": 4689821, "s2_id": "187c2aac33564fdfec1996bdbec7b9bd3ab51a95", "title": "Visualising Deep Network's Time-Series Representations", "abstract": "Despite the popularisation of machine learning models, more often than not, they still operate as black boxes with no insight into what is happening inside the model. There exist a few methods that allow to visualise and explain why a model has made a certain prediction. Those methods, however, allow visualisation of the link between the input and output of the model without presenting how the model learns to represent the data used to train the model as whole. In this paper, a method that addresses that issue is proposed, with a focus on visualising multi-dimensional time-series data. Experiments on a high-frequency stock market dataset show that the method provides fast and discernible visualisations. Large datasets can be visualised quickly and on one plot, which makes it easy for a user to compare the learned representations of the data. The developed method successfully combines known techniques to provide an insight into the inner workings of time-series classification models.", "venue": "Neural Comput. Appl.", "authors": ["Bla.zej  Leporowski", "Alexandros  Iosifidis"], "year": 2021, "n_citations": 0}
{"id": 4691741, "s2_id": "eaabde9159c5289873e758916a1af30882904636", "title": "Computing Linear Restrictions of Neural Networks", "abstract": "A linear restriction of a function is the same function with its domain restricted to points on a given line. This paper addresses the problem of computing a succinct representation for a linear restriction of a piecewise-linear neural network. This primitive, which we call ExactLine, allows us to exactly characterize the result of applying the network to all of the infinitely many points on a line. In particular, ExactLine computes a partitioning of the given input line segment such that the network is affine on each partition. We present an efficient algorithm for computing ExactLine for networks that use ReLU, MaxPool, batch normalization, fully-connected, convolutional, and other layers, along with several applications. First, we show how to exactly determine decision boundaries of an ACAS Xu neural network, providing significantly improved confidence in the results compared to prior work that sampled finitely many points in the input space. Next, we demonstrate how to exactly compute integrated gradients, which are commonly used for neural network attributions, allowing us to show that the prior heuristic-based methods had relative errors of 25-45% and show that a better sampling method can achieve higher accuracy with less computation. Finally, we use ExactLine to empirically falsify the core assumption behind a well-known hypothesis about adversarial examples, and in the process identify interesting properties of adversarially-trained networks.", "venue": "NeurIPS", "authors": ["Matthew  Sotoudeh", "Aditya V. Thakur"], "year": 2019, "n_citations": 12}
{"id": 4696422, "s2_id": "95210c74f28664d1481be29af411220d27cf63d7", "title": "POP909: A Pop-song Dataset for Music Arrangement Generation", "abstract": "Music arrangement generation is a subtask of automatic music generation, which involves reconstructing and re-conceptualizing a piece with new compositional techniques. Such a generation process inevitably requires reference from the original melody, chord progression, or other structural information. Despite some promising models for arrangement, they lack more refined data to achieve better evaluations and more practical results. In this paper, we propose POP909, a dataset which contains multiple versions of the piano arrangements of 909 popular songs created by professional musicians. The main body of the dataset contains the vocal melody, the lead instrument melody, and the piano accompaniment for each song in MIDI format, which are aligned to the original audio files. Furthermore, we provide the annotations of tempo, beat, key, and chords, where the tempo curves are hand-labeled and others are done by MIR algorithms. Finally, we conduct several baseline experiments with this dataset using standard deep music generation algorithms.", "venue": "ISMIR", "authors": ["Ziyu  Wang", "Ke  Chen", "Junyan  Jiang", "Yiyi  Zhang", "Maoran  Xu", "Shuqi  Dai", "Xianbin  Gu", "Gus  Xia"], "year": 2020, "n_citations": 16}
{"id": 4703508, "s2_id": "7613d67c7348f746ecaf71c6fd034fd577154050", "title": "Distilling Word Embeddings: An Encoding Approach", "abstract": "Distilling knowledge from a well-trained cumbersome network to a small one has recently become a new research topic, as lightweight neural networks with high performance are particularly in need in various resource-restricted systems. This paper addresses the problem of distilling word embeddings for NLP tasks. We propose an encoding approach to distill task-specific knowledge from a set of high-dimensional embeddings, so that we can reduce model complexity by a large margin as well as retain high accuracy, achieving a good compromise between efficiency and performance. Experiments reveal the phenomenon that distilling knowledge from cumbersome embeddings is better than directly training neural networks with small embeddings.", "venue": "CIKM", "authors": ["Lili  Mou", "Ran  Jia", "Yan  Xu", "Ge  Li", "Lu  Zhang", "Zhi  Jin"], "year": 2016, "n_citations": 19}
{"id": 4725414, "s2_id": "04ad5f7fa0b58f412f6b09fcfd14bd79248ad985", "title": "Multilabel 12-Lead Electrocardiogram Classification Using Gradient Boosting Tree Ensemble", "abstract": "The 12-lead electrocardiogram (ECG) is a commonly used tool for detecting cardiac abnormalities such as atrial fibrillation, blocks, and irregular complexes. For the Phy-sioNet/CinC 2020 Challenge, we built an algorithm using gradient boosted tree ensembles fitted on morphology and signal processing features to classify ECG diagnosis. For each lead, we derive features from heart rate variability, PQRST template shape, and the full signal wave-form. We join the features of all 12 leads to fit an ensemble of gradient boosting decision trees to predict probabilities of ECG instances belonging to each class. We train a phase one set of feature importance determining models to isolate the top 1,000 most important features to use in our phase two diagnosis prediction models. We use repeated random sub-sampling by splitting our dataset of 43,101 records into 100 independent runs of 85:15 training/validation splits for our internal evaluation results. Our methodology generates us an official phase validation set score of 0.476 and test set score of \u2212 0.080 under the team name, CVC, placing us 36 out of 41 in the rankings.", "venue": "2020 Computing in Cardiology", "authors": ["Alexander William Wong", "Weijie  Sun", "Sunil Vasu Kalmady", "Padma  Kaul", "Abram  Hindle"], "year": 2020, "n_citations": 0}
{"id": 4728887, "s2_id": "ce42b36c340396b0d922e80896d2d0fe2cb467be", "title": "Proficiency Comparison of LADTree and REPTree Classifiers for Credit Risk Forecast", "abstract": "Predicting the Credit Defaulter is a perilous task of Financial Industries like Banks. Ascertainingnonpayer before giving loan is a significant and conflict-ridden task of the Banker. Classification techniques are the better choice for predictive analysis like finding the claimant, whether he/she is an unpretentious customer or a cheat. Defining the outstanding classifier is a risky assignment for any industrialist like a banker. This allow computer science researchers to drill down efficient research works through evaluating different classifiers and finding out the best classifier for such predictive problems. This research work investigates the productivity of LADTree Classifier and REPTree Classifier for the credit risk prediction and compares their fitness through various measures. German credit dataset has been taken and used to predict the credit risk with a help of open source machine learning tool.", "venue": "ArXiv", "authors": ["C. Lakshmi Devasena"], "year": 2015, "n_citations": 3}
{"id": 4729298, "s2_id": "7efe6c9cdefc29a81b544cbf688d55b62e23dcb8", "title": "Self-Attention for Audio Super-Resolution", "abstract": "Convolutions operate only locally, thus failing to model global interactions. Self-attention is, however, able to learn representations that capture long-range dependencies in sequences. We propose a network architecture for audio super-resolution that combines convolution and self-attention. Attention-based Feature-Wise Linear Modulation (AFiLM) uses self-attention mechanism instead of recurrent neural networks to modulate the activations of the convolutional model. Extensive experiments show that our model outperforms existing approaches on standard benchmarks. Moreover, it allows for more parallelization resulting in significantly faster training.", "venue": "2021 IEEE 31st International Workshop on Machine Learning for Signal Processing (MLSP)", "authors": ["Nathanael Carraz Rakotonirina"], "year": 2021, "n_citations": 0}
{"id": 4732124, "s2_id": "a41102639956f946363db3c22dc84780518a8dfd", "title": "Bottom-Up Meta-Policy Search", "abstract": "Despite of the recent progress in agents that learn through interaction, there are several challenges in terms of sample efficiency and generalization across unseen behaviors during training. To mitigate these problems, we propose and apply a first-order Meta-Learning algorithm called Bottom-Up Meta-Policy Search (BUMPS), which works with two-phase optimization procedure: firstly, in a meta-training phase, it distills few expert policies to create a meta-policy capable of generalizing knowledge to unseen tasks during training; secondly, it applies a fast adaptation strategy named Policy Filtering, which evaluates few policies sampled from the meta-policy distribution and selects which best solves the task. We conducted all experiments in the RoboCup 3D Soccer Simulation domain, in the context of kick motion learning. We show that, given our experimental setup, BUMPS works in scenarios where simple multi-task Reinforcement Learning does not. Finally, we performed experiments in a way to evaluate each component of the algorithm.", "venue": "ArXiv", "authors": ["Luckeciano C. Melo", "Marcos R. O. A. Maximo", "Adilson Marques da Cunha"], "year": 2019, "n_citations": 1}
{"id": 4732582, "s2_id": "95218085633d2e911f9018dde4be7125230cb12f", "title": "Solving internal covariate shift in deep learning with linked neurons", "abstract": "This work proposes a novel solution to the problem of internal covariate shift and dying neurons using the concept of linked neurons. We define the neuron linkage in terms of two constraints: first, all neuron activations in the linkage must have the same operating point. That is to say, all of them share input weights. Secondly, a set of neurons is linked if and only if there is at least one member of the linkage that has a non-zero gradient in regard to the input of the activation function. This means that for any input in the activation function, there is at least one member of the linkage that operates in a non-flat and non-zero area. This simple change has profound implications in the network learning dynamics. In this article we explore the consequences of this proposal and show that by using this kind of units, internal covariate shift is implicitly solved. As a result of this, the use of linked neurons allows to train arbitrarily large networks without any architectural or algorithmic trick, effectively removing the need of using re-normalization schemes such as Batch Normalization, which leads to halving the required training time. It also solves the problem of the need for standarized input data. Results show that the units using the linkage not only do effectively solve the aforementioned problems, but are also a competitive alternative with respect to state-of-the-art with very promising results.", "venue": "ArXiv", "authors": ["Carles Roger Riera Molina", "Oriol Pujol Vila"], "year": 2017, "n_citations": 2}
{"id": 4733150, "s2_id": "7af1d880d51a98c66983e2ce812d6091d8d2528e", "title": "Quantum Algorithms for Learning and Testing Juntas", "abstract": "In this article we develop quantum algorithms for learning and testing juntas, i.e. Boolean functions which depend only on an unknown set of k out of n input variables. Our aim is to develop efficient algorithms: (1) whose sample complexity has no dependence on n, the dimension of the domain the Boolean functions are defined over; (2) with no access to any classical or quantum membership (\u201cblack-box\u201d) queries. Instead, our algorithms use only classical examples generated uniformly at random and fixed quantum superpositions of such classical examples; (3) which require only a few quantum examples but possibly many classical random examples (which are considered quite \u201ccheap\u201d relative to quantum examples). Our quantum algorithms are based on a subroutine FS which enables sampling according to the Fourier spectrum of f; the FS subroutine was used in earlier work of Bshouty and Jackson on quantum learning. Our results are as follows: (1) We give an algorithm for testing k-juntas to accuracy \u03b5 that uses O(k/\u03f5) quantum examples. This improves on the number of examples used by the best known classical algorithm. (2) We establish the following lower bound: any FS-based k-junta testing algorithm requires $$\\Omega(\\sqrt{k})$$ queries. (3) We give an algorithm for learning k-juntas to accuracy \u03f5 that uses O(\u03f5\u22121k\u00a0log k) quantum examples and O(2k log(1/\u03f5)) random examples. We show that this learning algorithm is close to optimal by giving a related lower bound.", "venue": "Quantum Inf. Process.", "authors": ["Alp  Atici", "Rocco A. Servedio"], "year": 2007, "n_citations": 62}
{"id": 4733462, "s2_id": "0cbdf70373d14ea654886cffbce259273dfbb845", "title": "Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders", "abstract": "We present Mockingjay as a new speech representation learning approach, where bidirectional Transformer encoders are pre-trained on a large amount of unlabeled speech. Previous speech representation methods learn through conditioning on past frames and predicting information about future frames. Whereas Mockingjay is designed to predict the current frame through jointly conditioning on both past and future contexts. The Mockingjay representation improves performance for a wide range of downstream tasks, including phoneme classification, speaker recognition, and sentiment classification on spoken content, while outperforming other approaches. Mockingjay is empirically powerful and can be fine-tuned with downstream models, with only 2 epochs we further improve performance dramatically. In a low resource setting with only 0.1% of labeled data, we outperform the result of Mel-features that uses all 100% labeled data.", "venue": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Andy T. Liu", "Shu-wen  Yang", "Po-Han  Chi", "Po-chun  Hsu", "Hung-yi  Lee"], "year": 2020, "n_citations": 114}
{"id": 4734113, "s2_id": "81ae743681a8c237267512df64b3e656d047632b", "title": "Open Compound Domain Adaptation", "abstract": "A typical domain adaptation approach is to adapt models trained on the annotated data in a source domain (e.g., sunny weather) for achieving high performance on the test data in a target domain (e.g., rainy weather). Whether the target contains a single homogeneous domain or multiple heterogeneous domains, existing works always assume that there exist clear distinctions between the domains, which is often not true in practice (e.g., changes in weather). We study an open compound domain adaptation (OCDA) problem, in which the target is a compound of multiple homogeneous domains without domain labels, reflecting realistic data collection from mixed and novel situations. We propose a new approach based on two technical insights into OCDA: 1) a curriculum domain adaptation strategy to bootstrap generalization across domains in a data-driven self-organizing fashion and 2) a memory module to increase the model's agility towards novel domains. Our experiments on digit classification, facial expression recognition, semantic segmentation, and reinforcement learning demonstrate the effectiveness of our approach.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Ziwei  Liu", "Zhongqi  Miao", "Xingang  Pan", "Xiaohang  Zhan", "Dahua  Lin", "Stella X. Yu", "Boqing  Gong"], "year": 2020, "n_citations": 51}
{"id": 4747439, "s2_id": "11db042ed2264f3ea1b8f20151adf725ec3461e8", "title": "Stuck in a What? Adventures in Weight Space", "abstract": "Deep learning researchers commonly suggest that converged models are stuck in local minima. More recently, some researchers observed that under reasonable assumptions, the vast majority of critical points are saddle points, not true minima. Both descriptions suggest that weights converge around a point in weight space, be it a local optima or merely a critical point. However, it\u2019s possible that neither interpretation is accurate. As neural networks are typically over-complete, it\u2019s easy to show the existence of vast continuous regions through weight space with equal loss. In this paper, we build on recent work empirically characterizing the error surfaces of neural networks. We analyze training paths through weight space, presenting evidence that apparent convergence of loss does not correspond to weights arriving at critical points, but instead to large movements through flat regions of weight space. While it\u2019s trivial to show that neural network error surfaces are globally non-convex, we show that error surfaces are also locally nonconvex, even after breaking symmetry with a random initialization and also after partial training.", "venue": "ArXiv", "authors": ["Zachary Chase Lipton"], "year": 2016, "n_citations": 16}
{"id": 4748220, "s2_id": "cff743cd610f0dcb5002872481ec1b5cff04bb3a", "title": "Gradientless Descent: High-Dimensional Zeroth-Order Optimization", "abstract": "Zeroth-order optimization is the process of minimizing an objective $f(x)$, given oracle access to evaluations at adaptively chosen inputs $x$. In this paper, we present two simple yet powerful GradientLess Descent (GLD) algorithms that do not rely on an underlying gradient estimate and are numerically stable. We analyze our algorithm from a novel geometric perspective and present a novel analysis that shows convergence within an $\\epsilon$-ball of the optimum in $O(kQ\\log(n)\\log(R/\\epsilon))$ evaluations, for any monotone transform of a smooth and strongly convex objective with latent dimension $k < n$, where the input dimension is $n$, $R$ is the diameter of the input space and $Q$ is the condition number. Our rates are the first of its kind to be both 1) poly-logarithmically dependent on dimensionality and 2) invariant under monotone transformations. We further leverage our geometric perspective to show that our analysis is optimal. Both monotone invariance and its ability to utilize a low latent dimensionality are key to the empirical success of our algorithms, as demonstrated on BBOB and MuJoCo benchmarks.", "venue": "ICLR", "authors": ["Daniel  Golovin", "John  Karro", "Greg  Kochanski", "Chansoo  Lee", "Xingyou  Song", "Qiuyi  Zhang"], "year": 2020, "n_citations": 33}
{"id": 4761953, "s2_id": "4b67f8e79628db9385e08fc0a4b48a321276e449", "title": "Effective Elastic Scaling of Deep Learning Workloads", "abstract": "We examine the elastic scaling of Deep Learning (DL) jobs and propose a novel resource allocation strategy for DL training jobs, resulting in improved job run time performance as well as increased cluster utilization. We begin by analyzing DL workloads and exploit the fact that DL jobs can be run with a range of batch sizes without affecting their final accuracy. We formulate an optimization problem that explores a dynamic batch size allocation to individual DL jobs based on their scaling efficiency, when running on multiple nodes. We design a fast dynamic programming based optimizer to solve this problem in real-time to determine jobs that can be scaled up/down, and use this optimizer in an autoscaler to dynamically change the allocated resources and batch sizes of individual DL jobs. We demonstrate empirically that our elastic scaling algorithm can complete up to as many jobs as compared to a strong baseline algorithm that also scales the number of GPUs but does not change the batch size, with average completion times up to faster.", "venue": "2020 28th International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)", "authors": ["Vaibhav  Saxena", "K. R. Jayaram", "Saurav  Basu", "Yogish  Sabharwal", "Ashish  Verma"], "year": 2020, "n_citations": 4}
{"id": 4766806, "s2_id": "7602e23d4ca4bce7fac80a2d8deb91dc67e4d813", "title": "Conjugate Gradients for Kernel Machines", "abstract": "Regularized least-squares (kernel-ridge / Gaussian process) regression is a fundamental algorithm of statistics and machine learning. Because generic algorithms for the exact solution have cubic complexity in the number of datapoints, large datasets require to resort to approximations. In this work, the computation of the least-squares prediction is itself treated as a probabilistic inference problem. We propose a structured Gaussian regression model on the kernel function that uses projections of the kernel matrix to obtain a low-rank approximation of the kernel and the matrix. A central result is an enhanced way to use the method of conjugate gradients for the specific setting of least-squares regression as encountered in machine learning. Our method improves the approximation of the kernel ridge regressor / Gaussian process posterior mean over vanilla conjugate gradients and, allows computation of the posterior variance and the log marginal likelihood (evidence) without further overhead.", "venue": "J. Mach. Learn. Res.", "authors": ["Simon  Bartels", "Philipp  Hennig"], "year": 2020, "n_citations": 0}
{"id": 4774412, "s2_id": "a45ab11f36abb45bd4efa48cfd261103954d5585", "title": "Dictionary Learning with Convex Update (ROMD)", "abstract": "Dictionary learning aims to find a dictionary under which the training data can be sparsely represented, and it is usually achieved by iteratively applying two stages: sparse coding and dictionary update. Typical methods for dictionary update focuses on refining both dictionary atoms and their corresponding sparse coefficients by using the sparsity patterns obtained from sparse coding stage, and hence it is a nonconvex bilinear inverse problem. In this paper, we propose a Rank-One Matrix Decomposition (ROMD) algorithm to recast this challenge into a convex problem by resolving these two variables into a set of rank-one matrices. Different from methods in the literature, ROMD updates the whole dictionary at a time using convex programming. The advantages hence include both convergence guarantees for dictionary update and faster convergence of the whole dictionary learning. The performance of ROMD is compared with other benchmark dictionary learning algorithms. The results show the improvement of ROMD in recovery accuracy, especially in the cases of high sparsity level and fewer observation data.", "venue": "ArXiv", "authors": ["Cheng  Cheng", "Wei  Dai"], "year": 2021, "n_citations": 0}
{"id": 4786730, "s2_id": "1da1cf37ac6c9813ca9f0fc8d2fd8a15259e3098", "title": "MRI Image Reconstruction via Learning Optimization Using Neural ODEs", "abstract": "We propose to formulate MRI image reconstruction as an optimization problem and model the optimization trajectory as a dynamic process using ordinary differential equations (ODEs). We model the dynamics in ODE with a neural network and solve the desired ODE with the off-the-shelf (fixed) solver to obtain reconstructed images. We extend this model and incorporate the knowledge of off-the-shelf ODE solvers into the network design (learned solvers). We investigate several models based on three ODE solvers and compare models with fixed solvers and learned solvers. Our models achieve better reconstruction results and are more parameter efficient than other popular methods such as UNet and cascaded CNN. We introduce a new way of tackling the MRI reconstruction problem by modeling the continuous optimization dynamics using neural ODEs.", "venue": "MICCAI", "authors": ["Eric Z. Chen", "Terrence  Chen", "Shanhui  Sun"], "year": 2020, "n_citations": 8}
{"id": 4790379, "s2_id": "4c69fb1210aa826244d6bd45898bca83752ec3b2", "title": "Sparse and Smooth: improved guarantees for Spectral Clustering in the Dynamic Stochastic Block Model", "abstract": "In this paper, we analyse classical variants of the Spectral Clustering (SC) algorithm in the Dynamic Stochastic Block Model (DSBM). Existing results show that, in the relatively sparse case where the expected degree grows logarithmically with the number of nodes, guarantees in the static case can be extended to the dynamic case and yield improved error bounds when the DSBM is sufficiently smooth in time, that is, the communities do not change too much between two time steps. We improve over these results by drawing a new link between the sparsity and the smoothness of the DSBM: the more regular the DSBM is, the more sparse it can be, while still guaranteeing consistent recovery. In particular, a mild condition on the smoothness allows to treat the sparse case with bounded degree. We also extend these guarantees to the normalized Laplacian, and as a by-product of our analysis, we obtain to our knowledge the best spectral concentration bound available for the normalized Laplacian of matrices with independent Bernoulli entries.", "venue": "ArXiv", "authors": ["Nicolas  Keriven", "Samuel  Vaiter"], "year": 2020, "n_citations": 6}
{"id": 4793746, "s2_id": "940f8f1bfdd03b4462085fe43be7b06bd1cb7a62", "title": "Evaluating Temporal Queries Over Video Feeds", "abstract": "Recent advances in Computer Vision and Deep Learning have made possible the efficient extraction of structured information from frames of video feeds. As such, a stream of objects and their associated classes along with unique object identifiers derived via object tracking can be generated, providing unique objects as they are captured across frames. In this paper we initiate a study of temporal queries involving objects and their co-occurrences in video feeds. For example, queries that identify video segments during which the same two red cars and the same two humans appear jointly for five minutes are of interest to many applications ranging from law enforcement to security and safety. We take the first step and define such queries in a way that they incorporate certain physical aspects of video capture such as object occlusion. We present an architecture consisting of three layers, namely object detection/tracking, intermediate data generation, and query evaluation. We propose two techniques, Marked Frame Set (MFS) and Sparse State Graph (SSG), to organize all detected objects in the intermediate data generation layer, which effectively, given the queries, minimizes the number of objects and frames that have to be considered during query evaluation. We also introduce an algorithm called SSG-CM that processes incoming frames against the SSG and efficiently prunes objects and frames unrelated to query evaluation, while maintaining all states required for succinct query evaluation. We present the results of a thorough experimental evaluation utilizing both real and synthetic data, establishing the trade-offs between MFS and SSG. We stress various parameters of interest in our evaluation and demonstrate that the proposed query evaluation methodology coupled with the proposed algorithms is capable to evaluate temporal queries over video feeds efficiently, achieving orders of magnitude performance benefits.", "venue": "SIGMOD Conference", "authors": ["Yueting  Chen", "Xiaohui  Yu", "Nick  Koudas"], "year": 2021, "n_citations": 1}
{"id": 4794966, "s2_id": "b00f6c9318ec6e816a2aa3af8527b5400a6ee82f", "title": "Measuring the User Satisfaction in a Recommendation Interface with Multiple Carousels", "abstract": "It is common for video-on-demand and music streaming services to adopt a user interface composed of several recommendation lists, i.e., widgets or swipeable carousels, each generated according to a specific criterion or algorithm (e.g., most recent, top popular, recommended for you, editors\u2019 choice, etc.). Selecting the appropriate combination of carousel has significant impact on user satisfaction. A crucial aspect of this user interface is that to measure the relevance a new carousel for the user it is not sufficient to account solely for its individual quality. Instead, it should be considered that other carousels will already be present in the interface. This is not considered by traditional evaluation protocols for recommenders systems, in which each carousel is evaluated in isolation, regardless of (i) which other carousels are displayed to the user and (ii) the relative position of the carousel with respect to other carousels. Hence, we propose a two-dimensional evaluation protocol for a carousel setting that will measure the quality of a recommendation carousel based on how much it improves upon the quality of an already available set of carousels. Our evaluation protocol takes into account also the position bias, i.e., users do not explore the carousels sequentially, but rather concentrate on the top-left corner of the screen. We report experiments on the movie domain and notice that under a carousel setting the definition of which criteria has to be preferred to generate a list of recommended items changes with respect to what is commonly understood.", "venue": "IMX", "authors": ["Nicolo  Felicioni", "Maurizio Ferrari Dacrema", "Paolo  Cremonesi"], "year": 2021, "n_citations": 0}
{"id": 4796234, "s2_id": "eef656a1683e9ea18a40a3a858b085101a088d8d", "title": "Are Adversarial Examples Created Equal? A Learnable Weighted Minimax Risk for Robustness under Non-uniform Attacks", "abstract": "Adversarial Training is proved to be an efficient method to defend against adversarial examples, being one of the few defenses that withstand strong attacks. However, traditional defense mechanisms assume a uniform attack over the examples according to the underlying data distribution, which is apparently unrealistic as the attacker could choose to focus on more vulnerable examples. We present a weighted minimax risk optimization that defends against non-uniform attacks, achieving robustness against adversarial examples under perturbed test data distributions. Our modified risk considers importance weights of different adversarial examples and focuses adaptively on harder examples that are wrongly classified or at higher risk of being classified incorrectly. The designed risk allows the training process to learn a strong defense through optimizing the importance weights. The experiments show that our model significantly improves state-of-the-art adversarial accuracy under non-uniform attacks without a significant drop under uniform attacks.", "venue": "AAAI", "authors": ["Huimin  Zeng", "Chen  Zhu", "Tom  Goldstein", "Furong  Huang"], "year": 2021, "n_citations": 2}
{"id": 4805926, "s2_id": "2d306e08cd67b5860fc3dabfb38a124d218275cd", "title": "Black-Box Reductions for Parameter-free Online Learning in Banach Spaces", "abstract": "We introduce several new black-box reductions that significantly improve the design of adaptive and parameter-free online learning algorithms by simplifying analysis, improving regret guarantees, and sometimes even improving runtime. We reduce parameter-free online learning to online exp-concave optimization, we reduce optimization in a Banach space to one-dimensional optimization, and we reduce optimization over a constrained domain to unconstrained optimization. All of our reductions run as fast as online gradient descent. We use our new techniques to improve upon the previously best regret bounds for parameter-free learning, and do so for arbitrary norms.", "venue": "COLT", "authors": ["Ashok  Cutkosky", "Francesco  Orabona"], "year": 2018, "n_citations": 54}
{"id": 4812122, "s2_id": "1dcf4a22a98f076595009c3570af5928eb4ce888", "title": "Collaborative Filtering under Model Uncertainty", "abstract": "In their work, Dean, Rich, and Recht create a model to research recourse and availability of items in a recommender system. We used the definition of predictive multiplicity by Marx, Pin Calmon, and Ustun to examine different variations of this model, using different values for two model parameters. Pairwise comparison of their models show, that most of these models produce very similar results in terms of discrepancy and ambiguity for the availability and only in some cases the availability sets differ significantly.", "venue": "ArXiv", "authors": ["Robin M. Schmidt", "Moritz  Hahn"], "year": 2020, "n_citations": 0}
{"id": 4831576, "s2_id": "1eff01027877843f1b492c4abecdbbc112497d29", "title": "Adversarial Robustness vs. Model Compression, or Both?", "abstract": "It is well known that deep neural networks (DNNs) are vulnerable to adversarial attacks, which are implemented by adding crafted perturbations onto benign examples. Min-max robust optimization based adversarial training can provide a notion of security against adversarial attacks. However, adversarial robustness requires a significantly larger capacity of the network than that for the natural training with only benign examples. This paper proposes a framework of concurrent adversarial training and weight pruning that enables model compression while still preserving the adversarial robustness and essentially tackles the dilemma of adversarial training. Furthermore, this work studies two hypotheses about weight pruning in the conventional setting and finds that weight pruning is essential for reducing the network model size in the adversarial setting; training a small model from scratch even with inherited initialization from the large model cannot achieve neither adversarial robustness nor high standard accuracy. Code is available at https://github.com/yeshaokai/Robustness-Aware-Pruning-ADMM.", "venue": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)", "authors": ["Shaokai  Ye", "Xue  Lin", "Kaidi  Xu", "Sijia  Liu", "Hao  Cheng", "Jan-Henrik  Lambrechts", "Huan  Zhang", "Aojun  Zhou", "Kaisheng  Ma", "Yanzhi  Wang"], "year": 2019, "n_citations": 62}
{"id": 4842591, "s2_id": "c754dbfb069d4e2e190d847c5c6fb991b6231948", "title": "Training a Large Scale Classifier with the Quantum Adiabatic Algorithm", "abstract": "In a previous publication we proposed discrete global optimization as a method to train a strong binary classifier constructed as a thresholded sum over weak classifiers. Our motivation was to cast the training of a classifier into a format amenable to solution by the quantum adiabatic algorithm. Applying adiabatic quantum computing (AQC) promises to yield solutions that are superior to those which can be achieved with classical heuristic solvers. Interestingly we found that by using heuristic solvers to obtain approximate solutions we could already gain an advantage over the standard method AdaBoost. In this communication we generalize the baseline method to large scale classifier training. By large scale we mean that either the cardinality of the dictionary of candidate weak classifiers or the number of weak learners used in the strong classifier exceed the number of variables that can be handled effectively in a single global optimization. For such situations we propose an iterative and piecewise approach in which a subset of weak classifiers is selected in each iteration via global optimization. The strong classifier is then constructed by concatenating the subsets of weak classifiers. We show in numerical studies that the generalized method again successfully competes with AdaBoost. We also provide theoretical arguments as to why the proposed optimization method, which does not only minimize the empirical loss but also adds L0-norm regularization, is superior to versions of boosting that only minimize the empirical loss. By conducting a Quantum Monte Carlo simulation we gather evidence that the quantum adiabatic algorithm is able to handle a generic training problem efficiently.", "venue": "ArXiv", "authors": ["Hartmut  Neven", "Vasil S. Denchev", "Geordie  Rose", "William G. Macready"], "year": 2009, "n_citations": 60}
{"id": 4847444, "s2_id": "3aabed9c0963f5924a19e8fa2c522a730db46e16", "title": "Learning Representations in Model-Free Hierarchical Reinforcement Learning", "abstract": "Common approaches to Reinforcement Learning (RL) are seriously challenged by large-scale applications involving huge state spaces and sparse delayed reward feedback. Hierarchical Reinforcement Learning (HRL) methods attempt to address this scalability issue by learning action selection policies at multiple levels of temporal abstraction. Abstraction can be had by identifying a relatively small set of states that are likely to be useful as subgoals, in concert with the learning of corresponding skill policies to achieve those subgoals. Many approaches to subgoal discovery in HRL depend on the analysis of a model of the environment, but the need to learn such a model introduces its own problems of scale. Once subgoals are identified, skills may be learned through intrinsic motivation, introducing an internal reward signal marking subgoal attainment. We present a novel model-free method for subgoal discovery using incremental unsupervised learning over a small memory of the most recent experiences of the agent. When combined with an intrinsic motivation learning mechanism, this method learns subgoals and skills together, based on experiences in the environment. Thus, we offer an original approach to HRL that does not require the acquisition of a model of the environment, suitable for large-scale applications. We demonstrate the efficiency of our method on a variant of the rooms environment.", "venue": "AAAI", "authors": ["Jacob  Rafati", "David C. Noelle"], "year": 2019, "n_citations": 19}
{"id": 4864684, "s2_id": "5d544cf1349d4ad66af301e59e64176fd8d7436a", "title": "Distribution Preserving Multiple Hypotheses Prediction for Uncertainty Modeling", "abstract": "Many supervised machine learning tasks, such as future state prediction in dynamical systems, require precise modeling of a forecast\u2019s uncertainty. The Multiple Hypotheses Prediction (MHP) approach addresses this problem by providing several hypotheses that represent possible outcomes. Unfortunately, with the common l2 loss function, these hypotheses do not preserve the data distribution\u2019s characteristics. We propose an alternative loss for distribution preserving MHP and review relevant theorems supporting our claims. Furthermore, we empirically show that our approach yields more representative hypotheses on a synthetic and a real-world motion prediction data set. The outputs of the proposed method can directly be used in sampling-based Monte-Carlo methods.", "venue": "ESANN 2021 proceedings", "authors": ["Tobias  Leemann", "Moritz  Sackmann", "Jorn  Thielecke", "Ulrich  Hofmann"], "year": 2021, "n_citations": 0}
{"id": 4867550, "s2_id": "8dcc2713f1bdb7aac45a4ea09a151f6aacd8ded5", "title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics", "abstract": "Unsupervised learning has recently made exceptional progress because of the development of more effective contrastive learning methods. However, CNNs are prone to depend on low-level features that humans deem non-semantic. This dependency has been conjectured to induce a lack of robustness to image perturbations or domain shift. In this paper, we show that by generating carefully designed negative samples, contrastive learning can learn more robust representations with less dependence on such features. Contrastive learning utilizes positive pairs that preserve semantic information while perturbing superficial features in the training images. Similarly, we propose to generate negative samples in a reversed way, where only the superfluous instead of the semantic features are preserved. We develop two methods, texture-based and patch-based augmentations, to generate negative samples. These samples achieve better generalization, especially under out-of-domain settings. We also analyze our method and the generated texture-based samples, showing that texture features are indispensable in classifying particular ImageNet classes and especially finer classes. We also show that model bias favors texture and shape features differently under different test settings. Our code, trained models, and ImageNet-Texutre dataset can be found at https://github.com/ SongweiGe/Contrastive-Learning-with-Non-Semantic-Negatives.", "venue": "ArXiv", "authors": ["Songwei  Ge", "Shlok  Mishra", "Haohan  Wang", "Chun-Liang  Li", "David  Jacobs"], "year": 2021, "n_citations": 0}
{"id": 4871659, "s2_id": "e9d15b38ae99962877ac8ed21e086c7933d23ed6", "title": "Towards a Taxonomy of Graph Learning Datasets", "abstract": "Graph neural networks (GNNs) have attracted much attention due to their ability to leverage the intrinsic geometries of the underlying data. Although many different types of GNN models have been developed, with many benchmarking procedures to demonstrate the superiority of one GNN model over the others, there is a lack of systematic understanding of the underlying benchmarking datasets, and what aspects of the model are being tested. Here, we provide a principled approach to taxonomize graph benchmarking datasets by carefully designing a collection of graph perturbations to probe the essential data characteristics that GNN models leverage to perform predictions. Our data-driven taxonomization of graph datasets provides a new understanding of critical dataset characteristics that will enable better model evaluation and the development of more specialized GNN models.", "venue": "ArXiv", "authors": ["Renming  Liu", "Semih  Canturk", "Frederik  Wenkel", "Dylan  Sandfelder", "Devin  Kreuzer", "Anna  Little", "Sarah  McGuire", "Leslie  O'Bray", "Michael  Perlmutter", "Bastian  Rieck", "Matthew  Hirn", "Guy  Wolf", "Ladislav  Ramp'avsek"], "year": 2021, "n_citations": 0}
{"id": 4874221, "s2_id": "b941940e3c0de388c5de2d72fe9a35cf295f6516", "title": "Weak signals in the mobility landscape: car sharing in ten European cities", "abstract": "Car sharing is one the pillars of a smart transportation infrastructure, as it is expected to reduce traffic congestion, parking demands and pollution in our cities. From the point of view of demand modelling, car sharing is a weak signal in the city landscape: only a small percentage of the population uses it, and thus it is difficult to study reliably with traditional techniques such as households travel diaries. In this work, we depart from these traditional approaches and we leverage web-based, digital records about vehicle availability in 10 European cities for one of the major active car sharing operators. We discuss which sociodemographic and urban activity indicators are associated with variations in car sharing demand, which forecasting approach (among the most popular in the related literature) is better suited to predict pickup and drop-off events, and how the spatio-temporal information about vehicle availability can be used to infer how different zones in a city are used by customers. We conclude the paper by presenting a direct application of the analysis of the dataset, aimed at identifying where to locate maintenance facilities within the car sharing operation area.", "venue": "EPJ Data Science", "authors": ["Chiara  Boldrini", "Raffaele  Bruno", "Mohamed Haitam Laarabi"], "year": 2019, "n_citations": 11}
{"id": 4885837, "s2_id": "213416f5e1e30d86719b6b8d064aebd0fa548d49", "title": "Horizontally Fused Training Array: An Effective Hardware Utilization Squeezer for Training Novel Deep Learning Models", "abstract": "Driven by the tremendous effort in researching novel deep learning (DL) algorithms, the training cost of developing new models increases staggeringly in recent years. We analyze GPU cluster usage statistics from a top research institute for more insights into the hardware efficiency achieved by typical DL training jobs. Our study reveals that single-accelerator training jobs can dominate the cluster-wide resource consumption when launched repetitively (e.g., for hyper-parameter tuning) while severely under-utilizing the hardware. Fortunately, we observe that such workloads have the following unique characteristics: (i) the models among jobs often have the same types of operators with the same shapes, and (ii) the inter-model horizontal fusion of such operators is mathematically equivalent to other already well-optimized operators. Thus, to help DL researchers and practitioners effectively improve the hardware utilization of their novel DL training workloads, we propose Horizontally Fused Training Array (HFTA). HFTA is a new DL framework extension library that horizontally fuses the models from different repetitive jobs deeply down to operators and then trains them simultaneously on a shared accelerator. To show the generality of our solution, we apply HFTA to six DL models training on state-of-the-art accelerators (GPUs and TPUs). Our results indicate that HFTA is highly effective in improving hardware utilization and achieves up to 15.1\u00d7 higher training throughput vs. the standard practice of running each job on a separate accelerator.", "venue": "ArXiv", "authors": ["Shang  Wang", "Peiming  Yang", "Yuxuan  Zheng", "Xin  Li", "Gennady  Pekhimenko"], "year": 2021, "n_citations": 0}
{"id": 4889049, "s2_id": "c30dddb194d0f24b799ae2c94f80373e4d67d06e", "title": "Heterotic String Model Building with Monad Bundles and Reinforcement Learning", "abstract": "We use reinforcement learning as a means of constructing string compactifications with prescribed properties. Specifically, we study heterotic SO(10) GUT models on Calabi-Yau three-folds with monad bundles, in search of phenomenologically promising examples. Due to the vast number of bundles and the sparseness of viable choices, methods based on systematic scanning are not suitable for this class of models. By focusing on two specific manifolds with Picard numbers two and three, we show that reinforcement learning can be used successfully to explore monad bundles. Training can be accomplished with minimal computing resources and leads to highly efficient policy networks. They produce phenomenologically promising states for nearly 100% of episodes and within a small number of steps. In this way, hundreds of new candidate standard models are found. andrei.constantin@physics.ox.ac.uk thomas.harvey@physics.ox.ac.uk andre.lukas@physics.ox.ac.uk 1 ar X iv :2 10 8. 07 31 6v 1 [ he pth ] 1 6 A ug 2 02 1", "venue": "ArXiv", "authors": ["Andrei  Constantin", "Thomas R. Harvey", "Andre  Lukas"], "year": 2021, "n_citations": 6}
{"id": 4893532, "s2_id": "3eb0f85ff84e4869387beffea2846c9243351aa7", "title": "Fluctuation-dissipation relations for stochastic gradient descent", "abstract": "The notion of the stationary equilibrium ensemble has played a central role in statistical mechanics. In machine learning as well, training serves as generalized equilibration that drives the probability distribution of model parameters toward stationarity. Here, we derive stationary fluctuation-dissipation relations that link measurable quantities and hyperparameters in the stochastic gradient descent algorithm. These relations hold exactly for any stationary state and can in particular be used to adaptively set training schedule. We can further use the relations to efficiently extract information pertaining to a loss-function landscape such as the magnitudes of its Hessian and anharmonicity. Our claims are empirically verified.", "venue": "ICLR", "authors": ["Sho  Yaida"], "year": 2019, "n_citations": 44}
{"id": 4897280, "s2_id": "f63348db1dc1aaded02508ca61baede514006758", "title": "THAP: A Matlab Toolkit for Learning with Hawkes Processes", "abstract": "As a powerful tool of asynchronous event sequence analysis, point processes have been studied for a long time and achieved numerous successes in different fields. Among various point process models, Hawkes process and its variants attract many researchers in statistics and computer science these years because they capture the self- and mutually-triggering patterns between different events in complicated sequences explicitly and quantitatively and are broadly applicable to many practical problems. In this paper, we describe an open-source toolkit implementing many learning algorithms and analysis tools for Hawkes process model and its variants. Our toolkit systematically summarizes recent state-of-the-art algorithms as well as most classic algorithms of Hawkes processes, which is beneficial for both academical education and research. Source code can be downloaded from this https URL", "venue": "ArXiv", "authors": ["Hongteng  Xu", "Hongyuan  Zha"], "year": 2017, "n_citations": 9}
{"id": 4898736, "s2_id": "04af2f1805afd18619bb2376e3d97cdb69009668", "title": "Communication-Efficient Federated Learning With Binary Neural Networks", "abstract": "Federated learning (FL) is a privacy-preserving machine learning setting that enables many devices to jointly train a shared global model without the need to reveal their data to a central server. However, FL involves a frequent exchange of the parameters between all the clients and the server that coordinates the training. This introduces extensive communication overhead, which can be a major bottleneck in FL with limited communication links. In this paper, we consider training the binary neural networks (BNNs) in the FL setting instead of the typical real-valued neural networks to fulfill the stringent delay and efficiency requirement in wireless edge networks. We introduce a novel FL framework of training BNNs, where the clients only upload the binary parameters to the server. We also propose a novel parameter updating scheme based on the Maximum Likelihood (ML) estimation that preserves the performance of the BNN even without the availability of aggregated real-valued auxiliary parameters that are usually needed during the training of the BNN. Moreover, for the first time in the literature, we theoretically derive the conditions under which the training of BNN is converging. Numerical results show that the proposed FL framework significantly reduces the communication cost compared to the conventional neural networks with typical real-valued parameters, and the performance loss incurred by the binarization can be further compensated by a hybrid method.", "venue": "IEEE Journal on Selected Areas in Communications", "authors": ["Yuzhi  Yang", "Zhaoyang  Zhang", "Qianqian  Yang"], "year": 2021, "n_citations": 2}
{"id": 4910014, "s2_id": "806c6d524bacafcc13a3f36fbfc878d9f0ed65c2", "title": "AdjointBackMapV2: Precise Reconstruction of Arbitrary CNN Unit's Activation via Adjoint Operators", "abstract": "Adjoint operators have been found to be effective in the exploration of CNN\u2019s inner workings [1]. However, the previous no-bias assumption restricted its generalization. We overcome the restriction via embedding input images into an extended normed space that includes bias in all CNN layers as part of the extended input space and propose an adjoint-operator-based algorithm that maps high-level weights back to the extended input space for reconstructing an effective hypersurface. Such hypersurface can be computed for an arbitrary unit in the CNN, and we prove that this reconstructed hypersurface, when multiplied by the original input (through an inner product), will precisely replicate the output value of each unit. We show experimental results based on the CIFAR-10 dataset that the proposed approach achieves near 0 reconstruction error.", "venue": "ArXiv", "authors": ["Qing  Wan", "Yoonsuck  Choe"], "year": 2021, "n_citations": 0}
{"id": 4920164, "s2_id": "d7a89a5a0a914331d063c28db33552b71a0f586f", "title": "HAD-GAN: A Human-perception Auxiliary Defense GAN to Defend Adversarial Examples", "abstract": "Adversarial examples reveal the vulnerability and unexplained nature of neural networks. Studying the defense of adversarial examples is of considerable practical importance. Most adversarial examples that misclassify networks are often undetectable by humans. In this paper, we propose a defense model to train the classifier into a human-perception classification model with shape preference. The proposed model comprising a texture transfer network (TTN) and an auxiliary defense generative adversarial networks (GAN) is called Human-perception Auxiliary Defense GAN (HAD-GAN). The TTN is used to extend the texture samples of a clean image and helps classifiers focus on its shape. GAN is utilized to form a training framework for the model and generate the necessary images. A series of experiments conducted on MNIST, Fashion-MNIST and CIFAR10 show that the proposed model outperforms the state-of-the-art defense methods for network robustness. The model also demonstrates a significant improvement on defense capability of adversarial examples.", "venue": "ArXiv", "authors": ["Wanting  Yu", "Hongyi  Yu", "Lingyun  Jiang", "Mengli  Zhang", "Kai  Qiao", "Linyuan  Wang", "Bin  Yan"], "year": 2019, "n_citations": 0}
{"id": 4923229, "s2_id": "62500ff173b7388572cd1685fa59d23ac6ca3d83", "title": "On the Parameterized Complexity of Polytree Learning", "abstract": "A Bayesian network is a directed acyclic graph that represents statistical dependencies between variables of a joint probability distribution. A fundamental task in data science is to learn a Bayesian network from observed data. POLYTREE LEARNING is the problem of learning an optimal Bayesian network that fulfills the additional property that its underlying undirected graph is a forest. In this work, we revisit the complexity of POLYTREE LEARNING. We show that POLYTREE LEARNING can be solved in 3 \u00b7 |I| time where n is the number of variables and |I| is the total instance size. Moreover, we consider the influence of the number of variables d that might receive a nonempty parent set in the final DAG on the complexity of POLYTREE LEARNING. We show that POLYTREE LEARNING has no f(d) \u00b7 |I|-time algorithm, unlike Bayesian network learning which can be solved in 2 \u00b7 |I| time. We show that, in contrast, if d and the maximum parent set size are bounded, then we can obtain efficient algorithms.", "venue": "IJCAI", "authors": ["Niels  Gr\u00fcttemeier", "Christian  Komusiewicz", "Nils  Morawietz"], "year": 2021, "n_citations": 1}
{"id": 4937395, "s2_id": "51f300c4c0de859f8c0a1598c78e5e71eeef42fd", "title": "Generating Neural Networks with Neural Networks", "abstract": "Hypernetworks are neural networks that transform a random input vector into weights for a specified target neural network. We formulate the hypernetwork training objective as a compromise between accuracy and diversity, where the diversity takes into account trivial symmetry transformations of the target network. We show that this formulation naturally arises as a relaxation of an optimistic probability distribution objective for the generated networks, and we explain how it is related to variational inference. We use multi-layered perceptrons to form the mapping from the low dimensional input random vector to the high dimensional weight space, and demonstrate how to reduce the number of parameters in this mapping by weight sharing. We perform experiments on a four layer convolutional target network which classifies MNIST images, and show that the generated weights are diverse and have interesting distributions.", "venue": "ArXiv", "authors": ["Lior  Deutsch"], "year": 2018, "n_citations": 11}
{"id": 4941927, "s2_id": "0ba95b192dadc0e8cf8d2d52cf027cf85d02ed10", "title": "Tuning Confidence Bound for Stochastic Bandits with Bandit Distance", "abstract": "We propose a novel modification of the standard upper confidence bound (UCB) method for the stochastic multi-armed bandit (MAB) problem which tunes the confidence bound of a given bandit based on its distance to others. Our UCB distance tuning (UCB-DT) formulation enables improved performance as measured by expected regret by preventing the MAB algorithm from focusing on non-optimal bandits which is a well-known deficiency of standard UCB. \"Distance tuning\" of the standard UCB is done using a proposed distance measure, which we call bandit distance, that is parameterizable and which therefore can be optimized to control the transition rate from exploration to exploitation based on problem requirements. We empirically demonstrate increased performance of UCB-DT versus many existing state-of-the-art methods which use the UCB formulation for the MAB problem. Our contribution also includes the development of a conceptual tool called the Exploration Bargain Point which gives insights into the tradeoffs between exploration and exploitation. We argue that the Exploration Bargain Point provides an intuitive perspective that is useful for comparatively analyzing the performance of UCB-based methods.", "venue": "ArXiv", "authors": ["Xinyu  Zhang", "Srinjoy  Das", "Ken  Kreutz-Delgado"], "year": 2021, "n_citations": 0}
{"id": 4948166, "s2_id": "d56ad8e78328b84a5e0b4c94dfec721e459bf7d5", "title": "Multi Instance Learning For Unbalanced Data", "abstract": "In the context of Multi Instance Learning, we analyze the Single Instance (SI) learning objective. We show that when the data is unbalanced and the family of classifiers is sufficiently rich, the SI method is a useful learning algorithm. In particular, we show that larger data imbalance, a quality that is typically perceived as negative, in fact implies a better resilience of the algorithm to the statistical dependencies of the objects in bags. In addition, our results shed new light on some known issues with the SI method in the setting of linear classifiers, and we show that these issues are significantly less likely to occur in the setting of neural networks. We demonstrate our results on a synthetic dataset, and on the COCO dataset for the problem of patch classification with weak image level labels derived from captions.", "venue": "ArXiv", "authors": ["Mark  Kozdoba", "Edward  Moroshko", "Lior  Shani", "Takuya  Takagi", "Takashi  Katoh", "Shie  Mannor", "Koby  Crammer"], "year": 2018, "n_citations": 0}
{"id": 4949875, "s2_id": "5c5867cf6ee45f6d368fc5c8f64df5edb4cb098b", "title": "Regret-optimal Estimation and Control", "abstract": "We consider estimation and control in linear time-varying dynamical systems from the perspective of regret minimization. Unlike most prior work in this area, we focus on the problem of designing causal estimators and controllers which compete against a clairvoyant noncausal policy, instead of the best policy selected in hindsight from some fixed parametric class. We show that the regret-optimal estimator and regret-optimal controller can be derived in state-space form using operator-theoretic techniques from robust control and present tight, data-dependent bounds on the regret incurred by our algorithms in terms of the energy of the disturbances. Our results can be viewed as extending traditional robust estimation and control, which focuses on minimizing worst-case cost, to minimizing worst-case regret. We propose regret-optimal analogs of Model-Predictive Control (MPC) and the Extended Kalman Filter (EKF) for systems with nonlinear dynamics and present numerical experiments which show that our regret-optimal algorithms can significantly outperform standard approaches to estimation and control.", "venue": "ArXiv", "authors": ["Gautam  Goel", "Babak  Hassibi"], "year": 2021, "n_citations": 2}
{"id": 4951841, "s2_id": "2ba1ca08540b77c7b5c4318e989050774aaca8d2", "title": "Voxel-FPN: multi-scale voxel feature aggregation in 3D object detection from point clouds", "abstract": "Object detection in point cloud data is one of the key components in computer vision systems, especially for autonomous driving applications. In this work, we present Voxel-FPN, a novel one-stage 3D object detector that utilizes raw data from LIDAR sensors only. The core framework consists of an encoder network and a corresponding decoder followed by a region proposal network. Encoder extracts multi-scale voxel information in a bottom-up manner while decoder fuses multiple feature maps from various scales in a top-down way. Extensive experiments show that the proposed method has better performance on extracting features from point data and demonstrates its superiority over some baselines on the challenging KITTI-3D benchmark, obtaining good performance on both speed and accuracy in real-world scenarios.", "venue": "ArXiv", "authors": ["Bei  Wang", "Jianping  An", "Jiayan  Cao"], "year": 2019, "n_citations": 30}
{"id": 4952599, "s2_id": "7e5e35f481c3bdc574ed0d844877c8bf197da8d3", "title": "A Bayesian Monte-Carlo Uncertainty Model for Assessment of Shear Stress Entropy", "abstract": "The entropy models have been recently adopted in many studies to evaluate the distribution of the shear stress in circular channels. However, the uncertainty in their predictions and their reliability remains an open question. We present a novel method to evaluate the uncertainty of four popular entropy models, including Shannon, Shannon-Power Low (PL), Tsallis, and Renyi, in shear stress estimation in circular channels. The Bayesian Monte-Carlo (BMC) uncertainty method is simplified considering a 95% Confidence Bound (CB). We developed a new statistic index called as FREEopt-based OCB (FOCB) using the statistical indices Forecasting Range of Error Estimation (FREE) and the percentage of observed data in the CB (Nin), which integrates their combined effect. The Shannon and Shannon PL entropies had close values of the FOCB equal to 8.781 and 9.808, respectively, had the highest certainty in the calculation of shear stress values in circular channels followed by traditional uniform flow shear stress and Tsallis models with close values of 14.491 and 14.895, respectively. However, Renyi entropy with much higher values of FOCB equal to 57.726 has less certainty in the estimation of shear stress than other models. Using the presented results in this study, the amount of confidence in entropy methods in the calculation of shear stress to design and implement different types of open channels and their stability is determined.", "venue": "ArXiv", "authors": ["Amin  Kazemian-Kale-Kale", "Azadeh  Gholami", "Mohammad  Rezaie-Balf", "Amir  Mosavi", "Ahmed M. A. Sattar", "Bahram  Gharabaghi", "Hossein  Bonakdari"], "year": 2020, "n_citations": 0}
{"id": 4956134, "s2_id": "00b6b62e71251eefa12402964a4ae6fc2b9c7d48", "title": "Modified Frank-Wolfe Algorithm for Enhanced Sparsity in Support Vector Machine Classifiers", "abstract": "This work proposes a new algorithm for training a re-weighted L2 Support Vector Machine (SVM), inspired on the re-weighted Lasso algorithm of Cand\\`es et al. and on the equivalence between Lasso and SVM shown recently by Jaggi. In particular, the margin required for each training vector is set independently, defining a new weighted SVM model. These weights are selected to be binary, and they are automatically adapted during the training of the model, resulting in a variation of the Frank-Wolfe optimization algorithm with essentially the same computational complexity as the original algorithm. As shown experimentally, this algorithm is computationally cheaper to apply since it requires less iterations to converge, and it produces models with a sparser representation in terms of support vectors and which are more stable with respect to the selection of the regularization hyper-parameter.", "venue": "Neurocomputing", "authors": ["Carlos M. Ala\u00edz", "Johan A. K. Suykens"], "year": 2018, "n_citations": 5}
{"id": 4972320, "s2_id": "1a7228f9b966d284d45638f60c77a950e8192145", "title": "Nonlinear Hawkes Process with Gaussian Process Self Effects", "abstract": "Traditionally, Hawkes processes are used to model time\u2013continuous point processes with history dependence. Here we propose an extended model where the self\u2013effects are of both excitatory and inhibitory type and follow a Gaussian Process. Whereas previous work either relies on a less flexible parameterization of the model, or requires a large amount of data, our formulation allows for both a flexible model and learning when data are scarce. We continue the line of work of Bayesian inference for Hawkes processes, and our approach dispenses with the necessity of estimating a branching structure for the posterior, as we perform inference on an aggregated sum of Gaussian Processes. Efficient approximate Bayesian inference is achieved via data augmentation, and we describe a mean\u2013field variational inference approach to learn the model parameters. To demonstrate the flexibility of the model we apply our methodology on data from three different domains and compare it to previously reported results.", "venue": "ArXiv", "authors": ["Noa  Malem-Shinitski", "Cesar  Ojeda", "Manfred  Opper"], "year": 2021, "n_citations": 0}
{"id": 4988424, "s2_id": "3d886afc2a5613e643ce975a1c272c823d133f7d", "title": "A Framework for Distributed Deep Learning Layer Design in Python", "abstract": "In this paper, a framework for testing Deep Neural Network (DNN) design in Python is presented. First, big data, machine learning (ML), and Artificial Neural Networks (ANNs) are discussed to familiarize the reader with the importance of such a system. Next, the benefits and detriments of implementing such a system in Python are presented. Lastly, the specifics of the system are explained, and some experimental results are presented to prove the effectiveness of the system.", "venue": "ArXiv", "authors": ["Clay  McLeod"], "year": 2015, "n_citations": 5}
{"id": 4989267, "s2_id": "f20940246416b610cac2f13c79d891366e52602b", "title": "A Generalized Stochastic Variational Bayesian Hyperparameter Learning Framework for Sparse Spectrum Gaussian Process Regression", "abstract": "While much research effort has been dedicated to scaling up sparse Gaussian process (GP) models based on inducing variables for big data, little attention is afforded to the other less explored class of low-rank GP approximations that exploit the sparse spectral representation of a GP kernel. This paper presents such an effort to advance the state of the art of sparse spectrum GP models to achieve competitive predictive performance for massive datasets. Our generalized framework of stochastic variational Bayesian sparse spectrum GP (sVBSSGP) models addresses their shortcomings by adopting a Bayesian treatment of the spectral frequencies to avoid overfitting, modeling these frequencies jointly in its variational distribution to enable their interaction a posteriori, and exploiting local data for boosting the predictive performance. However, such structural improvements result in a variational lower bound that is intractable to be optimized. To resolve this, we exploit a variational parameterization trick to make it amenable to stochastic optimization. Interestingly, the resulting stochastic gradient has a linearly decomposable structure that can be exploited to refine our stochastic optimization method to incur constant time per iteration while preserving its property of being an unbiased estimator of the exact gradient of the variational lower bound. Empirical evaluation on real-world datasets shows that sVBSSGP outperforms state-of-the-art stochastic implementations of sparse GP models.", "venue": "AAAI", "authors": ["Quang Minh Hoang", "Trong Nghia Hoang", "Kian Hsiang Low"], "year": 2017, "n_citations": 29}
{"id": 4997874, "s2_id": "eeb70ac9a86bc96fefecf347b5a910e959eb7df3", "title": "Boltzmann machines as two-dimensional tensor networks", "abstract": "Sujie Li,1, 2 Feng Pan,1, 2 Pengfei Zhou,1, 2 and Pan Zhang1, 3, 4, \u2217 1CAS Key Laboratory for Theoretical Physics, Institute of Theoretical Physics, Chinese Academy of Sciences, Beijing 100190, China 2School of Physical Sciences, University of Chinese Academy of Sciences, Beijing 100049, China 3School of Fundamental Physics and Mathematical Sciences, Hangzhou Institute for Advanced Study, UCAS, Hangzhou 310024, China 4International Centre for Theoretical Physics Asia-Pacific, Beijing/Hangzhou, China", "venue": "Physical Review B", "authors": ["Sujie  Li", "Feng  Pan", "Pengfei  Zhou", "Pan  Zhang"], "year": 2021, "n_citations": 1}
{"id": 5012161, "s2_id": "ccf413e4a730ee228769c82a8af1fddc2857fbe8", "title": "Deep Learning Based Multi-modal Addressee Recognition in Visual Scenes with Utterances", "abstract": "With the widespread use of intelligent systems, such as smart speakers, addressee recognition has become a concern in human-computer interaction, as more and more people expect such systems to understand complicated social scenes, including those outdoors, in cafeterias, and hospitals. Because previous studies typically focused only on pre-specified tasks with limited conversational situations such as controlling smart homes, we created a mock dataset called Addressee Recognition in Visual Scenes with Utterances (ARVSU) that contains a vast body of image variations in visual scenes with an annotated utterance and a corresponding addressee for each scenario. We also propose a multi-modal deep-learning-based model that takes different human cues, specifically eye gazes and transcripts of an utterance corpus, into account to predict the conversational addressee from a specific speaker's view in various real-life conversational scenarios. To the best of our knowledge, we are the first to introduce an end-to-end deep learning model that combines vision and transcripts of utterance for addressee recognition. As a result, our study suggests that future addressee recognition can reach the ability to understand human intention in many social situations previously unexplored, and our modality dataset is a first step in promoting research in this field.", "venue": "IJCAI", "authors": ["Thao Le Minh", "Nobuyuki  Shimizu", "Takashi  Miyazaki", "Koichi  Shinoda"], "year": 2018, "n_citations": 10}
{"id": 5013217, "s2_id": "ef0c9fe8263ff76154c46ceb8fa530d482e580ee", "title": "Convolutional Neural Networks in Multi-Class Classification of Medical Data", "abstract": "We report applications of Convolutional Neural Networks (CNN) to multi-classification classification of a large medical data set (Diabetes 130-US hospitals for years 1999-2008 dataset). We work on multi-classification of the patient\u2019s readmission, which resulted in classification of three classes: 0, <30, or > 30 days. We discuss in detail how changes in the CNN model and the data pre-processing impact the classification results. In the end, we introduce an ensemble model that consists of both deep learning (CNN) and shallow learning models (Gradient Boosting). The method achieves Accuracy of 64.93%, the highest three-class classification accuracy we achieved in this study. Our results also show that CNN and the ensemble consistently obtain a higher Recall than Precision. The highest Recall is 68.87, whereas the highest Precision is 65.04.", "venue": "ArXiv", "authors": ["YuanZheng  Hu", "Marina  Sokolova"], "year": 2020, "n_citations": 0}
{"id": 5015033, "s2_id": "1c5b16f980fedc25d9ad954f999e604df9f94fa7", "title": "Some Theoretical Properties of GANs", "abstract": "Generative Adversarial Networks (GANs) are a class of generative algorithms that have been shown to produce state-of-the art samples, especially in the domain of image creation. The fundamental principle of GANs is to approximate the unknown distribution of a given data set by optimizing an objective function through an adversarial game between a family of generators and a family of discriminators. In this paper, we offer a better theoretical understanding of GANs by analyzing some of their mathematical and statistical properties. We study the deep connection between the adversarial principle underlying GANs and the Jensen-Shannon divergence, together with some optimality characteristics of the problem. An analysis of the role of the discriminator family via approximation arguments is also provided. In addition, taking a statistical point of view, we study the large sample properties of the estimated distribution and prove in particular a central limit theorem. Some of our results are illustrated with simulated examples.", "venue": "ArXiv", "authors": ["G\u00e9rard  Biau", "Beno\u00eet  Cadre", "Maxime  Sangnier", "Ugo  Tanielian"], "year": 2018, "n_citations": 28}
{"id": 5023219, "s2_id": "7bea6c4c086162bd5ed7436a7c439d9513365b08", "title": "Probabilistic selection of inducing points in sparse Gaussian processes", "abstract": "Sparse Gaussian processes and various extensions thereof are enabled through inducing points, that simultaneously bottleneck the predictive capacity and act as the main contributor towards model complexity. However, the number of inducing points is generally not associated with uncertainty which prevents us from applying the apparatus of Bayesian reasoning in identifying an appropriate trade-off. In this work we place a point process prior on the inducing points and approximate the associated posterior through stochastic variational inference. By letting the prior encourage a moderate number of inducing points, we enable the model to learn which and how many points to utilise. We experimentally show that fewer inducing points are preferred by the model as the points become less informative, and further demonstrate how the method can be applied in deep Gaussian processes and latent variable modelling.", "venue": "UAI", "authors": ["Anders Kirk Uhrenholt", "Valentin  Charvet", "Bjorn Sand Jensen"], "year": 2021, "n_citations": 1}
{"id": 5051206, "s2_id": "14f8d5eb2b16e6649afba9a525336586f7ae4bcb", "title": "From which world is your graph", "abstract": "Discovering statistical structure from links is a fundamental problem in the analysis of social networks. Choosing a misspecified model, or equivalently, an incorrect inference algorithm will result in an invalid analysis or even falsely uncover patterns that are in fact artifacts of the model. This work focuses on unifying two of the most widely used link-formation models: the stochastic blockmodel (SBM) and the small world (or latent space) model (SWM). Integrating techniques from kernel learning, spectral graph theory, and nonlinear dimensionality reduction, we develop the first statistically sound polynomial-time algorithm to discover latent patterns in sparse graphs for both models. When the network comes from an SBM, the algorithm outputs a block structure. When it is from an SWM, the algorithm outputs estimates of each node's latent position.", "venue": "NIPS", "authors": ["Cheng  Li", "Felix Ming Fai Wong", "Zhenming  Liu", "Varun  Kanade"], "year": 2017, "n_citations": 5}
{"id": 5056950, "s2_id": "fa9c96e45111745dc37dfcc54c44c788e3e9dfc4", "title": "Simplifying Deep Reinforcement Learning via Self-Supervision", "abstract": "Supervised regression to demonstrations has been demonstrated to be a stable way to train deep policy networks. We are motivated to study how we can take full advantage of supervised loss functions for stably training deep reinforcement learning agents. This is a challenging task because it is unclear how the training data could be collected to enable policy improvement. In this work, we propose Self-Supervised Reinforcement Learning (SSRL), a simple algorithm that optimizes policies with purely supervised losses. We demonstrate that, without policy gradient or value estimation, an iterative procedure of \u201clabeling\u201d data and supervised regression is sufficient to drive stable policy improvement. By selecting and imitating trajectories with high episodic rewards, SSRL is surprisingly competitive to contemporary algorithms with more stable performance and less running time, showing the potential of solving reinforcement learning with supervised learning techniques. The code is available on GitHub.", "venue": "ArXiv", "authors": ["Daochen  Zha", "Kwei-Herng  Lai", "Kaixiong  Zhou", "Xia  Hu"], "year": 2021, "n_citations": 4}
{"id": 5059957, "s2_id": "a84abcdfb3ef8e55ba5576ea056443b7f1fd6fa5", "title": "Regret Minimization in Behaviorally-Constrained Zero-Sum Games", "abstract": "No-regret learning has emerged as a powerful tool for solving extensive-form games. This was facilitated by the counterfactual-regret minimization (CFR) framework, which relies on the instantiation of regret minimizers for simplexes at each information set of the game. We use an instantiation of the CFR framework to develop algorithms for solving behaviorally-constrained (and, as a special case, perturbed in the Selten sense) extensive-form games, which allows us to compute approximate Nash equilibrium refinements. Nash equilibrium refinements are motivated by a major deficiency in Nash equilibrium: it provides virtually no guarantees on how it will play in parts of the game tree that are reached with zero probability. Refinements can mend this issue, but have not been adopted in practice, mostly due to a lack of scalable algorithms. We show that, compared to standard algorithms, our method finds solutions that have substantially better refinement properties, while enjoying a convergence rate that is comparable to that of state-of-the-art algorithms for Nash equilibrium computation both in theory and practice.", "venue": "ICML", "authors": ["Gabriele  Farina", "Christian  Kroer", "Tuomas  Sandholm"], "year": 2017, "n_citations": 17}
{"id": 5075220, "s2_id": "4d3fbae7753c234590818a6e43a133d6e407b265", "title": "Additive Noise Annealing and Approximation Properties of Quantized Neural Networks", "abstract": "We present a theoretical and experimental investigation of the quantization problem for artificial neural networks. We provide a mathematical definition of quantized neural networks and analyze their approximation capabilities, showing in particular that any Lipschitz-continuous map defined on a hypercube can be uniformly approximated by a quantized neural network. We then focus on the regularization effect of additive noise on the arguments of multi-step functions inherent to the quantization of continuous variables. In particular, when the expectation operator is applied to a non-differentiable multi-step random function, and if the underlying probability density is differentiable (in either classical or weak sense), then a differentiable function is retrieved, with explicit bounds on its Lipschitz constant. Based on these results, we propose a novel gradient-based training algorithm for quantized neural networks that generalizes the straight-through estimator, acting on noise applied to the network's parameters. We evaluate our algorithm on the CIFAR-10 and ImageNet image classification benchmarks, showing state-of-the-art performance on AlexNet and MobileNetV2 for ternary networks.", "venue": "ArXiv", "authors": ["Matteo  Spallanzani", "Lukas  Cavigelli", "Gian Paolo Leonardi", "Marko  Bertogna", "Luca  Benini"], "year": 2019, "n_citations": 10}
{"id": 5084051, "s2_id": "616cc6826066184a8c77c3f2562e4e891ce42911", "title": "Combating Reinforcement Learning's Sisyphean Curse with Intrinsic Fear", "abstract": "To use deep reinforcement learning in the wild, we might hope for an agent that can avoid catastrophic mistakes. Unfortunately, even in simple environments, the popular deep Q-network (DQN) algorithm is doomed by a Sisyphean curse. Owing to the use of function approximation, these agents may eventually forget experiences as they become exceedingly unlikely under a new policy. Consequently, for as long as they continue to train, DQNs may periodically repeat avoidable catastrophic mistakes. In this paper, we learn a reward shaping that accelerates learning and guards oscillating policies against repeated catastrophes. First, we demonstrate unacceptable performance of DQNs on two toy problems. We then introduce intrinsic fear, a new method that mitigates these problems by avoiding dangerous states. Our approach incorporates a second model trained via supervised learning to predict the probability of catastrophe within a short number of steps. This score then acts to penalize the Q-learning objective. Equipped with intrinsic fear, our DQNs solve the toy environments and improve on the Atari games Seaquest, Asteroids, and Freeway.", "venue": "ArXiv", "authors": ["Zachary C. Lipton", "Jianfeng  Gao", "Lihong  Li", "Jianshu  Chen", "Li  Deng"], "year": 2016, "n_citations": 47}
{"id": 5084890, "s2_id": "addcf75e09f5857d7d56c647f455a65b612250a3", "title": "Identifying Audio Adversarial Examples via Anomalous Pattern Detection", "abstract": "Audio processing models based on deep neural networks are susceptible to adversarial attacks even when the adversarial audio waveform is 99.9% similar to a benign sample. Given the wide application of DNN-based audio recognition systems, detecting the presence of adversarial examples is of high practical relevance. By applying anomalous pattern detection techniques in the activation space of these models, we show that 2 of the recent and current state-of-the-art adversarial attacks on audio processing systems systematically lead to higher-than-expected activation at some subset of nodes and we can detect these with up to an AUC of 0.98 with no degradation in performance on benign samples.", "venue": "ArXiv", "authors": ["Victor  Akinwande", "Celia  Cintas", "Skyler  Speakman", "Srihari  Sridharan"], "year": 2020, "n_citations": 5}
{"id": 5086625, "s2_id": "9dd851c26b13008b08640c9fda52451fa17a0435", "title": "Forecasting of the Montreal Subway Smart Card Entry Logs with Event Data", "abstract": "One of the major goals of transport operators is to adapt the transport supply scheduling to the passenger demand for existing transport networks during each specific period. Another problem mentioned by operators is accurately estimating the demand for disposable ticket or pass to adapt ticket availability to passenger demand. In this context, we propose generic data shaping, allowing the use of well-known regression models (basic, statistical and machine learning models) for the long-term forecasting of passenger demand with fine-grained temporal resolution. Specifically, this paper investigates the forecasting until one year ahead of the number of passengers entering each station of a transport network with a quarter-hour aggregation by taking planned events into account (e.g., concerts, shows, and so forth). To compare the models and the quality of the prediction, we use a real smart card and event data set from the city of Montr\\'eal, Canada, that span a three-year period with two years for training and one year for testing.", "venue": "ArXiv", "authors": ["Florian  Toqu'e", "Etienne  Come", "Martin  Tr'epanier", "Latifa  Oukhellou"], "year": 2020, "n_citations": 1}
{"id": 5088476, "s2_id": "1c3d659e9459bb8aad72390d2b340e051add6dac", "title": "HINT: Hierarchical Invertible Neural Transport for Density Estimation and Bayesian Inference", "abstract": "A large proportion of recent invertible neural architectures is based on a coupling block design. It operates by dividing incoming variables into two sub-spaces, one of which parameterizes an easily invertible (usually affine) transformation that is applied to the other. While the Jacobian of such a transformation is triangular, it is very sparse and thus may lack expressiveness. This work presents a simple remedy by noting that (affine) coupling can be repeated recursively within the resulting sub-spaces, leading to an efficiently invertible block with dense triangular Jacobian. By formulating our recursive coupling scheme via a hierarchical architecture, HINT allows sampling from a joint distribution p(y,x) and the corresponding posterior p(x|y) using a single invertible network. We demonstrate the power of our method for density estimation and Bayesian inference on a novel data set of 2D shapes in Fourier parameterization, which enables consistent visualization of samples for different dimensionalities.", "venue": "AAAI", "authors": ["Jakob  Kruse", "Gianluca  Detommaso", "Robert  Scheichl", "Ullrich  K\u00f6the"], "year": 2021, "n_citations": 14}
{"id": 5091912, "s2_id": "78eff3318a511edd144ac3d63e510538b459d844", "title": "Towards a Robust Parameterization for Conditioning Facies Models Using Deep Variational Autoencoders and Ensemble Smoother", "abstract": "Abstract Ensemble-based methods have been applied with remarkable success for data assimilation in geosciences. However, they sometimes fail to preserve the geological realism of the model, which is particularly evident in reservoirs with complex facies distributions. This occurs mainly because of the underlying Gaussian assumptions on model parameters that are inherent in these methods. This fact has encouraged an intense research activity to develop Gaussian parameterizations in a latent space that maps into geologically-realistic facies realizations. Despite the large number of publications, the development of robust parameterizations for facies remains an open problem. Deep learning techniques have been delivering impressive results in a number of different areas and the first applications in data assimilation in geoscience have started to appear in the literature. The present paper reports the current results of our investigations on the use of deep neural networks towards the construction of a continuous parameterization of facies, which can be used for data assimilation with ensemble methods. Specifically, we use a convolutional variational autoencoder and the ensemble smoother with multiple data assimilation. We tested the parameterization in three synthetic history-matching problems with channelized facies. We focus on this type of facies because they are among the most challenging to preserve after the assimilation of data. The parameterization showed promising results, outperforming previous methods and generating well-defined channelized facies. However, more research is still required before deploying these methods for operational use. In particular, it is necessary to investigate procedures to improve the reconstruction accuracy in three-dimensional cases and reduce the computational requirements to train the networks.", "venue": "Comput. Geosci.", "authors": ["Smith W. A. Canchumuni", "Alexandre A. Emerick", "Marco Aur\u00e9lio Cavalcanti Pacheco"], "year": 2019, "n_citations": 39}
{"id": 5124330, "s2_id": "3f4615ce7118151e243cad5544f0c75b01be171e", "title": "Metric Learning for Adversarial Robustness", "abstract": "Deep networks are well-known to be fragile to adversarial attacks. We conduct an empirical analysis of deep representations under the state-of-the-art attack method called PGD, and find that the attack causes the internal representation to shift closer to the ``false'' class. Motivated by this observation, we propose to regularize the representation space under attack with metric learning to produce more robust classifiers. By carefully sampling examples for metric learning, our learned representation not only increases robustness, but also detects previously unseen adversarial samples. Quantitative experiments show improvement of robustness accuracy by up to 4% and detection efficiency by up to 6% according to Area Under Curve score over prior work. The code of our work is available at https://github.com/columbia/Metric_Learning_Adversarial_Robustness.", "venue": "NeurIPS", "authors": ["Chengzhi  Mao", "Ziyuan  Zhong", "Junfeng  Yang", "Carl  Vondrick", "Baishakhi  Ray"], "year": 2019, "n_citations": 76}
{"id": 5142250, "s2_id": "766c227f949d7a37871f957797aebb79e0fdc3a9", "title": "Knowledge discovery from social media using big data-provided sentiment analysis (SoMABiT)", "abstract": "In today\u2019s competitive business world, being aware of customer needs and market-oriented production is a key success factor for industries. To this aim, the use of efficient analytical algorithms ensures better understanding of customer feedback and improves the next generation of products. Accordingly, the dramatic increase in the use of social media in daily life provides beneficial sources for market analytics. Yet how traditional analytic algorithms and methods can be scaled up for such disparate and multistructured data sources is a major challenge. This paper presents and discusses the technological and scientific focus of SoMABiT as a social media analysis platform using big data technology. Sentiment analysis has been employed in order to discover knowledge from social media. The use of MapReduce and the development of a distributed algorithm towards an integrated platform that can scale for any data volume and provide social media-driven knowledge is the main novelty of the proposed concept in comparison to the state-of-the-art technologies.", "venue": "J. Inf. Sci.", "authors": ["Mahdi  Bohlouli", "Jens  Dalter", "Mareike  Dornh\u00f6fer", "Johannes  Zenkert", "Madjid  Fathi"], "year": 2015, "n_citations": 24}
{"id": 5158398, "s2_id": "143606b8aeb12ae7e75d28ae65354df60cedea5d", "title": "A Framework for Joint Unsupervised Learning of Cluster-Aware Embedding for Heterogeneous Networks", "abstract": "1Heterogeneous Information Network (HIN) embedding refers to the low-dimensional projections of the HIN nodes that preserve the HIN structure and semantics. HIN embedding has emerged as a promising research field for network analysis as it enables downstream tasks such as clustering and node classification. In this work, we propose VaCA-HINE for joint learning of cluster embeddings as well as cluster-aware HIN embedding. We assume that the connected nodes are highly likely to fall in the same cluster, and adopt a variational approach to preserve the information in the pairwise relations in a cluster-aware manner. In addition, we deploy contrastive modules to simultaneously utilize the information in multiple meta-paths, thereby alleviating the meta-path selection problem a challenge faced by many of the famous HIN embedding approaches. The HIN embedding, thus learned, not only improves the clustering performance but also preserves pairwise proximity as well as the high-order HIN structure. We show the effectiveness of our approach by comparing it with many competitive baselines on three real-world datasets on clustering and downstream node classification. CCS CONCEPTS \u2022 Information systems \u2192 Clustering and classification; Clustering and classification; \u2022 Theory of computation \u2192 Unsupervised learning and clustering; \u2022 Mathematics of computing \u2192 Variational methods; \u2022Computingmethodologies\u2192 Learning latent representations.", "venue": "ArXiv", "authors": ["Rayyan Ahmad Khan", "Martin  Kleinsteuber"], "year": 2021, "n_citations": 0}
{"id": 5159092, "s2_id": "68e2f7d9814287e836c9b0f632fb6127390478ab", "title": "Learning Nonparametric Volterra Kernels with Gaussian Processes", "abstract": "This paper introduces a method for the nonparametric Bayesian learning of nonlinear operators, through the use of the Volterra series with kernels represented using Gaussian processes (GPs), which we term the nonparametric Volterra kernels model (NVKM). When the input function to the operator is unobserved and has a GP prior, the NVKM constitutes a powerful method for both single and multiple output regression, and can be viewed as a nonlinear and nonparametric latent force model. When the input function is observed, the NVKM can be used to perform Bayesian system identification. We use recent advances in efficient sampling of explicit functions from GPs to map process realisations through the Volterra series without resorting to numerical integration, allowing scalability through doubly stochastic variational inference, and avoiding the need for Gaussian approximations of the output processes. We demonstrate the performance of the model for both multiple output regression and system identification using standard benchmarks.", "venue": "ArXiv", "authors": ["Magnus  Ross", "Michael T. Smith", "Mauricio A. 'Alvarez"], "year": 2021, "n_citations": 0}
{"id": 5161030, "s2_id": "92b3a08ea71aa7f8d2fec061a322ed7c8a7cca9a", "title": "Data Warehouse and Decision Support on Integrated Crop Big Data", "abstract": "In recent years, precision agriculture is becoming very popular. The introduction of modern information and communication technologies for collecting and processing Agricultural data revolutionise the agriculture practises. This has started a while ago (early 20th century) and it is driven by the low cost of collecting data about everything; from information on fields such as seed, soil, fertiliser, pest, to weather data, drones and satellites images. Specially, the agricultural data mining today is considered as Big Data application in terms of volume, variety, velocity and veracity. Hence it leads to challenges in processing vast amounts of complex and diverse information to extract useful knowledge for the farmer, agronomist, and other businesses. It is a key foundation to establishing a crop intelligence platform, which will enable efficient resource management and high quality agronomy decision making and recommendations. In this paper, we designed and implemented a continental level agricultural data warehouse (ADW). ADW is characterised by its (1) flexible schema; (2) data integration from real agricultural multi datasets; (3) data science and business intelligent support; (4) high performance; (5) high storage; (6) security; (7) governance and monitoring; (8) consistency, availability and partition tolerant; (9) cloud compatibility. We also evaluate the performance of ADW and present some complex queries to extract and return necessary knowledge about crop management.", "venue": "Int. J. Bus. Process. Integr. Manag.", "authors": ["V. M. Ngo", "N. A. Le-Khac", "M. T. Kechadi"], "year": 2020, "n_citations": 2}
{"id": 5167378, "s2_id": "13f25c69973373e616c48688d06a6b6ae2736ef0", "title": "Towards the Systematic Reporting of the Energy and Carbon Footprints of Machine Learning", "abstract": "Accurate reporting of energy and carbon usage is essential for understanding the potential climate impacts of machine learning research. We introduce a framework that makes this easier by providing a simple interface for tracking realtime energy consumption and carbon emissions, as well as generating standardized online appendices. Utilizing this framework, we create a leaderboard for energy efficient reinforcement learning algorithms to incentivize responsible research in this area as an example for other areas of machine learning. Finally, based on case studies using our framework, we propose strategies for mitigation of carbon emissions and reduction of energy consumption. By making accounting easier, we hope to further the sustainable development of machine learning experiments and spur more research into energy efficient algorithms.", "venue": "ArXiv", "authors": ["Peter  Henderson", "Jieru  Hu", "Joshua  Romoff", "Emma  Brunskill", "Dan  Jurafsky", "Joelle  Pineau"], "year": 2020, "n_citations": 77}
{"id": 5174167, "s2_id": "d9f836a2062864e4808e12224e2286a353498202", "title": "Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation", "abstract": "Generating novel graph structures that optimize given objectives while obeying some given underlying rules is fundamental for chemistry, biology and social science research. This is especially important in the task of molecular graph generation, whose goal is to discover novel molecules with desired properties such as drug-likeness and synthetic accessibility, while obeying physical laws such as chemical valency. However, designing models to find molecules that optimize desired properties while incorporating highly complex and non-differentiable rules remains to be a challenging task. Here we propose Graph Convolutional Policy Network (GCPN), a general graph convolutional network based model for goal-directed graph generation through reinforcement learning. The model is trained to optimize domain-specific rewards and adversarial loss through policy gradient, and acts in an environment that incorporates domain-specific rules. Experimental results show that GCPN can achieve 61% improvement on chemical property optimization over state-of-the-art baselines while resembling known molecules, and achieve 184% improvement on the constrained property optimization task.", "venue": "NeurIPS", "authors": ["Jiaxuan  You", "Bowen  Liu", "Rex  Ying", "Vijay S. Pande", "Jure  Leskovec"], "year": 2018, "n_citations": 409}
{"id": 5175525, "s2_id": "7039a4b798ef0ed96cd847940864b01184fb4c53", "title": "Synergy Effect between Convolutional Neural Networks and the Multiplicity of SMILES for Improvement of Molecular Prediction", "abstract": "In our study, we demonstrate the synergy effect between convolutional neural networks and the multiplicity of SMILES. The model we propose, the so-called Convolutional Neural Fingerprint (CNF) model, reaches the accuracy of traditional descriptors such as Dragon (Mauri et al. [22]), RDKit (Landrum [18]), CDK2 (Willighagen et al. [43]) and PyDescriptor (Masand and Rastija [20]). Moreover the CNF model generally performs better than highly fine-tuned traditional descriptors, especially on small data sets, which is of great interest for the chemical field where data sets are generally small due to experimental costs, the availability of molecules or accessibility to private databases. We evaluate the CNF model along with SMILES augmentation during both training and testing. To the best of our knowledge, this is the first time that such a methodology is presented. We show that using the multiplicity of SMILES during training acts as a regulariser and therefore avoids overfitting and can be seen as ensemble learning when considered for testing.", "venue": "ArXiv", "authors": ["Talia B. Kimber", "Sebastian  Engelke", "Igor V. Tetko", "Eric  Bruno", "Guillaume  Godin"], "year": 2018, "n_citations": 28}
{"id": 5177202, "s2_id": "f8d3a8a925b1ce13a24db8842326190fe39fa59f", "title": "Early Lane Change Prediction for Automated Driving Systems Using Multi-Task Attention-based Convolutional Neural Networks", "abstract": "Lane change (LC) is one of the safety-critical manoeuvres in highway driving according to various road accident records. Thus, reliably predicting such manoeuvre in advance is critical for the safe and comfortable operation of automated driving systems. The majority of previous studies rely on detecting a manoeuvre that has been already started, rather than predicting the manoeuvre in advance. Furthermore, most of the previous works do not estimate the key timings of the manoeuvre (e.g., crossing time), which can actually yield more useful information for the decision making in the ego vehicle. To address these shortcomings, this paper proposes a novel multi-task model to simultaneously estimate the likelihood of LC manoeuvres and the time-to-lane-change (TTLC). In both tasks, an attentionbased convolutional neural network (CNN) is used as a shared feature extractor from a bird\u2019s eye view representation of the driving environment. The spatial attention used in the CNN model improves the feature extraction process by focusing on the most relevant areas of the surrounding environment. In addition, two novel curriculum learning schemes are employed to train the proposed approach. The extensive evaluation and comparative analysis of the proposed method in existing benchmark datasets show that the proposed method outperforms state-of-the-art LC prediction models, particularly considering long-term prediction performance.", "venue": "ArXiv", "authors": ["Sajjad  Mozaffari", "Eduardo  Arnold", "Mehrdad  Dianati", "Saber  Fallah"], "year": 2021, "n_citations": 0}
{"id": 5178544, "s2_id": "12ba9187308683f1a37a154998f5c69525af3080", "title": "Thresholding Bandit with Optimal Aggregate Regret", "abstract": "We consider the thresholding bandit problem, whose goal is to find arms of mean rewards above a given threshold $\\theta$, with a fixed budget of $T$ trials. We introduce LSA, a new, simple and anytime algorithm that aims to minimize the aggregate regret (or the expected number of mis-classified arms). We prove that our algorithm is instance-wise asymptotically optimal. We also provide comprehensive empirical results to demonstrate the algorithm's superior performance over existing algorithms under a variety of different scenarios.", "venue": "NeurIPS", "authors": ["Chao  Tao", "Saul  Blanco", "Jian  Peng", "Yuan  Zhou"], "year": 2019, "n_citations": 5}
{"id": 5198427, "s2_id": "1628415e77f9c62262505415717dee3881b90502", "title": "\"I have vxxx bxx connexxxn!\": Facing Packet Loss in Deep Speech Emotion Recognition", "abstract": "In applications that use emotion recognition via speech, frame-loss can be a severe issue given manifold applications, where the audio stream loses some data frames, for a variety of reasons like low bandwidth. In this contribution, we investigate for the first time the effects of frame-loss on the performance of emotion recognition via speech. Reproducible extensive experiments are reported on the popular RECOLA corpus using a state-of-the-art end-to-end deep neural network, which mainly consists of convolution blocks and recurrent layers. A simple environment based on a Markov Chain model is used to model the loss mechanism based on two main parameters. We explore matched, mismatched, and multi-condition training settings. As one expects, the matched setting yields the best performance, while the mismatched yields the lowest. Furthermore, frame-loss as a data augmentation technique is introduced as a general-purpose strategy to overcome the effects of frame-loss. It can be used during training, and we observed it to produce models that are more robust against frame-loss in run-time environments.", "venue": "ArXiv", "authors": ["Mostafa M. Mohamed", "Bjorn W. Schuller"], "year": 2020, "n_citations": 1}
{"id": 5200665, "s2_id": "bfd01026c2e7ed82b8059e86ebc6ac829163a803", "title": "Observability Properties of Colored Graphs", "abstract": "A colored graph is a directed graph in which nodes or edges have been assigned colors that are not necessarily unique. Observability problems in such graphs consider whether an agent observing the colors of edges or nodes traversed on a path in the graph can determine which node they are at currently or which nodes were visited earlier in the traversal. Previous research efforts have identified several different notions of observability as well as the associated properties of graphs for which those observability properties hold. This paper unifies the prior work into a common framework with several new results about relationships between those notions and associated graph properties. The new framework provides an intuitive way to reason about the attainable accuracy as a function of lag and time spent observing, and identifies simple modifications to improve the observability of a given graph. We show that one form of the graph modification problem is in NP-Complete. The intuition of the new framework is borne out with numerical experiments. This work has implications for problems that can be described in terms of an agent traversing a colored graph, including the reconstruction of hidden states in a hidden Markov model (HMM).", "venue": "IEEE Transactions on Network Science and Engineering", "authors": ["Mark  Chilenski", "George  Cybenko", "Isaac  Dekine", "Piyush  Kumar", "Gil  Raz"], "year": 2020, "n_citations": 5}
{"id": 5220063, "s2_id": "ac4dab31f29256d632df68617047eb09eda382bb", "title": "Improve SGD Training via Aligning Mini-batches", "abstract": "Deep neural networks (DNNs) for supervised learning can be viewed as a pipeline of a feature extractor (i.e. last hidden layer) and a linear classifier (i.e. output layer) that is trained jointly with stochastic gradient descent (SGD). In each iteration of SGD, a mini-batch from the training data is sampled and the true gradient of the loss function is estimated as the noisy gradient calculated on this mini-batch. From the feature learning perspective, the feature extractor should be updated to learn meaningful features with respect to the entire data, and reduce the accommodation to noise in the mini-batch. With this motivation, we propose In-Training Distribution Matching (ITDM) to improve DNN training and reduce overfitting. Specifically, along with the loss function, ITDM regularizes the feature extractor by matching the moments of distributions of different mini-batches in each iteration of SGD, which is fulfilled by minimizing the maximum mean discrepancy. As such, ITDM does not assume any explicit parametric form of data distribution in the latent feature space. Extensive experiments are conducted to demonstrate the effectiveness of our proposed strategy.", "venue": "ArXiv", "authors": ["Xiangrui  Li", "Deng  Pan", "Xin  Li", "Dongxiao  Zhu"], "year": 2020, "n_citations": 0}
{"id": 5224361, "s2_id": "4817126497ef0dee7616dbd9542410dbca0ccd4a", "title": "Collaborative Distillation for Ultra-Resolution Universal Style Transfer", "abstract": "Universal style transfer methods typically leverage rich representations from deep Convolutional Neural Network (CNN) models (e.g., VGG-19) pre-trained on large collections of images. Despite the effectiveness, its application is heavily constrained by the large model size to handle ultra-resolution images given limited memory. In this work, we present a new knowledge distillation method (named Collaborative Distillation) for encoder-decoder based neural style transfer to reduce the convolutional filters. The main idea is underpinned by a finding that the encoder-decoder pairs construct an exclusive collaborative relationship, which is regarded as a new kind of knowledge for style transfer models. Moreover, to overcome the feature size mismatch when applying collaborative distillation, a linear embedding loss is introduced to drive the student network to learn a linear embedding of the teacher\u2019s features. Extensive experiments show the effectiveness of our method when applied to different universal style transfer approaches (WCT and AdaIN), even if the model size is reduced by 15.5 times. Especially, on WCT with the compressed models, we achieve ultra-resolution (over 40 megapixels) universal style transfer on a 12GB GPU for the first time. Further experiments on optimization-based stylization scheme show the generality of our algorithm on different stylization paradigms. Our code and trained models are available at https://github.com/mingsun-tse/collaborative-distillation.", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "authors": ["Huan  Wang", "Yijun  Li", "Yuehai  Wang", "Haoji  Hu", "Ming-Hsuan  Yang"], "year": 2020, "n_citations": 23}
{"id": 5235531, "s2_id": "4299a239f648fa62a3b58cf2dfb67b0a84e6a402", "title": "OIAD: One-for-all Image Anomaly Detection with Disentanglement Learning", "abstract": "Anomaly detection aims to recognize samples with anomalous and unusual patterns with respect to a set of normal data. This is significant for numerous domain applications, such as industrial inspection, medical imaging, and security enforcement. There are two key research challenges associated with existing anomaly detection approaches: (1) many approaches perform well on low-dimensional problems however the performance on high-dimensional instances, such as images, is limited; (2) many approaches often rely on traditional supervised approaches and manual engineering of features, while the topic has not been fully explored yet using modern deep learning approaches, even when the well-label samples are limited. In this paper, we propose a One-for-all Image Anomaly Detection system (OIAD) based on disentangled learning using only clean samples. Our key insight is that the impact of small perturbation on the latent representation can be bounded for normal samples while anomaly images are usually outside such bounded intervals, referred to as structure consistency. We implement this idea and evaluate its performance for anomaly detection. Our experiments with three datasets show that OIAD can detect over 90% of anomalies while maintaining a low false alarm rate. It can also detect suspicious samples from samples labeled as clean, coincided with what humans would deem unusual.", "venue": "2020 International Joint Conference on Neural Networks (IJCNN)", "authors": ["Shuo  Wang", "Tianle  Chen", "Shangyu  Chen", "Carsten  Rudolph", "Surya  Nepal", "Marthie  Grobler"], "year": 2020, "n_citations": 1}
{"id": 5237821, "s2_id": "1068eecedc2e623ef495f89cb84abf09f615db3e", "title": "Accelerating Gradient Boosting Machine", "abstract": "Gradient Boosting Machine (GBM) is an extremely powerful supervised learning algorithm that is widely used in practice. GBM routinely features as a leading algorithm in machine learning competitions such as Kaggle and the KDDCup. In this work, we propose Accelerated Gradient Boosting Machine (AGBM) by incorporating Nesterov's acceleration techniques into the design of GBM. The difficulty in accelerating GBM lies in the fact that weak (inexact) learners are commonly used, and therefore the errors can accumulate in the momentum term. To overcome it, we design a \"corrected pseudo residual\" and fit best weak learner to this corrected pseudo residual, in order to perform the z-update. Thus, we are able to derive novel computational guarantees for AGBM. This is the first GBM type of algorithm with theoretically-justified accelerated convergence rate. Finally we demonstrate with a number of numerical experiments the effectiveness of AGBM over conventional GBM in obtaining a model with good training and/or testing data fidelity.", "venue": "ArXiv", "authors": ["Haihao  Lu", "Sai Praneeth Karimireddy", "Natalia  Ponomareva", "Vahab S. Mirrokni"], "year": 2019, "n_citations": 10}
{"id": 5249283, "s2_id": "6b2077de7278c14aaa78b655f2e0e01e4dd565f3", "title": "Inducing Causal Structure for Interpretable Neural Networks", "abstract": "In many areas, we have well-founded insights about causal structure that would be useful to bring into our trained models while still allowing them to learn in a data-driven fashion. To achieve this, we present the new method of interchange intervention training (IIT). In IIT, we (1) align variables in the causal model with representations in the neural model and (2) train a neural model to match the counterfactual behavior of the causal model on a base input when aligned representations in both models are set to be the value they would be for a second source input. IIT is fully differentiable, flexibly combines with other objectives, and guarantees that the target causal model is a causal abstraction of the neural model when its loss is minimized. We evaluate IIT on a structured vision task (MNIST-PVR) and a navigational instruction task (ReaSCAN). We compare IIT against multi-task training objectives and data augmentation. In all our experiments, IIT achieves the best results and produces neural models that are more interpretable in the sense that they realize the target causal model.", "venue": "ArXiv", "authors": ["Atticus  Geiger", "Zhengxuan  Wu", "Hanson  Lu", "Josh  Rozner", "Elisa  Kreiss", "Thomas  Icard", "Noah D. Goodman", "Christopher  Potts"], "year": 2021, "n_citations": 1}
{"id": 5256486, "s2_id": "90695f261c12265fb2694fe89cf390aad029a7dc", "title": "Learning Energy-Based Models by Diffusion Recovery Likelihood", "abstract": "While energy-based models (EBMs) exhibit a number of desirable properties, training and sampling on high-dimensional datasets remains challenging. Inspired by recent progress on diffusion probabilistic models, we present a diffusion recovery likelihood method to tractably learn and sample from a sequence of EBMs trained on increasingly noisy versions of a dataset. Each EBM is trained by maximizing the recovery likelihood: the conditional probability of the data at a certain noise level given their noisy versions at a higher noise level. The recovery likelihood objective is more tractable than the marginal likelihood objective, since it only requires MCMC sampling from a relatively concentrated conditional distribution. Moreover, we show that this estimation method is theoretically consistent: it learns the correct conditional and marginal distributions at each noise level, given sufficient data. After training, synthesized images can be generated efficiently by a sampling process that initializes from a spherical Gaussian distribution and progressively samples the conditional distributions at decreasingly lower noise levels. Our method generates high fidelity samples on various image datasets. On unconditional CIFAR-10 our method achieves FID 9.60 and inception score 8.58, superior to the majority of GANs. Moreover, we demonstrate that unlike previous work on EBMs, our long-run MCMC samples from the conditional distributions do not diverge and still represent realistic images, allowing us to accurately estimate the normalized density of data even for high-dimensional datasets.", "venue": "ICLR", "authors": ["Ruiqi  Gao", "Yang  Song", "Ben  Poole", "Ying Nian Wu", "Diederik P. Kingma"], "year": 2021, "n_citations": 23}
{"id": 5266221, "s2_id": "c6d5a91e0f6a915c5fd46600e200390728f06fcf", "title": "Partition of Unity Networks: Deep HP-Approximation", "abstract": "Approximation theorists have established best-in-class optimal approximation rates of deep neural networks by utilizing their ability to simultaneously emulate partitions of unity and monomials. Motivated by this, we propose partition of unity networks (POUnets) which incorporate these elements directly into the architecture. Classification architectures of the type used to learn probability measures are used to build a meshfree partition of space, while polynomial spaces with learnable coefficients are associated to each partition. The resulting hpelement-like approximation allows use of a fast least-squares optimizer, and the resulting architecture size need not scale exponentially with spatial dimension, breaking the curse of dimensionality. An abstract approximation result establishes desirable properties to guide network design. Numerical results for two choices of architecture demonstrate that POUnets yield hp-convergence for smooth functions and consistently outperform MLPs for piecewise polynomial functions with large numbers of discontinuities. Overview We consider regression over the set D = {(xi, yi)} i=1 , where xi \u2208 R and yi = y(xi) are point samples of a piecewise smooth function. Following successes in classification problems in high-dimensional spaces (Chollet 2017), deep neural networks (DNNs) have garnered tremendous interest as tools for regression problems and numerical analysis, partially due to their apparent ability to alleviate the curse of dimensionality in the presence of latent low-dimensional structure. This is in contrast to classical methods for which the computational expense grows exponentially with d, a major challenge for solution of high-dimensional PDEs (Bach 2017; Bengio and Bengio 2000; Han, Jentzen, and Weinan 2018). Understanding the performance of DNNs requires accounting for both optimal approximation error and optimization error. While one may prove existence of DNN parameters providing exponential convergence with respect to architecture size, in practice a number of issues conspire to prevent realizing such convergence. Several approximation theoretic works seek to understand the role of width/depth in the absence of optimization error (He et al. 2018; Daubechies et al. 2019; Yarotsky 2017, 2018; Opschoor, Petersen, and Schwab preprint submitted to arxiv 01/27/2021 2019). In particular, Yarotsky and Opschoor et al. prove the existence of parameters for a deep neural network architecture that approximate algebraic operations, partitions of unity (POUs), and polynomials to exponential accuracy in the depth of the network. This shows that sufficently deep DNNs may in theory learn a spectrally convergent hp-element space without a hand-tailored mesh by constructing a POU to localize polynomial approximation. In practice, however, such convergent approximations are not realized when training DNNs using gradient descent optimizers, even for smooth target functions (Fokina and Oseledets 2019; Adcock and Dexter 2020). The thesis of this work is to incorporate the POU and polynomial elements directly into a deep learning architecture. Rather than attempting to force a DNN to simultaneously perform localization and high-order approximation, introducing localized polynomial spaces frees the DNN to play to its strengths by focusing exclusively on partitioning space, as in classification problems. An attractive property of the proposed architecture is its amenability to a fast training strategy. In previous work, we developed an optimizer which alternates between a gradient descent update of hidden layer parameters and a globally optimal least squares solve for a final linear layer (Cyr et al. 2019); this was applied as well to classification problems (Patel et al. 2020). A similar strategy is applied in the current work: updating the POU with gradient descent before finding a globally optimal polynomial fit at each iteration ensures an optimal representation of data over the course of training. While DNNs have been explored as a means of solving high-dimensional PDEs (Geist et al. 2020; Han, Jentzen, and Weinan 2018), optimization error prevents a practical demonstration of convergence with respect to size of either data or model parameters (Beck, Jentzen, and Kuckuck 2019; Wang, Teng, and Perdikaris 2020). The relatively simple regression problem considered here provides a critical first example of how the optimization error barrier may be circumvented to provide accuracy competitive with finite element methods. An abstract POU network Consider a partition of unity \u03a6 = {\u03c6\u03b1(x)} Npart \u03b1=1 satisfying \u2211 \u03b1 \u03c6\u03b1(x) = 1 and \u03c6\u03b1(x) \u2265 0 for all x. We work with the", "venue": "AAAI Spring Symposium: MLPS", "authors": ["Kookjin  Lee", "Nathaniel A. Trask", "Ravi G. Patel", "Mamikon A. Gulian", "Eric C. Cyr"], "year": 2021, "n_citations": 6}
{"id": 5294764, "s2_id": "3ab34bf892f8855b606e3a3cfe1e372bde4ae830", "title": "Zero-error dissimilarity based classifiers", "abstract": "We consider general non-Euclidean distance measures between real world objects that need to be classified. It is assumed that objects are represented by distances to other objects only. Conditions for zero-error dissimilarity based classifiers are derived. Additional conditions are given under which the zero-error decision boundary is a continues function of the distances to a finite set of training samples. These conditions affect the objects as well as the distance measure used. It is argued that they can be met in practice.", "venue": "ArXiv", "authors": ["Robert P. W. Duin", "Elzbieta  Pekalska"], "year": 2016, "n_citations": 2}
{"id": 5309361, "s2_id": "47bb9ad21ef0eefc07805f1c891f2782c01c5752", "title": "Non-myopic Planetary Exploration Combining In Situ and Remote Measurements", "abstract": "Remote sensing measurements can provide crucial information about the material properties of a planetary surface but their application is limited by their spatial resolution, typically tens of meters per pixel, when constituent materials are mixed at much finer scale. Consequently the orbital observations must be validated with in situ measurements from a spectrometer on the ground. In planetary exploration this means that a rover must visit selected locations that jointly improve a model of the environment and satisfy mobility and sampling constraints. Conventional planning methods used in this situation follow sub-optimal greedy strategies that are not scalable to large areas. We show how the problem can be effectively defined in a Markov Decision Process framework and propose a planning algorithm based on Monte Carlo Tree Search, which is efficient but devoid of these drawbacks thereby providing superior performance. We evaluate our approach using hyperspectral imagery of a well-studied geologic site in Cuprite, Nevada.", "venue": "2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)", "authors": ["Suhit  Kodgule", "Alberto  Candela", "David  Wettergreen"], "year": 2019, "n_citations": 3}
{"id": 5309587, "s2_id": "c86afba9c77a9b1085ccc6c44c36fa3a1fdb51c5", "title": "New Losses for Generative Adversarial Learning", "abstract": "Generative Adversarial Networks (Goodfellow et al., 2014), a major breakthrough in the field of generative modeling, learn a discriminator to estimate some distance between the target and the candidate distributions. \nThis paper examines mathematical issues regarding the way the gradients for the generative model are computed in this context, and notably how to take into account how the discriminator itself depends on the generator parameters. \nA unifying methodology is presented to define mathematically sound training objectives for generative models taking this dependency into account in a robust way, covering both GAN, VAE and some GAN variants as particular cases.", "venue": "ArXiv", "authors": ["Victor  Berger", "Mich\u00e8le  Sebag"], "year": 2018, "n_citations": 0}
{"id": 5321595, "s2_id": "e2999a3a0dda4df45513dbb1293fd2f552c1f729", "title": "An Evolutionary Deep Learning Method for Short-term Wind Speed Prediction: A Case Study of the Lillgrund Offshore Wind Farm", "abstract": "Accurate short-term wind speed forecasting is essential for large-scale integration of wind power generation. However, the seasonal and stochastic characteristics of wind speed make forecasting a challenging task. This study uses a new hybrid evolutionary approach that uses a popular evolutionary search algorithm, CMA-ES, to tune the hyper-parameters of two Long short-term memory(LSTM) ANN models for wind prediction. The proposed hybrid approach is trained on data gathered from an offshore wind turbine installed in a Swedish wind farm located in the Baltic Sea. Two forecasting horizons including ten-minutes ahead (absolute short term) and one-hour ahead (short term) are considered in our experiments. Our experimental results indicate that the new approach is superior to five other applied machine learning models, i.e., polynomial neural network (PNN), feed-forward neural network (FNN), nonlinear autoregressive neural network (NAR) and adaptive neuro-fuzzy inference system (ANFIS), as measured by five performance criteria.", "venue": "ArXiv", "authors": ["Mehdi  Neshat", "Meysam Majidi Nezhad", "Ehsan  Abbasnejad", "Lina Bertling Tjernberg", "Davide Astiaso Garcia", "Bradley  Alexander", "Markus  Wagner"], "year": 2020, "n_citations": 4}
{"id": 5323767, "s2_id": "97531484425715fd902cde01d9c03f2a96e7326d", "title": "Behavioral analysis of support vector machine classifier with Gaussian kernel and imbalanced data", "abstract": "The parameters of support vector machines (SVMs) such as the penalty parameter and the kernel parameters have a great impact on the classification accuracy and the complexity of the SVM model. Therefore, the model selection in SVM involves the tuning of these parameters. However, these parameters are usually tuned and used as a black box, without understanding the mathematical background or internal details. In this paper, the behavior of the SVM classification model is analyzed when these parameters take different values with balanced and imbalanced data. This analysis including visualization, mathematical and geometrical interpretations and illustrative numerical examples with the aim of providing the basics of the Gaussian and linear kernel functions with SVM. From this analysis, we proposed a novel search algorithm. In this algorithm, we search for the optimal SVM parameters into two one-dimensional spaces instead of searching into one two-dimensional space. This reduces the computational time significantly. Moreover, in our algorithm, from the analysis of the data, the range of kernel function can be expected. This also reduces the search space and hence reduces the required computational time. Different experiments were conducted to evaluate our search algorithm using different balanced and imbalanced datasets. The results demonstrated how the proposed strategy is fast and effective than other searching strategies.", "venue": "ArXiv", "authors": ["Alaa  Tharwat"], "year": 2020, "n_citations": 2}
{"id": 5324577, "s2_id": "8250f253195a623f2c7978a4d2c5142367500b62", "title": "Metapath- and Entity-aware Graph Neural Network for Recommendation", "abstract": "Due to the shallow structure, classic graph neural networks (GNNs) failed in modelling high-order graph structures that deliver critical insights of task relevant relations. The negligence of those insights lead to insufficient distillation of collaborative signals in recommender systems. In this paper, we propose PEAGNN, a unified GNN framework tailored for recommendation tasks, which is capable of exploiting the rich semantics in metapaths. PEAGNN trains multilayer GNNs to perform metapath-aware information aggregation on collaborative subgraphs, $h$-hop subgraphs around the target user-item pairs. After the attentive fusion of aggregated information from different metapaths, a graph-level representation is then extracted for matching score prediction. To leverage the local structure of collaborative subgraphs, we present entity-awareness that regularizes node embedding with the presence of features in a contrastive manner. Moreover, PEAGNN is compatible with the mainstream GNN structures such as GCN, GAT and GraphSage. The empirical analysis on three public datasets demonstrate that our model outperforms or is at least on par with other competitive baselines. Further analysis indicates that trained PEAGNN automatically derives meaningful metapath combinations from the given metapaths.", "venue": "ArXiv", "authors": ["Zhiwei  Han", "Muhammad Umer Anwaar", "Shyam  Arumugaswamy", "Thomas  Weber", "Tianming  Qiu", "Hao  Shen", "Yuanting  Liu", "Martin  Kleinsteuber"], "year": 2020, "n_citations": 2}
{"id": 5330256, "s2_id": "6b46bda8a3e22cb32045336f5875d58782a716e9", "title": "CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays", "abstract": "The use of smartphones to take photographs of chest x-rays represents an appealing solution for scaled deployment of deep learning models for chest x-ray interpretation. However, the performance of chest x-ray algorithms on photos of chest x-rays has not been thoroughly investigated. In this study, we measured the diagnostic performance for 8 different chest x-ray models when applied to photos of chest x-rays. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to smartphone photos of x-rays in the CheXphoto dataset without further tuning. We found that several models had a drop in performance when applied to photos of chest x-rays, but even with this drop, some models still performed comparably to radiologists. Further investigation could be directed towards understanding how different model training procedures may affect model generalization to photos of chest x-rays.", "venue": "ArXiv", "authors": ["Pranav  Rajpurkar", "Anirudh  Joshi", "Anuj  Pareek", "Jeremy  Irvin", "Andrew Y. Ng", "Matthew  Lungren"], "year": 2020, "n_citations": 3}
{"id": 5333640, "s2_id": "a6927967cc987ad5f0678be0218b94bfed737453", "title": "Model Inconsistent but Correlated Noise: Multi-view Subspace Learning with Regularized Mixture of Gaussians", "abstract": "Multi-view subspace learning (MSL) aims to find a low-dimensional subspace of the data obtained from multiple views. Different from single view case, MSL should take both common and specific knowledge among different views into consideration. To enhance the robustness of model, the complexity, non-consistency and similarity of noise in multi-view data should be fully taken into consideration. Most current MSL methods only assume a simple Gaussian or Laplacian distribution for the noise while neglect the complex noise configurations in each view and noise correlations among different views of practical data. To this issue, this work initiates a MSL method by encoding the multi-view-shared and single-view-specific noise knowledge in data. Specifically, we model data noise in each view as a separated Mixture of Gaussians (MoG), which can fit a wider range of complex noise types than conventional Gaussian/Laplacian. Furthermore, we link all single-view-noise as a whole by regularizing them by a common MoG component, encoding the shared noise knowledge among them. Such regularization component can be formulated as a concise KL-divergence regularization term under a MAP framework, leading to good interpretation of our model and simple EM-based solving strategy to the problem. Experimental results substantiate the superiority of our method.", "venue": "ArXiv", "authors": ["Hongwei  Yong", "Deyu  Meng", "Jinxing  Li", "Wangmeng  Zuo", "Lei  Zhang"], "year": 2018, "n_citations": 1}
{"id": 5339434, "s2_id": "f774a7b3a843736cfa477df718243b90a5d83792", "title": "Autoregressive Energy Machines", "abstract": "Neural density estimators are flexible families of parametric models which have seen widespread use in unsupervised machine learning in recent years. Maximum-likelihood training typically dictates that these models be constrained to specify an explicit density. However, this limitation can be overcome by instead using a neural network to specify an energy function, or unnormalized density, which can subsequently be normalized to obtain a valid distribution. The challenge with this approach lies in accurately estimating the normalizing constant of the high-dimensional energy function. We propose the Autoregressive Energy Machine, an energy-based model which simultaneously learns an unnormalized density and computes an importance-sampling estimate of the normalizing constant for each conditional in an autoregressive decomposition. The Autoregressive Energy Machine achieves state-of-the-art performance on a suite of density-estimation tasks.", "venue": "ICML", "authors": ["Charlie  Nash", "Conor  Durkan"], "year": 2019, "n_citations": 26}
{"id": 5351089, "s2_id": "fba87a29ded52126e80ebaa0b57ef916b8cf485e", "title": "A view of estimation of distribution algorithms through the lens of expectation-maximization", "abstract": "We show that a large class of Estimation of Distribution Algorithms, including, but not limited to, Covariance Matrix Adaption, can be written as a Monte Carlo Expectation-Maximization algorithm, and as exact EM in the limit of infinite samples. Because EM sits on a rigorous statistical foundation and has been thoroughly analyzed, this connection provides a new coherent framework with which to reason about EDAs.", "venue": "GECCO Companion", "authors": ["David H. Brookes", "Akosua  Busia", "Clara  Fannjiang", "Kevin  Murphy", "Jennifer  Listgarten"], "year": 2020, "n_citations": 10}
{"id": 5355911, "s2_id": "58b67d0eb52ccb59d5b153ec0080365092017c0e", "title": "Optimized Hidden Markov Model based on Constrained Particle Swarm Optimization", "abstract": "As one of Bayesian analysis tools, Hidden Markov Model (HMM) has been used to in extensive applications. Most HMMs are solved by Baum-Welch algorithm (BWHMM) to predict the model parameters, which is difficult to find global optimal solutions. This paper proposes an optimized Hidden Markov Model with Particle Swarm Optimization (PSO) algorithm and so is called PSOHMM. In order to overcome the statistical constraints in HMM, the paper develops re-normalization and re-mapping mechanisms to ensure the constraints in HMM. The experiments have shown that PSOHMM can search better solution than BWHMM, and has faster convergence speed.", "venue": "ArXiv", "authors": ["L.  Chang", "Yacine  Ouzrout", "Antoine  Nongaillard", "Abdelaziz  Bouras"], "year": 2018, "n_citations": 4}
{"id": 5356796, "s2_id": "6edc7103dd907a8a84ceb8a4bd775da3cccd9e98", "title": "PRETZEL: Opening the Black Box of Machine Learning Prediction Serving Systems", "abstract": "Machine Learning models are often composed of pipelines of transformations. While this design allows to efficiently execute single model components at training time, prediction serving has different requirements such as low latency, high throughput and graceful performance degradation under heavy load. Current prediction serving systems consider models as black boxes, whereby prediction-time-specific optimizations are ignored in favor of ease of deployment. In this paper, we present PRETZEL, a prediction serving system introducing a novel white box architecture enabling both end-to-end and multi-model optimizations. Using production-like model pipelines, our experiments show that PRETZEL is able to introduce performance improvements over different dimensions; compared to state-of-the-art approaches PRETZEL is on average able to reduce 99th percentile latency by 5.5x while reducing memory footprint by 25x, and increasing throughput by 4.7x.", "venue": "OSDI", "authors": ["Yunseong  Lee", "Alberto  Scolari", "Byung-Gon  Chun", "Marco D. Santambrogio", "Markus  Weimer", "Matteo  Interlandi"], "year": 2018, "n_citations": 55}
{"id": 5360605, "s2_id": "8fb545dc65d519ba000357089d6316ef9345dbd8", "title": "Towards Semi-Supervised Semantics Understanding from Speech", "abstract": "Much recent work on Spoken Language Understanding (SLU) falls short in at least one of three ways: models were trained on oracle text input and neglected the Automatics Speech Recognition (ASR) outputs, models were trained to predict only intents without the slot values, or models were trained on a large amount of in-house data. We proposed a clean and general framework to learn semantics directly from speech with semi-supervision from transcribed speech to address these. Our framework is built upon pretrained end-to-end (E2E) ASR and self-supervised language models, such as BERT, and fine-tuned on a limited amount of target SLU corpus. In parallel, we identified two inadequate settings under which SLU models have been tested: noise-robustness and E2E semantics evaluation. We tested the proposed framework under realistic environmental noises and with a new metric, the slots edit F1 score, on two public SLU corpora. Experiments show that our SLU framework with speech as input can perform on par with those with oracle text as input in semantics understanding, while environmental noises are present, and a limited amount of labeled semantics data is available.", "venue": "ArXiv", "authors": ["Cheng-I  Lai", "Jin  Cao", "Sravan  Bodapati", "Shang-Wen  Li"], "year": 2020, "n_citations": 3}
{"id": 5368644, "s2_id": "d0f9df60956f0fded43390583f2f49aa5e0efad8", "title": "Scalable Explanation of Inferences on Large Graphs", "abstract": "Probabilistic inferences distill knowledge from graphs to aid human make important decisions. Due to the inherent uncertainty in the model and the complexity of the knowledge, it is desirable to help the end-users understand the inference outcomes. Different from deep or high dimensional parametric models, the lack of interpretability in graphical models is due to the cyclic and long-range dependencies and the byzantine inference procedures. Prior works did not tackle cycles and make the inferences interpretable. We formulate the explanation of probabilistic inferences as a constrained cross-entropy minimization problem to find simple subgraphs that faithfully approximate the inferences. We prove that the optimization is NP-hard, while the objective is not monotonic and submodular to guarantee efficient greedy approximation. We propose a beam search algorithm to find trees to enhance the explanation interpretability and diversity. To allow efficient search on large and dense graphs without hurting faithfulness, we further propose parallelization and a pruning strategy. We demonstrate superior performance on four networks from distinct applications, comparing favorably to other explanation methods, including LIME.", "venue": "2019 IEEE International Conference on Data Mining (ICDM)", "authors": ["Chao  Chen", "Yifei  Liu", "Xi  Zhang", "Sihong  Xie"], "year": 2019, "n_citations": 2}
{"id": 5378484, "s2_id": "b52c337d2bc3f9d245cb02a7e0792e0dc11978ca", "title": "Location Anomalies Detection for Connected and Autonomous Vehicles", "abstract": "Future Connected and Automated Vehicles (CAVs), and more generally ITS, will form a highly interconnected system. Such a paradigm is referred to as the Internet of Vehicles (herein Internet of CAVs) and is a prerequisite to orchestrate traffic flows in cities. For optimal decision making and supervision, traffic centres will have access to suitably anonymized CAV mobility information. Safe and secure operations will then be contingent on early detection of anomalies. In this paper, a novel unsupervised learning model based on deep autoencoder is proposed to detect the self-reported location anomaly in CAVs, using vehicle locations and the Received Signal Strength Indicator (RSSI) as features. Quantitative experiments on simulation datasets show that the proposed approach is effective and robust in detecting self-reported location anomalies.", "venue": "2019 IEEE 2nd Connected and Automated Vehicles Symposium (CAVS)", "authors": ["Xiaoyang  Wang", "Ioannis  Mavromatis", "Andrea  Tassi", "Ra\u00fal  Santos-Rodr\u00edguez", "Robert J. Piechocki"], "year": 2019, "n_citations": 0}
{"id": 5386947, "s2_id": "be7e138142ee124065ce28fe1f21e9e5ec595d5a", "title": "Learning of Human-like Algebraic Reasoning Using Deep Feedforward Neural Networks", "abstract": "Abstract Human-like rewriting, which is an algebraic reasoning system imitating human intelligence of problem solving, is proposed in this work. In order to imitate both learning and reasoning aspects of human cognition, a deep feedforward neural network learns from algebraic reasoning examples produced by humans and then uses learnt experiences to guide other reasoning processes. This work shows that the neural network can learn human\u2019s behaviours of solving mathematical problems, and it can indicate suitable directions of reasoning, so that intelligent and heuristic reasoning can be performed. Moreover, human-like rewriting bridges the gap between symbolic reasoning and biologically inspired machine learning. To enable the neural network to recognise patterns of symbolic expressions with non-deterministic sizes, the expressions are reduced to partial tree representations and then vectorised as numeric features. Further, the centralisation method, symbolic association vectors and rule application records are used to improve the vectorised features. With these approaches, human-like rewriting shows satisfactory performance on the tasks of solving linear equations and computing derivations and indefinite integrals.", "venue": "Biologically Inspired Cognitive Architectures", "authors": ["Chenghao  Cai", "Dengfeng  Ke", "Yanyan  Xu", "Kaile  Su"], "year": 2018, "n_citations": 9}
{"id": 5387389, "s2_id": "b862368b76e04e1533ac231b9b2730dc192ec3e8", "title": "Estimating a Causal Order among Groups of Variables in Linear Models", "abstract": "The machine learning community has recently devoted much attention to the problem of inferring causal relationships from statistical data. Most of this work has focused on uncovering connections among scalar random variables. We generalize existing methods to apply to collections of multi-dimensional random vectors, focusing on techniques applicable to linear models. The performance of the resulting algorithms is evaluated and compared in simulations, which show that our methods can, in many cases, provide useful information on causal relationships even for relatively small sample sizes.", "venue": "ICANN", "authors": ["Doris  Entner", "Patrik O. Hoyer"], "year": 2012, "n_citations": 12}
{"id": 5392557, "s2_id": "d5f79a30b3975e447cede805cb24d9879d6c140a", "title": "Systolic Tensor Array: An Efficient Structured-Sparse GEMM Accelerator for Mobile CNN Inference", "abstract": "Convolutional neural network (CNN) inference on mobile devices demands efficient hardware acceleration of low-precision (INT8) general matrix multiplication (GEMM). The systolic array (SA) is a pipelined 2D array of processing elements (PEs), with very efficient local data movement, well suited to accelerating GEMM, and widely deployed in industry. In this letter, we describe two significant improvements to the traditional SA architecture, to specifically optimize for CNN inference. First, we generalize the traditional scalar PE, into a Tensor-PE, which gives rise to a family of new Systolic Tensor Array (STA) microarchitectures. The STA family increases intra-PE operand reuse and datapath efficiency, resulting in circuit area and power dissipation reduction of as much as 2.08\u00d7 and 1.36\u00d7 respectively, compared to the conventional SA at iso-throughput with INT8 operands. Second, we extend this design to support a novel block-sparse data format called density-bound block (DBB). This variant (STA-DBB) achieves a 3.14\u00d7 and 1.97\u00d7 improvement over the SA baseline at iso-throughput in area and power respectively, when processing specially-trained DBB-sparse models, while remaining fully backwards compatible with dense models.", "venue": "IEEE Computer Architecture Letters", "authors": ["Zhi-Gang  Liu", "Paul N. Whatmough", "Matthew  Mattina"], "year": 2020, "n_citations": 20}
{"id": 5408991, "s2_id": "cd5442754f24ef2f8121c137f0b76c5a3b6ae06b", "title": "Deep MIMO detection", "abstract": "In this paper, we consider the use of deep neural networks in the context of Multiple-Input-Multiple-Output (MIMO) detection. We give a brief introduction to deep learning and propose a modern neural network architecture suitable for this detection task. First, we consider the case in which the MIMO channel is constant, and we learn a detector for a specific system. Next, we consider the harder case in which the parameters are known yet changing and a single detector must be learned for all multiple varying channels. We demonstrate the performance of our deep MIMO detector using numerical simulations in comparison to competing methods including approximate message passing and semidefinite relaxation. The results show that deep networks can achieve state of the art accuracy with significantly lower complexity while providing robustness against ill conditioned channels and mis-specified noise variance.", "venue": "2017 IEEE 18th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC)", "authors": ["Neev  Samuel", "Tzvi  Diskin", "Ami  Wiesel"], "year": 2017, "n_citations": 263}
{"id": 5413496, "s2_id": "fd058b2ad0b66957b9da4fed51f6754980319fb9", "title": "Deep Machine Learning Based Egyptian Vehicle License Plate Recognition Systems", "abstract": "Automated Vehicle License Plate (VLP) detection and recognition have ended up being a significant research issue as of late. VLP localization and recognition are some of the most essential techniques for managing traffic using digital techniques. In this paper, four smart systems are developed to recognize Egyptian vehicles\u2019 license plates. Two systems are based on character recognition, which are (System1: Characters Recognition with Classical Machine Learning) and (System2: Characters Recognition with Deep Machine Learning). The other two systems are based on the whole plate recognition which are (System3: Whole License Plate Recognition with Classical Machine Learning) and (System4: Whole License Plate Recognition with Deep Machine Learning). We use object detection algorithms, and machine learning based object recognition algorithms. The performance of the developed systems has been tested on real images, and the experimental results demonstrate that the best detection accuracy rate for VLP is provided by using the deep learning method. Where the VLP detection accuracy rate is better than the classical system by 32%. However, the best detection accuracy rate for Vehicle License Plate Arabic Character (VLPAC) is provided by using the classical method. Where VLPAC detection accuracy rate is better than the deep learning-based system by 6%. Also, the results show that deep learning is better than the classical technique used in VLP recognition processes. Where the recognition accuracy rate is better than the classical system by 8%. Finally, the paper output recommends a robust VLP recognition system based on both statistical and deep machine learning.", "venue": "ArXiv", "authors": ["Mohamed  Shehata", "Mohamed Taha Abou-Kreisha", "Hany  Elnashar"], "year": 2021, "n_citations": 0}
{"id": 5418008, "s2_id": "6b08deaa7c136a29b9d9a1d41f1534008d7f91ba", "title": "Estimation of crowd density applying wavelet transform and machine learning", "abstract": "Abstract We conducted a simple experiment in which one pedestrian passed through a crowded area and measured the body-rotational angular velocity with commercial tablets. Then, we developed a new method for predicting crowd density by applying the continuous wavelet transform and machine learning to the data obtained in the experiment. We found that the accuracy of prediction using angular velocity data was as high as that using raw velocity data. Therefore, we concluded that angular velocity has relationship with crowd density and we could estimate crowd density by angular velocity. Our research will contribute to management of safety and comfort of pedestrians by developing an easy way to measure crowd density.", "venue": "Physica A: Statistical Mechanics and its Applications", "authors": ["Koki  Nagao", "Daichi  Yanagisawa", "Katsuhiro  Nishinari"], "year": 2018, "n_citations": 19}
{"id": 5418879, "s2_id": "ded62bb54bbf6d687504158ca145679ad2e755b1", "title": "Learning Real Estate Automated Valuation Models from Heterogeneous Data Sources", "abstract": "Real estate appraisal is a complex and important task, that can be made more precise and faster with the help of automated valuation tools. Usually the value of some property is determined by taking into account both structural and geographical characteristics. However, while geographical information is easily found, obtaining significant structural information requires the intervention of a real estate expert, a professional appraiser. In this paper we propose a Web data acquisition methodology, and a Machine Learning model, that can be used to automatically evaluate real estate properties. This method uses data from previous appraisal documents, from the advertised prices of similar properties found via Web crawling, and from open data describing the characteristics of a corresponding geographical area. We describe a case study, applicable to the whole Italian territory, and initially trained on a data set of individual homes located in the city of Turin, and analyze prediction and practical applicability.", "venue": "ArXiv", "authors": ["Francesco  Bergadano", "Roberto  Bertilone", "Daniela  Paolotti", "Giancarlo  Ruffo"], "year": 2019, "n_citations": 0}
{"id": 5428332, "s2_id": "4d357f1db6af28eb0e67bf6c019b3e7b00ddc2a4", "title": "Predicting Student's Performance Through Data Mining", "abstract": "Predicting the performance of students early and as accurately as possible is one of the biggest challenges of educational institutions. Analyzing the performance of students early can help in finding the strengths and weakness of students and help the perform better in examinations. Using machine learning the student\u2019s performance can be predicted with the help of students\u2019 data collected from Learning Management Systems (LMS). The data collected from LMSs can provide insights about student\u2019s behavior that will result in good or bad performance in examinations which then can be studied and used in helping students performing poorly in examinations to perform better.", "venue": "ArXiv", "authors": ["Aaditya  Bhusal"], "year": 2021, "n_citations": 0}
{"id": 5440736, "s2_id": "b7a5329afa4e646c8c166520586cb6322766a19a", "title": "Lagrangian Reachtubes: The Next Generation", "abstract": "We introduce LRT-NG, a set of techniques and an associated toolset that computes a reachtube (an over-approximation of the set of reachable states over a given time horizon) of a nonlinear dynamical system. LRT-NG significantly advances the state-of-the-art Langrangian Reachability and its associated tool LRT. From a theoretical perspective, LRT-NG is superior to LRT in three ways. First, it uses for the first time an analytically computed metric for the propagated ball which is proven to minimize the ball\u2019s volume. We emphasize that the metric computation is the centerpiece of all bloating-based techniques. Secondly, it computes the next reachset as the intersection of two balls: one based on the Cartesian metric and the other on the new metric. While the two metrics were previously considered opposing approaches, their joint use considerably tightens the reachtubes. Thirdly, it avoids the \"wrapping effect\" associated with the validated integration of the center of the reachset, by optimally absorbing the interval approximation in the radius of the next ball. From a tool-development perspective, LRT-NG is superior to LRT in two ways. First, it is a standalone tool that no longer relies on CAPD. This required the implementation of the Lohner method and a Runge-Kutta time-propagation method. Secondly, it has an improved interface, allowing the input model and initial conditions to be provided as external input files. Our experiments on a comprehensive set of benchmarks, including two Neural ODEs, demonstrates LRT-NG\u2019s superior performance compared to LRT, CAPD, and Flow*.", "venue": "2020 59th IEEE Conference on Decision and Control (CDC)", "authors": ["Sophie  Gruenbacher", "Jacek  Cyranka", "Mathias  Lechner", "Md. Ariful Islam", "Scott A. Smolka", "Radu  Grosu"], "year": 2020, "n_citations": 5}
{"id": 5441148, "s2_id": "ee95231783167baa4785a642e8ef563a572c5d63", "title": "Deep Defense: Training DNNs with Improved Adversarial Robustness", "abstract": "Despite the efficacy on a variety of computer vision tasks, deep neural networks (DNNs) are vulnerable to adversarial attacks, limiting their applications in security-critical systems. Recent works have shown the possibility of generating imperceptibly perturbed image inputs (a.k.a., adversarial examples) to fool well-trained DNN classifiers into making arbitrary predictions. To address this problem, we propose a training recipe named \"deep defense\". Our core idea is to integrate an adversarial perturbation-based regularizer into the classification objective, such that the obtained models learn to resist potential attacks, directly and precisely. The whole optimization problem is solved just like training a recursive network. Experimental results demonstrate that our method outperforms training with adversarial/Parseval regularizations by large margins on various datasets (including MNIST, CIFAR-10 and ImageNet) and different DNN architectures. Code and models for reproducing our results are available at this https URL", "venue": "NeurIPS", "authors": ["Ziang  Yan", "Yiwen  Guo", "Changshui  Zhang"], "year": 2018, "n_citations": 59}
{"id": 5452060, "s2_id": "0120aa09c25356935bd7fef812c77c5a6a38d600", "title": "Conjugate Gradients and Accelerated Methods Unified: The Approximate Duality Gap View", "abstract": "This note provides a novel, simple analysis of the method of conjugate gradients for the minimization of convex quadratic functions. In contrast with standard arguments, our proof is entirely self-contained and does not rely on the existence of Chebyshev polynomials. Another advantage of our development is that it clarifies the relation between the method of conjugate gradients and general accelerated methods for smooth minimization by unifying their analyses within the framework of the Approximate Duality Gap Technique that was introduced by the authors.", "venue": "ArXiv", "authors": ["Jelena  Diakonikolas", "Lorenzo  Orecchia"], "year": 2019, "n_citations": 2}
{"id": 5461075, "s2_id": "09ab3e3fcbbfa33cecb03fdaea6630fb1ad15807", "title": "Neural Identification for Control", "abstract": "We present a new method for learning control law that stabilizes an unknown nonlinear dynamical system at an equilibrium point. We formulate a system identification task in a self-supervised learning setting that jointly learns a controller and corresponding stable closed-loop dynamics hypothesis. The input-output behavior of the unknown dynamical system under random control inputs is used as the supervising signal to train the neural network-based system model and the controller. The proposed method relies on the Lyapunov stability theory to generate a stable closed-loop dynamics hypothesis and corresponding control law. We demonstrate our method on various nonlinear control problems such as n-link pendulum balancing and trajectory tracking, pendulum on cart balancing, and wheeled vehicle path following.", "venue": "IEEE Robotics and Automation Letters", "authors": ["Priyabrata  Saha", "Magnus  Egerstedt", "Saibal  Mukhopadhyay"], "year": 2021, "n_citations": 0}
{"id": 5461225, "s2_id": "b67701b6be997852c00676726926022771d0d647", "title": "A Review on the Application of Natural Computing in Environmental Informatics", "abstract": "Natural computing offers new opportunities to understand, model and analyze the complexity of the physical and human-created environment. This paper examines the application of natural computing in environmental informatics, by investigating related work in this research field. Various nature-inspired techniques are presented, which have been employed to solve different relevant problems. Advantages and disadvantages of these techniques are discussed, together with analysis of how natural computing is generally used in environmental research.", "venue": "ArXiv", "authors": ["Andreas  Kamilaris"], "year": 2018, "n_citations": 2}
{"id": 5463909, "s2_id": "4405c478e5b17531150743afb79a4984f6992150", "title": "Edge-Network-Assisted Real-Time Object Detection Framework for Autonomous Driving", "abstract": "Computer vision tasks such as object detection are crucial for the operations of autonomous vehicles (AVs). Results of many tasks, even those requiring high computational power, can be obtained within a short delay by offloading them to edge clouds. However, although edge clouds are exploited, real-time object detection cannot always be guaranteed due to dynamic channel quality. To mitigate this problem, we propose an edge-network-assisted real-time object detection framework (EODF). In an EODF, AVs extract the region of interest (Rols) of the captured image when the channel quality is not sufficiently good for supporting real-time object detection. Then AVs compress the image data on the basis of the Rols and transmit the compressed one to the edge cloud. In so doing, real-time object detection can be achieved due to the reduced transmission latency. To verify the feasibility of our framework, we evaluate the probability that the results of object detection are not received within the inter-frame duration (i.e., outage probability) and their accuracy. From the evaluation, we demonstrate that the proposed EODF provides the results to AVs in real time and achieves satisfactory accuracy.", "venue": "IEEE Network", "authors": ["Seung Wook Kim", "Keunsoo  Ko", "Haneul  Ko", "Victor C. M. Leung"], "year": 2021, "n_citations": 3}
{"id": 5465169, "s2_id": "56b369100cadfe33cb7b18c8a6a96f4d3ed3e778", "title": "Neural Network Detection of Data Sequences in Communication Systems", "abstract": "We consider detection based on deep learning, and show it is possible to train detectors that perform well without any knowledge of the underlying channel models. Moreover, when the channel model is known, we demonstrate that it is possible to train detectors that do not require channel state information (CSI). In particular, a technique we call a sliding bidirectional recurrent neural network (SBRNN) is proposed for detection where, after training, the detector estimates the data in real time as the signal stream arrives at the receiver. We evaluate this algorithm, as well as other neural network (NN) architectures, using the Poisson channel model, which is applicable to both optical and molecular communication systems. In addition, we also evaluate the performance of this detection method applied to data sent over a molecular communication platform, where the channel model is difficult to model analytically. We show that SBRNN is computationally efficient, and can perform detection under various channel conditions without knowing the underlying channel model. We also demonstrate that the bit error rate performance of the proposed SBRNN detector is better than that of a Viterbi detector with imperfect CSI as well as that of other NN detectors that have been previously proposed. Finally, we show that the SBRNN can perform well in rapidly changing channels, where the coherence time is on the order of a single symbol duration.", "venue": "IEEE Transactions on Signal Processing", "authors": ["Nariman  Farsad", "Andrea  Goldsmith"], "year": 2018, "n_citations": 164}
{"id": 5478450, "s2_id": "feda87d543b834ba0b5368479ed106ff63f6c715", "title": "Disagreement-based Active Learning in Online Settings", "abstract": "We study online active learning for classifying streaming instances within the framework of statistical learning theory. At each time, the learner either queries the label of the current instance or predicts the label based on past seen examples. The objective is to minimize the number of queries while constraining the number of prediction errors over a horizon of length $T$. We develop a disagreement-based online learning algorithm for a general hypothesis space and under the Tsybakov noise. We show that the proposed algorithm has a label complexity of $O(dT^{\\frac{2-2\\alpha}{2-\\alpha}}\\log^2 T)$ under a constraint of bounded regret in terms of classification errors, where $d$ is the VC dimension of the hypothesis space and $\\alpha$ is the Tsybakov noise parameter. We further establish a matching (up to a poly-logarithmic factor) lower bound, demonstrating the order optimality of the proposed algorithm. We address the tradeoff between label complexity and regret and show that the algorithm can be modified to operate at a different point on the tradeoff curve.", "venue": "ArXiv", "authors": ["Boshuang  Huang", "Qing  Zhao"], "year": 2019, "n_citations": 0}
{"id": 5492294, "s2_id": "b35465ae8ec16a5221caa73b4b185f84ba9cbb0d", "title": "Bayesian Optimisation over Multiple Continuous and Categorical Inputs", "abstract": "Efficient optimisation of black-box problems that comprise both continuous and categorical inputs is important, yet poses significant challenges. We propose a new approach, Continuous and Categorical Bayesian Optimisation (CoCaBO), which combines the strengths of multi-armed bandits and Bayesian optimisation to select values for both categorical and continuous inputs. We model this mixed-type space using a Gaussian Process kernel, designed to allow sharing of information across multiple categorical variables, each with multiple possible values; this allows CoCaBO to leverage all available data efficiently. We extend our method to the batch setting and propose an efficient selection procedure that dynamically balances exploration and exploitation whilst encouraging batch diversity. We demonstrate empirically that our method outperforms existing approaches on both synthetic and real-world optimisation tasks with continuous and categorical inputs.", "venue": "ICML", "authors": ["Binxin  Ru", "Ahsan S. Alvi", "Vu  Nguyen", "Michael A. Osborne", "Stephen J Roberts"], "year": 2020, "n_citations": 34}
{"id": 5505461, "s2_id": "93fea117719587f80b0817531656ff3ad89ec730", "title": "Calibrated Adaptive Probabilistic ODE Solvers", "abstract": "Probabilistic solvers for ordinary differential equations (ODEs) assign a posterior measure to the solution of an initial value problem. The joint covariance of this distribution provides an estimate of the (global) approximation error. The contraction rate of this error estimate as a function of the solver's step size identifies it as a well-calibrated worst-case error. But its explicit numerical value for a certain step size, which depends on certain parameters of this class of solvers, is not automatically a good estimate of the explicit error. Addressing this issue, we introduce, discuss, and assess several probabilistically motivated ways to calibrate the uncertainty estimate. Numerical experiments demonstrate that these calibration methods interact efficiently with adaptive step-size selection, resulting in descriptive, and efficiently computable posteriors. We demonstrate the efficiency of the methodology by benchmarking against the classic, widely used Dormand-Prince 4/5 Runge-Kutta method.", "venue": "AISTATS", "authors": ["Nathanael  Bosch", "Philipp  Hennig", "Filip  Tronarp"], "year": 2021, "n_citations": 10}
{"id": 5518348, "s2_id": "e2b2efdbd6621d46222b7b4e6deb276da34a1585", "title": "Overcoming Data Sparsity in Group Recommendation", "abstract": "It has been an important task for recommender systems to suggest satisfying activities to a group of users in people's daily social life. The major challenge in this task is how to aggregate personal preferences of group members to infer the decision of a group. Conventional group recommendation methods applied a predefined strategy for preference aggregation. However, these static strategies are too simple to model the real and complex process of group decision-making, especially for occasional groups which are formed ad-hoc. Moreover, group members should have non-uniform influences or weights in a group, and the weight of a user can be varied in different groups. Therefore, an ideal group recommender system should be able to accurately learn not only users' personal preferences but also the preference aggregation strategy from data. In this paper, we propose a novel end-to-end group recommender system named CAGR (short for Centrality Aware Group Recommender\"), which takes Bipartite Graph Embedding Model (BGEM), the self-attention mechanism and Graph Convolutional Networks (GCNs) as basic building blocks to learn group and user representations in a unified way. Specifically, we first extend BGEM to model group-item interactions, and then in order to overcome the limitation and sparsity of the interaction data generated by occasional groups, we propose a self-attentive mechanism to represent groups based on the group members. In addition, to overcome the sparsity issue of user-item interaction data, we leverage the user social networks to enhance user representation learning, obtaining centrality-aware user representations. We create three large-scale benchmark datasets and conduct extensive experiments on them. The experimental results show the superiority of our proposed CAGR by comparing it with state-of-the-art group recommender models.", "venue": "ArXiv", "authors": ["Hongzhi  Yin", "Qinyong  Wang", "Kai  Zheng", "Zhixu  Li", "Xiaofang  Zhou"], "year": 2020, "n_citations": 11}
{"id": 5518883, "s2_id": "977a1a48a10f5be5ba40a3f6eb2fa9ceed764c23", "title": "Learning Fair and Interpretable Representations via Linear Orthogonalization", "abstract": "To reduce human error and prejudice, many high-stakes decisions have been turned over to machine algorithms. However, recent research suggests that this does not remove discrimination, and can perpetuate harmful stereotypes. While algorithms have been developed to improve fairness, they typically face at least one of three shortcomings: they are not interpretable, their prediction quality deteriorates quickly compared to unbiased equivalents, and they are not easily transferable across models. To address these shortcomings, we propose a geometric method that removes correlations between data and any number of protected variables. Further, we can control the strength of debiasing through an adjustable parameter to address the trade-off between prediction quality and fairness. The resulting features are interpretable and can be used with many popular models, such as linear regression, random forest, and multilayer perceptrons. The resulting predictions are found to be more accurate and fair compared to several state-of-the-art fair AI algorithms across a variety of benchmark datasets. Our work shows that debiasing data is a simple and effective solution toward improving fairness.", "venue": "ArXiv", "authors": ["Yuzi  He", "Keith  Burghardt", "Kristina  Lerman"], "year": 2019, "n_citations": 1}
{"id": 5519612, "s2_id": "988a1ab0c1ebd7eb4817fbc8ce41f962dd519998", "title": "An Introduction to Deep Generative Modeling", "abstract": "Deep generative models (DGM) are neural networks with many hidden layers trained to approximate complicated, high-dimensional probability distributions using a large number of samples. When trained successfully, we can use the DGMs to estimate the likelihood of each observation and to create new samples from the underlying distribution. Developing DGMs has become one of the most hotly researched fields in artificial intelligence in recent years. The literature on DGMs has become vast and is growing rapidly. Some advances have even reached the public sphere, for example, the recent successes in generating realistic-looking images, voices, or movies; so-called deep fakes. Despite these successes, several mathematical and practical issues limit the broader use of DGMs: given a specific dataset, it remains challenging to design and train a DGM and even more challenging to find out why a particular model is or is not effective. To help advance the theoretical understanding of DGMs, we provide an introduction to DGMs and provide a concise mathematical framework for modeling the three most popular approaches: normalizing flows (NF), variational autoencoders (VAE), and generative adversarial networks (GAN). We illustrate the advantages and disadvantages of these basic approaches using numerical experiments. Our goal is to enable and motivate the reader to contribute to this proliferating research area. Our presentation also emphasizes relations between generative modeling and optimal transport.", "venue": "ArXiv", "authors": ["Lars  Ruthotto", "Eldad  Haber"], "year": 2021, "n_citations": 15}
{"id": 5522361, "s2_id": "f737b93ac7268cbe9bd1e1aaddb56bfeac16649f", "title": "Cost-Aware Learning and Optimization for Opportunistic Spectrum Access", "abstract": "In this paper, we investigate cost-aware joint learning and optimization for multi-channel opportunistic spectrum access in a cognitive radio system. We investigate a discrete-time model where the time axis is partitioned into frames. Each frame consists of a sensing phase, followed by a transmission phase. During the sensing phase, the user is able to sense a subset of channels sequentially before it decides to use one of them in the following transmission phase. We assume the channel states alternate between <italic>busy</italic> and <italic>idle</italic> according to independent Bernoulli random processes from frame to frame. To capture the <italic>inherent uncertainty</italic> in channel sensing, we assume the reward of each transmission when the channel is idle is a random variable. We also associate <italic>random costs</italic> with sensing and transmission actions. Our objective is to understand how the costs and reward of the actions would affect the optimal behavior of the user in both offline and online settings, and design the corresponding opportunistic spectrum access strategies to maximize the expected cumulative net reward (i.e., reward-minus-cost). We start with an offline setting where the statistics of the channel status, costs, and reward are known beforehand. We show that the optimal policy exhibits a recursive double-threshold structure, and the user needs to compare the channel statistics with those thresholds sequentially in order to decide its actions. With such insights, we then study the online setting, where the statistical information of the channels, costs and reward are unknown <italic>a priori</italic>. We judiciously balance exploration and exploitation, and show that the cumulative regret scales in <inline-formula> <tex-math notation=\"LaTeX\">${O}$ </tex-math></inline-formula>(log <inline-formula> <tex-math notation=\"LaTeX\">${T}$ </tex-math></inline-formula>). We also establish a matched lower bound, which implies that our online algorithm is order-optimal. Simulation results corroborate our theoretical analysis.", "venue": "IEEE Transactions on Cognitive Communications and Networking", "authors": ["Chao  Gan", "Ruida  Zhou", "Jing  Yang", "Cong  Shen"], "year": 2019, "n_citations": 3}
{"id": 5527680, "s2_id": "636509872cfffe40a6d6ea98a87ce4956f82a361", "title": "Multi-label classification method based on extreme learning machines", "abstract": "In this paper, an Extreme Learning Machine (ELM) based technique for Multi-label classification problems is proposed and discussed. In multi-label classification, each of the input data samples belongs to one or more than one class labels. The traditional binary and multi-class classification problems are the subset of the multi-label problem with the number of labels corresponding to each sample limited to one. The proposed ELM based multi-label classification technique is evaluated with six different benchmark multi-label datasets from different domains such as multimedia, text and biology. A detailed comparison of the results is made by comparing the proposed method with the results from nine state of the arts techniques for five different evaluation metrics. The nine methods are chosen from different categories of multi-label methods. The comparative results shows that the proposed Extreme Learning Machine based multi-label classification technique is a better alternative than the existing state of the art methods for multi-label problems.", "venue": "2014 13th International Conference on Control Automation Robotics & Vision (ICARCV)", "authors": ["Rajasekar  Venkatesan", "Meng Joo Er"], "year": 2014, "n_citations": 15}
{"id": 5529657, "s2_id": "b20c0077a1b7c5041821f3a43f079eb1d695f740", "title": "Disentangled Attribution Curves for Interpreting Random Forests and Boosted Trees", "abstract": "Tree ensembles, such as random forests and AdaBoost, are ubiquitous machine learning models known for achieving strong predictive performance across a wide variety of domains. However, this strong performance comes at the cost of interpretability (i.e. users are unable to understand the relationships a trained random forest has learned and why it is making its predictions). In particular, it is challenging to understand how the contribution of a particular feature, or group of features, varies as their value changes. To address this, we introduce Disentangled Attribution Curves (DAC), a method to provide interpretations of tree ensemble methods in the form of (multivariate) feature importance curves. For a given variable, or group of variables, DAC plots the importance of a variable(s) as their value changes. We validate DAC on real data by showing that the curves can be used to increase the accuracy of logistic regression while maintaining interpretability, by including DAC as an additional feature. In simulation studies, DAC is shown to out-perform competing methods in the recovery of conditional expectations. Finally, through a case-study on the bike-sharing dataset, we demonstrate the use of DAC to uncover novel insights into a dataset.", "venue": "ArXiv", "authors": ["Summer  Devlin", "Chandan  Singh", "W. James Murdoch", "Bin  Yu"], "year": 2019, "n_citations": 6}
{"id": 5531273, "s2_id": "a1565c484a1414f073ba79d01ae8abe149f3ba4d", "title": "Hyperparameter Importance Across Datasets", "abstract": "With the advent of automated machine learning, automated hyperparameter optimization methods are by now routinely used in data mining. However, this progress is not yet matched by equal progress on automatic analyses that yield information beyond performance-optimizing hyperparameter settings. In this work, we aim to answer the following two questions: Given an algorithm, what are generally its most important hyperparameters, and what are typically good values for these? We present methodology and a framework to answer these questions based on meta-learning across many datasets. We apply this methodology using the experimental meta-data available on OpenML to determine the most important hyperparameters of support vector machines, random forests and Adaboost, and to infer priors for all their hyperparameters. The results, obtained fully automatically, provide a quantitative basis to focus efforts in both manual algorithm design and in automated hyperparameter optimization. The conducted experiments confirm that the hyperparameters selected by the proposed method are indeed the most important ones and that the obtained priors also lead to statistically significant improvements in hyperparameter optimization.", "venue": "KDD", "authors": ["Jan N. van Rijn", "Frank  Hutter"], "year": 2018, "n_citations": 85}
{"id": 5536986, "s2_id": "d5dec7c20409e1034073ae0353b16b3914392669", "title": "A review: Deep learning for medical image segmentation using multi-modality fusion", "abstract": "Multi-modality is widely used in medical imaging, because it can provide multiinformation about a target (tumor, organ or tissue). Segmentation using multimodality consists of fusing multi-information to improve the segmentation. Recently, deep learning-based approaches have presented the state-of-the-art performance in image classification, segmentation, object detection and tracking tasks. Due to their self-learning and generalization ability over large amounts of data, deep learning recently has also gained great interest in multi-modal medical image segmentation. In this paper, we give an overview of deep learning-based approaches for multi-modal medical image segmentation task. Firstly, we introduce the general principle of deep learning and multi-modal medical image segmentation. Secondly, we present different deep learning network architectures, then analyze their fusion strategies and compare their results. The earlier fusion is commonly used, since it's simple and it focuses on the subsequent segmentation network architecture. However, the later fusion gives more attention on fusion strategy to learn the complex relationship between different modalities. In general, compared to the earlier fusion, the later fusion can give more accurate result if the fusion method is effective enough. We also discuss some common problems in medical image segmentation. Finally, we summarize and provide some perspectives on the future research.", "venue": "Array", "authors": ["Tongxue  Zhou", "Su  Ruan", "St\u00e9phane  Canu"], "year": 2019, "n_citations": 147}
{"id": 5537619, "s2_id": "475a5c61814c72847f23d9d91e0ef7af985c17d3", "title": "A Variational U-Net for Weather Forecasting", "abstract": "Not only can discovering patterns and insights from atmospheric data enable more accurate weather predictions, but it may also provide valuable information to help tackle climate change. Weather4cast is an open competition that aims to evaluate machine learning algorithms\u2019 capability to predict future atmospheric states. Here, we describe our third-place solution to Weather4cast. We present a novel Variational U-Net that combines a Variational Autoencoder\u2019s ability to consider the probabilistic nature of data with a U-Net\u2019s ability to recover fine-grained details. This solution is an evolution from our fourth-place solution to Traffic4cast 2020 with many commonalities, suggesting its applicability to vastly different domains, such as weather and traffic. The code for this solution is available at https://github.com/qiq208/weather4cast2021_Stage1", "venue": "CIKM Workshops", "authors": ["Pak Hay Kwok", "Qi  Qi"], "year": 2021, "n_citations": 1}
{"id": 5539676, "s2_id": "842aec8d1382fa9a6fa9abc8061678ccc7def7fb", "title": "Parametrized Accelerated Methods Free of Condition Number", "abstract": "Analyses of accelerated (momentum-based) gradient descent usually assume bounded condition number to obtain exponential convergence rates. However, in many real problems, e.g., kernel methods or deep neural networks, the condition number, even locally, can be unbounded, unknown or mis-estimated. This poses problems in both implementing and analyzing accelerated algorithms. In this paper, we address this issue by proposing parametrized accelerated methods by considering the condition number as a free parameter. We provide spectral-level analysis for several important accelerated algorithms, obtain explicit expressions and improve worst case convergence rates. Moreover, we show that those algorithm converge exponentially even when the condition number is unknown or mis-estimated.", "venue": "ArXiv", "authors": ["Chaoyue  Liu", "Mikhail  Belkin"], "year": 2018, "n_citations": 3}
{"id": 5543550, "s2_id": "bdc47f8a781c99578b76e27708afac3691b6b1ec", "title": "Practical Deep Learning with Bayesian Principles", "abstract": "Bayesian methods promise to fix many shortcomings of deep learning, but they are impractical and rarely match the performance of standard methods, let alone improve them. In this paper, we demonstrate practical training of deep networks with natural-gradient variational inference. By applying techniques such as batch normalisation, data augmentation, and distributed training, we achieve similar performance in about the same number of epochs as the Adam optimiser, even on large datasets such as ImageNet. Importantly, the benefits of Bayesian principles are preserved: predictive probabilities are well-calibrated, uncertainties on out-of-distribution data are improved, and continual-learning performance is boosted. This work enables practical deep learning while preserving benefits of Bayesian principles. A PyTorch implementation is available as a plug-and-play optimiser.", "venue": "NeurIPS", "authors": ["Kazuki  Osawa", "Siddharth  Swaroop", "Anirudh  Jain", "Runa  Eschenhagen", "Richard E. Turner", "Rio  Yokota", "Mohammad Emtiyaz Khan"], "year": 2019, "n_citations": 103}
{"id": 5553327, "s2_id": "d5318a4ebb4160743e3af568b310ebc5aaebc09e", "title": "Federated learning for 6G communications: Challenges, methods, and future directions", "abstract": "As the 5G communication networks are being widely deployed worldwide, both industry and academia have started to move beyond 5G and explore 6G communications. It is generally believed that 6G will be established on ubiquitous Artificial Intelligence (AI) to achieve data-driven Machine Learning (ML) solutions in heterogeneous and massive-scale networks. However, traditional ML techniques require centralized data collection and processing by a central server, which is becoming a bottleneck of large-scale implementation in daily life due to significantly increasing privacy concerns. Federated learning, as an emerging distributed AI approach with privacy preservation nature, is particularly attractive for various wireless applications, especially being treated as one of the vital solutions to achieve ubiquitous AI in 6G. In this article, we first introduce the integration of 6G and federated learning and provide potential federated learning applications for 6G. We then describe key technical challenges, the corresponding federated learning methods, and open problems for future research on federated learning in the context of 6G communications.", "venue": "China Communications", "authors": ["Yi  Liu", "Xingliang  Yuan", "Zehui  Xiong", "Jiawen  Kang", "Xiaofei  Wang", "Dusit  Niyato"], "year": 2020, "n_citations": 50}
{"id": 5554612, "s2_id": "3977f8b694cb482c1fa6999d71a5c712918b32f7", "title": "CDF Transform-and-Shift: An effective way to deal with datasets of inhomogeneous cluster densities", "abstract": "Abstract The problem of inhomogeneous cluster densities has been a long-standing issue for distance-based and density-based algorithms in clustering and anomaly detection. These algorithms implicitly assume that all clusters have approximately the same density. As a result, they often exhibit a bias towards dense clusters in the presence of sparse clusters. Many remedies have been suggested; yet, we show that they are partial solutions which do not address the issue satisfactorily. To match the implicit assumption, we propose to transform a given dataset such that the transformed clusters have approximately the same density while all regions of locally low density become globally low density\u2014homogenising cluster density while preserving the cluster structure of the dataset. We show that this can be achieved by using a new multi-dimensional Cumulative Distribution Function in a transform-and-shift method. The method can be applied to every dataset, before the dataset is used in many existing algorithms to match their implicit assumption without algorithmic modification. We show that the proposed method performs better than existing remedies.", "venue": "Pattern Recognit.", "authors": ["Ye  Zhu", "Kai Ming Ting", "Mark J. Carman", "Maia  Angelova"], "year": 2021, "n_citations": 0}
{"id": 5556729, "s2_id": "2bc472478247173b25aaf5e12f2604a74a8d2063", "title": "The KiTS19 Challenge Data: 300 Kidney Tumor Cases with Clinical Context, CT Semantic Segmentations, and Surgical Outcomes", "abstract": "The morphometry of a kidney tumor revealed by contrast-enhanced Computed Tomography (CT) imaging is an important factor in clinical decision making surrounding the lesion's diagnosis and treatment. Quantitative study of the relationship between kidney tumor morphology and clinical outcomes is difficult due to data scarcity and the laborious nature of manually quantifying imaging predictors. Automatic semantic segmentation of kidneys and kidney tumors is a promising tool towards automatically quantifying a wide array of morphometric features, but no sizeable annotated dataset is currently available to train models for this task. We present the KiTS19 challenge dataset: A collection of multi-phase CT imaging, segmentation masks, and comprehensive clinical outcomes for 300 patients who underwent nephrectomy for kidney tumors at our center between 2010 and 2018. 210 (70%) of these patients were selected at random as the training set for the 2019 MICCAI KiTS Kidney Tumor Segmentation Challenge and have been released publicly. With the presence of clinical context and surgical outcomes, this data can serve not only for benchmarking semantic segmentation models, but also for developing and studying biomarkers which make use of the imaging and semantic segmentation masks.", "venue": "ArXiv", "authors": ["Nicholas  Heller", "Niranjan  Sathianathen", "Arveen  Kalapara", "Edward  Walczak", "Keenan  Moore", "Heather  Kaluzniak", "Joel  Rosenberg", "Paul  Blake", "Zachary  Rengel", "Makinna  Oestreich", "Joshua  Dean", "Michael  Tradewell", "Aneri  Shah", "Resha  Tejpaul", "Zachary  Edgerton", "Matthew  Peterson", "Shaneabbas  Raza", "Subodh  Regmi", "Nikolaos  Papanikolopoulos", "Christopher  Weight"], "year": 2019, "n_citations": 149}
{"id": 5558409, "s2_id": "f5651f098149627b5d33f5e4d78f0d4cdb12ca03", "title": "Improving COVID-19 Forecasting using eXogenous Variables", "abstract": "In this work, we study the pandemic course in the United States by considering national and state levels data. We propose and compare multiple time-series prediction techniques which incorporate auxiliary variables. One type of approach is based on spatio-temporal graph neural networks which forecast the pandemic course by utilizing a hybrid deep learning architecture and human mobility data. Nodes in this graph represent the state-level deaths due to COVID-19, edges represent the human mobility trend and temporal edges correspond to node attributes across time. The second approach is based on a statistical technique for COVID-19 mortality prediction in the United States that uses the SARIMA model and eXogenous variables. We evaluate these techniques on both state and national levels COVID-19 data in the United States and claim that the SARIMA and MCP models generated forecast values by the eXogenous variables can enrich the underlying model to capture complexity in respectively national and state levels data. We demonstrate signicant enhancement in the forecasting accuracy for a COVID-19 dataset, with a maximum improvement in forecasting accuracy by 64.58% and 59.18% (on average) over the GCN-LSTM Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for prot or commercial advantage and that copies bear this notice and the full citation on the rst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specic permission and/or a fee. Request permissions from permissions@acm.org. MileTS \u201921, August 14th, 2021, Singapore \u00a9 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-9999-9/18/06. . . $15.00 https://doi.org/10.1145/nnnnnnn.nnnnnnn model in the national level data, and 58.79% and 52.40% (on average) over the GCN-LSTMmodel in the state level data. Additionally, our proposed model outperforms a parallel study (AUG-NN) by 27.35% improvement of accuracy on average.", "venue": "ArXiv", "authors": ["Mohammadhossein  Toutiaee", "Xiaochuan  Li", "Yogesh  Chaudhari", "Shophine  Sivaraja", "Aishwarya  Venkataraj", "Indrajeet  Javeri", "Yuan  Ke", "Ismailcem  Arpinar", "Nicole  Lazar", "John  Miller"], "year": 2021, "n_citations": 0}
{"id": 5567041, "s2_id": "86dd671db36e3780f9f9716f4297dc9d9ba127b9", "title": "Sports highlights generation bas ed on acoustic events detection: A rugby case study", "abstract": "We approach the challenging problem of generating highlights from sports broadcasts utilizing audio information only. A language-independent, multi-stage classification approach is employed for detection of key acoustic events which then act as a platform for summarization of highlight scenes. Objective results and human experience indicate that our system is highly efficient.", "venue": "2015 IEEE International Conference on Consumer Electronics (ICCE)", "authors": ["Anant  Baijal", "Jaeyoun  Cho", "Woojung  Lee", "Byeong-Seob  Ko"], "year": 2015, "n_citations": 9}
{"id": 5578617, "s2_id": "b8bce28f766a05cfa379b39e082a2586b5c31058", "title": "Staring at Economic Aggregators through Information Lenses", "abstract": "It is hard to exaggerate the role of economic aggregators \u2014 functions that summarize numerous and / or heterogeneous data \u2014 in economic models since the early XX th century. In many cases, as witnessed by the pioneering works of Cobb and Douglas, these functions were information quantities tailored to economic theories, i.e. they were built to fit economic phenomena. In this paper, we look at these functions from the complementary side: information. We use a recent toolbox built on top of a vast class of distortions coined by Bregman, whose application field rivals metrics\u2019 in various subfields of mathematics. This toolbox makes it possible to find the quality of an aggregator (for consumptions, prices, labor, capital, wages, etc.), from the standpoint of the information it carries. We prove a rather striking result. From the informational standpoint, well-known economic aggregators do belong to the optimal set. As common economic assumptions enter the analysis, this large set shrinks, and it essentially ends up exactly fitting either CES, or Cobb-Douglas, or both. To summarize, in the relevant economic contexts, one could not have crafted better some aggregator from the information standpoint. We also discuss global economic behaviors of optimal information aggregators in general, and present a brief panorama of the links between economic and information aggregators.", "venue": "ArXiv", "authors": ["Richard  Nock", "Nicolas  Sanz", "Fred  Celimene", "Frank  Nielsen"], "year": 2008, "n_citations": 0}
{"id": 5589224, "s2_id": "76446e217958ad266cd886a9b06f18d564df9d28", "title": "Modeling the Intensity Function of Point Process Via Recurrent Neural Networks", "abstract": "Event sequence, asynchronously generated with random timestamp, is ubiquitous among applications. The precise and arbitrary timestamp can carry important clues about the underlying dynamics, and has lent the event data fundamentally different from the time-series whereby series is indexed with fixed and equal time interval. One expressive mathematical tool for modeling event is point process. The intensity functions of many point processes involve two components: the background and the effect by the history. Due to its inherent spontaneousness, the background can be treated as a time series while the other need to handle the history events. In this paper, we model the background by a Recurrent Neural Network (RNN) with its units aligned with time series indexes while the history effect is modeled by another RNN whose units are aligned with asynchronous events to capture the long-range dynamics. The whole model with event type and timestamp prediction output layers can be trained end-to-end. Our approach takes an RNN perspective to point process, and models its background and history effect. For utility, our method allows a black-box treatment for modeling the intensity which is often a pre-defined parametric form in point processes. Meanwhile end-to-end training opens the venue for reusing existing rich techniques in deep network for point process modeling. We apply our model to the predictive maintenance problem using a log dataset by more than 1000 ATMs from a global bank headquartered in North America.", "venue": "AAAI", "authors": ["Shuai  Xiao", "Junchi  Yan", "Xiaokang  Yang", "Hongyuan  Zha", "Stephen M. Chu"], "year": 2017, "n_citations": 126}
{"id": 5600086, "s2_id": "12803c8629f7a1f6360db752144069d1cce9fb31", "title": "Learning Temporally Causal Latent Processes from General Temporal Data", "abstract": "Our goal is to recover time-delayed latent causal variables and identify their relations from measured temporal data. Estimating causally-related latent variables from observations is particularly challenging as the latent variables are not uniquely recoverable in the most general case. In this work, we consider both a nonparametric, nonstationary setting and a parametric setting for the latent processes and propose two provable conditions under which temporally causal latent processes can be identified from their nonlinear mixtures. We propose LEAP, a theoretically-grounded framework that extends Variational AutoEncoders (VAEs) by enforcing our conditions through proper constraints in causal process prior. Experimental results on various datasets demonstrate that temporally causal latent processes are reliably identified from observed variables under different dependency structures and that our approach considerably outperforms baselines that do not properly leverage history or nonstationarity information. This demonstrates that using temporal information to learn latent processes from their invertible nonlinear mixtures in an unsupervised manner, for which we believe our work is one of the first, seems promising even without sparsity or minimality assumptions.", "venue": "ArXiv", "authors": ["Weiran  Yao", "Yuewen  Sun", "Alex  Ho", "Changyin  Sun", "Kun  Zhang"], "year": 2021, "n_citations": 0}
{"id": 5610804, "s2_id": "1eefce0cadc66bad19667226ed3e34d0e5dc106b", "title": "Interpretable Active Learning", "abstract": "Active learning has long been a topic of study in machine learning. However, as increasingly complex and opaque models have become standard practice, the process of active learning, too, has become more opaque. There has been little investigation into interpreting what specific trends and patterns an active learning strategy may be exploring. This work expands on the Local Interpretable Model-agnostic Explanations framework (LIME) to provide explanations for active learning recommendations. We demonstrate how LIME can be used to generate locally faithful explanations for an active learning strategy, and how these explanations can be used to understand how different models and datasets explore a problem space over time. In order to quantify the per-subgroup differences in how an active learning strategy queries spatial regions, we introduce a notion of uncertainty bias (based on disparate impact) to measure the discrepancy in the confidence for a model's predictions between one subgroup and another. Using the uncertainty bias measure, we show that our query explanations accurately reflect the subgroup focus of the active learning queries, allowing for an interpretable explanation of what is being learned as points with similar sources of uncertainty have their uncertainty bias resolved. We demonstrate that this technique can be applied to track uncertainty bias over user-defined clusters or automatically generated clusters based on the source of uncertainty.", "venue": "FAT", "authors": ["Richard L. Phillips", "Kyu Hyun Chang", "Sorelle A. Friedler"], "year": 2018, "n_citations": 23}
{"id": 5621153, "s2_id": "0c9a2adda11ed49d091948211fcfd517113b5243", "title": "Personalized Transformer for Explainable Recommendation", "abstract": "Personalization of natural language generation plays a vital role in a large spectrum of tasks, such as explainable recommendation, review summarization and dialog systems. In these tasks, user and item IDs are important identifiers for personalization. Transformer, which is demonstrated with strong language modeling capability, however, is not personalized and fails to make use of the user and item IDs since the ID tokens are not even in the same semantic space as the words. To address this problem, we present a PErsonalized Transformer for Explainable Recommendation (PETER1), on which we design a simple and effective learning objective that utilizes the IDs to predict the words in the target explanation, so as to endow the IDs with linguistic meanings and to achieve personalized Transformer. Besides generating explanations, PETER can also make recommendations, which makes it a unified model for the whole recommendationexplanation pipeline. Extensive experiments show that our small unpretrained model outperforms fine-tuned BERT on the generation task, in terms of both effectiveness and efficiency, which highlights the importance and the nice utility of our design.", "venue": "ACL/IJCNLP", "authors": ["Lei  Li", "Yongfeng  Zhang", "Li  Chen"], "year": 2021, "n_citations": 7}
{"id": 5621733, "s2_id": "2d03ad49e5dec46ba465e82d4f4eb788c362e87f", "title": "Provably-Efficient Double Q-Learning", "abstract": "In this paper, we establish a theoretical comparison between the asymptotic mean-squared error of Double Q-learning and Q-learning. Our result builds upon an analysis for linear stochastic approximation based on Lyapunov equations and applies to both tabular setting and with linear function approximation, provided that the optimal policy is unique and the algorithms converge. We show that the asymptotic mean-squared error of Double Q-learning is exactly equal to that of Q-learning if Double Q-learning uses twice the learning rate of Q-learning and outputs the average of its two estimators. We also present some practical implications of this theoretical observation using simulations.", "venue": "ArXiv", "authors": ["Wentao  Weng", "Harsh  Gupta", "Niao  He", "Lei  Ying", "R.  Srikant"], "year": 2020, "n_citations": 4}
{"id": 5656083, "s2_id": "52f3960fa991a3b9a0a750bd2740f3dade369011", "title": "Adaptive Submodularity: Theory and Applications in Active Learning and Stochastic Optimization", "abstract": "Solving stochastic optimization problems under partial observability, where one needs to adaptively make decisions with uncertain outcomes, is a fundamental but notoriously difficult challenge. In this paper, we introduce the concept of adaptive submodularity, generalizing submodular set functions to adaptive policies. We prove that if a problem satisfies this property, a simple adaptive greedy algorithm is guaranteed to be competitive with the optimal policy. In addition to providing performance guarantees for both stochastic maximization and coverage, adaptive submodularity can be exploited to drastically speed up the greedy algorithm by using lazy evaluations. We illustrate the usefulness of the concept by giving several examples of adaptive submodular objectives arising in diverse applications including sensor placement, viral marketing and active learning. Proving adaptive submodularity for these problems allows us to recover existing results in these applications as special cases, improve approximation guarantees and handle natural generalizations.", "venue": "J. Artif. Intell. Res.", "authors": ["Daniel  Golovin", "Andreas  Krause"], "year": 2011, "n_citations": 496}
{"id": 5661470, "s2_id": "80528cf74583bf9c22ae0288d78d195a5ec9e8ff", "title": "A Witness Function Based Construction of Discriminative Models Using Hermite Polynomials", "abstract": "In machine learning, we are given a dataset of the form {(xj,yj)}j=1M, drawn as i.i.d. samples from an unknown probability distribution \u03bc; the marginal distribution for the xj's being \u03bc*, and the marginals of the kth class \u03bck*(x) possibly overlapping. We address the problem of detecting, with a high degree of certainty, for which x we have \u03bck*(x)>\u03bci*(x) for all i \u2260 k. We propose that rather than using a positive kernel such as the Gaussian for estimation of these measures, using a non-positive kernel that preserves a large number of moments of these measures yields an optimal approximation. We use multi-variate Hermite polynomials for this purpose, and prove optimal and local approximation results in a supremum norm in a probabilistic sense. Together with a permutation test developed with the same kernel, we prove that the kernel estimator serves as a \u201cwitness function\u201d in classification problems. Thus, if the value of this estimator at a point x exceeds a certain threshold, then the point is reliably in a certain class. This approach can be used to modify pretrained algorithms, such as neural networks or nonlinear dimension reduction techniques, to identify in-class vs out-of-class regions for the purposes of generative models, classification uncertainty, or finding robust centroids. This fact is demonstrated in a number of real world data sets including MNIST, CIFAR10, Science News documents, and LaLonde data sets.", "venue": "Frontiers in Applied Mathematics and Statistics", "authors": ["Hrushikesh N. Mhaskar", "Alexander  Cloninger", "Xiuyuan  Cheng"], "year": 2020, "n_citations": 4}
{"id": 5662408, "s2_id": "8bae78a5b33879591a17de7d6d85f7d7af3d17c4", "title": "SenseGen: A deep learning architecture for synthetic sensor data generation", "abstract": "Our ability to synthesize sensory data that preserves specific statistical properties of the real data has had tremendous implications on data privacy and big data analytics. The synthetic data can be used as a substitute for selective real data segments - that are sensitive to the user - thus protecting privacy and resulting in improved analytics. However, increasingly adversarial roles taken by data recipients such as mobile apps, or other cloud-based analytics services, mandate that the synthetic data, in addition to preserving statistical properties, should also be \u201cdifficult\u201d to distinguish from the real data. Typically, visual inspection has been used as a test to distinguish between datasets. But more recently, sophisticated classifier models (discriminators), corresponding to a set of events, have also been employed to distinguish between synthesized and real data. The model operates on both datasets and the respective event outputs are compared for consistency. Prior work on data synthesis have often focussed on classifiers that are built for features explicitly preserved by the synthetic data. This suggests that an adversary can build classifiers that can exploit a potentially disjoint set of features for differentiating between the two datasets. In this paper, we take a step towards generating sensory data that can pass a deep learning based discriminator model test, and make two specific contributions: first, we present a deep learning based architecture for synthesizing sensory data. This architecture comprises of a generator model, which is a stack of multiple Long-Short-Term-Memory (LSTM) networks and a Mixture Density Network (MDN); second, we use another LSTM network based discriminator model for distinguishing between the true and the synthesized data. Using a dataset of accelerometer traces, collected using smartphones of users doing their daily activities, we show that the deep learning based discriminator model can only distinguish between the real and synthesized traces with an accuracy in the neighborhood of 50%.", "venue": "2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops)", "authors": ["Moustafa  Alzantot", "Supriyo  Chakraborty", "Mani B. Srivastava"], "year": 2017, "n_citations": 67}
{"id": 5664755, "s2_id": "78cd10fd7fbd916d0529d47d113e2ab6e1f01d64", "title": "A Gradient Flow Framework For Analyzing Network Pruning", "abstract": "Recent network pruning methods focus on pruning models early-on in training. To estimate the impact of removing a parameter, these methods use importance measures that were originally designed to prune trained models. Despite lacking justification for their use early-on in training, such measures result in surprisingly low accuracy loss. To better explain this behavior, we develop a general gradient flow based framework that unifies state-of-the-art importance measures through the norm of model parameters. We use this framework to determine the relationship between pruning measures and evolution of model parameters, establishing several results related to pruning models early-on in training: (i) magnitude-based pruning removes parameters that contribute least to reduction in loss, resulting in models that converge faster than magnitude-agnostic methods; (ii) loss-preservation based pruning preserves first-order model evolution dynamics and is therefore appropriate for pruning minimally trained models; and (iii) gradient-norm based pruning affects second-order model evolution dynamics, such that increasing gradient norm via pruning can produce poorly performing models. We validate our claims on several VGG-13, MobileNet-V1, and ResNet-56 models trained on CIFAR-10 and CIFAR-100. Code available at this https URL.", "venue": "ICLR", "authors": ["Ekdeep Singh Lubana", "Robert P. Dick"], "year": 2021, "n_citations": 6}
{"id": 5665154, "s2_id": "66a7f14900bd962d412c74f512e4356dfc16f733", "title": "Siamese Graph Neural Networks for Data Integration", "abstract": "Data integration has been studied extensively for decades and approached from different angles. However, this domain still remains largely rule-driven and lacks universal automation. Recent development in machine learning and in particular deep learning has opened the way to more general and more efficient solutions to data integration problems. In this work, we propose a general approach to modeling and integrating entities from structured data, such as relational databases, as well as unstructured sources, such as free text from news articles. Our approach is designed to explicitly model and leverage relations between entities, thereby using all available information and preserving as much context as possible. This is achieved by combining siamese and graph neural networks to propagate information between connected entities and support high scalability. We evaluate our method on the task of integrating data about business entities, and we demonstrate that it outperforms standard rule-based systems, as well as other deep learning approaches that do not use graph-based representations.", "venue": "ArXiv", "authors": ["Evgeny  Krivosheev", "Mattia  Atzeni", "Katsiaryna  Mirylenka", "Paolo  Scotton", "Fabio  Casati"], "year": 2020, "n_citations": 4}
{"id": 5665222, "s2_id": "52babc837d175f0323d75b4f13cae829070daeba", "title": "Exploring Decomposition for Table-based Fact Verification", "abstract": "Fact verification based on structured data is challenging as it requires models to understand both natural language and symbolic operations performed over tables. Although pretrained language models have demonstrated a strong capability in verifying simple statements, they struggle with complex statements that involve multiple operations. In this paper, we improve fact verification by decomposing complex statements into simpler subproblems. Leveraging the programs synthesized by a weakly supervised semantic parser, we propose a program-guided approach to constructing a pseudo dataset for decomposition model training. The subproblems, together with their predicted answers, serve as the intermediate evidence to enhance our fact verification model. Experiments show that our proposed approach achieves the new state-of-theart performance, an 82.7% accuracy, on the TABFACT benchmark.", "venue": "EMNLP", "authors": ["Xiaoyu  Yang", "Xiaodan  Zhu"], "year": 2021, "n_citations": 0}
{"id": 5673081, "s2_id": "b4077b168793ae5c92843984ab5759af9b4e50cd", "title": "Information Theory Measures via Multidimensional Gaussianization", "abstract": "Information theory is an outstanding framework to measure uncertainty, dependence and relevance in data and systems. It has several desirable properties for real world applications: it naturally deals with multivariate data, it can handle heterogeneous data types, and the measures can be interpreted in physical units. However, it has not been adopted by a wider audience because obtaining information from multidimensional data is a challenging problem due to the curse of dimensionality. Here we propose an indirect way of computing information based on a multivariate Gaussianization transform. Our proposal mitigates the difficulty of multivariate density estimation by reducing it to a composition of tractable (marginal) operations and simple linear transformations, which can be interpreted as a particular deep neural network. We introduce specific Gaussianization-based methodologies to estimate total correlation, entropy, mutual information and Kullback-Leibler divergence. We compare them to recent estimators showing the accuracy on synthetic data generated from different multivariate distributions. We made the tools and datasets publicly available to provide a test-bed to analyze future methodologies. Results show that our proposal is superior to previous estimators particularly in high-dimensional scenarios; and that it leads to interesting insights in neuroscience, geoscience, computer vision, and machine learning.", "venue": "ArXiv", "authors": ["Valero  Laparra", "J. Emmanuel Johnson", "Gustau  Camps-Valls", "Raul  Santos-Rodr'iguez", "Jesus  Malo"], "year": 2020, "n_citations": 2}
{"id": 5677845, "s2_id": "c075c78c0effc19da82b4a80d037af20b34c1beb", "title": "NUQSGD: Provably Communication-efficient Data-parallel SGD via Nonuniform Quantization", "abstract": "As the size and complexity of models and datasets grow, so does the need for communication-efficient variants of stochastic gradient descent that can be deployed to perform parallel model training. One popular communication-compression method for data-parallel SGD is QSGD (Alistarh et al., 2017), which quantizes and encodes gradients to reduce communication costs. The baseline variant of QSGD provides strong theoretical guarantees, however, for practical purposes, the authors proposed a heuristic variant which we call QSGDinf, which demonstrated impressive empirical gains for distributed training of large neural networks. In this paper, we build on this work to propose a new gradient quantization scheme, and show that it has both stronger theoretical guarantees than QSGD, and matches and exceeds the empirical performance of the QSGDinf heuristic and of other compression methods.", "venue": "ArXiv", "authors": ["Ali  Ramezani-Kebrya", "Fartash  Faghri", "Ilya  Markov", "Vitalii  Aksenov", "Dan  Alistarh", "Daniel M. Roy"], "year": 2021, "n_citations": 6}
{"id": 5684443, "s2_id": "0211e4529c51b1affe77385d6af4887df3d2906d", "title": "Robust Generalization of Quadratic Neural Networks via Function Identification", "abstract": "A key challenge facing deep learning is that neural networks are often not robust to shifts in the underlying data distribution. We study this problem from the perspective of the statistical concept of parameter identification. Generalization bounds from learning theory often assume that the test distribution is close to the training distribution. In contrast, if we can identify the \u201ctrue\u201d parameters, then the model generalizes to arbitrary distribution shifts. However, neural networks are typically overparameterized, making parameter identification impossible. We show that for quadratic neural networks, we can identify the function represented by the model even though we cannot identify its parameters. Thus, we can obtain robust generalization bounds even in the overparameterized setting. We leverage this result to obtain new bounds for contextual bandits and transfer learning with quadratic neural networks. Overall, our results suggest that we can improve robustness of neural networks by designing models that can represent the true data generating process. In practice, the true data generating process is often very complex; thus, we study how our framework might connect to neural module networks, which are designed to break down complex tasks into compositions of simpler ones. We prove robust generalization bounds when individual neural modules are identifiable.", "venue": "ArXiv", "authors": ["Kan  Xu", "Hamsa  Bastani", "Osbert  Bastani"], "year": 2021, "n_citations": 0}
{"id": 5704147, "s2_id": "f73ee8a34fd4fb901620e3d57ae951f6f7ead4e9", "title": "Structured Low-Rank Matrix Factorization: Global Optimality, Algorithms, and Applications", "abstract": "Convex formulations of low-rank matrix factorization problems have received considerable attention in machine learning. However, such formulations often require solving for a matrix of the size of the data matrix, making it challenging to apply them to large scale datasets. Moreover, in many applications the data can display structures beyond simply being low-rank, e.g., images and videos present complex spatio-temporal structures that are largely ignored by standard low-rank methods. In this paper we study a matrix factorization technique that is suitable for large datasets and captures additional structure in the factors by using a particular form of regularization that includes well-known regularizers such as total variation and the nuclear norm as particular cases. Although the resulting optimization problem is non-convex, we show that if the size of the factors is large enough, under certain conditions, any local minimizer for the factors yields a global minimizer. A few practical algorithms are also provided to solve the matrix factorization problem, and bounds on the distance from a given approximate solution of the optimization problem to the global optimum are derived. Examples in neural calcium imaging video segmentation and hyperspectral compressed recovery show the advantages of our approach on high-dimensional datasets.", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "authors": ["Benjamin D. Haeffele", "Ren\u00e9  Vidal"], "year": 2020, "n_citations": 36}
{"id": 5720171, "s2_id": "8c39c73b624eec1eb4cf502a017a8a3efecab227", "title": "CNN Detection of GAN-Generated Face Images based on Cross-Band Co-occurrences Analysis", "abstract": "Last-generation GAN models allow to generate synthetic images which are visually indistinguishable from natural ones, raising the need to develop tools to distinguish fake and natural images thus contributing to preserve the trustworthiness of digital images. While modern GAN models can generate very high-quality images with no visible spatial artifacts, reconstruction of consistent relationships among colour channels is expectedly more difficult. In this paper, we propose a method for distinguishing GAN-generated from natural images by exploiting inconsistencies among spectral bands, with specific focus on the generation of synthetic face images. Specifically, we use cross-band co-occurrence matrices, in addition to spatial co-occurrence matrices, as input to a CNN model, which is trained to distinguish between real and synthetic faces. The results of our experiments confirm the goodness of our approach which outperforms a similar detection technique based on intra-band spatial co-occurrences only. The performance gain is particularly significant with regard to robustness against post-processing, like geometric transformations, filtering and contrast manipulations.", "venue": "2020 IEEE International Workshop on Information Forensics and Security (WIFS)", "authors": ["Mauro  Barni", "Kassem  Kallas", "Ehsan  Nowroozi", "Benedetta  Tondi"], "year": 2020, "n_citations": 12}
{"id": 5727459, "s2_id": "a6256769d78547b0524e49f34bd058c243545aba", "title": "Online Learning of Optimal Bidding Strategy in Repeated Multi-Commodity Auctions", "abstract": "We study the online learning problem of a bidder who participates in repeated auctions. With the goal of maximizing his T-period payoff, the bidder determines the optimal allocation of his budget among his bids for $K$ goods at each period. As a bidding strategy, we propose a polynomial-time algorithm, inspired by the dynamic programming approach to the knapsack problem. The proposed algorithm, referred to as dynamic programming on discrete set (DPDS), achieves a regret order of $O(\\sqrt{T\\log{T}})$. By showing that the regret is lower bounded by $\\Omega(\\sqrt{T})$ for any strategy, we conclude that DPDS is order optimal up to a $\\sqrt{\\log{T}}$ term. We evaluate the performance of DPDS empirically in the context of virtual trading in wholesale electricity markets by using historical data from the New York market. Empirical results show that DPDS consistently outperforms benchmark heuristic methods that are derived from machine learning and online learning approaches.", "venue": "NIPS", "authors": ["M. Sevi Baltaoglu", "Lang  Tong", "Qing  Zhao"], "year": 2017, "n_citations": 5}
{"id": 5737986, "s2_id": "33f55dbdc005ec8df4c7a4412a30a704432e125c", "title": "Integrating Informativeness, Representativeness and Diversity in Pool-Based Sequential Active Learning for Regression", "abstract": "In many real-world machine learning applications, unlabeled samples are easy to obtain, but it is expensive and/or time-consuming to label them. Active learning is a common approach for reducing this data labeling effort. It optimally selects the best few samples to label, so that a better machine learning model can be trained from the same number of labeled samples. This paper considers active learning for regression (ALR) problems. Three essential criteria \u2013 informativeness, representativeness, and diversity \u2013 have been proposed for ALR. However, very few approaches in the literature have considered all three of them simultaneously. We propose three new ALR approaches, with different strategies for integrating the three criteria. Extensive experiments on 12 datasets in various domains demonstrated their effectiveness.", "venue": "2020 International Joint Conference on Neural Networks (IJCNN)", "authors": ["Ziang  Liu", "Dongrui  Wu"], "year": 2020, "n_citations": 1}
{"id": 5745330, "s2_id": "1cf4e23e715339ea8f94a563d75c16acaa19741c", "title": "Reinforcement Learning based Condition-oriented Maintenance Scheduling for Flow Line Systems", "abstract": "Maintenance scheduling is a complex decision-making problem in the production domain, where a number of maintenance tasks and resources has to be assigned and scheduled to production entities in order to prevent unplanned production downtime. Intelligent maintenance strategies are required that are able to adapt to the dynamics and different conditions of production systems. The paper introduces a deep reinforcement learning approach for condition-oriented maintenance scheduling in flow line systems. Different policies are learned, analyzed and evaluated against a benchmark scheduling heuristic based on reward modelling. The evaluation of the learned policies shows that reinforcement learning based maintenance strategies meet the requirements of the presented use case and are suitable for maintenance scheduling in the shop floor.", "venue": "2021 IEEE 19th International Conference on Industrial Informatics (INDIN)", "authors": ["Raphael  Lamprecht", "Ferdinand  Wurst", "Marco F. Huber"], "year": 2021, "n_citations": 0}
{"id": 5748570, "s2_id": "f74da9c5a37d6a85c19548a7810cb9523c565272", "title": "A Distributionally Robust Boosting Algorithm", "abstract": "Distributionally Robust Optimization (DRO) has been shown to provide a flexible framework for decision making under uncertainty and statistical estimation. For example, recent works in DRO have shown that popular statistical estimators can be interpreted as the solutions of suitable formulated data-driven DRO problems. In turn, this connection is used to optimally select tuning parameters in terms of a principled approach informed by robustness considerations. This paper contributes to this growing literature, connecting DRO and statistics, by showing how boosting algorithms can be studied via DRO. We propose a boosting type algorithm, named DRO-Boosting, as a procedure to solve our DRO formulation. Our DRO-Boosting algorithm recovers Adaptive Boosting (AdaBoost) in particular, thus showing that AdaBoost is effectively solving a DRO problem. We apply our algorithm to a financial dataset on credit card default payment prediction. Our approach compares favorably to alternative boosting methods which are widely used in practice.", "venue": "2019 Winter Simulation Conference (WSC)", "authors": ["Jose  Blanchet", "Yang  Kang", "Fan  Zhang", "Zhangyi  Hu"], "year": 2019, "n_citations": 3}
{"id": 5749067, "s2_id": "f00c87cac325a6dda1e6982bb042c7583ed5590d", "title": "When and how epochwise double descent happens", "abstract": "Deep neural networks are known to exhibit a \u2018double descent\u2019 behavior as the number of parameters increases. Recently, it has also been shown that an \u2018epochwise double descent\u2019 effect exists in which the generalization error initially drops, then rises, and finally drops again with increasing training time. This presents a practical problem in that the amount of time required for training is long, and early stopping based on validation performance may result in suboptimal generalization. In this work we develop an analytically tractable model of epochwise double descent that allows us to characterise theoretically when this effect is likely to occur. This model is based on the hypothesis that the training data contains features that are slow to learn but informative. We then show experimentally that deep neural networks behave similarly to our theoretical model. Our findings indicate that epochwise double descent requires a critical amount of noise to occur, but above a second critical noise level early stopping remains effective. Using insights from theory, we give two methods by which epochwise double descent can be removed: one that removes slow to learn features from the input and reduces generalization performance, and another that instead modifies the training dynamics and matches or exceeds the generalization performance of standard training. Taken together, our results suggest a new picture of how epochwise double descent emerges from the interplay between the dynamics of training and noise in the training data.", "venue": "ArXiv", "authors": ["Cory  Stephenson", "Tyler  Lee"], "year": 2021, "n_citations": 1}
{"id": 5763397, "s2_id": "80763fc2ae7b2f9cba9e44c599b394abef84fbf2", "title": "Learning from Conditional Distributions via Dual Embeddings", "abstract": "Many machine learning tasks, such as learning with invariance and policy evaluation in reinforcement learning, can be characterized as problems of learning from conditional distributions. In such problems, each sample $x$ itself is associated with a conditional distribution $p(z|x)$ represented by samples $\\{z_i\\}_{i=1}^M$, and the goal is to learn a function $f$ that links these conditional distributions to target values $y$. These learning problems become very challenging when we only have limited samples or in the extreme case only one sample from each conditional distribution. Commonly used approaches either assume that $z$ is independent of $x$, or require an overwhelmingly large samples from each conditional distribution. \nTo address these challenges, we propose a novel approach which employs a new min-max reformulation of the learning from conditional distribution problem. With such new reformulation, we only need to deal with the joint distribution $p(z,x)$. We also design an efficient learning algorithm, Embedding-SGD, and establish theoretical sample complexity for such problems. Finally, our numerical experiments on both synthetic and real-world datasets show that the proposed approach can significantly improve over the existing algorithms.", "venue": "AISTATS", "authors": ["Bo  Dai", "Niao  He", "Yunpeng  Pan", "Byron  Boots", "Le  Song"], "year": 2017, "n_citations": 90}
{"id": 5766844, "s2_id": "2cbfb1646d87c223d332c8b7eae7f653e284cf92", "title": "SGD without Replacement: Sharper Rates for General Smooth Convex Functions", "abstract": "We study stochastic gradient descent {\\em without replacement} (\\sgdwor) for smooth convex functions. \\sgdwor is widely observed to converge faster than true \\sgd where each sample is drawn independently {\\em with replacement} \\cite{bottou2009curiously} and hence, is more popular in practice. But it's convergence properties are not well understood as sampling without replacement leads to coupling between iterates and gradients. By using method of exchangeable pairs to bound Wasserstein distance, we provide the first non-asymptotic results for \\sgdwor when applied to {\\em general smooth, strongly-convex} functions. In particular, we show that \\sgdwor converges at a rate of $O(1/K^2)$ while \\sgd is known to converge at $O(1/K)$ rate, where $K$ denotes the number of passes over data and is required to be {\\em large enough}. Existing results for \\sgdwor in this setting require additional {\\em Hessian Lipschitz assumption} \\cite{gurbuzbalaban2015random,haochen2018random}. \nFor {\\em small} $K$, we show \\sgdwor can achieve same convergence rate as \\sgd for {\\em general smooth strongly-convex} functions. Existing results in this setting require $K=1$ and hold only for generalized linear models \\cite{shamir2016without}. In addition, by careful analysis of the coupling, for both large and small $K$, we obtain better dependence on problem dependent parameters like condition number.", "venue": "ICML", "authors": ["Prateek  Jain", "Dheeraj  Nagaraj", "Praneeth  Netrapalli"], "year": 2019, "n_citations": 42}
{"id": 5767893, "s2_id": "832dd29871124a487eb9f099033420fdfb58e7f3", "title": "Deep Learning of Nanopore Sensing Signals Using a Bi-Path Network", "abstract": "Temporal changes in electrical resistance of a nanopore sensor caused by translocating target analytes are recorded as a sequence of pulses on current traces. Prevalent algorithms for feature extraction in pulse-like signals lack objectivity because empirical amplitude thresholds are user-defined to single out the pulses from the noisy background. Here, we use deep learning for feature extraction based on a bi-path network (B-Net). After training, the B-Net acquires the prototypical pulses and the ability of both pulse recognition and feature extraction without a priori assigned parameters. The B-Net is evaluated on simulated data sets and further applied to experimental data of DNA and protein translocation. The B-Net results are characterized by small relative errors and stable trends. The B-Net is further shown capable of processing data with a signal-to-noise ratio equal to 1, an impossibility for threshold-based algorithms. The B-Net presents a generic architecture applicable to pulse-like signals beyond nanopore currents.", "venue": "ACS nano", "authors": ["Dario  Dematties", "Chenyu  Wen", "Mauricio David P'erez", "Dian  Zhou", "Shi-Li  Zhang"], "year": 2021, "n_citations": 1}
{"id": 5774174, "s2_id": "f08edcd6dfe28aa600c3fbc38ddbe76d387e59f1", "title": "Quantum algorithms for group convolution, cross-correlation, and equivariant transformations", "abstract": "Group convolutions and cross-correlations, which are equivariant to the actions of group elements, are commonly used in mathematics to analyze or take advantage of symmetries inherent in a given problem setting. Here, we provide efficient quantum algorithms for performing linear group convolutions and cross-correlations on data stored as quantum states. Runtimes for our algorithms are logarithmic in the dimension of the group thus offering an exponential speedup compared to classical algorithms when input data is provided as a quantum state and linear operations are well conditioned. Motivated by the rich literature on quantum algorithms for solving algebraic problems, our theoretical framework opens a path for quantizing many algorithms in machine learning and numerical methods that employ group operations.", "venue": "ArXiv", "authors": ["Grecia  Castelazo", "Quynh T. Nguyen", "Giacomo De Palma", "Dirk  Englund", "Seth  Lloyd", "Bobak T. Kiani"], "year": 2021, "n_citations": 0}
{"id": 5781957, "s2_id": "28081353f65aa0b97a6bda836c7b0772048766e9", "title": "The Weighted Kendall and High-order Kernels for Permutations", "abstract": "We propose new positive definite kernels for permutations. First we introduce a weighted version of the Kendall kernel, which allows to weight unequally the contributions of different item pairs in the permutations depending on their ranks. Like the Kendall kernel, we show that the weighted version is invariant to relabeling of items and can be computed efficiently in $O(n \\ln(n))$ operations, where $n$ is the number of items in the permutation. Second, we propose a supervised approach to learn the weights by jointly optimizing them with the function estimated by a kernel machine. Third, while the Kendall kernel considers pairwise comparison between items, we extend it by considering higher-order comparisons among tuples of items and show that the supervised approach of learning the weights can be systematically generalized to higher-order permutation kernels.", "venue": "ICML", "authors": ["Yunlong  Jiao", "Jean-Philippe  Vert"], "year": 2018, "n_citations": 3}
{"id": 5789052, "s2_id": "dc6cc4874d7a2184d008649b8a58df980d531fec", "title": "A short letter on the dot product between rotated Fourier transforms", "abstract": "Spatial Semantic Pointers (SSPs) have recently emerged as a powerful tool for representing and transforming continuous space, with numerous applications to cognitive modelling and deep learning. Fundamental to SSPs is the notion of \"similarity\" between vectors representing different points in $n$-dimensional space -- typically the dot product or cosine similarity between vectors with rotated unit-length complex coefficients in the Fourier domain. The similarity measure has previously been conjectured to be a Gaussian function of Euclidean distance. Contrary to this conjecture, we derive a simple trigonometric formula relating spatial displacement to similarity, and prove that, in the case where the Fourier coefficients are uniform i.i.d., the expected similarity is a product of normalized sinc functions: $\\prod_{k=1}^{n} \\operatorname{sinc} \\left( a_k \\right)$, where $\\mathbf{a} \\in \\mathbb{R}^n$ is the spatial displacement between the two $n$-dimensional points. This establishes a direct link between space and the similarity of SSPs, which in turn helps bolster a useful mathematical framework for architecting neural networks that manipulate spatial structures.", "venue": "ArXiv", "authors": ["Aaron R. Voelker"], "year": 2020, "n_citations": 2}
{"id": 5789406, "s2_id": "361996e4fbbabe5ef028c85d7ab9e4213e5c777c", "title": "Frivolous Units: Wider Networks Are Not Really That Wide", "abstract": "A remarkable characteristic of overparameterized deep neural networks (DNNs) is that their accuracy does not degrade when the network's width is increased. Recent evidence suggests that developing compressible representations is key for adjusting the complexity of large networks to the learning task at hand. However, these compressible representations are poorly understood. A promising strand of research inspired from biology is understanding representations at the unit level as it offers a more granular and intuitive interpretation of the neural mechanisms. In order to better understand what facilitates increases in width without decreases in accuracy, we ask: Are there mechanisms at the unit level by which networks control their effective complexity as their width is increased? If so, how do these depend on the architecture, dataset, and training parameters? We identify two distinct types of \"frivolous\" units that proliferate when the network's width is increased: prunable units which can be dropped out of the network without significant change to the output and redundant units whose activities can be expressed as a linear combination of others. These units imply complexity constraints as the function the network represents could be expressed by a network without them. We also identify how the development of these units can be influenced by architecture and a number of training factors. Together, these results help to explain why the accuracy of DNNs does not degrade when width is increased and highlight the importance of frivolous units toward understanding implicit regularization in DNNs.", "venue": "AAAI", "authors": ["Stephen  Casper", "Xavier  Boix", "Vanessa  D'Amario", "Ling  Guo", "Martin  Schrimpf", "Kasper  Vinken", "Gabriel  Kreiman"], "year": 2021, "n_citations": 4}
{"id": 5797543, "s2_id": "848e3ed9b9b14f648b63ea66cbf2a5663bd22fdd", "title": "The Ladder: A Reliable Leaderboard for Machine Learning Competitions", "abstract": "The organizer of a machine learning competition faces the problem of maintaining an accurate leaderboard that faithfully represents the quality of the best submission of each competing team. What makes this estimation problem particularly challenging is its sequential and adaptive nature. As participants are allowed to repeatedly evaluate their submissions on the leaderboard, they may begin to overfit to the holdout data that supports the leaderboard. Few theoretical results give actionable advice on how to design a reliable leaderboard. Existing approaches therefore often resort to poorly understood heuristics such as limiting the bit precision of answers and the rate of resubmission. \n \nIn this work, we introduce a notion of leaderboard accuracy tailored to the format of a competition. We introduce a natural algorithm called the Ladder and demonstrate that it simultaneously supports strong theoretical guarantees in a fully adaptive model of estimation, withstands practical adversarial attacks, and achieves high utility on real submission files from an actual competition hosted by Kaggle. \n \nNotably, we are able to sidestep a powerful recent hardness result for adaptive risk estimation that rules out algorithms such as ours under a seemingly very similar notion of accuracy. On a practical note, we provide a completely parameter-free variant of our algorithm that can be deployed in a real competition with no tuning required whatsoever.", "venue": "ICML", "authors": ["Avrim  Blum", "Moritz  Hardt"], "year": 2015, "n_citations": 100}
{"id": 5819914, "s2_id": "8cb3000e8959d1065532d54a07cf8fe97ef6b9c6", "title": "Knowledge Transfer via Distillation of Activation Boundaries Formed by Hidden Neurons", "abstract": "An activation boundary for a neuron refers to a separating hyperplane that determines whether the neuron is activated or deactivated. It has been long considered in neural networks that the activations of neurons, rather than their exact output values, play the most important role in forming classificationfriendly partitions of the hidden feature space. However, as far as we know, this aspect of neural networks has not been considered in the literature of knowledge transfer. In this paper, we propose a knowledge transfer method via distillation of activation boundaries formed by hidden neurons. For the distillation, we propose an activation transfer loss that has the minimum value when the boundaries generated by the student coincide with those by the teacher. Since the activation transfer loss is not differentiable, we design a piecewise differentiable loss approximating the activation transfer loss. By the proposed method, the student learns a separating boundary between activation region and deactivation region formed by each neuron in the teacher. Through the experiments in various aspects of knowledge transfer, it is verified that the proposed method outperforms the current state-of-the-art.", "venue": "AAAI", "authors": ["Byeongho  Heo", "Minsik  Lee", "Sangdoo  Yun", "Jin Young Choi"], "year": 2019, "n_citations": 143}
{"id": 5829880, "s2_id": "d05f5068c330bc02579e56254317bb2081172799", "title": "Neural Network Gaussian Processes by Increasing Depth", "abstract": "Recent years have witnessed an increasing interest in the correspondence between infinitely wide networks and Gaussian processes. Despite the effectiveness and elegance of the current neural network Gaussian process theory, to the best of our knowledge, all the neural network Gaussian processes are essentially induced by increasing width. However, in the era of deep learning, what concerns us more regarding a neural network is its depth as well as how depth impacts the behaviors of a network. Inspired by a width-depth symmetry consideration, we use a shortcut network to show that increasing depth of a neural network can also give rise to a Gaussian process, which is a valuable addition to the existing theory and contributes to revealing the true picture of deep learning. Beyond the proposed Gaussian process by depth, we theoretically characterize its uniform tightness property and the smallest eigenvalue of its associated kernel. These characterizations can not only enhance our understanding of the proposed depth-induced Gaussian processes, but also pave the way for future applications. Lastly, we examine the performance of the proposed Gaussian process by regression experiments on two real-world data sets.", "venue": "ArXiv", "authors": ["Shao-Qun  Zhang", "Feng-Lei  Fan"], "year": 2021, "n_citations": 0}
{"id": 5833909, "s2_id": "c689c2f080ff8260a39d1bc4196e3a6ef7985dd8", "title": "Arbitrage of Energy Storage in Electricity Markets with Deep Reinforcement Learning", "abstract": "In this letter, we address the problem of controlling energy storage systems (ESSs) for arbitrage in real-time electricity markets under price uncertainty. We first formulate this problem as a Markov decision process, and then develop a deep reinforcement learning based algorithm to learn a stochastic control policy that maps a set of available information processed by a recurrent neural network to ESSs' charging/discharging actions. Finally, we verify the effectiveness of our algorithm using real-time electricity prices from PJM.", "venue": "ArXiv", "authors": ["Hanchen  Xu", "Xiao  Li", "Xiangyu  Zhang", "Junbo  Zhang"], "year": 2019, "n_citations": 10}
{"id": 5841377, "s2_id": "a8d1e71ae98b7ee0d6d76a5a07bc069f8ec9fa30", "title": "Approximate Ranking from Pairwise Comparisons", "abstract": "A common problem in machine learning is to rank a set of n items based on pairwise comparisons. Here ranking refers to partitioning the items into sets of pre-specified sizes according to their scores, which includes identification of the top-k items as the most prominent special case. The score of a given item is defined as the probability that it beats a randomly chosen other item. Finding an exact ranking typically requires a prohibitively large number of comparisons, but in practice, approximate rankings are often adequate. Accordingly, we study the problem of finding approximate rankings from pairwise comparisons. We analyze an active ranking algorithm that counts the number of comparisons won, and decides whether to stop or which pair of items to compare next, based on confidence intervals computed from the data collected in previous steps. We show that this algorithm succeeds in recovering approximate rankings using a number of comparisons that is close to optimal up to logarithmic factors. We also present numerical results, showing that in practice, approximation can drastically reduce the number of comparisons required to estimate a ranking.", "venue": "AISTATS", "authors": ["Reinhard  Heckel", "Max  Simchowitz", "Kannan  Ramchandran", "Martin J. Wainwright"], "year": 2018, "n_citations": 18}
{"id": 5842474, "s2_id": "3e33869a0bb5750346690e7d494d87eab7d0164c", "title": "A fast learning algorithm for One-Class Slab Support Vector Machines", "abstract": "One Class Slab Support Vector Machines (OCSSVM) have turned out to be better in terms of accuracy in certain classes of classification problems than the traditional SVMs and One Class SVMs or even other One class classifiers. This paper proposes fast training method for One Class Slab SVMs using an updated Sequential Minimal Optimization (SMO) which divides the multi variable optimization problem to smaller sub problems of size two that can then be solved analytically. The results indicate that this training method scales better to large sets of training data than other Quadratic Programming (QP) solvers.", "venue": "Knowl. Based Syst.", "authors": ["Bagesh  Kumar", "Ayush  Sinha", "Sourin  Chakrabarti", "O. P. Vyas"], "year": 2021, "n_citations": 0}
{"id": 5857042, "s2_id": "542ad79bb96fc10c46086778aaafc8f3509c5c18", "title": "Global Convergence and Variance-Reduced Optimization for a Class of Nonconvex-Nonconcave Minimax Problems", "abstract": "Nonconvex minimax problems appear frequently in emerging machine learning applications, such as generative adversarial networks and adversarial learning. Simple algorithms such as the gradient descent ascent (GDA) are the common practice for solving these nonconvex games and receive lots of empirical success. Yet, it is known that these vanilla GDA algorithms with constant step size can potentially diverge even in the convex setting. In this work, we show that for a subclass of nonconvex-nonconcave objectives satisfying a so-called two-sided Polyak-\u0141ojasiewicz inequality, the alternating gradient descent ascent (AGDA) algorithm converges globally at a linear rate and the stochastic AGDA achieves a sublinear rate. We further develop a variance reduced algorithm that attains a provably faster rate than AGDA when the problem has the finite-sum structure.", "venue": "ArXiv", "authors": ["Junchi  Yang", "Negar  Kiyavash", "Niao  He"], "year": 2020, "n_citations": 34}
{"id": 5858340, "s2_id": "96f091439e1754f7353f330ef11200e6345a7a9b", "title": "Learning-Based Procedural Content Generation", "abstract": "Procedural content generation (PCG) has recently become one of the hottest topics in computational intelligence and AI game research. While some substantial progress has been made in this area, there are still several challenges ranging from content evaluation to personalized content generation. In this paper, we present a novel PCG framework based on machine learning, named learning-based procedure content generation (LBPCG), to tackle a number of challenging problems. By exploring and exploiting information gained in game development and public player test, our framework can generate robust content adaptable to end-user or target players on-line with minimal interruption to their gameplay experience. As the data-driven methodology is emphasized in our framework, we develop learning-based enabling techniques to implement the various models required in our framework. For a proof of concept, we have developed a prototype based on the classic open source first-person shooter game, Quake. Simulation results suggest that our framework is promising in generating quality content.", "venue": "IEEE Transactions on Computational Intelligence and AI in Games", "authors": ["Jonathan Ralph Roberts"], "year": 2015, "n_citations": 22}
{"id": 5859718, "s2_id": "713230c137a43ee90965de27f4103a0e222f51a9", "title": "Commuting Network Spillovers and COVID-19 Deaths Across US Counties", "abstract": "This study explored how population mobility flows form commuting networks across US counties and influence the spread of COVID-19. We utilized 3-level mixed effects negative binomial regression models to estimate the impact of network COVID-19 exposure on county confirmed cases and deaths over time. We also conducted weighting-based analyses to estimate the causal effect of network exposure. Results showed that commuting networks matter for COVID-19 deaths and cases, net of spatial proximity, socioeconomic, and demographic factors. Different local racial and ethnic concentrations are also associated with unequal outcomes. These findings suggest that commuting is an important causal mechanism in the spread of COVID-19 and highlight the significance of interconnected of communities. The results suggest that local level mitigation and prevention efforts are more effective when complemented by similar efforts in the network of connected places. Implications for research on inequality in health and flexible work arrangements are discussed.", "venue": "ArXiv", "authors": ["Christopher  Seto", "Aria  Khademi", "Corina  Graif", "Vasant G. Honavar"], "year": 2020, "n_citations": 1}
{"id": 5860553, "s2_id": "5e39d08c3c8587b7ba09c5e3b36b844648f56b11", "title": "Early Anomaly Detection in Time Series: A Hierarchical Approach for Predicting Critical Health Episodes", "abstract": "The early detection of anomalous events in time series data is essential in many domains of application. In this paper we deal with critical health events, which represent a significant cause of mortality in intensive care units of hospitals. The timely prediction of these events is crucial for mitigating their consequences and improving healthcare. One of the most common approaches to tackle early anomaly detection problems is standard classification methods. In this paper we propose a novel method that uses a layered learning architecture to address these tasks. One key contribution of our work is the idea of pre-conditional events, which denote arbitrary but computable relaxed versions of the event of interest. We leverage this idea to break the original problem into two hierarchical layers, which we hypothesize are easier to solve. The results suggest that the proposed approach leads to a better performance relative to state of the art approaches for critical health episode prediction.", "venue": "ArXiv", "authors": ["Vitor  Cerqueira", "Luis  Torgo", "Carlos  Soares"], "year": 2020, "n_citations": 0}
{"id": 5860878, "s2_id": "c318db9a7a517384a740b26f0596c39e4ce064a2", "title": "Reconsidering Dependency Networks from an Information Geometry Perspective", "abstract": "Dependency networks (Heckerman et al., 2000) are potential probabilistic graphical models for systems comprising a large number of variables. Like Bayesian networks, the structure of a dependency network is represented by a directed graph, and each node has a conditional probability table. Learning and inference are realized locally on individual nodes; therefore, computation remains tractable even with a large number of variables. However, the dependency network\u2019s learned distribution is the stationary distribution of a Markov chain called pseudo-Gibbs sampling and has no closed-form expressions. This technical disadvantage has impeded the development of dependency networks. In this paper, we consider a certain manifold for each node. Then, we can interpret pseudo-Gibbs sampling as iterative m-projections onto these manifolds. This interpretation provides a theoretical bound for the location where the stationary distribution of pseudo-Gibbs sampling exists in distribution space. Furthermore, this interpretation involves structure and parameter learning algorithms as optimization problems. In addition, we compare dependency and Bayesian networks experimentally. The results demonstrate that the dependency network and the Bayesian network have roughly the same performance in terms of the accuracy of their learned distributions. The results also show that the dependency network can learn much faster than the Bayesian network.", "venue": "ArXiv", "authors": ["Kazuya  Takabatake", "Shotaro  Akaho"], "year": 2021, "n_citations": 0}
{"id": 5874418, "s2_id": "3cede38ad20b17d7811c79932376cc4e7347c3bb", "title": "Machine-learning-enhanced time-of-flight mass spectrometry analysis", "abstract": "Summary Mass spectrometry is a widespread approach used to work out what the constituents of a material are. Atoms and molecules are removed from the material and collected, and subsequently, a critical step is to infer their correct identities based on patterns formed in their mass-to-charge ratios and relative isotopic abundances. However, this identification step still mainly relies on individual users' expertise, making its standardization challenging, and hindering efficient data processing. Here, we introduce an approach that leverages modern machine learning technique to identify peak patterns in time-of-flight mass spectra within microseconds, outperforming human users without loss of accuracy. Our approach is cross-validated on mass spectra generated from different time-of-flight mass spectrometry (ToF-MS) techniques, offering the ToF-MS community an open-source, intelligent mass spectra analysis.", "venue": "Patterns", "authors": ["Ye  Wei", "Rama Srinivas Varanasi", "Torsten  Schwarz", "Leonie  Gomell", "Huan  Zhao", "David J. Larson", "Binhan  Sun", "Geng  Liu", "Hao  Chen", "Dierk  Raabe", "Baptiste  Gault"], "year": 2021, "n_citations": 3}
{"id": 5874779, "s2_id": "0073230b618d842c797fc840ada95f04c5d16ac1", "title": "A Modulation Front-End for Music Audio Tagging", "abstract": "Convolutional Neural Networks have been extensively explored in the task of automatic music tagging. The problem can be approached by using either engineered time-frequency features or raw audio as input. Modulation filter bank representations that have been actively researched as a basis for timbre perception have the potential to facilitate the extraction of perceptually salient features. We explore end-to-end learned front-ends for audio representation learning, ModNet and SincModNet, that incorporate a temporal modulation processing block. The structure is effectively analogous to a modulation filter bank, where the FIR filter center frequencies are learned in a data-driven manner. The expectation is that a perceptually motivated filter bank can provide a useful representation for identifying music features. Our experimental results provide a fully visualisable and interpretable front-end temporal modulation decomposition of raw audio. We evaluate the performance of our model against the state-of-the-art of music tagging on the MagnaTagATune dataset. We analyse the impact on performance for particular tags when time-frequency bands are subsampled by the modulation filters at a progressively reduced rate. We demonstrate that modulation filtering provides promising results for music tagging and feature representation, without using extensive musical domain knowledge in the design of this frontend.", "venue": "2021 International Joint Conference on Neural Networks (IJCNN)", "authors": ["Cyrus  Vahidi", "Charalampos  Saitis", "Gyorgy  Fazekas"], "year": 2021, "n_citations": 0}
{"id": 5879508, "s2_id": "34be854a7d5fec1eb2139ecdf3f703fe4eacd263", "title": "Soft Actor-Critic With Integer Actions", "abstract": "Reinforcement learning is well-studied under discrete actions. Integer actions setting is popular in the industry yet still challenging due to its high dimensionality. To this end, we study reinforcement learning under integer actions by incorporating the Soft Actor-Critic (SAC) algorithm with an integer reparameterization. Our key observation for integer actions is that their discrete structure can be simplified using their comparability property. Hence, the proposed integer reparameterization does not need one-hot encoding and is of low dimensionality. Experiments show that the proposed SAC under integer actions is as good as the continuous action version on robot control tasks and outperforms Proximal Policy Optimization on power distribution systems control tasks.", "venue": "ArXiv", "authors": ["Ting-Han  Fan", "Yubo  Wang"], "year": 2021, "n_citations": 1}
{"id": 5887125, "s2_id": "ed6297433cfc580837e87592f550cc96296c7d0a", "title": "Inherent Trade-Offs in the Fair Determination of Risk Scores", "abstract": "Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. Moreover, even satisfying all three conditions approximately requires that the data lie in an approximate version of one of the constrained special cases identified by our theorem. These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-offs between them.", "venue": "ITCS", "authors": ["Jon M. Kleinberg", "Sendhil  Mullainathan", "Manish  Raghavan"], "year": 2017, "n_citations": 934}
{"id": 5902933, "s2_id": "969c47fe20e41b3331c8aec3b2b964396d914b2c", "title": "Mining Associated Text and Images with Dual-Wing Harmoniums", "abstract": "We propose a multi-wing harmonium model for mining multimedia data that extends and improves on earlier models based on two-layer random fields, which capture bidirectional dependencies between hidden topic aspects and observed inputs. This model can be viewed as an undirected counterpart of the two-layer directed models such as LDA for similar tasks, but bears significant difference in inference/learning cost tradeoffs, latent topic representations, and topic mixing mechanisms. In particular, our model facilitates efficient inference and robust topic mixing, and potentially provides high flexibilities in modeling the latent topic spaces. A contrastive divergence and a variational algorithm are derived for learning. We specialized our model to a dual-wing harmonium for captioned images, incorporating a multivariate Poisson for word-counts and a multivariate Gaussian for color histogram. We present empirical results on the applications of this model to classification, retrieval and image annotation on news video collections, and we report an extensive comparison with various extant models.", "venue": "UAI", "authors": ["Eric P. Xing", "Rong  Yan", "Alexander G. Hauptmann"], "year": 2005, "n_citations": 147}
{"id": 5907708, "s2_id": "efccb62274930340d11ff627d09673a4c95bc66f", "title": "Effectiveness of Optimization Algorithms in Deep Image Classification", "abstract": "Adam[4] is applied widely to train neural networks. Different kinds of Adam methods with different features pop out. Recently two new adam optimizers, AdaBelief[1] and Padam[5] are introduced among the community. We analyze these two adam optimizers and compare them with other conventional optimizers (Adam, SGD + Momentum) in the scenario of image classification. We evaluate the performance of these optimization algorithms on AlexNet[8] and simplified versions of VGGNet[7], ResNet[9] using the EMNIST[6] dataset. (Benchmark algorithm is available at https://github.com/chuiyunjun/projectCSC413).", "venue": "ArXiv", "authors": ["Zhaoyang  Zhu", "Haozhe  Sun", "Chi  Zhang"], "year": 2021, "n_citations": 0}
{"id": 5926126, "s2_id": "1c8a6345508583043c2d03a2dc7e9999c34b1a77", "title": "Lifelong Learning of Hate Speech Classification on Social Media", "abstract": "Existing work on automated hate speech classification assumes that the dataset is fixed and the classes are pre-defined. However, the amount of data in social media increases every day, and the hot topics changes rapidly, requiring the classifiers to be able to continuously adapt to new data without forgetting the previously learned knowledge. This ability, referred to as lifelong learning, is crucial for the real-word application of hate speech classifiers in social media. In this work, we propose lifelong learning of hate speech classification on social media. To alleviate catastrophic forgetting, we propose to use Variational Representation Learning (VRL) along with a memory module based on LB-SOINN (Load-Balancing Self-Organizing Incremental Neural Network). Experimentally, we show that combining variational representation learning and the LB-SOINN memory module achieves better performance than the commonly-used lifelong learning techniques.", "venue": "NAACL", "authors": ["Jing  Qian", "Hong  Wang", "Mai  ElSherief", "Xifeng  Yan"], "year": 2021, "n_citations": 2}
{"id": 5935650, "s2_id": "c76d82d8ce6f5dab54f178832b26fa90f417a18a", "title": "Few-shot Learning for Named Entity Recognition in Medical Text", "abstract": "Deep neural network models have recently achieved state-of-the-art performance gains in a variety of natural language processing (NLP) tasks (Young, Hazarika, Poria, & Cambria, 2017). However, these gains rely on the availability of large amounts of annotated examples, without which state-of-the-art performance is rarely achievable. This is especially inconvenient for the many NLP fields where annotated examples are scarce, such as medical text. To improve NLP models in this situation, we evaluate five improvements on named entity recognition (NER) tasks when only ten annotated examples are available: (1) layer-wise initialization with pre-trained weights, (2) hyperparameter tuning, (3) combining pre-training data, (4) custom word embeddings, and (5) optimizing out-of-vocabulary (OOV) words. Experimental results show that the F1 score of 69.3% achievable by state-of-the-art models can be improved to 78.87%.", "venue": "ArXiv", "authors": ["Maximilian  Hofer", "Andrey  Kormilitzin", "Paul  Goldberg", "Alejo J. Nevado-Holgado"], "year": 2018, "n_citations": 25}
{"id": 5938011, "s2_id": "b8d9b3b17ce498dc981ce231d78e4162deaf2d59", "title": "How to Evaluate the Quality of Unsupervised Anomaly Detection Algorithms?", "abstract": "When sufficient labeled data are available, classical criteria based on Receiver Operating Characteristic (ROC) or Precision-Recall (PR) curves can be used to compare the performance of un-supervised anomaly detection algorithms. However , in many situations, few or no data are labeled. This calls for alternative criteria one can compute on non-labeled data. In this paper, two criteria that do not require labels are empirically shown to discriminate accurately (w.r.t. ROC or PR based criteria) between algorithms. These criteria are based on existing Excess-Mass (EM) and Mass-Volume (MV) curves, which generally cannot be well estimated in large dimension. A methodology based on feature sub-sampling and aggregating is also described and tested, extending the use of these criteria to high-dimensional datasets and solving major drawbacks inherent to standard EM and MV curves.", "venue": "ArXiv", "authors": ["Nicolas  Goix"], "year": 2016, "n_citations": 37}
{"id": 5942581, "s2_id": "6d15683422ffa9c044c2a90f45ea0ff845de83d9", "title": "Interpolated Adversarial Training: Achieving Robust Neural Networks Without Sacrificing Too Much Accuracy", "abstract": "Adversarial robustness has become a central goal in deep learning, both in theory and in practice. However, successful methods to improve the adversarial robustness (such as adversarial training) greatly hurt generalization performance on the unperturbed data. This could have a major impact on how achieving adversarial robustness affects real world systems (i.e. many may opt to forego robustness if it can improve accuracy on the unperturbed data). We propose Interpolated Adversarial Training, which employs recently proposed interpolation based training methods in the framework of adversarial training. On CIFAR-10, adversarial training increases the standard test error (when there is no adversary) from 4.43% to 12.32%, whereas with our Interpolated adversarial training we retain adversarial robustness while achieving a standard test error of only 6.45%. With our technique, the relative increase in the standard error for the robust model is reduced from 178.1% to just 45.5%.", "venue": "AISec@CCS", "authors": ["Alex  Lamb", "Vikas  Verma", "Juho  Kannala", "Yoshua  Bengio"], "year": 2019, "n_citations": 41}
{"id": 5954871, "s2_id": "49545d45ec3856ba3945671906a9c3f794581809", "title": "Tensor Regression Networks with various Low-Rank Tensor Approximations", "abstract": "Tensor regression networks achieve high compression rate of neural networks while having slight impact on performances. They do so by imposing low tensor rank structure on the weight matrices of fully connected layers. In recent years, tensor regression networks have been investigated from the perspective of their compressive power, however, the regularization effect of enforcing low-rank tensor structure has not been investigated enough. We study tensor regression networks using various low-rank tensor approximations, aiming to compare the compressive and regularization power of different low-rank constraints. We evaluate the compressive and regularization performances of the proposed model with both deep and shallow convolutional neural networks. The outcome of our experiment suggests the superiority of Global Average Pooling Layer over Tensor Regression Layer when applied to deep convolutional neural network with CIFAR-10 dataset. On the contrary, shallow convolutional neural networks with tensor regression layer and dropout achieved lower test error than both Global Average Pooling and fully-connected layer with dropout function when trained with a small number of samples.", "venue": "ArXiv", "authors": ["Xingwei  Cao", "Guillaume  Rabusseau", "Joelle  Pineau"], "year": 2017, "n_citations": 16}
{"id": 5957242, "s2_id": "66304cfaf9ab413814ce8a834b54219c3a9c71f1", "title": "Multi-Sensor Data Pattern Recognition for Multi-Target Localization: A Machine Learning Approach", "abstract": "Data-target pairing is an important step towards multi-target localization for the intelligent operation of unmanned systems. Target localization plays a crucial role in numerous applications, such as search, and rescue missions, traffic management and surveillance. The objective of this paper is to present an innovative target location learning approach, where numerous machine learning approaches, including K-means clustering and supported vector machines (SVM), are used to learn the data pattern across a list of spatially distributed sensors. To enable the accurate data association from different sensors for accurate target localization, appropriate data pre-processing is essential, which is then followed by the application of different machine learning algorithms to appropriately group data from different sensors for the accurate localization of multiple targets. Through simulation examples, the performance of these machine learning algorithms is quantified and compared.", "venue": "ArXiv", "authors": ["Kasthurirengan  Suresh", "Samuel  Silva", "Johnathan  Votion", "Yongcan  Cao"], "year": 2017, "n_citations": 0}
{"id": 5981715, "s2_id": "88d001e980841acde3d2a480227d70bd4b1528b0", "title": "On the Importance of Strong Baselines in Bayesian Deep Learning", "abstract": "Like all sub-fields of machine learning Bayesian Deep Learning is driven by empirical validation of its theoretical proposals. Given the many aspects of an experiment it is always possible that minor or even major experimental flaws can slip by both authors and reviewers. One of the most popular experiments used to evaluate approximate inference techniques is the regression experiment on UCI datasets. However, in this experiment, models which have been trained to convergence have often been compared with baselines trained only for a fixed number of iterations. We find that a well-established baseline, Monte Carlo dropout, when evaluated under the same experimental settings shows significant improvements. In fact, the baseline outperforms or performs competitively with methods that claimed to be superior to the very same baseline method when they were introduced. Hence, by exposing this flaw in experimental procedure, we highlight the importance of using identical experimental setups to evaluate, compare, and benchmark methods in Bayesian Deep Learning.", "venue": "ArXiv", "authors": ["Jishnu  Mukhoti", "Pontus  Stenetorp", "Yarin  Gal"], "year": 2018, "n_citations": 24}
{"id": 6017812, "s2_id": "0bc0d5b8f08c3469fcb945a29e3cd7d70f999130", "title": "Multimodal Sentiment Analysis To Explore the Structure of Emotions", "abstract": "We propose a novel approach to multimodal sentiment analysis using deep neural networks combining visual analysis and natural language processing. Our goal is different than the standard sentiment analysis goal of predicting whether a sentence expresses positive or negative sentiment; instead, we aim to infer the latent emotional state of the user. Thus, we focus on predicting the emotion word tags attached by users to their Tumblr posts, treating these as \"self-reported emotions.\" We demonstrate that our multimodal model combining both text and image features outperforms separate models based solely on either images or text. Our model's results are interpretable, automatically yielding sensible word lists associated with emotions. We explore the structure of emotions implied by our model and compare it to what has been posited in the psychology literature, and validate our model on a set of images that have been used in psychology studies. Finally, our work also provides a useful tool for the growing academic study of images - both photographs and memes - on social networks.", "venue": "KDD", "authors": ["Anthony  Hu", "Seth  Flaxman"], "year": 2018, "n_citations": 48}
{"id": 6023911, "s2_id": "077464660ead528429e39dcf73c1b8cbd467bfb2", "title": "TSAX is Trending", "abstract": "Time series mining is an important branch of data mining, as time series data is ubiquitous and has many applications in several domains. The main task in time series mining is classification. Time series representation methods play an important role in time series classification and other time series mining tasks. One of the most popular representation methods of time series data is the Symbolic Aggregate approXimation (SAX). The secret behind its popularity is its simplicity and efficiency. SAX has however one major drawback, which is its inability to represent trend information. Several methods have been proposed to enable SAX to capture trend information, but this comes at the expense of complex processing, preprocessing, or post-processing procedures. In this paper we present a new modification of SAX that we call Trending SAX (TSAX), which only adds minimal complexity to SAX, but substantially improves its performance in time series classification. This is validated experimentally on 50 datasets. The results show the superior performance of our method, as it gives a smaller classification error on 39 datasets compared with SAX.", "venue": "ICCS", "authors": ["Muhammad Marwan Muhammad Fuad"], "year": 2021, "n_citations": 0}
{"id": 6031271, "s2_id": "8031dc315102e3ef23856817e10989c6c395047a", "title": "Automated identification of thoracic pathology from chest radiographs with enhanced training pipeline", "abstract": "Chest x-rays are the most common radiology studies for diagnosing lung and heart disease. Hence, a system for automated pre-reporting of pathologic findings on chest x-rays would greatly enhance radiologists\u2019 productivity. To this end, we investigate a deep-learning framework with novel training schemes for classification of different thoracic pathology labels from chest x-rays. We use the currently largest publicly available annotated dataset ChestX-ray14 of 112,120 chest radiographs of 30,805 patients. Each image was annotated with either a 'NoFinding' class, or one or more of 14 thoracic pathology labels. Subjects can have multiple pathologies, resulting in a multi-class, multi-label problem. We encoded labels as binary vectors using k-hot encoding. We study the ResNet34 architecture, pre-trained on ImageNet, where two key modifications were incorporated into the training framework: (1) Stochastic gradient descent with momentum and with restarts using cosine annealing, (2) Variable image sizes for fine-tuning to prevent overfitting. Additionally, we use a heuristic algorithm to select a good learning rate. Learning with restarts was used to avoid local minima. Area Under receiver operating characteristics Curve (AUC) was used to quantitatively evaluate diagnostic quality. Our results are comparable to, or outperform the best results of current state-of-the-art methods with AUCs as follows: Atelectasis:0.81, Cardiomegaly:0.91, Consolidation:0.81, Edema:0.92, Effusion:0.89, Emphysema: 0.92, Fibrosis:0.81, Hernia:0.84, Infiltration:0.73, Mass:0.85, Nodule:0.76, Pleural Thickening:0.81, Pneumonia:0.77, Pneumothorax:0.89 and NoFinding:0.79. Our results suggest that, in addition to using sophisticated network architectures, a good learning rate, scheduler and a robust optimizer can boost performance.", "venue": "Medical Imaging", "authors": ["Adora M. DSouza", "Anas Z. Abidin", "Axel  Wism\u00fcller"], "year": 2019, "n_citations": 2}
{"id": 6044724, "s2_id": "75a284d52cd47b00a31917946ee762009eb065d2", "title": "Streaming Coresets for Symmetric Tensor Factorization", "abstract": "Factorizing tensors has recently become an important optimization module in a number of machine learning pipelines, especially in latent variable models. We show how to do this efficiently in the streaming setting. Given a set of $n$ vectors, each in $\\mathbb{R}^d$, we present algorithms to select a sublinear number of these vectors as coreset, while guaranteeing that the CP decomposition of the $p$-moment tensor of the coreset approximates the corresponding decomposition of the $p$-moment tensor computed from the full data. We introduce two novel algorithmic techniques: online filtering and kernelization. Using these two, we present six algorithms that achieve different tradeoffs of coreset size, update time and working space, beating or matching various state of the art algorithms. In the case of matrices ($2$-ordered tensor), our online row sampling algorithm guarantees $(1 \\pm \\epsilon)$ relative error spectral approximation. We show applications of our algorithms in learning single topic modeling.", "venue": "ICML", "authors": ["Rachit  Chhaya", "Jayesh  Choudhari", "Anirban  Dasgupta", "Supratim  Shit"], "year": 2020, "n_citations": 5}
{"id": 6048335, "s2_id": "76c6d1f4c82ac1a796fa47f0592deef1ecc4f33b", "title": "Towards a General Theory of Infinite-Width Limits of Neural Classifiers", "abstract": "Obtaining theoretical guarantees for neural networks training appears to be a hard problem in a general case. Recent research has been focused on studying this problem in the limit of infinite width and two different theories have been developed: a mean-field (MF) and a constant kernel (NTK) limit theories. We propose a general framework that provides a link between these seemingly distinct theories. Our framework out of the box gives rise to a discrete-time MF limit which was not previously explored in the literature. We prove a convergence theorem for it, and show that it provides a more reasonable approximation for finite-width nets compared to the NTK limit if learning rates are not very small. Also, our framework suggests a limit model that coincides neither with the MF limit nor with the NTK one. We show that for networks with more than two hidden layers RMSProp training has a non-trivial MF limit but GD training does not have one. Overall, our framework demonstrates that both MF and NTK limits have considerable limitations in approximating finite-sized neural nets, indicating the need for designing more accurate infinite-width approximations for them.", "venue": "ICML", "authors": ["Eugene A. Golikov"], "year": 2020, "n_citations": 3}
{"id": 6052087, "s2_id": "37283490f38c39301b32fa3f1cf80309bb479a6d", "title": "A Map of Bandits for E-commerce", "abstract": "The rich body of Bandit literature not only offers a diverse toolbox of algorithms, but also makes it hard for a practitioner to find the right solution to solve the problem at hand. Typical textbooks on Bandits focus on designing and analyzing algorithms, and surveys on applications often present a list of individual applications. While these are valuable resources, there exists a gap in mapping applications to appropriate Bandit algorithms. In this paper, we aim to reduce this gap with a structured map of Bandits to help practitioners navigate to find relevant and practical Bandit algorithms. Instead of providing a comprehensive overview, we focus on a small number of key decision points related to reward, action, and features, which often affect how Bandit algorithms are chosen in practice.", "venue": "ArXiv", "authors": ["Yi  Liu", "Lihong  Li"], "year": 2021, "n_citations": 0}
{"id": 6054946, "s2_id": "db85d49e2bec862e943f0e24f2a235051bcc352e", "title": "Learning Contact Dynamics using Physically Structured Neural Networks", "abstract": "Learning physically structured representations of dynamical systems that include contact between different objects is an important problem for learning-based approaches in robotics. Black-box neural networks can learn to approximately represent discontinuous dynamics, but they typically require large quantities of data and often suffer from pathological behaviour when forecasting for longer time horizons. In this work, we use connections between deep neural networks and differential equations to design a family of deep network architectures for representing contact dynamics between objects. We show that these networks can learn discontinuous contact events in a data-efficient manner from noisy observations in settings that are traditionally difficult for black-box approaches and recent physics inspired neural networks. Our results indicate that an idealised form of touch feedback\u2014which is heavily relied upon by biological systems\u2014is a key component of making this learning problem tractable. Together with the inductive biases introduced through the network architectures, our techniques enable accurate learning of contact dynamics from observations. Proceedings of the 24 International Conference on Artificial Intelligence and Statistics (AISTATS) 2021, San Diego, California, USA. PMLR: Volume 130. Copyright 2021 by the author(s).", "venue": "AISTATS", "authors": ["Andreas  Hochlehnert", "Alexander  Terenin", "Steind\u00f3r  S\u00e6mundsson", "Marc Peter Deisenroth"], "year": 2021, "n_citations": 5}
{"id": 6060741, "s2_id": "652fad49a9582a5902ce23b9644ba0319791727e", "title": "An Effectiveness Metric for Ordinal Classification: Formal Properties and Experimental Results", "abstract": "In Ordinal Classification tasks, items have to be assigned to classes that have a relative ordering, such as \u201cpositive\u201d, \u201cneutral\u201d, \u201cnegative\u201d in sentiment analysis. Remarkably, the most popular evaluation metrics for ordinal classification tasks either ignore relevant information (for instance, precision/recall on each of the classes ignores their relative ordering) or assume additional information (for instance, Mean Average Error assumes absolute distances between classes). In this paper we propose a new metric for Ordinal Classification, Closeness Evaluation Measure, that is rooted on Measurement Theory and Information Theory. Our theoretical analysis and experimental results over both synthetic data and data from NLP shared tasks indicate that the proposed metric captures quality aspects from different traditional tasks simultaneously. In addition, it generalizes some popular classification (nominal scale) and error minimization (interval scale) metrics, depending on the measurement scale in which it is instantiated.", "venue": "ACL", "authors": ["Enrique  Amig'o", "Julio  Gonzalo", "Stefano  Mizzaro", "Jorge  Carrillo-de-Albornoz"], "year": 2020, "n_citations": 8}
{"id": 6072959, "s2_id": "d81dd2dc0ee02d996763f3ea1703eaff681485d7", "title": "Investigating Generalisation in Continuous Deep Reinforcement Learning", "abstract": "Deep Reinforcement Learning has shown great success in a variety of control tasks. However, it is unclear how close we are to the vision of putting Deep RL into practice to solve real world problems. In particular, common practice in the field is to train policies on largely deterministic simulators and to evaluate algorithms through training performance alone, without a train/test distinction to ensure models generalise and are not overfitted. Moreover, it is not standard practice to check for generalisation under domain shift, although robustness to such system change between training and testing would be necessary for real-world Deep RL control, for example, in robotics. In this paper we study these issues by first characterising the sources of uncertainty that provide generalisation challenges in Deep RL. We then provide a new benchmark and thorough empirical evaluation of generalisation challenges for state of the art Deep RL methods. In particular, we show that, if generalisation is the goal, then common practice of evaluating algorithms based on their training performance leads to the wrong conclusions about algorithm choice. Finally, we evaluate several techniques for improving generalisation and draw conclusions about the most robust techniques to date.", "venue": "ArXiv", "authors": ["Chenyang  Zhao", "Olivier  Sigaud", "Freek  Stulp", "Timothy M. Hospedales"], "year": 2019, "n_citations": 30}
{"id": 6073481, "s2_id": "414dd9249f1486ab1ceea3229a0bd26d261a83ae", "title": "Feature Construction for Relational Sequence Learning", "abstract": "We tackle the problem of multi-class relational sequence learning using relevant patterns discovered from a set of labelled sequences. To deal with this problem, firstly each relational sequence is mapped into a feature vector using the result of a feature construction method. Since, the efficacy of sequence learning algorithms strongly depends on the features used to represent the sequences, the second step is to find an optimal subset of the constructed features leading to high classification accuracy. This feature selection task has been solved adopting a wrapper approach that uses a stochastic local search algorithm embedding a naive Bayes classifier. The performance of the proposed method applied to a real-world dataset shows an improvement when compared to other established methods, such as hidden Markov models, Fisher kernels and conditional random fields for relational sequences.", "venue": "ArXiv", "authors": ["Nicola Di Mauro", "Teresa Maria Altomare Basile", "Stefano  Ferilli", "Floriana  Esposito"], "year": 2010, "n_citations": 4}
{"id": 6073597, "s2_id": "cb5988c89140dbdb8e9b38ea98f8dbebb629bf61", "title": "Reinforcement Learning for Load-balanced Parallel Particle Tracing", "abstract": "We explore an online learning reinforcement learning (RL) paradigm for optimizing parallel particle tracing performance in distributed-memory systems. Our method combines three novel components: (1) a workload donation model, (2) a high-order workload estimation model, and (3) a communication cost model, to optimize the performance of data-parallel particle tracing dynamically. First, we design an RL-based workload donation model. Our workload donation model monitors the workload of processes and creates RL agents to donate particles and data blocks from high-workload processes to low-workload processes to minimize the execution time. The agents learn the donation strategy on-the-fly based on reward and cost functions. The reward and cost functions are designed to consider the processes\u2019 workload change and the data transfer cost for every donation action. Second, we propose an online workload estimation model, in order to help our RL model estimate the workload distribution of processes in future computations. Third, we design the communication cost model that considers both block and particle data exchange costs, helping the agents make effective decisions with minimized communication cost. We demonstrate that our algorithm adapts to different flow behaviors in large-scale fluid dynamics, ocean, and weather simulation data. Our algorithm improves parallel particle tracing performance in terms of parallel efficiency, load balance, and costs of I/O and communication for evaluations up to 16,384 processors.", "venue": "ArXiv", "authors": ["Jiayi  Xu", "Hanqi  Guo", "Han-Wei  Shen", "Mukund  Raj", "Skylar W. Wurster", "Tom  Peterka"], "year": 2021, "n_citations": 0}
{"id": 6096533, "s2_id": "4199b550839dfd189a44662c4094394245d9af78", "title": "Cloudy with high chance of DBMS: a 10-year prediction for Enterprise-Grade ML", "abstract": "Machine learning (ML) has proven itself in high-value web applications such as search ranking and is emerging as a powerful tool in a much broader range of enterprise scenarios including voice recognition and conversational understanding for customer support, autotuning for videoconferencing, intelligent feedback loops in large-scale sysops, manufacturing and autonomous vehicle management, complex financial predictions, just to name a few. Meanwhile, as the value of data is increasingly recognized and monetized, concerns about securing valuable data and risks to individual privacy have been growing. Consequently, rigorous data management has emerged as a key requirement in enterprise settings. How will these trends (ML growing popularity, and stricter data governance) intersect? What are the unmet requirements for applying ML in enterprise settings? What are the technical challenges for the DB community to solve? In this paper, we present our vision of how ML and database systems are likely to come together, and early steps we take towards making this vision a reality.", "venue": "CIDR", "authors": ["Ashvin  Agrawal", "Rony  Chatterjee", "Carlo  Curino", "Avrilia  Floratou", "Neha  Godwal", "Matteo  Interlandi", "Alekh  Jindal", "Konstantinos  Karanasos", "Subru  Krishnan", "Brian  Kroth", "Jyoti  Leeka", "Kwanghyun  Park", "Hiren  Patel", "Olga  Poppe", "Fotis  Psallidas", "Raghu  Ramakrishnan", "Abhishek  Roy", "Karla  Saur", "Rathijit  Sen", "Markus  Weimer", "Travis  Wright", "Yiwen  Zhu"], "year": 2020, "n_citations": 22}
{"id": 6102985, "s2_id": "c1f7a9e33aabd141e126add85f63d39070459b4f", "title": "NumGPT: Improving Numeracy Ability of Generative Pre-trained Models", "abstract": "Existing generative pre-trained language models (e.g., GPT) focus on modeling the language structure and semantics of general texts. However, those models do not consider the numerical properties of numbers and cannot perform robustly on numerical reasoning tasks (e.g., math word problems and measurement estimation). In this paper, we propose NumGPT, a generative pre-trained model that explicitly models the numerical properties of numbers in texts. Specifically, it leverages a prototype-based numeral embedding to encode the mantissa of the number and an individual embedding to encode the exponent of the number. A numeral-aware loss function is designed to integrate numerals into the pre-training objective of NumGPT. We conduct extensive experiments on four different datasets to evaluate the numeracy ability of NumGPT. The experiment results show that NumGPT outperforms baseline models (e.g., GPT and GPT with DICE) on a range of numerical reasoning tasks such as measurement estimation, number comparison, math word problems, and magnitude classification. Ablation studies are also conducted to evaluate the impact of pre-training and model hyperparameters on the", "venue": "ArXiv", "authors": ["Zhihua  Jin", "Xin  Jiang", "Xingbo  Wang", "Qun  Liu", "Yong  Wang", "Xiaozhe  Ren", "Huamin  Qu"], "year": 2021, "n_citations": 1}
{"id": 6117137, "s2_id": "63d56435544a48ce508da40e31581920e8608b24", "title": "Structured and Efficient Variational Deep Learning with Matrix Gaussian Posteriors", "abstract": "We introduce a variational Bayesian neural network where the parameters are governed via a probability distribution on random matrices. Specifically, we employ a matrix variate Gaussian (Gupta & Nagar, 1999) parameter posterior distribution where we explicitly model the covariance among the input and output dimensions of each layer. Furthermore, with approximate covariance matrices we can achieve a more efficient way to represent those correlations that is also cheaper than fully factorized parameter posteriors. We further show that with the \"local reprarametrization trick\" (Kingma et al., 2015) on this posterior distribution we arrive at a Gaussian Process (Rasmussen, 2006) interpretation of the hidden units in each layer and we, similarly with (Gal & Ghahramani, 2015), provide connections with deep Gaussian processes. We continue in taking advantage of this duality and incorporate \"pseudo-data\" (Snelson & Ghahramani, 2005) in our model, which in turn allows for more efficient posterior sampling while maintaining the properties of the original model. The validity of the proposed approach is verified through extensive experiments.", "venue": "ICML", "authors": ["Christos  Louizos", "Max  Welling"], "year": 2016, "n_citations": 176}
{"id": 6124522, "s2_id": "ee7137d8b728871c9cab94f60f3e5bbbe203783a", "title": "A dynamic\u2010adversarial mining approach to the security of machine learning", "abstract": "Operating in a dynamic real\u2010world environment requires a forward thinking and adversarial aware design for classifiers beyond fitting the model to the training data. In such scenarios, it is necessary to make classifiers such that they are: (a) harder to evade, (b) easier to detect changes in the data distribution over time, and (c) be able to retrain and recover from model degradation. While most works in the security of machine learning have concentrated on the evasion resistance problem (a), there is little work in the areas of reacting to attacks (b) and (c). Additionally, while streaming data research concentrates on the ability to react to changes to the data distribution, they often take an adversarial agnostic view of the security problem. This makes them vulnerable to adversarial activity, which is aimed toward evading the concept drift detection mechanism itself. In this paper, we analyze the security of machine learning from a dynamic and adversarial aware perspective. The existing techniques of restrictive one\u2010class classifier models, complex learning\u2010based ensemble models, and randomization\u2010based ensemble models are shown to be myopic as they approach security as a static task. These methodologies are ill suited for a dynamic environment, as they leak excessive information to an adversary who can subsequently launch attacks which are indistinguishable from the benign data. Based on empirical vulnerability analysis against a sophisticated adversary, a novel feature importance hiding approach for classifier design is proposed. The proposed design ensures that future attacks on classifiers can be detected and recovered from. The proposed work provides motivation, by serving as a blueprint, for future work in the area of dynamic\u2010adversarial mining, which combines lessons learned from streaming data mining, adversarial learning, and cybersecurity.", "venue": "Wiley Interdiscip. Rev. Data Min. Knowl. Discov.", "authors": ["Tegjyot Singh Sethi", "Mehmed M. Kantardzic", "Lingyu  Lyu", "Jiashun  Chen"], "year": 2018, "n_citations": 6}
{"id": 6124716, "s2_id": "be57787ecd94db84fcfb341068b5c1b26fe4334c", "title": "Triad State Space Construction for Chaotic Signal Classification with Deep Learning", "abstract": "Inspired by the well-known permutation entropy (PE), an effective image encoding scheme for chaotic time series, Triad State Space Construction (TSSC), is proposed. The TSSC image can recognize higher-order temporal patterns and identify new forbidden regions in time series motifs beyond the Bandt-Pompe probabilities. The Convolutional Neural Network (ConvNet) is widely used in image classification. The ConvNet classifier based on TSSC images (TSSC-ConvNet) are highly accurate and very robust in the chaotic signal classification.", "venue": "ArXiv", "authors": ["Yadong  Zhang", "Xin  Chen"], "year": 2020, "n_citations": 0}
{"id": 6130230, "s2_id": "3a493f68aee741036e620652485bea4a289890dd", "title": "Linear Bandit algorithms using the Bootstrap", "abstract": "This study presents two new algorithms for solving linear stochastic bandit problems. The proposed methods use an approach from non-parametric statistics called bootstrapping to create confidence bounds. This is achieved without making any assumptions about the distribution of noise in the underlying system. We present the X-Random and X-Fixed bootstrap bandits which correspond to the two well-known approaches for conducting bootstraps on models, in the literature. The proposed methods are compared to other popular solutions for linear stochastic bandit problems, namely, OFUL, LinUCB and Thompson Sampling. The comparisons are carried out using a simulation study on a hierarchical probability meta-model, built from published data of experiments, which are run on real systems. The model representing the response surfaces is conceptualized as a Bayesian Network which is presented with varying degrees of noise for the simulations. One of the proposed methods, X-Random bootstrap, performs better than the baselines in-terms of cumulative regret across various degrees of noise and different number of trials. In certain settings the cumulative regret of this method is less than half of the best baseline. The X-Fixed bootstrap performs comparably in most situations and particularly well when the number of trials is low. The study concludes that these algorithms could be a preferred alternative for solving linear bandit problems, especially when the distribution of the noise in the system is unknown.", "venue": "ArXiv", "authors": ["Nandan  Sudarsanam", "Balaraman  Ravindran"], "year": 2016, "n_citations": 1}
{"id": 6134142, "s2_id": "2fa8b14875ac1f101294b977ea2b95b410279883", "title": "Solutions to problems with deep learning", "abstract": "Despite the several successes of deep learning systems, there are concerns about their limitations, discussed most recently by Gary Marcus. This paper discusses Marcus's concerns and some others, together with solutions to several of these problems provided by the \"P theory of intelligence\" and its realisation in the \"SP computer model\". The main advantages of the SP system are: relatively small requirements for data and the ability to learn from a single experience; the ability to model both hierarchical and non-hierarchical structures; strengths in several kinds of reasoning, including `commonsense' reasoning; transparency in the representation of knowledge, and the provision of an audit trail for all processing; the likelihood that the SP system could not be fooled into bizarre or eccentric recognition of stimuli, as deep learning systems can be; the SP system provides a robust solution to the problem of `catastrophic forgetting' in deep learning systems; the SP system provides a theoretically-coherent solution to the problems of correcting over- and under-generalisations in learning, and learning correct structures despite errors in data; unlike most research on deep learning, the SP programme of research draws extensively on research on human learning, perception, and cognition; and the SP programme of research has an overarching theory, supported by evidence, something that is largely missing from research on deep learning. In general, the SP system provides a much firmer foundation than deep learning for the development of artificial general intelligence.", "venue": "ArXiv", "authors": ["J. Gerard Wolff"], "year": 2018, "n_citations": 8}
{"id": 6146004, "s2_id": "5bbb6f9a8204eb13070b6f033e61c84ef8ee68dd", "title": "Deep Reinforcement Learning from Human Preferences", "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on less than one percent of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any that have been previously learned from human feedback.", "venue": "NIPS", "authors": ["Paul F. Christiano", "Jan  Leike", "Tom B. Brown", "Miljan  Martic", "Shane  Legg", "Dario  Amodei"], "year": 2017, "n_citations": 459}
{"id": 6154030, "s2_id": "43aa597bcadecdbb5739652fa96efaee88887e40", "title": "Fast Variational Inference in the Conjugate Exponential Family", "abstract": "We present a general method for deriving collapsed variational inference algorithms for probabilistic models in the conjugate exponential family. Our method unifies many existing approaches to collapsed variational inference. Our collapsed variational inference leads to a new lower bound on the marginal likelihood. We exploit the information geometry of the bound to derive much faster optimization methods based on conjugate gradients for these models. Our approach is very general and is easily applied to any model where the mean field update equations have been derived. Empirically we show significant speed-ups for probabilistic inference using our bound.", "venue": "NIPS", "authors": ["James  Hensman", "Magnus  Rattray", "Neil D. Lawrence"], "year": 2012, "n_citations": 111}
{"id": 6157826, "s2_id": "6dca2ee4cda6c75ba18e5efbcf8b1930c7c04ed8", "title": "Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation", "abstract": "Spiking Neural Networks (SNNs) operate with asynchronous discrete events (or spikes) which can potentially lead to higher energy-efficiency in neuromorphic hardware implementations. Many works have shown that an SNN for inference can be formed by copying the weights from a trained Artificial Neural Network (ANN) and setting the firing threshold for each layer as the maximum input received in that layer. These type of converted SNNs require a large number of time-steps to achieve competitive accuracy which diminishes the energy savings. The number of time-steps can be reduced by training SNNs with spike-based backpropagation from scratch, but that is computationally expensive and slow. To address these challenges, we present a computationally-efficient training technique for deep SNNs. We propose a hybrid training methodology: 1) take a converted SNN and use its weights and thresholds as an initialization step for spike-based backpropagation, and 2) perform incremental spike-timing dependent backpropagation (STDB) on this carefully initialized network to obtain an SNN that converges within few epochs and requires fewer time-steps for input processing. STDB is performed with a novel surrogate gradient function defined using neuron's spike time. The weight update is proportional to the difference in spike timing between the current time-step and the most recent time-step the neuron generated an output spike. The SNNs trained with our hybrid conversion-and-STDB training perform at 10X-25X fewer number of time-steps and achieve similar accuracy compared to purely converted SNNs. The proposed training methodology converges in less than 20 epochs of spike-based backpropagation for most standard image classification datasets, thereby greatly reducing the training complexity compared to training SNNs from scratch. We perform experiments on CIFAR-10, CIFAR-100 and ImageNet datasets for both VGG and ResNet architectures. We achieve top-1 accuracy of 65.19% for ImageNet dataset on SNN with 250 time-steps, which is 10X faster compared to converted SNNs with similar accuracy.", "venue": "ICLR", "authors": ["Nitin  Rathi", "Gopalakrishnan  Srinivasan", "Priyadarshini  Panda", "Kaushik  Roy"], "year": 2020, "n_citations": 52}
{"id": 6158787, "s2_id": "5b3e68658c99ed9c461a909b16b862221946d6ad", "title": "Reinforcement Learning for Non-Stationary Markov Decision Processes: The Blessing of (More) Optimism", "abstract": "We consider un-discounted reinforcement learning (RL) in Markov decision processes (MDPs) under drifting non-stationarity, i.e., both the reward and state transition distributions are allowed to evolve over time, as long as their respective total variations, quantified by suitable metrics, do not exceed certain variation budgets. We first develop the Sliding Window Upper-Confidence bound for Reinforcement Learning with Confidence Widening (SWUCRL2-CW) algorithm, and establish its dynamic regret bound when the variation budgets are known. In addition, we propose the Bandit-over-Reinforcement Learning (BORL) algorithm to adaptively tune the SWUCRL2-CW algorithm to achieve the same dynamic regret bound, but in a parameter-free manner, i.e., without knowing the variation budgets. Notably, learning non-stationary MDPs via the conventional optimistic exploration technique presents a unique challenge absent in existing (non-stationary) bandit learning settings. We overcome the challenge by a novel confidence widening technique that incorporates additional optimism.", "venue": "ICML", "authors": ["Wang Chi Cheung", "David  Simchi-Levi", "Ruihao  Zhu"], "year": 2020, "n_citations": 19}
{"id": 6161471, "s2_id": "b6c2b0d22920509b0d8dee1f1b55dfad372b9aa5", "title": "Nonstochastic Bandits with Composite Anonymous Feedback", "abstract": "We investigate a nonstochastic bandit setting in which the loss of an action is not immediately charged to the player, but rather spread over at most d consecutive steps in an adversarial way. This implies that the instantaneous loss observed by the player at the end of each round is a sum of as many as d loss components of previously played actions. Hence, unlike the standard bandit setting with delayed feedback, here the player cannot observe the individual delayed losses, but only their sum. Our main contribution is a general reduction transforming a standard bandit algorithm into one that can operate in this harder setting. We also show how the regret of the transformed algorithm can be bounded in terms of the regret of the original algorithm. Our reduction cannot be improved in general: we prove a lower bound on the regret of any bandit algorithm in this setting that matches (up to log factors) the upper bound obtained via our reduction. Finally, we show how our reduction can be extended to more complex bandit settings, such as combinatorial linear bandits and online bandit convex optimization.", "venue": "COLT", "authors": ["Nicol\u00f2  Cesa-Bianchi", "Claudio  Gentile", "Yishay  Mansour"], "year": 2018, "n_citations": 24}
{"id": 6161744, "s2_id": "ca45dab4cbd01d7cce52c87c855c71271033bfa0", "title": "Dual Neural Network Architecture for Determining Epistemic and Aleatoric Uncertainties", "abstract": "Deep learning techniques have been shown to be extremely effective for various classification and regression problems, but quantifying the uncertainty of their predictions and separating them into the epistemic and aleatoric fractions is still considered challenging. In oil and gas exploration projects, tools consisting of seismic, sonic, magnetic resonance, resistivity, dielectric and/or nuclear sensors are sent downhole through boreholes to probe the earth's rock and fluid properties. The measurements from these tools are used to build reservoir models that are subsequently used for estimation and optimization of hydrocarbon production. Machine learning algorithms are often used to estimate the rock and fluid properties from the measured downhole data. Quantifying uncertainties of these properties is crucial for rock and fluid evaluation and subsequent reservoir optimization and production decisions. These machine learning algorithms are often trained on a \"ground-truth\" or core database. During the inference phase which involves application of these algorithms to field data, it is critical that the machine learning algorithm flag data as out of distribution from new geologies that the model was not trained upon. It is also highly important to be sensitive to heteroscedastic aleatoric noise in the feature space arising from the combination of tool and geological conditions. Understanding the source of the uncertainty and reducing them is key to designing intelligent tools and applications such as automated log interpretation answer products for exploration and field development. In this paper we describe a methodology consisting of a system of dual networks comprising of the combination of a Bayesian Neural Network (BNN) and an Artificial Neural Network (ANN) addressing this challenge for geophysical applications.", "venue": "ArXiv", "authors": ["Augustin  Prado", "Ravinath  Kausik", "Lalitha  Venkataramanan"], "year": 2019, "n_citations": 3}
{"id": 6162008, "s2_id": "23f425d6cb57938ceaa98fce8133a6924c2f953b", "title": "Three scenarios for continual learning", "abstract": "Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning difficult for machine learning. In recent years, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more structured comparisons, we describe three continual learning scenarios based on whether at test time task identity is provided and--in case it is not--whether it must be inferred. Any sequence of well-defined tasks can be performed according to each scenario. Using the split and permuted MNIST task protocols, for each scenario we carry out an extensive comparison of recently proposed continual learning methods. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of how efficient different methods are. In particular, when task identity must be inferred (i.e., class incremental learning), we find that regularization-based approaches (e.g., elastic weight consolidation) fail and that replaying representations of previous experiences seems required for solving this scenario.", "venue": "ArXiv", "authors": ["Gido M. van de Ven", "Andreas S. Tolias"], "year": 2019, "n_citations": 187}
{"id": 6165058, "s2_id": "7ea33e54c91759fd46cd31f8fe70d727fd985d6e", "title": "Reinforcement Learning Under Algorithmic Triage", "abstract": "Methods to learn under algorithmic triage have predominantly focused on supervised learning settings where each decision, or prediction, is independent of each other. Under algorithmic triage, a supervised learning model predicts a fraction of the instances and humans predict the remaining ones. In this work, we take a first step towards developing reinforcement learning models that are optimized to operate under algorithmic triage. To this end, we look at the problem through the framework of options and develop a two-stage actor-critic method to learn reinforcement learning models under triage. The first stage performs offline, off-policy training using human data gathered in an environment where the human has operated on their own. The second stage performs on-policy training to account for the impact that switching may have on the human policy, which may be difficult to anticipate from the above human data. Extensive simulation experiments in a synthetic car driving task show that the machine models and the triage policies trained using our two-stage method effectively complement human policies and outperform those provided by several competitive baselines.", "venue": "ArXiv", "authors": ["Eleni  Straitouri", "Adish  Singla", "Vahid Balazadeh Meresht", "Manuel  Gomez-Rodriguez"], "year": 2021, "n_citations": 0}
{"id": 6167616, "s2_id": "c60cc4f91b596fbc37590eb304ba20a9b0932bd4", "title": "Block-wise Partitioning for Extreme Multi-label Classification", "abstract": "Extreme multi-label classification aims to learn a classifier that annotates an instance with a relevant subset of labels from an extremely large label set. Many existing solutions embed the label matrix to a low-dimensional linear subspace, or examine the relevance of a test instance to every label via a linear scan. In practice, however, those approaches can be computationally exorbitant. To alleviate this drawback, we propose a Block-wise Partitioning (BP) pretreatment that divides all instances into disjoint clusters, to each of which the most frequently tagged label subset is attached. One multi-label classifier is trained on one pair of instance and label clusters, and the label set of a test instance is predicted by first delivering it to the most appropriate instance cluster. Experiments on benchmark multi-label data sets reveal that BP pretreatment significantly reduces prediction time, and retains almost the same level of prediction accuracy.", "venue": "ArXiv", "authors": ["Yuefeng  Liang", "Cho-Jui  Hsieh", "Thomas C. M. Lee"], "year": 2018, "n_citations": 1}
{"id": 6172138, "s2_id": "70acb0ee229593fffe73885f3004f24df38f74ec", "title": "A Survey of Deep Learning for Scientific Discovery", "abstract": "Over the past few years, we have seen fundamental breakthroughs in core problems in machine learning, largely driven by advances in deep neural networks. At the same time, the amount of data collected in a wide array of scientific domains is dramatically increasing in both size and complexity. Taken together, this suggests many exciting opportunities for deep learning applications in scientific settings. But a significant challenge to this is simply knowing where to start. The sheer breadth and diversity of different deep learning techniques makes it difficult to determine what scientific problems might be most amenable to these methods, or which specific combination of methods might offer the most promising first approach. In this survey, we focus on addressing this central issue, providing an overview of many widely used deep learning models, spanning visual, sequential and graph structured data, associated tasks and different training methods, along with techniques to use deep learning with less data and better interpret these complex models --- two central considerations for many scientific use cases. We also include overviews of the full design process, implementation tips, and links to a plethora of tutorials, research summaries and open-sourced deep learning pipelines and pretrained models, developed by the community. We hope that this survey will help accelerate the use of deep learning across different scientific domains.", "venue": "ArXiv", "authors": ["Maithra  Raghu", "Eric  Schmidt"], "year": 2020, "n_citations": 63}
{"id": 6175125, "s2_id": "13cf1e00f0c97fc9170eb074a3afda10ea40d033", "title": "A Joint Graph and Image Convolution Network for Automatic Brain Tumor Segmentation", "abstract": "We present a joint graph convolution \u2013 image convolution neural network as our submission to the Brain Tumor Segmentation (BraTS) 2021 challenge. We model each brain as a graph composed of distinct image regions, which is initially segmented by a graph neural network (GNN). Subsequently, the tumorous volume identified by the GNN is further refined by a simple (voxel) convolutional neural network (CNN), which produces the final segmentation. This approach captures both global brain feature interactions via the graphical representation and local image details through the use of convolutional filters. We find that the GNN component by itself can effectively identify and segment the brain tumors. The addition of the CNN further improves the median performance of the model by 2 percent across all metrics evaluated. On the validation set, our joint GNN-CNN model achieves mean Dice scores of 0.89, 0.81, 0.73 and mean Hausdorff distances (95 percentile) of 6.8, 12.6, 28.2 mm on the whole tumor, core tumor, and enhancing tumor, respectively.", "venue": "ArXiv", "authors": ["Camillo  Saueressig", "Adam  Berkley", "Reshma  Munbodh", "Ritambhara  Singh"], "year": 2021, "n_citations": 0}
{"id": 6185234, "s2_id": "e0f49d02c8e142388c8d87600bc1c187ff1f06aa", "title": "Learning to Address Health Inequality in the United States with a Bayesian Decision Network", "abstract": "Life-expectancy is a complex outcome driven by genetic, socio-demographic, environmental and geographic factors. Increasing socio-economic and health disparities in the United States are propagating the longevity-gap, making it a cause for concern. Earlier studies have probed individual factors but an integrated picture to reveal quantifiable actions has been missing. There is a growing concern about a further widening of healthcare inequality caused by Artificial Intelligence (AI) due to differential access to AI-driven services. Hence, it is imperative to explore and exploit the potential of AI for illuminating biases and enabling transparent policy decisions for positive social and health impact. In this work, we reveal actionable interventions for decreasing the longevitygap in the United States by analyzing a County-level data resource containing healthcare, socio-economic, behavioral, education and demographic features. We learn an ensembleaveraged structure, draw inferences using the joint probability distribution and extend it to a Bayesian Decision Network for identifying policy actions. We draw quantitative estimates for the impact of diversity, preventive-care quality and stablefamilies within the unified framework of our decision network. Finally, we make this analysis and dashboard available as an interactive web-application for enabling users and policy-makers to validate our reported findings and to explore the impact of ones beyond reported in this work.", "venue": "AAAI", "authors": ["Tavpritesh  Sethi", "Anant  Mittal", "Shubham  Maheshwari", "Samarth  Chugh"], "year": 2019, "n_citations": 5}
{"id": 6188201, "s2_id": "b7ca434ea56b3b7305c65626a0ab9a815de6bf76", "title": "Efficient Regularized Piecewise-Linear Regression Trees", "abstract": "We present a detailed analysis of the class of regression decision tree algorithms which employ a regulized piecewise-linear node-splitting criterion and have regularized linear models at the leaves. From a theoretic standpoint, based on Rademacher complexity framework, we present new high-probability upper bounds for the generalization error for the proposed classes of regularized regression decision tree algorithms, including LASSO-type, and $\\ell_{2}$ regularization for linear models at the leaves. Theoretical result are further extended by considering a general type of variable selection procedure. Furthermore, in our work we demonstrate that the class of piecewise-linear regression trees is not only numerically stable but can be made tractable via an algorithmic implementation, presented herein, as well as with the help of modern GPU technology. Empirically, we present results on multiple datasets which highlight the strengths and potential pitfalls, of the proposed tree algorithms compared to baselines which grow trees based on piecewise constant models.", "venue": "ArXiv", "authors": ["Leonidas  Lefakis", "Oleksandr  Zadorozhnyi", "Gilles  Blanchard"], "year": 2019, "n_citations": 1}
{"id": 6189614, "s2_id": "4dc02a5ce78e9824bfab564493444b0064e2c070", "title": "Reducing the Amortization Gap in Variational Autoencoders: A Bayesian Random Function Approach", "abstract": "Variational autoencoder (VAE) is a very successful generative model whose key element is the so called amortized inference network, which can perform test time inference using a single feed forward pass. Unfortunately, this comes at the cost of degraded accuracy in posterior approximation, often underperforming the instance-wise variational optimization. Although the latest semi-amortized approaches mitigate the issue by performing a few variational optimization updates starting from the VAE\u2019s amortized inference output, they inherently suffer from computational overhead for inference at test time. In this paper, we address the problem in a completely different way by considering a random inference model, where we model the mean and variance functions of the variational posterior as random Gaussian processes (GP). The motivation is that the deviation of the VAE\u2019s amortized posterior distribution from the true posterior can be regarded as random noise, which allows us to take into account the uncertainty in posterior approximation in a principled manner. In particular, our model can quantify the difficulty in posterior approximation by a Gaussian variational density. Inference in our GP model is done by a single feed forward pass through the network, significantly faster than semi-amortized methods. We show that our approach attains higher test data likelihood than the state-of-the-arts on several benchmark datasets.", "venue": "ArXiv", "authors": ["Minyoung  Kim", "Vladimir  Pavlovic"], "year": 2021, "n_citations": 1}
{"id": 6203904, "s2_id": "38806817d41206663dcf9e988fa53ca7e15a8e2c", "title": "Faster Balanced Clusterings in High Dimension", "abstract": "The problem of constrained clustering has attracted significant attention in the past decades. In this paper, we study the balanced $k$-center, $k$-median, and $k$-means clustering problems where the size of each cluster is constrained by the given lower and upper bounds. The problems are motivated by the applications in processing large-scale data in high dimension. Existing methods often need to compute complicated matchings (or min cost flows) to satisfy the balance constraint, and thus suffer from high complexities especially in high dimension. We develop an effective framework for the three balanced clustering problems to address this issue, and our method is based on a novel spatial partition idea in geometry. For the balanced $k$-center clustering, we provide a $4$-approximation algorithm that improves the existing approximation factors; for the balanced $k$-median and $k$-means clusterings, our algorithms yield constant and $(1+\\epsilon)$-approximation factors with any $\\epsilon>0$. More importantly, our algorithms achieve linear or nearly linear running times when $k$ is a constant, and significantly improve the existing ones. Our results can be easily extended to metric balanced clusterings and the running times are sub-linear in terms of the complexity of $n$-point metric.", "venue": "Theor. Comput. Sci.", "authors": ["Hu  Ding"], "year": 2020, "n_citations": 5}
{"id": 6206609, "s2_id": "55bd8874d29485aa586678e7a297bd56e7298966", "title": "Yet another but more efficient black-box adversarial attack: tiling and evolution strategies", "abstract": "We introduce a new black-box attack achieving state of the art performances. Our approach is based on a new objective function, borrowing ideas from $\\ell_\\infty$-white box attacks, and particularly designed to fit derivative-free optimization requirements. It only requires to have access to the logits of the classifier without any other information which is a more realistic scenario. Not only we introduce a new objective function, we extend previous works on black box adversarial attacks to a larger spectrum of evolution strategies and other derivative-free optimization methods. We also highlight a new intriguing property that deep neural networks are not robust to single shot tiled attacks. Our models achieve, with a budget limited to $10,000$ queries, results up to $99.2\\%$ of success rate against InceptionV3 classifier with $630$ queries to the network on average in the untargeted attacks setting, which is an improvement by $90$ queries of the current state of the art. In the targeted setting, we are able to reach, with a limited budget of $100,000$, $100\\%$ of success rate with a budget of $6,662$ queries on average, i.e. we need $800$ queries less than the current state of the art.", "venue": "ArXiv", "authors": ["Laurent  Meunier", "Jamal  Atif", "Olivier  Teytaud"], "year": 2019, "n_citations": 22}
{"id": 6234275, "s2_id": "88679822a8303202dce5f4f654b9a722e670f5b4", "title": "Constructive Universal High-Dimensional Distribution Generation through Deep ReLU Networks", "abstract": "We present an explicit deep neural network construction that transforms uniformly distributed one-dimensional noise into an arbitrarily close approximation of any two-dimensional Lipschitz-continuous target distribution. The key ingredient of our design is a generalization of the \"space-filling\" property of sawtooth functions discovered in (Bailey & Telgarsky, 2018). We elicit the importance of depth - in our neural network construction - in driving the Wasserstein distance between the target distribution and the approximation realized by the network to zero. An extension to output distributions of arbitrary dimension is outlined. Finally, we show that the proposed construction does not incur a cost - in terms of error measured in Wasserstein-distance - relative to generating $d$-dimensional target distributions from $d$ independent random variables.", "venue": "ICML", "authors": ["Dmytro  Perekrestenko", "Stephan  M\u00fcller", "Helmut  B\u00f6lcskei"], "year": 2020, "n_citations": 6}
{"id": 6251468, "s2_id": "57633ff5c6f0708be25e651f51eef29d2fbfe48b", "title": "BEHRT: Transformer for Electronic Health Records", "abstract": "Today, despite decades of developments in medicine and the growing interest in precision healthcare, vast majority of diagnoses happen once patients begin to show noticeable signs of illness. Early indication and detection of diseases, however, can provide patients and carers with the chance of early intervention, better disease management, and efficient allocation of healthcare resources. The latest developments in machine learning (including deep learning) provides a great opportunity to address this unmet need. In this study, we introduce BEHRT: A deep neural sequence transduction model for electronic health records (EHR), capable of simultaneously predicting the likelihood of 301 conditions in one\u2019s future visits. When trained and evaluated on the data from nearly 1.6 million individuals, BEHRT shows a striking improvement of 8.0\u201313.2% (in terms of average precision scores for different tasks), over the existing state-of-the-art deep EHR models. In addition to its scalability and superior accuracy, BEHRT enables personalised interpretation of its predictions; its flexible architecture enables it to incorporate multiple heterogeneous concepts (e.g., diagnosis, medication, measurements, and more) to further improve the accuracy of its predictions; its (pre-)training results in disease and patient representations can be useful for future studies (i.e., transfer learning).", "venue": "Scientific Reports", "authors": ["Yikuan  Li", "Shishir  Rao", "Jos\u00e9 Roberto Ayala Solares", "Abdelaali  Hassaine", "Rema  Ramakrishnan", "Dexter  Canoy", "Yajie  Zhu", "Kazem  Rahimi", "Gholamreza  Salimi-Khorshidi"], "year": 2020, "n_citations": 79}
{"id": 6259548, "s2_id": "5d87d55f8bf58f574324f42f4a3a8826f59383e8", "title": "Auto-Keras: An Efficient Neural Architecture Search System", "abstract": "Neural architecture search (NAS) has been proposed to automatically tune deep neural networks, but existing search algorithms, e.g., NASNet, PNAS, usually suffer from expensive computational cost. Network morphism, which keeps the functionality of a neural network while changing its neural architecture, could be helpful for NAS by enabling more efficient training during the search. In this paper, we propose a novel framework enabling Bayesian optimization to guide the network morphism for efficient neural architecture search. The framework develops a neural network kernel and a tree-structured acquisition function optimization algorithm to efficiently explores the search space. Extensive experiments on real-world benchmark datasets have been done to demonstrate the superior performance of the developed framework over the state-of-the-art methods. Moreover, we build an open-source AutoML system based on our method, namely Auto-Keras. The code and documentation are available at https://autokeras.com. The system runs in parallel on CPU and GPU, with an adaptive search strategy for different GPU memory limits.", "venue": "KDD", "authors": ["Haifeng  Jin", "Qingquan  Song", "Xia  Hu"], "year": 2019, "n_citations": 303}
{"id": 6262279, "s2_id": "d8cb732ec6f008de7b17dc7f692e7cc6defdccaa", "title": "Learning Individualized Treatment Rules with Estimated Translated Inverse Propensity Score", "abstract": "Randomized controlled trials typically analyze the effectiveness of treatments with the goal of making treatment recommendations for patient subgroups. With the advance of electronic health records, a great variety of data has been collected in clinical practice, enabling the evaluation of treatments and treatment policies based on observational data. In this paper, we focus on learning individualized treatment rules (ITRs) to derive a treatment policy that is expected to generate a better outcome for an individual patient. In our framework, we cast ITRs learning as a contextual bandit problem and minimize the expected risk of the treatment policy. We conduct experiments with the proposed framework both in a simulation study and based on a real-world dataset. In the latter case, we apply our proposed method to learn the optimal ITRs for the administration of intravenous (IV) fluids and vasopressors (VP). Based on various offline evaluation methods, we could show that the policy derived in our framework demonstrates better performance compared to both the physicians and other baselines, including a simple treatment prediction approach. As a long-term goal, our derived policy might eventually lead to better clinical guidelines for the administration of IV and VP.", "venue": "2020 IEEE International Conference on Healthcare Informatics (ICHI)", "authors": ["Zhiliang  Wu", "Yinchong  Yang", "Yunpu  Ma", "Yushan  Liu", "Rui  Zhao", "Michael  Moor", "Volker  Tresp"], "year": 2020, "n_citations": 1}
{"id": 6274599, "s2_id": "aba53f7a02c0695e1391f5d63a223045deab3415", "title": "ProtoAttend: Attention-Based Prototypical Learning", "abstract": "We propose a novel inherently interpretable machine learning method that bases decisions on few relevant examples that we call prototypes. Our method, ProtoAttend, can be integrated into a wide range of neural network architectures including pre-trained models. It utilizes an attention mechanism that relates the encoded representations to samples in order to determine prototypes. The resulting model outperforms state of the art in three high impact problems without sacrificing accuracy of the original model: (1) it enables high-quality interpretability that outputs samples most relevant to the decision-making (i.e. a sample-based interpretability method); (2) it achieves state of the art confidence estimation by quantifying the mismatch across prototype labels; and (3) it obtains state of the art in distribution mismatch detection. All this can be achieved with minimal additional test time and a practically viable training time computational cost.", "venue": "J. Mach. Learn. Res.", "authors": ["Sercan O. Arik", "Tomas  Pfister"], "year": 2020, "n_citations": 11}
{"id": 6283116, "s2_id": "a27eb3eb8770a851dbc123d406c73182583f3f83", "title": "Global field reconstruction from sparse sensors with Voronoi tessellation-assisted deep learning", "abstract": "Achieving accurate and robust global situational awareness of a complex time-evolving field from a limited number of sensors has been a longstanding challenge. This reconstruction problem is especially difficult when sensors are sparsely positioned in a seemingly random or unorganized manner, which is often encountered in a range of scientific and engineering problems. Moreover, these sensors can be in motion and can become online or offline over time. The key leverage in addressing this scientific issue is the wealth of data accumulated from the sensors. As a solution to this problem, we propose a data-driven spatial field recovery technique founded on a structured grid-based deep-learning approach for arbitrary positioned sensors of any numbers. It should be noted that the na\u00efve use of machine learning becomes prohibitively expensive for global field reconstruction and is furthermore not adaptable to an arbitrary number of sensors. In the present work, we consider the use of Voronoi tessellation to obtain a structured-grid representation from sensor locations enabling the computationally tractable use of convolutional neural networks. One of the central features of the present method is its compatibility with deep-learning based super-resolution reconstruction techniques for structured sensor data that are established for image processing. The proposed reconstruction technique is demonstrated for unsteady wake flow, geophysical data, and three-dimensional turbulence. The current framework is able to handle an arbitrary number of moving sensors, and thereby overcomes a major limitation with existing reconstruction methods. The presented technique opens a new pathway towards the practical use of neural networks for real-time global field estimation.", "venue": "Nat. Mach. Intell.", "authors": ["Kai  Fukami", "Romit  Maulik", "Nesar  Ramachandra", "Koji  Fukagata", "Kunihiko  Taira"], "year": 2021, "n_citations": 12}
{"id": 6287527, "s2_id": "7603cd7bdc0b686971ceb2a26b31b2e2bd874184", "title": "Zero-Shot Learning via Class-Conditioned Deep Generative Models", "abstract": "We present a deep generative model for learning to predict classes not seen at training time. Unlike most existing methods for this problem, that represent each class as a point (via a semantic embedding), we represent each seen/unseen class using a class-specific latent-space distribution, conditioned on class attributes. We use these latent-space distributions as a prior for a supervised variational autoencoder (VAE), which also facilitates learning highly discriminative feature representations for the inputs. The entire framework is learned end-to-end using only the seen-class training data. The model infers corresponding attributes of a test image by maximizing the VAE lower bound; the inferred attributes may be linked to labels not seen when training. We further extend our model to a (1) semi-supervised/transductive setting by leveraging unlabeled unseen-class data via an unsupervised learning module, and (2) few-shot learning where we also have a small number of labeled inputs from the unseen classes. We compare our model with several state-of-the-art methods through a comprehensive set of experiments on a variety of benchmark data sets.", "venue": "AAAI", "authors": ["Wenlin  Wang", "Yunchen  Pu", "Vinay Kumar Verma", "Kai  Fan", "Yizhe  Zhang", "Changyou  Chen", "Piyush  Rai", "Lawrence  Carin"], "year": 2018, "n_citations": 102}
{"id": 6296471, "s2_id": "13225995db548b0aa7e304b92519bb92d744ef90", "title": "Improved Visual Relocalization by Discovering Anchor Points", "abstract": "We address the visual relocalization problem of predicting the location and camera orientation or pose (6DOF) of the given input scene. We propose a method based on how humans determine their location using the visible landmarks. We define anchor points uniformly across the route map and propose a deep learning architecture which predicts the most relevant anchor point present in the scene as well as the relative offsets with respect to it. The relevant anchor point need not be the nearest anchor point to the ground truth location, as it might not be visible due to the pose. Hence we propose a multi task loss function, which discovers the relevant anchor point, without needing the ground truth for it. We validate the effectiveness of our approach by experimenting on CambridgeLandmarks (large scale outdoor scenes) as well as 7 Scenes (indoor scenes) using variousCNN feature extractors. Our method improves the median error in indoor as well as outdoor localization datasets compared to the previous best deep learning model known as PoseNet (with geometric re-projection loss) using the same feature extractor. We improve the median error in localization in the specific case of Street scene, by over 8m.", "venue": "BMVC", "authors": ["Soham  Saha", "Girish  Varma", "C. V. Jawahar"], "year": 2018, "n_citations": 25}
{"id": 6299492, "s2_id": "8c16d04e9d2bee51852c0f0d9e4c1110c7994fe1", "title": "UnProjection: Leveraging Inverse-Projections for Visual Analytics of High-Dimensional Data", "abstract": "Projection techniques are often used to visualize high-dimensional data, allowing users to better understand the overall structure of multi-dimensional spaces on a 2D screen. Although many such methods exist, comparably little work has been done on generalizable methods of inverse-projection -- the process of mapping the projected points, or more generally, the projection space back to the original high-dimensional space. In this paper we present NNInv, a deep learning technique with the ability to approximate the inverse of any projection or mapping. NNInv learns to reconstruct high-dimensional data from any arbitrary point on a 2D projection space, giving users the ability to interact with the learned high-dimensional representation in a visual analytics system. We provide an analysis of the parameter space of NNInv, and offer guidance in selecting these parameters. We extend validation of the effectiveness of NNInv through a series of quantitative and qualitative analyses. We then demonstrate the method's utility by applying it to three visualization tasks: interactive instance interpolation, classifier agreement, and gradient visualization.", "venue": "IEEE transactions on visualization and computer graphics", "authors": ["Mateus  Espadoto", "Gabriel  Appleby", "Ashley  Suh", "Dylan  Cashman", "Mingwei  Li", "Carlos  Scheidegger", "Erik W Anderson", "Remco  Chang", "Alexandru C Telea"], "year": 2021, "n_citations": 0}
{"id": 6301975, "s2_id": "5ff91dc63640ff53bb01c9fbed264d1e717b69a2", "title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime", "abstract": "Motivated by the recent successes of neural networks that have the ability to fit the data perfectly and generalize well, we study the noiseless model in the fundamental least-squares setup. We assume that an optimum predictor fits perfectly inputs and outputs $\\langle \\theta_* , \\phi(X) \\rangle = Y$, where $\\phi(X)$ stands for a possibly infinite dimensional non-linear feature map. To solve this problem, we consider the estimator given by the last iterate of stochastic gradient descent (SGD) with constant step-size. In this context, our contribution is two fold: (i) from a (stochastic) optimization perspective, we exhibit an archetypal problem where we can show explicitly the convergence of SGD final iterate for a non-strongly convex problem with constant step-size whereas usual results use some form of average and (ii) from a statistical perspective, we give explicit non-asymptotic convergence rates in the over-parameterized setting and leverage a fine-grained parameterization of the problem to exhibit polynomial rates that can be faster than $O(1/T)$. The link with reproducing kernel Hilbert spaces is established.", "venue": "ArXiv", "authors": ["Aditya  Varre", "Loucas  Pillaud-Vivien", "Nicolas  Flammarion"], "year": 2021, "n_citations": 6}
{"id": 6303007, "s2_id": "3ab63ec505afefe603de8525a521b14018c91c1d", "title": "JukeBox: A Multilingual Singer Recognition Dataset", "abstract": "A text-independent speaker recognition system relies on successfully encoding speech factors such as vocal pitch, intensity, and timbre to achieve good performance. A majority of such systems are trained and evaluated using spoken voice or everyday conversational voice data. Spoken voice, however, exhibits a limited range of possible speaker dynamics, thus constraining the utility of the derived speaker recognition models. Singing voice, on the other hand, covers a broader range of vocal and ambient factors and can, therefore, be used to evaluate the robustness of a speaker recognition system. However, a majority of existing speaker recognition datasets only focus on the spoken voice. In comparison, there is a significant shortage of labeled singing voice data suitable for speaker recognition research. To address this issue, we assemble \\textit{JukeBox} - a speaker recognition dataset with multilingual singing voice audio annotated with singer identity, gender, and language labels. We use the current state-of-the-art methods to demonstrate the difficulty of performing speaker recognition on singing voice using models trained on spoken voice alone. We also evaluate the effect of gender and language on speaker recognition performance, both in spoken and singing voice data. The complete \\textit{JukeBox} dataset can be accessed at this http URL.", "venue": "INTERSPEECH", "authors": ["Anurag  Chowdhury", "Austin  Cozzo", "Arun  Ross"], "year": 2020, "n_citations": 1}
{"id": 6306496, "s2_id": "d3e8b100038c2bf3983ffae96a56c6af0793a62f", "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence", "abstract": "This paper explores the important role of critical science, and in particular of post-colonial and decolonial theories, in understanding and shaping the ongoing advances in artificial intelligence. Artificial Intelligence (AI) is viewed as amongst the technological advances that will reshape modern societies and their relations. Whilst the design and deployment of systems that continually adapt holds the promise of far-reaching positive change, they simultaneously pose significant risks, especially to already vulnerable peoples. Values and power are central to this discussion. Decolonial theories use historical hindsight to explain patterns of power that shape our intellectual, political, economic, and social world. By embedding a decolonial critical approach within its technical practice, AI communities can develop foresight and tactics that can better align research and technology development with established ethical principles, centring vulnerable peoples who continue to bear the brunt of negative impacts of innovation and scientific progress. We highlight problematic applications that are instances of coloniality, and using a decolonial lens, submit three tactics that can form a decolonial field of artificial intelligence: creating a critical technical practice of AI, seeking reverse tutelage and reverse pedagogies, and the renewal of affective and political communities. The years ahead will usher in a wave of new scientific breakthroughs and technologies driven by AI research, making it incumbent upon AI communities to strengthen the social contract through ethical foresight and the multiplicity of intellectual perspectives available to us; ultimately supporting future technologies that enable greater well-being, with the goal of beneficence and justice for all.", "venue": "ArXiv", "authors": ["Shakir  Mohamed", "Marie-Therese  Png", "William  Isaac"], "year": 2020, "n_citations": 89}
{"id": 6307117, "s2_id": "fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea", "title": "A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications", "abstract": "Generative adversarial networks (GANs) are a hot research topic recently. GANs have been widely studied since 2014, and a large number of algorithms have been proposed. However, there is few comprehensive study explaining the connections among different GANs variants, and how they have evolved. In this paper, we attempt to provide a review on various GANs methods from the perspectives of algorithms, theory, and applications. Firstly, the motivations, mathematical representations, and structure of most GANs algorithms are introduced in details. Furthermore, GANs have been combined with other machine learning algorithms for specific applications, such as semi-supervised learning, transfer learning, and reinforcement learning. This paper compares the commonalities and differences of these GANs methods. Secondly, theoretical issues related to GANs are investigated. Thirdly, typical applications of GANs in image processing and computer vision, natural language processing, music, speech and audio, medical field, and data science are illustrated. Finally, the future open research problems for GANs are pointed out.", "venue": "IEEE Transactions on Knowledge and Data Engineering", "authors": ["Jie  Gui", "Zhenan  Sun", "Yonggang  Wen", "Dacheng  Tao", "Jieping  Ye"], "year": 2021, "n_citations": 136}
{"id": 6311193, "s2_id": "3161bc5a2736946bc640ee1d5dab544a866c69e5", "title": "Overton: A Data System for Monitoring and Improving Machine-Learned Products", "abstract": "We describe a system called Overton, whose main design goal is to support engineers in building, monitoring, and improving production machine learning systems. Key challenges engineers face are monitoring fine-grained quality, diagnosing errors in sophisticated applications, and handling contradictory or incomplete supervision data. Overton automates the life cycle of model construction, deployment, and monitoring by providing a set of novel high-level, declarative abstractions. Overton's vision is to shift developers to these higher-level tasks instead of lower-level machine learning tasks. In fact, using Overton, engineers can build deep-learning-based applications without writing any code in frameworks like TensorFlow. For over a year, Overton has been used in production to support multiple applications in both near-real-time applications and back-of-house processing. In that time, Overton-based applications have answered billions of queries in multiple languages and processed trillions of records reducing errors 1.7-2.9 times versus production systems.", "venue": "CIDR", "authors": ["Christopher  R\u00e9", "Feng  Niu", "Pallavi  Gudipati", "Charles  Srisuwananukorn"], "year": 2020, "n_citations": 21}
{"id": 6312962, "s2_id": "56266654a1a2eb08648928636608f83317fed90b", "title": "Information Elicitation Meets Clustering", "abstract": "In the setting where we want to aggregate people\u2019s subjective evaluations, plurality vote may be meaningless when a large amount of low-effort people always report \u201cgood\u201d regardless of the true quality. \u201cSurprisingly popular\u201d method, picking the most surprising answer compared to the prior, handle this issue to some extent. However, it is still not fully robust to people\u2019s strategies. Here in the setting where a large number of people are asked to answer a small number of multi-choice questions (multi-task, large group), we propose an information aggregation method which is robust to people\u2019s strategies. Interestingly, this method can be seen as a rotated \u201csurprisingly popular\u201d. It is based on a new clustering method, Determinant MaxImization (DMI)-clustering, and a key conceptual idea that information elicitation without ground-truth can be seen as a clustering problem. Of independent interest, DMI-clustering is a general clustering method that aims to maximize the volume of the simplex consisting of each cluster\u2019s mean multiplying the product of the cluster sizes. We show that DMI-clustering is invariant to any non-degenerate affine transformation for all data points. When the data point\u2019s dimension is a constant, DMI-clustering can be solved in polynomial time. In general, we present a simple heuristic for DMI-clustering which is very similar to Lloyd\u2019s algorithm for k-means. Additionally, we also apply the clustering idea in the single-task setting and use spectral method to propose a new aggregation method that utilizes the second-moment information elicited from the crowds.", "venue": "ArXiv", "authors": ["Yuqing  Kong"], "year": 2021, "n_citations": 0}
{"id": 6319148, "s2_id": "4c7346ae1126dd853f4802962d26f844ceb82940", "title": "Compressing Language Models using Doped Kronecker Products", "abstract": "Kronecker Products (KP) have been used to compress IoT RNN Applications by 15-38x compression factors, achieving better results than traditional compression methods. However when KP is applied to large Natural Language Processing tasks, it leads to significant accuracy loss (approx 26%). This paper proposes a way to recover accuracy otherwise lost when applying KP to large NLP tasks, by allowing additional degrees of freedom in the KP matrix. More formally, we propose doping, a process of adding an extremely sparse overlay matrix on top of the pre-defined KP structure. We call this compression method doped kronecker product compression. To train these models, we present a new solution to the phenomenon of co-matrix adaption (CMA), which uses a new regularization scheme called co matrix dropout regularization (CMR). We present experimental results that demonstrate compression of a large language model with LSTM layers of size 25 MB by 25x with 1.4% loss in perplexity score. At 25x compression, an equivalent pruned network leads to 7.9% loss in perplexity score, while HMD and LMF lead to 15% and 27% loss in perplexity score respectively.", "venue": "ArXiv", "authors": ["Urmish  Thakker", "Paul  Whatamough", "Matthew  Mattina", "Jesse  Beu"], "year": 2020, "n_citations": 7}
{"id": 6319858, "s2_id": "12c0751b4f51ed833172a713b7e32390032ead93", "title": "Soft Actor-Critic Algorithms and Applications", "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.", "venue": "ArXiv", "authors": ["Tuomas  Haarnoja", "Aurick  Zhou", "Kristian  Hartikainen", "George  Tucker", "Sehoon  Ha", "Jie  Tan", "Vikash  Kumar", "Henry  Zhu", "Abhishek  Gupta", "Pieter  Abbeel", "Sergey  Levine"], "year": 2018, "n_citations": 579}
{"id": 6321718, "s2_id": "b4fbcd41f9339528fd04d9c5eb66e05a51eefd5b", "title": "Scheduling Optimization Techniques for Neural Network Training", "abstract": "Neural network training requires a large amount of computation and thus GPUs are often used for the acceleration. While they improve the performance, GPUs are underutilized during the training. This paper proposes out-of-order (ooo) backprop, an effective scheduling technique for neural network training. By exploiting the dependencies of gradient computations, ooo backprop enables to reorder their executions to make the most of the GPU resources. We show that the GPU utilization in single-GPU, data-parallel, and pipelineparallel training can be commonly improve by applying ooo backprop and prioritizing critical operations. We propose three scheduling algorithms based on ooo backprop. For single-GPU training, we schedule with multi-stream out-of-order computation to mask the kernel launch overhead. In data-parallel training, we reorder the gradient computations to maximize the overlapping of computation and parameter communication; in pipeline-parallel training, we prioritize critical gradient computations to reduce the pipeline stalls. We evaluate our optimizations with twelve neural networks including a light-weight computer vision model (MobileNet) and large NLP models (BERT and GPT-3) with up to forty eight V100 GPUs. Our scheduling algorithms effectively improve the performance of single-GPU training as well as dataand pipeline-parallel training. Compared to the respective state of the art training systems, the throughput is substantially improved for single-GPU, data-parallel, and pipeline-parallel training.", "venue": "ArXiv", "authors": ["Hyungjun  Oh", "Junyeol  Lee", "HyeongJu  Kim", "Jiwon  Seo"], "year": 2021, "n_citations": 0}
{"id": 6325818, "s2_id": "818bdfac4186c0b0a348a4f264639222a2c7f539", "title": "Learning the Evolution of the Universe in N-body Simulations", "abstract": "Understanding the physics of large cosmological surveys down to small (nonlinear) scales will significantly improve our knowledge of the Universe. Large N-body simulations have been built to obtain predictions in the non-linear regime. However, N-body simulations are computationally expensive and generate large amount of data, putting burdens on storage. These data are snapshots of the simulated Universe at different times, and fine sampling is necessary to accurately save its whole history. We employ a deep neural network model to predict the nonlinear N-body simulation at an intermediate time step given two widely separated snapshots. Our results outperform the cubic Hermite interpolation benchmark method in interpolating N-body simulations. This work can greatly reduce the storage requirement and allow us to reconstruct the cosmic history from far fewer snapshots of the universe.", "venue": "ArXiv", "authors": ["Chang  Chen", "Yin  Li", "Francisco  Villaescusa-Navarro", "Shirley  Ho", "Anthony  Pullen"], "year": 2020, "n_citations": 0}
{"id": 6334124, "s2_id": "fb31e3a66c7d7b8e2bda6e8c2ab8d817ca6dedc4", "title": "An optimized Capsule-LSTM model for facial expression recognition with video sequences", "abstract": "To overcome the limitations of convolutional neural network in the process of facial expression recognition, a facial expression recognition model Capsule-LSTM based on video frame sequence is proposed. This model is composed of three networks includingcapsule encoders, capsule decoders and LSTM network. The capsule encoder extracts the spatial information of facial expressions in video frames. Capsule decoder reconstructs the images to optimize the network. LSTM extracts the temporal information between video frames and analyzes the differences in expression changes between frames. The experimental results from the MMI dataset show that the Capsule-LSTM model proposed in this paper can effectively improve the accuracy of video expression recognition.", "venue": "ArXiv", "authors": ["Siwei  Liu", "Yuanpeng  Long", "Gao  Xu", "Lijia  Yang", "Shimei  Xu", "Xiaoming  Yao", "Kunxian  Shu"], "year": 2021, "n_citations": 0}
{"id": 6371134, "s2_id": "2ad0b5dde2a8b905154902245f1c61bd5f0b64cb", "title": "SIMLR: Machine Learning inside the SIR model for COVID-19 Forecasting", "abstract": "Accurate forecasts of the number of newly infected people during an epidemic are critical for making effective timely decisions. This paper addresses this challenge using the SIMLR model, which incorporates machine learning (ML) into the epidemiological SIR model. For each region, SIMLR tracks the changes in the policies implemented at the government level, which it uses to estimate the time-varying parameters of an SIR model for forecasting the number of new infections 1to 4-weeks in advance. It also forecasts the probability of changes in those government policies at each of these future times, which is essential for the longer-range forecasts. We applied SIMLR to data from regions in Canada and in the United States, and show that its MAPE (mean average percentage error) performance is as good as SOTA forecasting models, with the added advantage of being an interpretable model. We expect that this approach will be useful not only for forecasting COVID-19 infections, but also in predicting the evolution of other infectious diseases.", "venue": "ArXiv", "authors": ["Roberto  Vega", "Leonardo  Flores", "Russell  Greiner"], "year": 2021, "n_citations": 0}
{"id": 6380890, "s2_id": "24d2559f65b4fe721073b78ff59b13e97cc2812b", "title": "Ad hoc microphone array calibration: Euclidean distance matrix completion algorithm and theoretical guarantees", "abstract": "This paper addresses the problem of ad hoc microphone array calibration where only partial information about the distances between microphones is available. We construct a matrix consisting of the pairwise distances and propose to estimate the missing entries based on a novel Euclidean distance matrix completion algorithm by alternative low-rank matrix completion and projection onto the Euclidean distance space. This approach confines the recovered matrix to the EDM cone at each iteration of the matrix completion algorithm. The theoretical guarantees of the calibration performance are obtained considering the random and locally structured missing entries as well as the measurement noise on the known distances. This study elucidates the links between the calibration error and the number of microphones along with the noise level and the ratio of missing distances. Thorough experiments on real data recordings and simulated setups are conducted to demonstrate these theoretical insights. A significant improvement is achieved by the proposed Euclidean distance matrix completion algorithm over the state-of-the-art techniques for ad hoc microphone array calibration. HighlightsEuclidean matrix completion enables calibration from partial distance measurements.A novel Euclidean matrix completion algorithm is proposed.The relation between error and number of microphones, noise and missing distances is derived.Theoretical insights are demonstrated by thorough experiments on real and simulated data.The performance is compared with SDP, S-Stress, MDS-MAP and Matrix completion.", "venue": "Signal Process.", "authors": ["Mohammad Javad Taghizadeh", "Reza  Parhizkar", "Philip N. Garner", "Herv\u00e9  Bourlard", "Afsaneh  Asaei"], "year": 2015, "n_citations": 19}
{"id": 6406481, "s2_id": "7a958af007db6ddc4b462eeb7603857c9239f137", "title": "Adversarial Feature Training for Generalizable Robotic Visuomotor Control", "abstract": "Deep reinforcement learning (RL) has enabled training action-selection policies, end-to-end, by learning a function which maps image pixels to action outputs. However, it's application to visuomotor robotic policy training has been limited because of the challenge of large-scale data collection when working with physical hardware. A suitable visuomotor policy should perform well not just for the task-setup it has been trained for, but also for all varieties of the task, including novel objects at different viewpoints surrounded by task-irrelevant objects. However, it is impractical for a robotic setup to sufficiently collect interactive samples in a RL framework to generalize well to novel aspects of a task.In this work, we demonstrate that by using adversarial training for domain transfer, it is possible to train visuomotor policies based on RL frameworks, and then transfer the acquired policy to other novel task domains. We propose to leverage the deep RL capabilities to learn complex visuomotor skills for uncomplicated task setups, and then exploit transfer learning to generalize to new task domains provided only still images of the task in the target domain. We evaluate our method on two real robotic tasks, picking and pouring, and compare it to a number of prior works, demonstrating its superiority.", "venue": "2020 IEEE International Conference on Robotics and Automation (ICRA)", "authors": ["Xi  Chen", "Ali  Ghadirzadeh", "M\u00e5rten  Bj\u00f6rkman", "Patric  Jensfelt"], "year": 2020, "n_citations": 7}
{"id": 6406651, "s2_id": "d2812f7e81b3871f1bf88659d505f997a5e5b9d2", "title": "Recommending Short-lived Dynamic Packages for Golf Booking Services", "abstract": "We introduce an approach to recommending short-lived dynamic packages for golf booking services. Two challenges are addressed in this work. The first is the short life of the items, which puts the system in a state of a permanent cold start. The second is the uninformative nature of the package attributes, which makes clustering or figuring latent packages challenging. Although such settings are fairly pervasive, they have not been studied in traditional recommendation research, and there is thus a call for original approaches for recommender systems. In this paper, we introduce a hybrid method that leverages user analysis and its relation to the packages, as well as package pricing and environmental analysis, and traditional collaborative filtering. The proposed approach achieved appreciable improvement in precision compared with baselines", "venue": "CIKM", "authors": ["Robin  Swezey", "Young-joo  Chung"], "year": 2015, "n_citations": 1}
{"id": 6408279, "s2_id": "9dc547ec8462bc833323aa6e75d881f0040f30d2", "title": "Graph Mining Meets Crowdsourcing: Extracting Experts for Answer Aggregation", "abstract": "Aggregating responses from crowd workers is a fundamental task in the process of crowdsourcing. In cases where a few experts are overwhelmed by a large number of non-experts, most answer aggregation algorithms such as the majority voting fail to identify the correct answers. Therefore, it is crucial to extract reliable experts from the crowd workers. In this study, we introduce the notion of \"expert core\", which is a set of workers that is very unlikely to contain a non-expert. We design a graph-mining-based efficient algorithm that exactly computes the expert core. To answer the aggregation task, we propose two types of algorithms. The first one incorporates the expert core into existing answer aggregation algorithms such as the majority voting, whereas the second one utilizes information provided by the expert core extraction algorithm pertaining to the reliability of workers. We then give a theoretical justification for the first type of algorithm. Computational experiments using synthetic and real-world datasets demonstrate that our proposed answer aggregation algorithms outperform state-of-the-art algorithms.\u00a0", "venue": "IJCAI", "authors": ["Yasushi  Kawase", "Yuko  Kuroki", "Atsushi  Miyauchi"], "year": 2019, "n_citations": 5}
{"id": 6410325, "s2_id": "31b086e92e431cfcc216aae6202f5c56aafd766f", "title": "The Greedy Miser: Learning under Test-time Budgets", "abstract": "As machine learning algorithms enter applications in industrial settings, there is increased interest in controlling their cpu-time during testing. The cpu-time consists of the running time of the algorithm and the extraction time of the features. The latter can vary drastically when the feature set is diverse. In this paper, we propose an algorithm, the Greedy Miser, that incorporates the feature extraction cost during training to explicitly minimize the cpu-time during testing. The algorithm is a straightforward extension of stagewise regression and is equally suitable for regression or multi-class classification. Compared to prior work, it is significantly more cost-effective and scales to larger data sets.", "venue": "ICML", "authors": ["Zhixiang Eddie Xu", "Kilian Q. Weinberger", "Olivier  Chapelle"], "year": 2012, "n_citations": 109}
{"id": 6412743, "s2_id": "e50afeba9b6373357edbcf64fef0145c3f374642", "title": "Reinforced Epidemic Control: Saving Both Lives and Economy", "abstract": "Saving lives or economy is a dilemma for epidemic control in most cities while smart-tracing technology raises people's privacy concerns. In this paper, we propose a solution for the life-or-economy dilemma that does not require private data. We bypass the private-data requirement by suppressing epidemic transmission through a dynamic control on inter-regional mobility that only relies on Origin-Designation (OD) data. We develop DUal-objective Reinforcement-Learning Epidemic Control Agent (DURLECA) to search mobility-control policies that can simultaneously minimize infection spread and maximally retain mobility. DURLECA hires a novel graph neural network, namely Flow-GNN, to estimate the virus-transmission risk induced by urban mobility. The estimated risk is used to support a reinforcement learning agent to generate mobility-control actions. The training of DURLECA is guided with a well-constructed reward function, which captures the natural trade-off relation between epidemic control and mobility retaining. Besides, we design two exploration strategies to improve the agent's searching efficiency and help it get rid of local optimums. Extensive experimental results on a real-world OD dataset show that DURLECA is able to suppress infections at an extremely low level while retaining 76\\% of the mobility in the city. Our implementation is available at this https URL.", "venue": "ArXiv", "authors": ["Sirui  Song", "Zefang  Zong", "Yong  Li", "Xue  Liu", "Yang  Yu"], "year": 2020, "n_citations": 7}
{"id": 6422516, "s2_id": "06fda70d88eadaaf3270fc8e1f09dc8357e4b73b", "title": "An efficient quantum algorithm for generative machine learning", "abstract": "A central task in the field of quantum computing is to find applications where quantum computer could provide exponential speedup over any classical computer. Machine learning represents an important field with broad applications where quantum computer may offer significant speedup. Several quantum algorithms for discriminative machine learning have been found based on efficient solving of linear algebraic problems, with potential exponential speedup in runtime under the assumption of effective input from a quantum random access memory. In machine learning, generative models represent another large class which is widely used for both supervised and unsupervised learning. Here, we propose an efficient quantum algorithm for machine learning based on a quantum generative model. We prove that our proposed model is exponentially more powerful to represent probability distributions compared with classical generative models and has exponential speedup in training and inference at least for some instances under a reasonable assumption in computational complexity theory. Our result opens a new direction for quantum machine learning and offers a remarkable example in which a quantum algorithm shows exponential improvement over any classical algorithm in an important application field.", "venue": "ArXiv", "authors": ["Xun  Gao", "Zhengyu  Zhang", "Luming  Duan"], "year": 2017, "n_citations": 21}
{"id": 6424200, "s2_id": "d826cd1c9ad907ae1c57a14740eb84a3075f2725", "title": "Simple vs complex temporal recurrences for video saliency prediction", "abstract": "This paper investigates modifying an existing neural network architecture for static saliency prediction using two types of recurrences that integrate information from the temporal domain. The first modification is the addition of a ConvLSTM within the architecture, while the second is a conceptually simple exponential moving average of an internal convolutional state. We use weights pre-trained on the SALICON dataset and fine-tune our model on DHF1K. Our results show that both modifications achieve state-of-the-art results and produce similar saliency maps. Source code is available at this https URL.", "venue": "BMVC", "authors": ["Panagiotis  Linardos", "Eva  Mohedano", "Juan Jos\u00e9 Nieto", "Noel E. O'Connor", "Xavier  Gir\u00f3", "Kevin  McGuinness"], "year": 2019, "n_citations": 30}
{"id": 6433526, "s2_id": "014d37092b52bd2874759679d780e1286478ba03", "title": "PrivacyNet: Semi-Adversarial Networks for Multi-Attribute Face Privacy", "abstract": "Recent research has established the possibility of deducing soft-biometric attributes such as age, gender, and race from an individual\u2019s face image with high accuracy. However, this raises privacy concerns, especially when face images collected for biometric recognition purposes are used for attribute analysis without the person\u2019s consent. To address this problem, we develop a technique for imparting soft biometric privacy to face images via an image perturbation methodology. The image perturbation is undertaken using a GAN-based Semi-Adversarial Network (SAN) \u2014 referred to as PrivacyNet \u2014 that modifies an input face image such that it can be used by a face matcher for matching purposes but cannot be reliably used by an attribute classifier. Further, PrivacyNet allows a person to choose specific attributes that have to be obfuscated in the input face images (e.g., age and race), while allowing for other types of attributes to be extracted (e.g., gender). Extensive experiments using multiple face matchers, multiple age/gender/race classifiers, and multiple face datasets demonstrate the generalizability of the proposed multi-attribute privacy enhancing method across multiple face and attribute classifiers.", "venue": "IEEE Transactions on Image Processing", "authors": ["Vahid  Mirjalili", "Sebastian  Raschka", "Arun  Ross"], "year": 2020, "n_citations": 22}
{"id": 6437658, "s2_id": "e8547ed898414fa4924fa4a720b5cf564d208411", "title": "Word Equations: Inherently Interpretable Sparse Word Embeddings through Sparse Coding", "abstract": "Word embeddings are a powerful natural language processing technique, but they are extremely difficult to interpret. To enable interpretable NLP models, we create vectors where each dimension is inherently interpretable. By inherently interpretable, we mean a system where each dimension is associated with some human-understandable hint that can describe the meaning of that dimension. In order to create more interpretable word embeddings, we transform pretrained dense word embeddings into sparse embeddings. These new embeddings are inherently interpretable: each of their dimensions is created from and represents a natural language word or specific grammatical concept. We construct these embeddings through sparse coding, where each vector in the basis set is itself a word embedding. Therefore, each dimension of our sparse vectors corresponds to a natural language word. We also show that models trained using these sparse embeddings can achieve good performance and are more interpretable in practice, including through human evaluations.", "venue": "BLACKBOXNLP", "authors": ["Adly  Templeton"], "year": 2021, "n_citations": 1}
{"id": 6450311, "s2_id": "8b81b404f5b69138a9df697a9c9f2af3a178ea56", "title": "On Recursive Edit Distance Kernels With Application to Time Series Classification", "abstract": "This paper proposes some extensions to the work on kernels dedicated to string or time series global alignment based on the aggregation of scores obtained by local alignments. The extensions that we propose allow us to construct, from classical recursive definition of elastic distances, recursive edit distance (or time-warp) kernels that are positive definite if some sufficient conditions are satisfied. The sufficient conditions we end up with are original and weaker than those proposed in earlier works, although a recursive regularizing term is required to get proof of the positive definiteness as a direct consequence of the Haussler's convolution theorem. Furthermore, the positive definiteness is maintained when a symmetric corridor is used to reduce the search space, and thus the algorithmic complexity, which is quadratic in the worst case. The classification experiment we conducted on three classical time-warp distances (two of which are metrics), using support vector machine classifier, leads to the conclusion that when the pairwise distance matrix obtained from the training data is far from definiteness, the positive definite recursive elastic kernels outperform in general the distance substituting kernels for several classical elastic distances we have tested.", "venue": "IEEE Transactions on Neural Networks and Learning Systems", "authors": ["Pierre-Fran\u00e7ois  Marteau", "Sylvie  Gibet"], "year": 2015, "n_citations": 66}
{"id": 6471316, "s2_id": "4f2c15d392695280f64f9cfaf5910359d3fe0e50", "title": "Richness of Deep Echo State Network Dynamics", "abstract": "Reservoir Computing (RC) is a popular methodology for the efficient design of Recurrent Neural Networks (RNNs). Recently, the advantages of the RC approach have been extended to the context of multi-layered RNNs, with the introduction of the Deep Echo State Network (DeepESN) model. In this paper, we study the quality of state dynamics in progressively higher layers of DeepESNs, using tools from the areas of information theory and numerical analysis. Our experimental results on RC benchmark datasets reveal the fundamental role played by the strength of inter-reservoir connections to increasingly enrich the representations developed in higher layers. Our analysis also gives interesting insights into the possibility of effective exploitation of training algorithms based on stochastic gradient descent in the RC field.", "venue": "IWANN", "authors": ["Claudio  Gallicchio", "Alessio  Micheli"], "year": 2019, "n_citations": 12}
{"id": 6474691, "s2_id": "b614ae0709be57712dc4ccbe7b50ba646d113f4c", "title": "Graph Optimal Transport with Transition Couplings of Random Walks", "abstract": "We present a novel approach to optimal transport between graphs from the perspective of stationary Markov chains. A weighted graph may be associated with a stationary Markov chain by means of a random walk on the vertex set with transition distributions depending on the edge weights of the graph. After drawing this connection, we describe how optimal transport techniques for stationary Markov chains may be used in order to perform comparison and alignment of the graphs under study. In particular, we propose the graph optimal transition coupling problem, referred to as GraphOTC, in which the Markov chains associated to two given graphs are optimally synchronized to minimize an expected cost. The joint synchronized chain yields an alignment of the vertices and edges in the two graphs, and the expected cost of the synchronized chain acts as a measure of distance or dissimilarity between the two graphs. We demonstrate that GraphOTC performs equal to or better than existing state-of-the-art techniques in graph optimal transport for several tasks and datasets. Finally, we also describe a generalization of the GraphOTC problem, called the FusedOTC problem, from which we recover the GraphOTC and OT costs as special cases.", "venue": "ArXiv", "authors": ["Kevin  O'Connor", "Bongsoo  Yi", "Kevin  McGoff", "Andrew B. Nobel"], "year": 2021, "n_citations": 3}
{"id": 6475229, "s2_id": "3374e94cf02d76f8f4e2e60d41b8ed99f2b59f1d", "title": "Geometric All-Way Boolean Tensor Decomposition", "abstract": "Boolean tensor has been broadly utilized in representing high dimensional logical data collected on spatial, temporal and/or other relational domains. Boolean Tensor Decomposition (BTD) factorizes a binary tensor into the Boolean sum of multiple rank-1 tensors, which is an NP-hard problem. Existing BTD methods have been limited by their high computational cost, in applications to large scale or higher order tensors. In this work, we presented a computationally efficient BTD algorithm, namely \\textit{Geometric Expansion for all-order Tensor Factorization} (GETF), that sequentially identifies the rank-1 basis components for a tensor from a geometric perspective. We conducted rigorous theoretical analysis on the validity as well as algorithemic efficiency of GETF in decomposing all-order tensor. Experiments on both synthetic and real-world data demonstrated that GETF has significantly improved performance in reconstruction accuracy, extraction of latent structures and it is an order of magnitude faster than other state-of-the-art methods.", "venue": "NeurIPS", "authors": ["Changlin  Wan", "Wennan  Chang", "Tong  Zhao", "Sha  Cao", "Chi  Zhang"], "year": 2020, "n_citations": 1}
{"id": 6481422, "s2_id": "7063fca2b814f2afd4b7cbba63b32a0e9633c358", "title": "Visual Evaluation of Generative Adversarial Networks for Time Series Data", "abstract": "A crucial factor to trust Machine Learning (ML) algorithm decisions is a good representation of its application field by the training dataset. This is particularly true when parts of the training data have been artificially generated to overcome common training problems such as lack of data or imbalanced dataset. Over the last few years, Generative Adversarial Networks (GANs) have shown remarkable results in generating realistic data. However, this ML approach lacks an objective function to evaluate the quality of the generated data. Numerous GAN applications focus on generating image data mostly because they can be easily evaluated by a human eye. Less efforts have been made to generate time series data. Assessing their quality is more complicated, particularly for technical data. In this paper, we propose a human-centered approach supporting a ML or domain expert to accomplish this task using Visual Analytics (VA) techniques. The presented approach consists of two views, namely a GAN Iteration View showing similarity metrics between real and generated data over the iterations of the generation process and a Detailed Comparative View equipped with different time series visualizations such as TimeHistograms, to compare the generated data at different iteration steps. Starting from the GAN Iteration View, the user can choose suitable iteration steps for detailed inspection. We evaluate our approach with a usage scenario that enabled an efficient comparison of two different GAN models.", "venue": "ArXiv", "authors": ["Hiba  Arnout", "Johannes  Kehrer", "Johanna  Bronner", "Thomas  Runkler"], "year": 2020, "n_citations": 2}
{"id": 6485780, "s2_id": "9189de6e641dad88b194f6bff6096154cee06177", "title": "On Extending Amdahl's law to Learn Computer Performance", "abstract": "The problem of learning parallel computer performance is investigated in the context of multicore processors. Given a fixed workload, the effect of varying system configuration on performance is sought. Conventionally, the performance speedup due to a single resource enhancement is formulated using Amdahl\u2019s law. However, in case of multiple configurable resources the conventional formulation results in several disconnected speedup equations that cannot be combined together to determine the overall speedup. To solve this problem, we propose to (1) extend Amdahl\u2019s law to accommodate multiple configurable resources into the overall speedup equation, and (2) transform the speedup equation into a multivariable regression problem suitable for machine learning. Using experimental data from two benchmarks (SPECCPU 2017 and PCMark 10 ) and four hardware platforms (Intel Xeon 8180M, AMD EPYC 7702P, Intel CoffeeLake 8700K, and AMD Ryzen 3900X ), analytical models are developed and cross-validated. Findings indicate that in most cases, the models result in an average cross-validated accuracy higher than 95%, thereby validating the proposed extension of Amdahl\u2019s law. The proposed methodology enables rapid generation of intelligent analytical models to support future industrial development, optimization, and simulation needs.", "venue": "ArXiv", "authors": ["Chaitanya  Poolla", "Rahul  Saxena"], "year": 2021, "n_citations": 0}
{"id": 6486484, "s2_id": "76faaf292c6d9dc29d3a99300a7fdd7a35d6d107", "title": "Online and Linear-Time Attention by Enforcing Monotonic Alignments", "abstract": "Recurrent neural network models with an attention mechanism have proven to be extremely effective on a wide variety of sequence-to-sequence problems. However, the fact that soft attention mechanisms perform a pass over the entire input sequence when producing each element in the output sequence precludes their use in online settings and results in a quadratic time complexity. Based on the insight that the alignment between input and output sequence elements is monotonic in many problems of interest, we propose an end-to-end differentiable method for learning monotonic alignments which, at test time, enables computing attention online and in linear time. We validate our approach on sentence summarization, machine translation, and online speech recognition problems and achieve results competitive with existing sequence-to-sequence models.", "venue": "ICML", "authors": ["Colin  Raffel", "Minh-Thang  Luong", "Peter J. Liu", "Ron J. Weiss", "Douglas  Eck"], "year": 2017, "n_citations": 152}
{"id": 6488255, "s2_id": "86cdd3b262b6464814214d4ed61d0dcbe7e81934", "title": "Learning discrete distributions: user vs item-level privacy", "abstract": "Much of the literature on differential privacy focuses on item-level privacy, where loosely speaking, the goal is to provide privacy per item or training example. However, recently many practical applications such as federated learning require preserving privacy for all items of a single user, which is much harder to achieve. Therefore understanding the theoretical limit of user-level privacy becomes crucial. \nWe study the fundamental problem of learning discrete distributions over $k$ symbols with user-level differential privacy. If each user has $m$ samples, we show that straightforward applications of Laplace or Gaussian mechanisms require the number of users to be $\\mathcal{O}(k/(m\\alpha^2) + k/\\epsilon\\alpha)$ to achieve an $\\ell_1$ distance of $\\alpha$ between the true and estimated distributions, with the privacy-induced penalty $k/\\epsilon\\alpha$ independent of the number of samples per user $m$. Moreover, we show that any mechanism that only operates on the final aggregate should require a user complexity of the same order. We then propose a mechanism such that the number of users scales as $\\tilde{\\mathcal{O}}(k/(m\\alpha^2) + k/\\sqrt{m}\\epsilon\\alpha)$ and further show that it is nearly-optimal under certain regimes. Thus the privacy penalty is $\\mathcal{O}(\\sqrt{m})$ times smaller compared to the standard mechanisms. \nWe also propose general techniques for obtaining lower bounds on restricted differentially private estimators and a lower bound on the total variation between binomial distributions, both of which might be of independent interest.", "venue": "NeurIPS", "authors": ["Yuhan  Liu", "Ananda Theertha Suresh", "Felix  Yu", "Sanjiv  Kumar", "Michael  Riley"], "year": 2020, "n_citations": 9}
{"id": 6488664, "s2_id": "3262e13f20bb0bae2c517c6d8bee11b3a166e4d9", "title": "Global Aggregations of Local Explanations for Black Box models", "abstract": "The decision-making process of many state-of-the-art machine learning models is inherently inscrutable to the extent that it is impossible for a human to interpret the model directly: they are black box models. This has led to a call for research on explaining black box models, for which there are two main approaches. Global explanations that aim to explain a model's decision making process in general, and local explanations that aim to explain a single prediction. Since it remains challenging to establish fidelity to black box models in globally interpretable approximations, much attention is put on local explanations. However, whether local explanations are able to reliably represent the black box model and provide useful insights remains an open question. We present Global Aggregations of Local Explanations (GALE) with the objective to provide insights in a model's global decision making process. Overall, our results reveal that the choice of aggregation matters. We find that the global importance introduced by Local Interpretable Model-agnostic Explanations (LIME) does not reliably represent the model's global behavior. Our proposed aggregations are better able to represent how features affect the model's predictions, and to provide global insights by identifying distinguishing features.", "venue": "ArXiv", "authors": ["Ilse van der Linden", "Hinda  Haned", "Evangelos  Kanoulas"], "year": 2019, "n_citations": 21}
{"id": 6491067, "s2_id": "e21991ff2f5c09797df4b23c9fa438cea902622f", "title": "Compressive PCA for Low-Rank Matrices on Graphs", "abstract": "We introduce a novel framework for an approximate recovery of data matrices which are low rank on graphs, from sampled measurements. The rows and columns of such matrices belong to the span of the first few eigenvectors of the graphs constructed between their rows and columns. We leverage this property to recover the nonlinear low-rank structures efficiently from sampled data measurements, with a low cost (linear in <inline-formula> <tex-math notation=\"LaTeX\">$n$</tex-math></inline-formula>). First, a resrtricted isometry property condition is introduced for efficient uniform sampling of the rows and columns of such matrices based on the cumulative coherence of graph eigenvectors. Second, a state-of-the-art fast low-rank recovery method is suggested for the sampled data. Finally, several efficient, parallel, and parameter-free decoders are presented along with their theoretical analysis for decoding the low-rank and cluster indicators for the full data matrix. Thus, we overcome the computational limitations of the standard <italic>linear</italic> low-rank recovery methods for big datasets. Our method can also be seen as a major step toward efficient recovery of nonlinear low-rank structures. For a matrix of size <inline-formula> <tex-math notation=\"LaTeX\">$n \\times p$</tex-math></inline-formula>, on a single core machine, our method gains a speed up of <inline-formula><tex-math notation=\"LaTeX\">$p^2/k$</tex-math></inline-formula> over robust principal component analysis (RPCA), where <inline-formula><tex-math notation=\"LaTeX\">$k \\ll p$</tex-math></inline-formula> is the subspace dimension. Numerically, we can recover a low-rank matrix of size <inline-formula><tex-math notation=\"LaTeX\"> $10304 \\times 1000$</tex-math></inline-formula>, 100 times faster than RPCA.", "venue": "IEEE Transactions on Signal and Information Processing over Networks", "authors": ["Nauman  Shahid", "Nathanael  Perraudin", "Gilles  Puy", "Pierre  Vandergheynst"], "year": 2017, "n_citations": 10}
{"id": 6507119, "s2_id": "08e6b491579b0a4297fc69dba8e139ec4480fcbe", "title": "Multi-Precision Policy Enforced Training (MuPPET): A precision-switching strategy for quantised fixed-point training of CNNs", "abstract": "Large-scale convolutional neural networks (CNNs) suffer from very long training times, spanning from hours to weeks, limiting the productivity and experimentation of deep learning practitioners. As networks grow in size and complexity, training time can be reduced through low-precision data representations and computations. However, in doing so the final accuracy suffers due to the problem of vanishing gradients. Existing state-of-the-art methods combat this issue by means of a mixed-precision approach utilising two different precision levels, FP32 (32-bit floating-point) and FP16/FP8 (16-/8-bit floating-point), leveraging the hardware support of recent GPU architectures for FP16 operations to obtain performance gains. This work pushes the boundary of quantised training by employing a multilevel optimisation approach that utilises multiple precisions including low-precision fixed-point representations. The novel training strategy, MuPPET, combines the use of multiple number representation regimes together with a precision-switching mechanism that decides at run time the transition point between precision regimes. Overall, the proposed strategy tailors the training process to the hardware-level capabilities of the target hardware architecture and yields improvements in training time and energy efficiency compared to state-of-the-art approaches. Applying MuPPET on the training of AlexNet, ResNet18 and GoogLeNet on ImageNet (ILSVRC12) and targeting an NVIDIA Turing GPU, MuPPET achieves the same accuracy as standard full-precision training with training-time speedup of up to 1.84$\\times$ and an average speedup of 1.58$\\times$ across the networks.", "venue": "ICML", "authors": ["Aditya  Rajagopal", "Diederik A. Vink", "Stylianos I. Venieris", "Christos-Savvas  Bouganis"], "year": 2020, "n_citations": 7}
{"id": 6509006, "s2_id": "400ba0f7479067046a4705331fbb31c59e3994f8", "title": "Learning Object Manipulation Skills via Approximate State Estimation from Real Videos", "abstract": "Humans are adept at learning new tasks by watching a few instructional videos. On the other hand, robots that learn new actions either require a lot of effort through trial and error, or use expert demonstrations that are challenging to obtain. In this paper, we explore a method that facilitates learning object manipulation skills directly from videos. Leveraging recent advances in 2D visual recognition and differentiable rendering, we develop an optimization based method to estimate a coarse 3D state representation for the hand and the manipulated object(s) without requiring any supervision. We use these trajectories as dense rewards for an agent that learns to mimic them through reinforcement learning. We evaluate our method on simple single- and two-object actions from the Something-Something dataset. Our approach allows an agent to learn actions from single videos, while watching multiple demonstrations makes the policy more robust. We show that policies learned in a simulated environment can be easily transferred to a real robot.", "venue": "CoRL", "authors": ["Vladim'ir  Petr'ik", "Makarand  Tapaswi", "Ivan  Laptev", "Josef  Sivic"], "year": 2020, "n_citations": 6}
{"id": 6518833, "s2_id": "5154fbe5fba1c0b2dee6429d7a22879ae8c38e7a", "title": "Augmenting Decision Making via Interactive What-If Analysis", "abstract": "The fundamental goal of business data analysis is to improve business decisions using data. Business users such as sales, marketing, product, or operations managers often make decisions to achieve key performance indicator (KPI) goals such as increasing customer retention, decreasing cost, and increasing sales. To discover the relationship between data attributes hypothesized to be drivers and those corresponding to KPIs of interest, business users currently need to perform lengthy exploratory analyses, considering multitudes of combinations and scenarios, slicing, dicing, and transforming the data accordingly. For example, analyzing customer retention across quarters of the year or suggesting optimal media channels across strata of customers. However, the increasing complexity of datasets combined with the cognitive limitations of humans makes it challenging to carry over multiple hypotheses, even for simple datasets. Therefore mentally performing such analyses is hard. Existing commercial tools either provide partial solutions whose effectiveness remains unclear or fail to cater to business users. Here we argue for four functionalities that we believe are necessary to enable business users to interactively learn and reason about the relationships (functions) between sets of data attributes, facilitating data-driven decision making. We implement these functionalities in SYSTEMD, an interactive visual data analysis system enabling business users to experiment with the data by asking what-if questions. *Also with University of Maryland. \u2020Also with University of Amsterdam. We evaluate the system through three business use cases: marketing mix modeling analysis, customer retention analysis, and deal closing analysis, and report on feedback from multiple business users. Overall, business users find SYSTEMD intuitive and useful for quick testing and validation of their hypotheses around interested KPI as well as in making effective and fast data-driven decisions.", "venue": "ArXiv", "authors": ["Sneha  Gathani", "Madelon  Hulsebos", "James  Gale", "Peter J. Haas", "cCaugatay  Demiralp"], "year": 2021, "n_citations": 1}
{"id": 6521116, "s2_id": "6d5fa110410d84731ab1d944fd04f6898ef4a8c9", "title": "Bridging the Performance Gap between FGSM and PGD Adversarial Training", "abstract": "Deep learning achieves state-of-the-art performance in many tasks but exposes to the underlying vulnerability against adversarial examples. Across existing defense techniques, adversarial training with the projected gradient decent attack (adv.PGD) is considered as one of the most effective ways to achieve moderate adversarial robustness. However, adv.PGD requires too much training time since the projected gradient attack (PGD) takes multiple iterations to generate perturbations. On the other hand, adversarial training with the fast gradient sign method (adv.FGSM) takes much less training time since the fast gradient sign method (FGSM) takes one step to generate perturbations but fails to increase adversarial robustness. In this work, we extend adv.FGSM to make it achieve the adversarial robustness of adv.PGD. We demonstrate that the large curvature along FGSM perturbed direction leads to a large difference in performance of adversarial robustness between adv.FGSM and adv.PGD, and therefore propose combining adv.FGSM with a curvature regularization (adv.FGSMR) in order to bridge the performance gap between adv.FGSM and adv.PGD. The experiments show that adv.FGSMR has higher training efficiency than adv.PGD. In addition, it achieves comparable performance of adversarial robustness on MNIST dataset under white-box attack, and it achieves better performance than adv.PGD under white-box attack and effectively defends the transferable adversarial attack on CIFAR-10 dataset.", "venue": "ArXiv", "authors": ["Tianjin  Huang", "Vlado  Menkovski", "Yulong  Pei", "Mykola  Pechenizkiy"], "year": 2020, "n_citations": 4}
{"id": 6524349, "s2_id": "7d611bd97b812748b464ac8b2e6cdb3841d28464", "title": "Comparing Bayesian Models for Organ Contouring in Headand Neck Radiotherapy", "abstract": "Deep learning models for organ contouring in radiotherapy are poised for clinical usage, but currently, there exist few tools for automated quality assessment (QA) of the predicted contours. Using Bayesian models and their associated uncertainty, one can potentially automate the process of detecting inaccurate predictions. We investigate two Bayesian models for auto-contouring, DropOut and FlipOut, using a quantitative measure \u2013 expected calibration error (ECE) and a qualitative measure \u2013 region-based accuracy-vs-uncertainty (R-AvU) graphs. It is well understood that a model should have low ECE to be considered trustworthy. However, in a QA context, a model should also have high uncertainty in inaccurate regions and low uncertainty in accurate regions. Such behaviour could direct visual attention of expert users to potentially inaccurate regions, leading to a speed-up in the QA process. Using R-AvU graphs, we qualitatively compare the behaviour of different models in accurate and inaccurate regions. Experiments are conducted on the MICCAI2015 Head and Neck Segmentation Challenge and on the DeepMindTCIA CT dataset using three models: DropOut-DICE, DropoutCE (Cross Entropy) and FlipOut-CE. Quantitative results show that DropOut-DICE has the highest ECE, while Dropout-CE and FlipOut-CE have the lowest ECE. To better understand the difference between DropOut-CE and FlipOut-CE, we use the R-AvU graph which shows that FlipOut-CE has better uncertainty coverage in inaccurate regions than DropOut-CE. Such a combination of quantitative and qualitative metrics explores a new approach that helps to select which model can be deployed as a QA tool in clinical settings.", "venue": "ArXiv", "authors": ["Prerak  Mody", "Nicolas  Chaves-de-Plaza", "Klaus  Hildebrandt", "Rene van Egmond", "Huib de Ridder", "Marius  Staring"], "year": 2021, "n_citations": 0}
{"id": 6534875, "s2_id": "f16dbdc05e2e35bcdcf403e67dbd5a1923c614a7", "title": "\"Oddball SGD\": Novelty Driven Stochastic Gradient Descent for Training Deep Neural Networks", "abstract": "Stochastic Gradient Descent (SGD) is arguably the most popular of the machine learning methods applied to training deep neural networks (DNN) today. It has recently been demonstrated that SGD can be statistically biased so that certain elements of the training set are learned more rapidly than others. In this article, we place SGD into a feedback loop whereby the probability of selection is proportional to error magnitude. This provides a novelty-driven oddball SGD process that learns more rapidly than traditional SGD by prioritising those elements of the training set with the largest novelty (error). In our DNN example, oddball SGD trains some 50x faster than regular SGD.", "venue": "ArXiv", "authors": ["Andrew J. R. Simpson"], "year": 2015, "n_citations": 4}
{"id": 6536331, "s2_id": "ec00f47e1e106c3ef9597c51acf2a761222e47f7", "title": "A GAN-based Approach for Mitigating Inference Attacks in Smart Home Environment", "abstract": "The proliferation of smart, connected, always listening devices have introduced significant privacy risks to users in a smart home environment. Beyond the notable risk of eavesdropping, intruders can adopt machine learning techniques to infer sensitive information from audio recordings on these devices, resulting in a new dimension of privacy concerns and attack variables to smart home users. Techniques such as sound masking and microphone jamming have been effectively used to prevent eavesdroppers from listening in to private conversations. In this study, we explore the problem of adversaries spying on smart home users to infer sensitive information with the aid of machine learning techniques. We then analyze the role of randomness in the effectiveness of sound masking for mitigating sensitive information leakage. We propose a Generative Adversarial Network (GAN) based approach for privacy preservation in smart homes which generates random noise to distort the unwanted machine learning-based inference. Our experimental results demonstrate that GANs can be used to generate more effective sound masking noise signals which exhibit more randomness and effectively mitigate deep learning-based inference attacks while preserving the semantics of the audio samples.", "venue": "ArXiv", "authors": ["Olakunle  Ibitoye", "Ashraf  Matrawy", "M. Omair Shafiq"], "year": 2020, "n_citations": 0}
{"id": 6537004, "s2_id": "aa02403b713ff4dbd6636027ea0c693514e210fe", "title": "AdvCodeMix: Adversarial Attack on Code-Mixed Data", "abstract": "Research on adversarial attacks are becoming widely popular in the recent years. One of the unexplored areas where prior research is lacking is the effect of adversarial attacks on code-mixed data. Therefore, in the present work, we have explained the first generalized framework on text perturbation to attack code-mixed classification models in a black-box setting. We rely on various perturbation techniques that preserve the semantic structures of the sentences and also obscure the attacks from the perception of a human user. The present methodology leverages the importance of a token to decide where to attack by employing various perturbation strategies. We test our strategies on various sentiment classification models trained on Bengali-English and Hindi-English code-mixed datasets, and reduce their F1-scores by nearly 51% and 53% respectively, which can be further reduced if a larger number of tokens are perturbed in a given sentence.", "venue": "ArXiv", "authors": ["Sourya Dipta Das", "Ayan  Basak", "Soumil  Mandal", "Dipankar  Das"], "year": 2021, "n_citations": 0}
{"id": 6543843, "s2_id": "6fc82887d2ffc0e664657fac8c8605ca40fb20a2", "title": "Restricted Recurrent Neural Networks", "abstract": "Recurrent Neural Network (RNN) and its variations such as Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU), have become standard building blocks for learning online data of sequential nature in many research areas, including natural language processing and speech data analysis. In this paper, we present a new methodology to significantly reduce the number of parameters in RNNs while maintaining performance that is comparable or even better than classical RNNs. The new proposal, referred to as Restricted Recurrent Neural Network (RRNN), restricts the weight matrices corresponding to the input data and hidden states at each time step to share a large proportion of parameters. The new architecture can be regarded as a compression of its classical counterpart, but it does not require pre-training or sophisticated parameter fine-tuning, both of which are major issues in most existing compression techniques. Experiments on natural language modeling show that compared with its classical counterpart, the restricted recurrent architecture generally produces comparable results at about 50% compression rate. In particular, the Restricted LSTM can outperform classical RNN with even less number of parameters.", "venue": "2019 IEEE International Conference on Big Data (Big Data)", "authors": ["Enmao  Diao", "Jie  Ding", "Vahid  Tarokh"], "year": 2019, "n_citations": 7}
{"id": 6545843, "s2_id": "f74633a6971fcd4fa5499525c83eb8cd2f3864ac", "title": "Major Depressive Disorder Recognition and Cognitive Analysis Based on Multi-layer Brain Functional Connectivity Networks", "abstract": "On the increase of major depressive disorders (MDD), many researchers paid attention to their recognition and treatment. Existing MDD recognition algorithms always use a single time-frequency domain method, but the single time-frequency domain method is too simple and is not conducive to simulating the complex link relationship between brain functions. To solve this problem, this paper proposes a recognition method based on multi-layer brain functional connectivity networks (MBFCN) for major depressive disorder and conducts cognitive analysis. Cognitive analysis based on the proposed MBFCN finds that the AlphaBeta1 frequency band is the key sub-band for recognizing MDD. The connections between the right prefrontal lobe and the temporal lobe of the extremely depressed disorders (EDD) are deficient in the brain functional connectivity networks (BFCN) based on phase lag index (PLI). Furthermore, potential biomarkers by the significance analysis of depression features and PHQ-9 can be found.", "venue": "ArXiv", "authors": ["Xiaofang  Sun", "Xiangwei  Zheng", "Yonghui  Xu", "Lizhen  Cui", "Bin  Hu"], "year": 2021, "n_citations": 0}
{"id": 6548096, "s2_id": "e54dda76ad834db951ab3f6e97a0e6d2115e35a8", "title": "STORM+: Fully Adaptive SGD with Momentum for Nonconvex Optimization", "abstract": "In this work we investigate stochastic non-convex optimization problems where the objective is an expectation over smooth loss functions, and the goal is to find an approximate stationary point. The most popular approach to handling such problems is variance reduction techniques, which are also known to obtain tight convergence rates, matching the lower bounds in this case. Nevertheless, these techniques require a careful maintenance of anchor points in conjunction with appropriately selected \u201cmega-batchsizes\". This leads to a challenging hyperparameter tuning problem, that weakens their practicality. Recently, [Cutkosky and Orabona, 2019] have shown that one can employ recursive momentum in order to avoid the use of anchor points and large batchsizes, and still obtain the optimal rate for this setting. Yet, their method called STORM crucially relies on the knowledge of the smoothness, as well a bound on the gradient norms. In this work we propose STORM, a new method that is completely parameter-free, does not require large batch-sizes, and obtains the optimal O(1/T ) rate for finding an approximate stationary point. Our work builds on the STORM algorithm, in conjunction with a novel approach to adaptively set the learning rate and momentum parameters.", "venue": "ArXiv", "authors": ["Kfir Y. Levy", "Ali  Kavis", "Volkan  Cevher"], "year": 2021, "n_citations": 0}
{"id": 6553341, "s2_id": "f93a12884c60d46d906f447a7c8cff64e98de1b6", "title": "Gauss-Legendre Features for Gaussian Process Regression", "abstract": "Gaussian processes provide a powerful probabilistic kernel learning framework, which allows learning high quality nonparametric regression models via methods such as Gaussian process regression. Nevertheless, the learning phase of Gaussian process regression requires massive computations which are not realistic for large datasets. In this paper, we present a Gauss-Legendre quadrature based approach for scaling up Gaussian process regression via a low rank approximation of the kernel matrix. We utilize the structure of the low rank approximation to achieve effective hyperparameter learning, training and prediction. Our method is very much inspired by the well-known random Fourier features approach, which also builds low-rank approximations via numerical integration. However, our method is capable of generating high quality approximation to the kernel using an amount of features which is poly-logarithmic in the number of training points, while similar guarantees will require an amount that is at the very least linear in the number of training points when random Fourier features. Furthermore, the structure of the low-rank approximation that our method builds is subtly different from the one generated by random Fourier features, and this enables much more efficient hyperparameter learning. The utility of our method for learning with low-dimensional datasets is demonstrated using numerical experiments.", "venue": "ArXiv", "authors": ["Paz Fink Shustin", "Haim  Avron"], "year": 2021, "n_citations": 2}
{"id": 6558812, "s2_id": "cb0195d2ea9778e2b30145b5539de754b88d00f6", "title": "Adaptive Routing Between Capsules", "abstract": "Capsule network is the most recent exciting advancement in the deep learning field and represents positional information by stacking features into vectors. The dynamic routing algorithm is used in the capsule network, however, there are some disadvantages such as the inability to stack multiple layers and a large amount of computation. In this paper, we propose an adaptive routing algorithm that can solve the problems mentioned above. First, the low-layer capsules adaptively adjust their direction and length in the routing algorithm and removing the influence of the coupling coefficient on the gradient propagation, so that the network can work when stacked in multiple layers. Then, the iterative process of routing is simplified to reduce the amount of computation and we introduce the gradient coefficient $\\lambda$. Further, we tested the performance of our proposed adaptive routing algorithm on CIFAR10, Fashion-MNIST, SVHN and MNIST, while achieving better results than the dynamic routing algorithm.", "venue": "ArXiv", "authors": ["Qiang  Ren", "Shaohua  Shang", "Lianghua  He"], "year": 2019, "n_citations": 0}
{"id": 6561620, "s2_id": "4d4d3182732500085ec9e9724ac4f95fb0d48254", "title": "Information Directed Sampling for Sparse Linear Bandits", "abstract": "Stochastic sparse linear bandits offer a practical model for high-dimensional online decision-making problems and have a rich information-regret structure. In this work we explore the use of information-directed sampling (IDS), which naturally balances the information-regret trade-off. We develop a class of informationtheoretic Bayesian regret bounds that nearly match existing lower bounds on a variety of problem instances, demonstrating the adaptivity of IDS. To efficiently implement sparse IDS, we propose an empirical Bayesian approach for sparse posterior sampling using a spike-and-slab Gaussian-Laplace prior. Numerical results demonstrate significant regret reductions by sparse IDS relative to several baselines.", "venue": "ArXiv", "authors": ["Botao  Hao", "Tor  Lattimore", "Wei  Deng"], "year": 2021, "n_citations": 0}
{"id": 6580323, "s2_id": "0b43be098c486743f4a382cb9a01d3735073c750", "title": "Exploring the Efficacy of Transfer Learning in Mining Image-Based Software Artifacts", "abstract": "Transfer learning allows us to train deep architectures requiring a large number of learned parameters, even if the amount of available data is limited, by leveraging existing models previously trained for another task. Here we explore the applicability of transfer learning utilizing models pre-trained on non-software engineering data applied to the problem of classifying software UML diagrams. Our experimental results show training reacts positively to transfer learning as related to sample size, even though the pre-trained model was not exposed to training instances from the software domain. We contrast the transferred network with other networks to show its advantage on different sized training sets, which indicates that transfer learning is equally effective to custom deep architectures when large amounts of training data is not available.", "venue": "ArXiv", "authors": ["Natalie  Best", "Jordan  Ott", "Erik  Linstead"], "year": 2020, "n_citations": 6}
{"id": 6586324, "s2_id": "86f110b1b1b57f147fd948510007635fe97bc487", "title": "VICause: Simultaneous Missing Value Imputation and Causal Discovery with Groups", "abstract": "Missing values constitute an important challenge in realworld machine learning for both prediction and causal discovery tasks. However, existing imputation methods are agnostic to causality, while only few methods in traditional causal discovery can handle missing data in an efficient way. In this work we propose VICAUSE, a novel approach to simultaneously tackle missing value imputation and causal discovery efficiently with deep learning. Particularly, we propose a generative model with a structured latent space and a graph neural network-based architecture, scaling to large number of variables. Moreover, our method can discover relationships between groups of variables which is useful in many real-world applications. VICAUSE shows improved performance compared to popular and recent approaches in both missing value imputation and causal discovery.", "venue": "ArXiv", "authors": ["Pablo  Morales-Alvarez", "Angus  Lamb", "Simon  Woodhead", "Simon Peyton Jones", "Miltiadis  Allamanis", "Cheng  Zhang"], "year": 2021, "n_citations": 0}
{"id": 6588336, "s2_id": "c2ce95b6474e0e6597544f61c006cfbdac997cb4", "title": "Comparing Nonparametric Bayesian Tree Priors for Clonal Reconstruction of Tumors", "abstract": "Statistical machine learning methods, especially nonparametric Bayesian methods, have become increasingly popular to infer clonal population structure of tumors. Here we describe the treeCRP, an extension of the Chinese restaurant process (CRP), a popular construction used in nonparametric mixture models, to infer the phylogeny and genotype of major subclonal lineages represented in the population of cancer cells. We also propose new split-merge updates tailored to the subclonal reconstruction problem that improve the mixing time of Markov chains. In comparisons with the tree-structured stick breaking prior used in PhyloSub, we demonstrate superior mixing and running time using the treeCRP with our new split-merge procedures. We also show that given the same number of samples, TSSB and treeCRP have similar ability to recover the subclonal structure of a tumor\u2026", "venue": "Pacific Symposium on Biocomputing", "authors": ["Amit G. Deshwar", "Shankar  Vembu", "Quaid  Morris"], "year": 2015, "n_citations": 2}
{"id": 6601260, "s2_id": "9dc822d8c41d1091b3ae200fe5efa6f98bd4ecf3", "title": "Dual Principal Component Pursuit", "abstract": "We consider the problem of outlier rejection in single subspace learning. Classical approaches work directly with a low-dimensional representation of the subspace. Our approach works with a dual representation of the subspace and hence aims to find its orthogonal complement. We pose this problem as an l1-minimization problem on the sphere and show that, under certain conditions on the distribution of the data, any global minimizer of this non-convex problem gives a vector orthogonal to the subspace. Moreover, we show that such a vector can still be found by relaxing the non-convex problem with a sequence of linear programs. Experiments on synthetic and real data show that the proposed approach, which we call Dual Principal Component Pursuit (DPCP), outperforms state-of-the art methods, especially in the case of high-dimensional subspaces.", "venue": "2015 IEEE International Conference on Computer Vision Workshop (ICCVW)", "authors": ["Manolis C. Tsakiris", "Ren\u00e9  Vidal"], "year": 2015, "n_citations": 68}
{"id": 6601849, "s2_id": "8c802c7092cb24462e56c0a0fe0ef37b374ca267", "title": "Toward Compact Data from Big Data", "abstract": "Bigdata is a dataset of which size is beyond the ability of handling a valuable raw material that can be refined and distilled into valuable specific insights. Compact data is a method that optimizes the big dataset that gives best assets without handling complex bigdata. The compact dataset contains the maximum knowledge patterns at fine grained level for effective and personalized utilization of bigdata systems without big data. The compact data method is a tailor-made design which depends on problem situations. Various compact data techniques have been demonstrated into various data-driven research area in the paper.", "venue": "2020 15th International Conference for Internet Technology and Secured Transactions (ICITST)", "authors": ["Song-Kyoo  Kim"], "year": 2020, "n_citations": 0}
{"id": 6604633, "s2_id": "9669568093d22deedd4acf44d0463ce38ffd5f48", "title": "Causality and Generalizability: Identifiability and Learning Methods", "abstract": "This PhD thesis contains several contributions to the field of statistical causal modeling. Statistical causal models are statistical models embedded with causal assumptions that allow for the inference and reasoning about the behavior of stochastic systems affected by external manipulation (interventions). This thesis contributes to the research areas concerning the estimation of causal effects, causal structure learning, and distributionally robust (out-of-distribution generalizing) prediction methods. We present novel and consistent linear and non-linear causal effects estimators in instrumental variable settings that employ data-dependent mean squared prediction error regularization. Our proposed estimators show, in certain settings, mean squared error improvements compared to both canonical and state-of-the-art estimators. We show that recent research on distributionally robust prediction methods has connections to well-studied estimators from econometrics. This connection leads us to prove that general K-class estimators possess distributional robustness properties. We, furthermore, propose a general framework for distributional robustness with respect to intervention-induced distributions. In this framework, we derive sufficient conditions for the identifiability of distributionally robust prediction methods and present impossibility results that show the necessity of several of these conditions. We present a new structure learning method applicable in additive noise models with directed trees as causal graphs. We prove consistency in a vanishing identifiability setup and provide a method for testing substructure hypotheses with asymptotic family-wise error control that remains valid post-selection. Finally, we present heuristic ideas for learning summary graphs of nonlinear time-series models.", "venue": "ArXiv", "authors": ["Martin Emil Jakobsen"], "year": 2021, "n_citations": 0}
{"id": 6609903, "s2_id": "2c49a41f95faabf6d8a5050f3f04bfbc0d56e5a0", "title": "Artificial Neural Network and its Application Research Progress in Distillation", "abstract": "Artificial neural networks learn various rules and algorithms to form different ways of processing information, and have been widely used in various chemical processes. Among them, with the development of rectification technology, its production scale continues to expand, and its calculation requirements are also more stringent, because the artificial neural network has the advantages of self-learning, associative storage and high-speed search for optimized solutions, it can make high-precision simulation predictions for rectification operations, so it is widely used in the chemical field of rectification. This article gives a basic overview of artificial neural networks, and introduces the application research of artificial neural networks in distillation at home and abroad.", "venue": "ArXiv", "authors": ["Jing  Sun", "Qi  Tang"], "year": 2021, "n_citations": 0}
{"id": 6616791, "s2_id": "52d25a2c734848bf86b289eb2b2c40449c864756", "title": "Spring-Rod System Identification via Differentiable Physics Engine", "abstract": "We propose a novel differentiable physics engine for system identification of complex spring-rod assemblies. Unlike black-box data-driven methods for learning the evolution of a dynamical system \\emph{and} its parameters, we modularize the design of our engine using a discrete form of the governing equations of motion, similar to a traditional physics engine. We further reduce the dimension from 3D to 1D for each module, which allows efficient learning of system parameters using linear regression. The regression parameters correspond to physical quantities, such as spring stiffness or the mass of the rod, making the pipeline explainable. The approach significantly reduces the amount of training data required, and also avoids iterative identification of data sampling and model training. We compare the performance of the proposed engine with previous solutions, and demonstrate its efficacy on tensegrity systems, such as NASA's icosahedron.", "venue": "ArXiv", "authors": ["Kun  Wang", "Mridul  Aanjaneya", "Kostas  Bekris"], "year": 2020, "n_citations": 0}
{"id": 6624430, "s2_id": "5c072297547c7f012ddd687d381b04183973af98", "title": "Fairkit, Fairkit, on the Wall, Who's the Fairest of Them All? Supporting Data Scientists in Training Fair Models", "abstract": "Modern software relies heavily on data and machine learning, and affects decisions that shape our world. Unfortunately, recent studies have shown that because of biases in data, software systems frequently inject bias into their decisions, from producing better closed caption transcriptions of men\u2019s voices than of women\u2019s voices to overcharging people of color for financial loans. To address bias in machine learning, data scientists need tools that help them understand the trade-offs between model quality and fairness in their specific data domains. Toward that end, we present fairkit-learn, a toolkit for helping data scientists reason about and understand fairness. Fairkit-learn works with state-of-the-art machine learning tools and uses the same interfaces to ease adoption. It can evaluate thousands of models produced by multiple machine learning algorithms, hyperparameters, and data permutations, and compute and visualize a small Pareto-optimal set of models that describe the optimal trade-offs between fairness and quality. We evaluate fairkitlearn via a user study with 54 students, showing that students using fairkit-learn produce models that provide a better balance between fairness and quality than students using scikit-learn and IBM AI Fairness 360 toolkits. With fairkit-learn, users can select models that are up to 67% more fair and 10% more accurate than the models they are likely to train with scikit-learn.", "venue": "ArXiv", "authors": ["Brittany  Johnson", "Jesse  Bartola", "Rico  Angell", "Katherine  Keith", "Sam  Witty", "Stephen J. Giguere", "Yuriy  Brun"], "year": 2020, "n_citations": 6}
{"id": 6631986, "s2_id": "f35f9a967fea696f2522d395ceae0988a53ddeae", "title": "Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling", "abstract": "Recurrent neural networks (RNNs) have shown promising performance for language modeling. However, traditional training of RNNs using back-propagation through time often suffers from overfitting. One reason for this is that stochastic optimization (used for large training sets) does not provide good estimates of model uncertainty. This paper leverages recent advances in stochastic gradient Markov Chain Monte Carlo (also appropriate for large training sets) to learn weight uncertainty in RNNs. It yields a principled Bayesian learning algorithm, adding gradient noise during training (enhancing exploration of the model-parameter space) and model averaging when testing. Extensive experiments on various RNN models and across a broad range of applications demonstrate the superiority of the proposed approach relative to stochastic optimization.", "venue": "ACL", "authors": ["Zhe  Gan", "Chunyuan  Li", "Changyou  Chen", "Yunchen  Pu", "Qinliang  Su", "Lawrence  Carin"], "year": 2017, "n_citations": 32}
{"id": 6636519, "s2_id": "6180856d42b30e0e7cf4270448763e204c0dd125", "title": "Large-Margin Classification with Multiple Decision Rules", "abstract": "Binary classification is a common statistical learning problem in which a model is estimated on a set of covariates for some outcome indicating the membership of one of two classes. In the literature, there exists a distinction between hard and soft classification. In soft classification, the conditional class probability is modeled as a function of the covariates. In contrast, hard classification methods only target the optimal prediction boundary. While hard and soft classification methods have been studied extensively, not much work has been done to compare the actual tasks of hard and soft classification. In this paper we propose a spectrum of statistical learning problems which span the hard and soft classification tasks based on fitting multiple decision rules to the data. By doing so, we reveal a novel collection of learning tasks of increasing complexity. We study the problems using the framework of large-margin classifiers and a class of piecewise linear convex surrogates, for which we derive statistical properties and a corresponding sub-gradient descent algorithm. We conclude by applying our approach to simulation settings and a magnetic resonance imaging (MRI) dataset from the Alzheimer's Disease Neuroimaging Initiative (ADNI) study.", "venue": "Stat. Anal. Data Min.", "authors": ["Patrick K. Kimes", "D. Neil Hayes", "J. S. Marron", "Yufeng  Liu"], "year": 2016, "n_citations": 0}
{"id": 6643807, "s2_id": "afe5f47ad0e5b9ce71f816d981eb4b6a13ed189f", "title": "Discovering the Hidden Structure of Complex Dynamic Systems", "abstract": "Dynamic Bayesian networks provide a compact and natural representation for complex dynamic systems. However, in many cases, there is no expert available from whom a model can be elicited. Learning provides an alternative approach for constructing models of dynamic systems. In this paper, we address some of the crucial computational aspects of learning the structure of dynamic systems, particularly those where some relevant variables are partially observed or even entirely unknown. Our approach is based on the Structural Expectation Maximization (SEM) algorithm. The main computational cost of the SEM algorithm is the gathering of expected sufficient statistics. We propose a novel approximation scheme that allows these sufficient statistics to be computed efficiently. We also investigate the fundamental problem of discovering the existence of hidden variables without exhaustive and expensive search. Our approach is based on the observation that, in dynamic systems, ignoring a hidden variable typically results in a violation of the Markov property. Thus, our algorithm searches for such violations in the data, and introduces hidden variables to explain them. We provide empirical results showing that the algorithm is able to learn the dynamics of complex systems in a computationally tractable way.", "venue": "UAI", "authors": ["Xavier  Boyen", "Nir  Friedman", "Daphne  Koller"], "year": 1999, "n_citations": 82}
{"id": 6645245, "s2_id": "2df47e281f2070081e2b76566d4366fe375fabf1", "title": "Analytical Equations based Prediction Approach for PM2.5 using Artificial Neural Network", "abstract": "Particulate matter pollution is one of the deadliest types of air pollution worldwide due to its significant impacts on the global environment and human health. Particulate Matter (PM2.5) is one of the important particulate pollutants to measure the Air Quality Index (AQI). The conventional instruments used by the air quality monitoring stations to monitor PM2.5 are costly, bulkier, time-consuming, and power-hungry. Furthermore, due to limited data availability and non-scalability, these stations cannot provide high spatial and temporal resolution in real-time. To overcome the disadvantages of existing methodology this article presents analytical equations based prediction approach for PM2.5 using an Artificial Neural Network (ANN). Since the derived analytical equations for the prediction can be computed using a Wireless Sensor Node (WSN) or low-cost processing tool, it demonstrates the usefulness of the proposed approach. Moreover, the study related to correlation among the PM2.5 and other pollutants is performed to select the appropriate predictors. The large authenticate data set of Central Pollution Control Board (CPCB) online station, India is used for the proposed approach. The RMSE and coefficient of determination (R2) obtained for the proposed prediction approach using eight predictors are 1.7973 ug/m3 and 0.9986 respectively. While the proposed approach results show RMSE of 7.5372 ug/m3 and R2 of 0.9708 using three predictors. Therefore, the results demonstrate that the proposed approach is one of the promising approaches for monitoring PM2.5 without power-hungry gas sensors and bulkier analyzers.", "venue": "ArXiv", "authors": ["Jalpa  Shah", "Biswajit  Mishra"], "year": 2020, "n_citations": 4}
{"id": 6647169, "s2_id": "68a8ced8bdb7a813fc816db9bdba60c7fb9c3656", "title": "Neurons learn slower than they think", "abstract": "Recent studies revealed complex convergence dynamics in gradient-based methods, which has been little understood so far. Changing the step size to balance between high convergence rate and small generalization error may not be sufficient: maximizing the test accuracy usually requires a larger learning rate than minimizing the training loss. To explore the dynamic bounds of convergence rate, this study introduces differential capability into an optimization process, which measures whether the test accuracy increases as fast as a model approaches the decision boundary in a classification problem. The convergence analysis showed that: 1) a higher convergence rate leads to slower capability growth; 2) a lower convergence rate results in faster capability growth and decay; 3) regulating a convergence rate in either direction reduces differential capability.", "venue": "ArXiv", "authors": ["Ilona  Kulikovskikh"], "year": 2021, "n_citations": 0}
{"id": 6648984, "s2_id": "51d6da20f295735049c3218071dac771174267c3", "title": "FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes", "abstract": "When designing Convolutional Neural Networks (CNNs), one must select the size of the convolutional kernels before training. Recent works show CNNs benefit from different kernel sizes at different layers, but exploring all possible combinations is unfeasible in practice. A more efficient approach is to learn the kernel size during training. However, existing works that learn the kernel size have a limited bandwidth. These approaches scale kernels by dilation, and thus the detail they can describe is limited. In this work, we propose FlexConv, a novel convolutional operation with which high bandwidth convolutional kernels of learnable kernel size can be learned at a fixed parameter cost. FlexNets model long-term dependencies without the use of pooling, achieve state-of-the-art performance on several sequential datasets, outperform recent works with learned kernel sizes, and are competitive with much deeper ResNets on image benchmark datasets. Additionally, FlexNets can be deployed at higher resolutions than those seen during training. To avoid aliasing, we propose a novel kernel parameterization with which the frequency of the kernels can be analytically controlled. Our novel kernel parameterization shows higher descriptive power and faster convergence speed than existing parameterizations. This leads to important improvements in classification accuracy.", "venue": "ArXiv", "authors": ["David W. Romero", "Robert-Jan  Bruintjes", "Jakub M. Tomczak", "Erik J. Bekkers", "Mark  Hoogendoorn", "Jan C. van Gemert"], "year": 2021, "n_citations": 1}
{"id": 6652876, "s2_id": "7c1355e7b2a7035525151610c9d16f373814b754", "title": "Deep Learning for the Classification of Lung Nodules", "abstract": "Deep learning, as a promising new area of machine learning, has attracted a rapidly increasing attention in the field of medical imaging. Compared to the conventional machine learning methods, deep learning requires no hand-tuned feature extractor, and has shown a superior performance in many visual object recognition applications. In this study, we develop a deep convolutional neural network (CNN) and apply it to thoracic CT images for the classification of lung nodules. We present the CNN architecture and classification accuracy for the original images of lung nodules. In order to understand the features of lung nodules, we further construct new datasets, based on the combination of artificial geometric nodules and some transformations of the original images, as well as a stochastic nodule shape model. It is found that simplistic geometric nodules cannot capture the important features of lung nodules.", "venue": "ArXiv", "authors": ["He  Yang", "Hengyong  Yu", "Ge  Wang"], "year": 2016, "n_citations": 35}
{"id": 6661780, "s2_id": "59909bcec667cc281e6f2637c77d36945ae7a70a", "title": "A generalization of the symmetrical and optimal probability-to-possibility transformations", "abstract": "Possibility and probability theories are alternative and complementary ways to deal with uncertainty, which has motivated over the last years an interest for the study of ways to transform probability distributions into possibility distributions and conversely. This paper studies the advantages and shortcomings of two well-known discrete probability to possibility transformations: the optimal transformation and the symmetrical transformation, and presents a novel parametric family of probability to possibility transformations which generalizes them and alleviate their shortcomings, showing a big potential for practical application. The paper also introduces a novel fuzzy measure of specificity for probability distributions based on the concept of fuzzy subsethood and presents a empirical validation of the generalized transformation usefulness applying it to the text authorship attribution problem.", "venue": "ArXiv", "authors": ["Esteve del Acebo", "Yousef  Alizadeh-Q", "Sayyed Ali Hossayni"], "year": 2020, "n_citations": 0}
{"id": 6662980, "s2_id": "d2ff747701f3a44cd6b2d4fafcdc14b37c5a2e89", "title": "An extended physics informed neural network for preliminary analysis of parametric optimal control problems", "abstract": "In this work we propose an extension of physics informed supervised learning strategies to parametric partial differential equations. Indeed, even if the latter are indisputably useful in many applications, they can be computationally expensive most of all in a real-time and many-query setting. Thus, our main goal is to provide a physics informed learning paradigm to simulate parametrized phenomena in a small amount of time. The physics information will be exploited in many ways, in the loss function (standard physics informed neural networks), as an augmented input (extra feature employment) and as a guideline to build an effective structure for the neural network (physics informed architecture). These three aspects, combined together, will lead to a faster training phase and to a more accurate parametric prediction. The methodology has been tested for several equations and also in an optimal control framework.", "venue": "ArXiv", "authors": ["Nicola  Demo", "Maria  Strazzullo", "Gianluigi  Rozza"], "year": 2021, "n_citations": 1}
{"id": 6681279, "s2_id": "55b8654ab4c3e833a4005871b04c5d7ba2ab2189", "title": "Robust Spectral Inference for Joint Stochastic Matrix Factorization", "abstract": "Spectral inference provides fast algorithms and provable optimality for latent topic analysis. But for real data these algorithms require additional ad-hoc heuristics, and even then often produce unusable results. We explain this poor performance by casting the problem of topic inference in the framework of Joint Stochastic Matrix Factorization (JSMF) and showing that previous methods violate the theoretical conditions necessary for a good solution to exist. We then propose a novel rectification method that learns high quality topics and their interactions even on small, noisy data. This method achieves results comparable to probabilistic techniques in several domains while maintaining scalability and provable optimality.", "venue": "NIPS", "authors": ["Moontae  Lee", "David  Bindel", "David M. Mimno"], "year": 2015, "n_citations": 11}
{"id": 6688658, "s2_id": "28b14000bc8c91179a02870b65aec3b31d78927d", "title": "Linearly Constrained Neural Networks", "abstract": "We present an approach to designing neural network based models that will explicitly satisfy known linear operator constraints. To achieve this, the target function is modelled as a linear transformation of an underlying function. This transformation is chosen such that any prediction of the target function is guaranteed to satisfy the constraints. The approach is demonstrated on both simulated and real-data examples.", "venue": "ArXiv", "authors": ["Johannes N. Hendriks", "Carl  Jidling", "Adrian  Wills", "Thomas B. Sch\u00f6n"], "year": 2020, "n_citations": 5}
{"id": 6692330, "s2_id": "bebf26ae4def2c8e27730cf0173ceb3fdf4fda62", "title": "Targeting solutions in Bayesian multi-objective optimization: sequential and batch versions", "abstract": "Multi-objective optimization aims at finding trade-off solutions to conflicting objectives. These constitute the Pareto optimal set. In the context of expensive-to-evaluate functions, it is impossible and often non-informative to look for the entire set. As an end-user would typically prefer a certain part of the objective space, we modify the Bayesian multi-objective optimization algorithm which uses Gaussian Processes and works by maximizing the Expected Hypervolume Improvement, to focus the search in the preferred region. The cumulated effects of the Gaussian Processes and the targeting strategy lead to a particularly efficient convergence to the desired part of the Pareto set. To take advantage of parallel computing, a multi-point extension of the targeting criterion is proposed and analyzed.", "venue": "Annals of Mathematics and Artificial Intelligence", "authors": ["David  Gaudrie", "Rodolphe  Le Riche", "Victor  Picheny", "Beno\u00eet  Enaux", "Vincent  Herbert"], "year": 2019, "n_citations": 13}
{"id": 6693563, "s2_id": "8c6f79ee88cb07e47497bde91910f00dec43d591", "title": "Generalizing Psychological Similarity Spaces to Unseen Stimuli", "abstract": "The cognitive framework of conceptual spaces proposes to represent concepts as regions in psychological similarity spaces. These similarity spaces are typically obtained through multidimensional scaling (MDS), which converts human dissimilarity ratings for a fixed set of stimuli into a spatial representation. One can distinguish metric MDS (which assumes that the dissimilarity ratings are interval or ratio scaled) from nonmetric MDS (which only assumes an ordinal scale). In our first study, we show that despite its additional assumptions, metric MDS does not necessarily yield better solutions than nonmetric MDS. In this chapter, we furthermore propose to learn a mapping from raw stimuli into the similarity space using artificial neural networks (ANNs) in order to generalize the similarity space to unseen inputs. In our second study, we show that a linear regression from the activation vectors of a convolutional ANN to similarity spaces obtained by MDS can be successful and that the results are sensitive to the number of dimensions of the similarity space.", "venue": "ArXiv", "authors": ["Lucas  Bechberger", "Kai-Uwe  K\u00fchnberger"], "year": 2019, "n_citations": 3}