{"id": 618999, "s2_id": "e3cff8b9d7ae95e7211383a0b10efe5991762546", "title": "Decentralized Cooperative Reinforcement Learning with Hierarchical Information Structure", "abstract": "Multi-agent reinforcement learning (MARL) problems are challenging due to information asymmetry. To overcome this challenge, existing methods often require high level of coordination or communication between the agents. We consider two-agent multi-armed bandits (MABs) and Markov decision processes (MDPs) with a hierarchical information structure arising in applications, which we exploit to propose simpler and more efficient algorithms that require no coordination or communication. In the structure, in each step the \u201cleader\u201d chooses her action first, and then the \u201cfollower\u201d decides his action after observing the leader\u2019s action. The two agents observe the same reward (and the same state transition in the MDP setting) that depends on their joint action. For the bandit setting, we propose a hierarchical bandit algorithm that achieves a near-optimal gap-independent regret of \u00d5( \u221a ABT ) and a near-optimal gap-dependent regret of O(log(T )), where A and B are the numbers of actions of the leader and the follower, respectively, and T is the number of steps. We further extend to the case of multiple followers and the case with a deep hierarchy, where we both obtain near-optimal regret bounds. For the MDP setting, we obtain \u00d5( \u221a HSABT ) regret, where H is the number of steps per episode, S is the number of states, T is the number of episodes. This matches the existing lower bound in terms of A,B, and T .", "venue": "ArXiv", "authors": ["Hsu  Kao", "Chen-Yu  Wei", "Vijay  Subramanian"], "year": 2021, "n_citations": 0}
{"id": 1762624, "s2_id": "083afaf8c8eb4d3f61a884221b340c3436c4bc13", "title": "Beyond human-level accuracy: computational challenges in deep learning", "abstract": "Deep learning (DL) research yields accuracy and product improvements from both model architecture changes and scale: larger data sets and models, and more computation. For hardware design, it is difficult to predict DL model changes. However, recent prior work shows that as dataset sizes grow, DL model accuracy and model size grow predictably. This paper leverages the prior work to project the dataset and model size growth required to advance DL accuracy beyond human-level, to frontier targets defined by machine learning experts. Datasets will need to grow 33--971\u00d7, while models will need to grow 6.6--456\u00d7 to achieve target accuracies. We further characterize and project the computational requirements to train these applications at scale. Our characterization reveals an important segmentation of DL training challenges for recurrent neural networks (RNNs) that contrasts with prior studies of deep convolutional networks. RNNs will have comparatively moderate operational intensities and very large memory footprint requirements. In contrast to emerging accelerator designs, large-scale RNN training characteristics suggest designs with significantly larger memory capacity and on-chip caches.", "venue": "PPoPP", "authors": ["Joel  Hestness", "Newsha  Ardalani", "Gregory Frederick Diamos"], "year": 2019, "n_citations": 27}